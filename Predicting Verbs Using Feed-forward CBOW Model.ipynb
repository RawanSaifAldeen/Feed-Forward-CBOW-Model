{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import justext\n",
    "import ftfy\n",
    "import re\n",
    "import sys\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import gensim.downloader as api\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random\n",
    "import torch\n",
    "from torch import nn , optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split , KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the needed functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grapping text from the text files and building the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_bbc_folder(category , corpus , lemmatize = False):\n",
    "    '''\n",
    "    Given a category name and a corpus class instance, the text files are read and sentences are extracted and then passed to\n",
    "    the corpus for preprocessing, tokenization and saving vocabulary.\n",
    "    '''\n",
    "    folder = \"bbc/\" + category\n",
    "    textfiles = [join(folder, f) for f in listdir(folder) if isfile(join(folder, f)) and f.endswith(\".txt\")]\n",
    "    for tf in textfiles:\n",
    "        with open(tf, encoding='utf-8') as f:\n",
    "            try:\n",
    "                lines = f.readlines()\n",
    "            except:\n",
    "                print(tf , ' had a problem')\n",
    "            for line in lines:\n",
    "                sentences = line.split('.') # saperating sentences by fullstops\n",
    "                corpus.add_to_corpus(sentences, lemmatize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The corpus class and helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To convert nltk's pos tags to wordnet pos tags\n",
    "def get_wordnet_pos(nltk_pos):\n",
    "    if nltk_pos.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_pos.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_pos.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_pos.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return 'n'\n",
    "\n",
    "#-----------------------------------\n",
    "\n",
    "def preprocess(text):\n",
    "    numbers = re.compile(r'[\\w|\\.\\_,-]*\\d+[\\w|-]*')\n",
    "    cleaned_text = numbers.sub(\"\", text) # removing numbers\n",
    "    fixed_text = ftfy.fix_text(cleaned_text) # fixing the text\n",
    "    return fixed_text\n",
    "    \n",
    "def tokenise(text):\n",
    "    tokenise_re = re.compile(r\"[-\\w]+|\\'[a-z]*\") # capturing words and any apostrophes followed be letters\n",
    "    tokens = tokenise_re.findall(text)\n",
    "    return tokens\n",
    "\n",
    "#-----------------------------------\n",
    "    \n",
    "class Corpus:\n",
    "    def __init__(self, meta={}):\n",
    "        self.meta = meta\n",
    "        self.verbs_fql = Counter()\n",
    "        self.vocabs_fql = Counter()\n",
    "        self.rare_verbs = []\n",
    "        self.verbs_to_learn = []\n",
    "        self.rare_vocabs = []\n",
    "        self.vocabs_to_learn = []\n",
    "        self._lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        \n",
    "    def add_to_corpus(self, sentences , lemmatize):\n",
    "        '''\n",
    "        Given a set of sentences, each sentence is preprocessed, tokenized then POS tagged.\n",
    "        Each word in the sentence is then checked:\n",
    "            The word is added to the input vocabulary \"vocabs\" if the word is not a stop word..\n",
    "            The word is added to the output vocabulary \"verbs\" if the POS tag of that word starts with \"V\"\n",
    "        When lemmatize = True; the words are stemmed before being added to the corpus.\n",
    "        '''\n",
    "        for sent in sentences:\n",
    "            p_sent = preprocess(sent)\n",
    "            tokens = tokenise(p_sent)\n",
    "            pos_tagged = nltk.pos_tag(tokens)\n",
    "            \n",
    "            for ps in pos_tagged:\n",
    "                \n",
    "                if lemmatize:\n",
    "                    lemmatized_token = self._lemmatizer.lemmatize(ps[0], pos = get_wordnet_pos(ps[1]))\n",
    "                    word = lemmatized_token.lower()\n",
    "                else:\n",
    "                    word = ps[0].lower()\n",
    "                    \n",
    "                if word not in stopwords.words('english'):\n",
    "                    self.vocabs_fql.update([word])\n",
    "                    if (ps[1].startswith('V')) and (not ps[0].startswith('\\'')): # The POS tagger sometimes defines 's as a verb\n",
    "                        self.verbs_fql.update([word])\n",
    "                    \n",
    "    def get_verbs_to_learn(self):\n",
    "        '''\n",
    "        Returns a list of distinct verbs that occured in the data at least 3 times\n",
    "        '''\n",
    "        if len(self.verbs_to_learn) == 0: # if the list wasn't made yet \n",
    "            for verb in self.verbs_fql.items():\n",
    "                if verb[1] < 3:\n",
    "                    self.rare_verbs.append(verb[0]) # if it occured less than 3 times, add it to the rare_verbs list\n",
    "                else:\n",
    "                    self.verbs_to_learn.append(verb[0])\n",
    "        return self.verbs_to_learn\n",
    "    \n",
    "    def get_vocabs_to_learn(self):\n",
    "        '''\n",
    "        Returns a list of distinct vocabulary words that occured in the data at least 3 times\n",
    "        '''\n",
    "        if len(self.vocabs_to_learn) == 0:\n",
    "            for vocab in self.vocabs_fql.items():\n",
    "                if vocab[1] < 3:\n",
    "                    self.rare_vocabs.append(vocab[0]) # if it occured less than 3 times, add it to the rare_verbs list\n",
    "                else:\n",
    "                    self.vocabs_to_learn.append(vocab[0])\n",
    "        return self.vocabs_to_learn\n",
    "                \n",
    "    def get_vocabs_list(self):\n",
    "        '''\n",
    "        Returns a list of all the vocabulary captured from the text\n",
    "        '''\n",
    "        return list(self.vocabs_fql.keys())\n",
    "    \n",
    "    def get_vocab_index(self , word):\n",
    "        '''\n",
    "        Given a word (or a list of words), it returns the index of that word from the vocabulary corpus\n",
    "        '''\n",
    "        if type(word) == list:\n",
    "            indexes = []\n",
    "            for w in word:\n",
    "                indexes.append(self.get_vocab_index(w))\n",
    "            return indexes\n",
    "        return self.get_vocabs_to_learn().index(word)\n",
    "    \n",
    "    def get_vocab_from_index(self, index):\n",
    "        '''\n",
    "        Given an index (or a list of indexes), it returns the word that correspond to that index from the vocabulary corpus\n",
    "        '''\n",
    "        if type(index) == list:\n",
    "            words = []\n",
    "            for i in index:\n",
    "                words.append(self.get_vocab_from_index(i))\n",
    "            return words\n",
    "        return self.get_vocabs_to_learn()[index]\n",
    "    \n",
    "    def get_verbs_list(self):\n",
    "        '''\n",
    "        Returns a list of all the verbs captured from the text\n",
    "        '''\n",
    "        return list(self.verbs_fql.keys())\n",
    "    \n",
    "    def get_verb_index(self , word):\n",
    "        '''\n",
    "        Given a word (or a list of words), it returns the index of that word from the verbs corpus\n",
    "        '''\n",
    "        if type(word) == list:\n",
    "            indexes = []\n",
    "            for w in word:\n",
    "                indexes.append(self.get_verb_index(w))\n",
    "            return indexes\n",
    "        return self.get_verbs_to_learn().index(word)\n",
    "    \n",
    "    def get_verb_from_index(self, index):\n",
    "        '''\n",
    "        Given an index (or a list of indexes), it returns the verb that correspond to that index from the verbs corpus\n",
    "        '''\n",
    "        if type(index) == list:\n",
    "            words = []\n",
    "            for i in index:\n",
    "                words.append(self.get_verb_from_index(i))\n",
    "            return words\n",
    "        return self.get_verbs_to_learn()[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing the sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sentences(category, corpus, window=3, lemmatize = False):\n",
    "    '''\n",
    "    Yields a list of words extracted from the sentences in the text file given the words in the vocabulary corpus.\n",
    "    A sliding window is used to obtain the words by sliding it across each sentence to capture the words within that window and return them.\n",
    "    '''\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    folder = \"bbc/\" + category\n",
    "    textfiles = [join(folder, f) for f in listdir(folder) if isfile(join(folder, f)) and f.endswith(\".txt\")]\n",
    "    \n",
    "    for tf in textfiles:\n",
    "        with open(tf, encoding='utf-8') as f:\n",
    "            try:\n",
    "                lines = f.readlines()\n",
    "            except:\n",
    "                print(tf , ' had a problem')\n",
    "                continue\n",
    "                \n",
    "            for line in lines:\n",
    "                sentences = line.split('.')\n",
    "                for sent in sentences:\n",
    "                    sentence_words = []\n",
    "                    if len(sent.split()) > window: # only consider the sentece if it has length greater than the size of the window\n",
    "                        \n",
    "                        p_sent = preprocess(sent.lower())\n",
    "                        tokens = tokenise(p_sent)\n",
    "                        pos_tagged = nltk.pos_tag(tokens)\n",
    "                        for ps in pos_tagged:\n",
    "                            if lemmatize:\n",
    "                                lemmatized_token = lemmatizer.lemmatize(ps[0], pos = get_wordnet_pos(ps[1]))\n",
    "                                word = lemmatized_token.lower()\n",
    "                            else:\n",
    "                                word = ps[0].lower()\n",
    "                                \n",
    "                            if word in corpus.get_vocabs_to_learn(): # only add words that are known to our vocabulary corpus\n",
    "                                sentence_words.append(word)\n",
    "                                \n",
    "                    else: continue\n",
    "                                \n",
    "                    length = len(sentence_words)\n",
    "                    # The sliding window:\n",
    "                    for i in range(length):\n",
    "                        if int(np.around((i+1)*window - i*(window-1))) <= length :\n",
    "                            yield sentence_words[i : int((i+1)*window - i*(window-1))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the dataset of sentences and target verbs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Build_Dataset(category, corpus, window = 3 , one_hot = False , lemmatize = False):\n",
    "    '''\n",
    "    Constructs the dataset as X, y\n",
    "    It uses the build_sentences function to get one [X,y] pair at a time.\n",
    "    X can be either a one-hot encoded sentence or a list of word indexes.\n",
    "    '''\n",
    "    x = []\n",
    "    y = []\n",
    "    for cat in category:\n",
    "        for sent_words in build_sentences(cat, corpus, window, lemmatize):\n",
    "            # get the verbs in the obtained filtered sentense that exist in the verbs corpus\n",
    "            verbs = list(set(sent_words).intersection(set(corpus.get_verbs_to_learn())))\n",
    "            \n",
    "            if len(verbs) > 0: # make sure that we at least have one verb in the sentence (the filtered sentence => context words)\n",
    "                target = random.choice(verbs) # to ensure that we choose one verb randomly when multiple verbs are captured by the window\n",
    "                y.append(corpus.get_verb_index(target))\n",
    "                sent_words.remove(target) # remove it before adding the words to the input variable (the input context words)\n",
    "                \n",
    "                sent_indxs = corpus.get_vocab_index(sent_words)\n",
    "                \n",
    "                if not one_hot:\n",
    "                    x.append(sent_indxs)\n",
    "                else: # make the context encoded vector by adding the one-hot encodings of the words\n",
    "                    x_ = np.zeros(len(corpus.get_vocabs_to_learn()))\n",
    "                    for inx in sent_indxs:\n",
    "                        x_[inx] += 1 \n",
    "                    x.append(x_)\n",
    "                    \n",
    "    return np.array(x, dtype = np.float32) , np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grapping batches of data for the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(x ,y ,batch_size):\n",
    "    '''\n",
    "    Given the data as x and y, it yields batches of the data of size = batch_size.\n",
    "    x and y are returned as torch tensors\n",
    "    '''\n",
    "    for i in range(int(np.floor(len(x)/batch_size))):\n",
    "            \n",
    "        batch_x = x[i*batch_size:(i+1)*batch_size]\n",
    "        batch_y = y[i*batch_size:(i+1)*batch_size]\n",
    "        \n",
    "        yield torch.tensor(batch_x) , torch.tensor(batch_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The CBOW model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "    '''\n",
    "    The continous-bag-of-words model, made of 2 fully connected layers with a dropout layer in between followed by a log-softmax activation function.\n",
    "    '''\n",
    "    def __init__(self, vocab_size, hidden_dim, verbs_size):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.linear1 = nn.Linear(vocab_size, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, verbs_size)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        out = self.linear1(inputs)\n",
    "        out = self.dropout(out)\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The training function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_model(model, lr, batch_size, n_epochs, file_name, x_train, y_train, x_valid, y_valid):\n",
    "    '''\n",
    "    Given the model, this function sets up the loss criterion and the optimizer used to train the model, then trains and validates the model.\n",
    "    In each epoch, the model is trained using the training set and evaluated using the validation set, the model parameters are saved whenever a lower validation loss is reached.\n",
    "    '''\n",
    "\n",
    "    criterion = nn.NLLLoss() # setting the loss function that allows the error to be packprobagated\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr) # the model optimizer\n",
    "    \n",
    "    # to keep track of the losses\n",
    "    valid_loss_min = np.Inf\n",
    "    train_losses, valid_losses = [], []\n",
    "\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        # training the model #\n",
    "        model.train() # to keep track of the operations and save the gradients\n",
    "        for sentences, words in get_batch(x_train , y_train , batch_size):\n",
    "            sentences, words = sentences.cuda(), words.cuda() # move the data to GPU\n",
    "            optimizer.zero_grad() # clear the gradients\n",
    "            output = model(sentences.float()) # pass the data to the model and get the output\n",
    "            loss = criterion(output, words.long()) # measure the loss\n",
    "            loss.backward() # backpropagate the loss and calculate the gradients\n",
    "            optimizer.step() # update the model parameters\n",
    "            train_loss += loss.item()*batch_size # add the obtained training loss\n",
    "        del sentences, words, output\n",
    "\n",
    "        # validating the model #\n",
    "        model.eval() # to prevent keeping track of the operation since the gradients are not needed\n",
    "        for sentences, words in get_batch(x_valid , y_valid , batch_size):\n",
    "            sentences, words = sentences.cuda(), words.cuda()  # move the data to GPU\n",
    "            output = model(sentences.float()) # pass the data to the model and get the output\n",
    "            loss = criterion(output, words.long()) # measure the loss\n",
    "            valid_loss += loss.item()*batch_size # add the obtained validation loss\n",
    "        del sentences, words, output\n",
    "\n",
    "        # normalizing the losses and appending them to their respective lists\n",
    "        train_loss = train_loss/len(x_train)\n",
    "        valid_loss = valid_loss/len(x_valid)\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch, train_loss, valid_loss))\n",
    "        \n",
    "        # saving the model if a lower validation loss is obtained\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.5f} --> {:.5f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n",
    "            torch.save(model.state_dict(), file_name)\n",
    "            valid_loss_min = valid_loss\n",
    "            \n",
    "    return train_losses, valid_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The testing function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test_model(model, x_test, y_test, batch_size):\n",
    "    '''\n",
    "    Using the testing set to evaluate predictions of the model by measuring the fration of times the true varb appeared in the top 5 and top 10 probabilites.\n",
    "    '''\n",
    "    model.eval()\n",
    "    it=0 # iteration counter\n",
    "    predicted_intop5 = 0\n",
    "    predicted_intop10 = 0\n",
    "\n",
    "    for sentences, words in get_batch(x_test, y_test, batch_size):\n",
    "        it+=1\n",
    "        output = model(sentences.cuda().float())\n",
    "        ps = torch.exp(output).cpu() # to cancel the natural log of the outputs and get the probabilities\n",
    "        top_p, top_class = ps.topk(10, dim=1) # to obtain the top 10 probabilities and classes\n",
    "\n",
    "        for word, preds in zip(words,top_class):\n",
    "            # counting the number of times the target word appeared in the top 5 and top 10 predicted classes\n",
    "            if word in preds:\n",
    "                predicted_intop10 +=1\n",
    "            if word in preds[:5]:\n",
    "                predicted_intop5 +=1\n",
    "                \n",
    "    # getting the fraction of those measures out of the number of instances (batch_size*it)\n",
    "    predicted_intop10_fraction = predicted_intop10/(batch_size*it)\n",
    "    predicted_intop5_fraction = predicted_intop5/(batch_size*it)\n",
    "    \n",
    "    return predicted_intop5_fraction, predicted_intop10_fraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The K-fold cross validtion function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_fold_Cross_validate(K , x , y , corpus, lr, batch_size, n_epochs , file_name, random_state):\n",
    "    '''\n",
    "    Performing K-fold cross validation given the dataset as X and y.\n",
    "    '''\n",
    "    \n",
    "    training_losses, validation_losses, predicted_intop5, predicted_intop10 = [] , [] , [] , []\n",
    "    \n",
    "    kf = KFold(n_splits=K, random_state=random_state, shuffle=True) # the K-fold splitter\n",
    "    \n",
    "    for train_index, test_index in kf.split(x):\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        # Splitting the training set to train and valid sets\n",
    "        x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.1, random_state=123)\n",
    "        \n",
    "        # Setting up the model\n",
    "        vocab_size = len(corpus.get_vocabs_to_learn())\n",
    "        verbs_size = len(corpus.get_verbs_to_learn())\n",
    "        hidden_dim = 500\n",
    "\n",
    "        model = CBOW(vocab_size, hidden_dim, verbs_size)\n",
    "        model.cuda()\n",
    "        \n",
    "        # Train the model\n",
    "        train_loss, valid_loss = Train_model(model, lr, batch_size, n_epochs, file_name, x_train, y_train, x_valid, y_valid)\n",
    "        model.load_state_dict(torch.load(file_name)) # load the saved version of the model\n",
    "        # Test the model\n",
    "        predicted_intop5_fraction, predicted_intop10_fraction = Test_model(model, x_test, y_test, batch_size)\n",
    "        \n",
    "        # Append the recorded measures to their respective lists\n",
    "        training_losses.append(train_loss)\n",
    "        validation_losses.append(valid_loss)\n",
    "        predicted_intop5.append(predicted_intop5_fraction)\n",
    "        predicted_intop10.append(predicted_intop10_fraction)\n",
    "        \n",
    "    return training_losses, validation_losses, predicted_intop5, predicted_intop10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Predicting :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Obtaining prediction results when learning the verbs in business articles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'business'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting:...-> Lemmatize = False , window = 3 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.658982 \tValidation Loss: 5.639777\n",
      "Validation loss decreased (inf --> 5.63978).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.157184 \tValidation Loss: 5.550756\n",
      "Validation loss decreased (5.63978 --> 5.55076).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.965014 \tValidation Loss: 5.427280\n",
      "Validation loss decreased (5.55076 --> 5.42728).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.676569 \tValidation Loss: 5.250045\n",
      "Validation loss decreased (5.42728 --> 5.25004).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.275452 \tValidation Loss: 5.048991\n",
      "Validation loss decreased (5.25004 --> 5.04899).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.793271 \tValidation Loss: 4.853325\n",
      "Validation loss decreased (5.04899 --> 4.85333).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.282009 \tValidation Loss: 4.680234\n",
      "Validation loss decreased (4.85333 --> 4.68023).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.784696 \tValidation Loss: 4.541676\n",
      "Validation loss decreased (4.68023 --> 4.54168).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.335006 \tValidation Loss: 4.440100\n",
      "Validation loss decreased (4.54168 --> 4.44010).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.948710 \tValidation Loss: 4.370829\n",
      "Validation loss decreased (4.44010 --> 4.37083).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.623990 \tValidation Loss: 4.328509\n",
      "Validation loss decreased (4.37083 --> 4.32851).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.361354 \tValidation Loss: 4.306397\n",
      "Validation loss decreased (4.32851 --> 4.30640).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.146881 \tValidation Loss: 4.298850\n",
      "Validation loss decreased (4.30640 --> 4.29885).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.975837 \tValidation Loss: 4.302058\n",
      "Epoch: 15 \tTraining Loss: 1.835023 \tValidation Loss: 4.313747\n",
      "Epoch: 16 \tTraining Loss: 1.719002 \tValidation Loss: 4.332027\n",
      "Epoch: 17 \tTraining Loss: 1.626617 \tValidation Loss: 4.358509\n",
      "Epoch: 18 \tTraining Loss: 1.547302 \tValidation Loss: 4.389005\n",
      "Epoch: 19 \tTraining Loss: 1.482238 \tValidation Loss: 4.421018\n",
      "Epoch: 20 \tTraining Loss: 1.426656 \tValidation Loss: 4.455500\n",
      "Epoch: 1 \tTraining Loss: 6.664158 \tValidation Loss: 5.618393\n",
      "Validation loss decreased (inf --> 5.61839).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.159581 \tValidation Loss: 5.533567\n",
      "Validation loss decreased (5.61839 --> 5.53357).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.965968 \tValidation Loss: 5.412297\n",
      "Validation loss decreased (5.53357 --> 5.41230).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.673827 \tValidation Loss: 5.236725\n",
      "Validation loss decreased (5.41230 --> 5.23672).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.273133 \tValidation Loss: 5.035256\n",
      "Validation loss decreased (5.23672 --> 5.03526).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.791355 \tValidation Loss: 4.839256\n",
      "Validation loss decreased (5.03526 --> 4.83926).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.282712 \tValidation Loss: 4.670649\n",
      "Validation loss decreased (4.83926 --> 4.67065).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.787601 \tValidation Loss: 4.538760\n",
      "Validation loss decreased (4.67065 --> 4.53876).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.335095 \tValidation Loss: 4.443703\n",
      "Validation loss decreased (4.53876 --> 4.44370).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.947185 \tValidation Loss: 4.378614\n",
      "Validation loss decreased (4.44370 --> 4.37861).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.624681 \tValidation Loss: 4.338151\n",
      "Validation loss decreased (4.37861 --> 4.33815).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.362092 \tValidation Loss: 4.316821\n",
      "Validation loss decreased (4.33815 --> 4.31682).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.147646 \tValidation Loss: 4.311063\n",
      "Validation loss decreased (4.31682 --> 4.31106).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.976749 \tValidation Loss: 4.315056\n",
      "Epoch: 15 \tTraining Loss: 1.838474 \tValidation Loss: 4.328833\n",
      "Epoch: 16 \tTraining Loss: 1.721909 \tValidation Loss: 4.350867\n",
      "Epoch: 17 \tTraining Loss: 1.631004 \tValidation Loss: 4.377017\n",
      "Epoch: 18 \tTraining Loss: 1.553296 \tValidation Loss: 4.404441\n",
      "Epoch: 19 \tTraining Loss: 1.490377 \tValidation Loss: 4.439658\n",
      "Epoch: 20 \tTraining Loss: 1.430497 \tValidation Loss: 4.476290\n",
      "Epoch: 1 \tTraining Loss: 6.663084 \tValidation Loss: 5.663415\n",
      "Validation loss decreased (inf --> 5.66341).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.160533 \tValidation Loss: 5.575880\n",
      "Validation loss decreased (5.66341 --> 5.57588).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.975992 \tValidation Loss: 5.463532\n",
      "Validation loss decreased (5.57588 --> 5.46353).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.694480 \tValidation Loss: 5.292186\n",
      "Validation loss decreased (5.46353 --> 5.29219).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.298697 \tValidation Loss: 5.085724\n",
      "Validation loss decreased (5.29219 --> 5.08572).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.816942 \tValidation Loss: 4.881841\n",
      "Validation loss decreased (5.08572 --> 4.88184).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.302709 \tValidation Loss: 4.705758\n",
      "Validation loss decreased (4.88184 --> 4.70576).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.804033 \tValidation Loss: 4.565061\n",
      "Validation loss decreased (4.70576 --> 4.56506).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.351407 \tValidation Loss: 4.460861\n",
      "Validation loss decreased (4.56506 --> 4.46086).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.961259 \tValidation Loss: 4.388736\n",
      "Validation loss decreased (4.46086 --> 4.38874).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.639818 \tValidation Loss: 4.342467\n",
      "Validation loss decreased (4.38874 --> 4.34247).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.373130 \tValidation Loss: 4.316127\n",
      "Validation loss decreased (4.34247 --> 4.31613).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.158589 \tValidation Loss: 4.306075\n",
      "Validation loss decreased (4.31613 --> 4.30608).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.986135 \tValidation Loss: 4.308852\n",
      "Epoch: 15 \tTraining Loss: 1.847521 \tValidation Loss: 4.320164\n",
      "Epoch: 16 \tTraining Loss: 1.730803 \tValidation Loss: 4.339780\n",
      "Epoch: 17 \tTraining Loss: 1.636091 \tValidation Loss: 4.364433\n",
      "Epoch: 18 \tTraining Loss: 1.555604 \tValidation Loss: 4.393324\n",
      "Epoch: 19 \tTraining Loss: 1.495667 \tValidation Loss: 4.425161\n",
      "Epoch: 20 \tTraining Loss: 1.436825 \tValidation Loss: 4.460445\n",
      "Epoch: 1 \tTraining Loss: 6.668741 \tValidation Loss: 5.624283\n",
      "Validation loss decreased (inf --> 5.62428).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.165025 \tValidation Loss: 5.535351\n",
      "Validation loss decreased (5.62428 --> 5.53535).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.972260 \tValidation Loss: 5.411478\n",
      "Validation loss decreased (5.53535 --> 5.41148).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.682669 \tValidation Loss: 5.232150\n",
      "Validation loss decreased (5.41148 --> 5.23215).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.280882 \tValidation Loss: 5.031299\n",
      "Validation loss decreased (5.23215 --> 5.03130).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.799226 \tValidation Loss: 4.836636\n",
      "Validation loss decreased (5.03130 --> 4.83664).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.287640 \tValidation Loss: 4.670845\n",
      "Validation loss decreased (4.83664 --> 4.67085).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.788785 \tValidation Loss: 4.542424\n",
      "Validation loss decreased (4.67085 --> 4.54242).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.337373 \tValidation Loss: 4.449801\n",
      "Validation loss decreased (4.54242 --> 4.44980).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.949053 \tValidation Loss: 4.385490\n",
      "Validation loss decreased (4.44980 --> 4.38549).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.622715 \tValidation Loss: 4.346130\n",
      "Validation loss decreased (4.38549 --> 4.34613).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.359882 \tValidation Loss: 4.327086\n",
      "Validation loss decreased (4.34613 --> 4.32709).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.144340 \tValidation Loss: 4.321695\n",
      "Validation loss decreased (4.32709 --> 4.32170).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.972893 \tValidation Loss: 4.327979\n",
      "Epoch: 15 \tTraining Loss: 1.832301 \tValidation Loss: 4.344358\n",
      "Epoch: 16 \tTraining Loss: 1.720324 \tValidation Loss: 4.365332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 \tTraining Loss: 1.624016 \tValidation Loss: 4.391511\n",
      "Epoch: 18 \tTraining Loss: 1.550818 \tValidation Loss: 4.422252\n",
      "Epoch: 19 \tTraining Loss: 1.480884 \tValidation Loss: 4.454697\n",
      "Epoch: 20 \tTraining Loss: 1.425019 \tValidation Loss: 4.489904\n",
      "Epoch: 1 \tTraining Loss: 6.654436 \tValidation Loss: 5.677383\n",
      "Validation loss decreased (inf --> 5.67738).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.152224 \tValidation Loss: 5.585193\n",
      "Validation loss decreased (5.67738 --> 5.58519).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.963118 \tValidation Loss: 5.468080\n",
      "Validation loss decreased (5.58519 --> 5.46808).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.673894 \tValidation Loss: 5.297629\n",
      "Validation loss decreased (5.46808 --> 5.29763).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.273005 \tValidation Loss: 5.099337\n",
      "Validation loss decreased (5.29763 --> 5.09934).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.791683 \tValidation Loss: 4.907388\n",
      "Validation loss decreased (5.09934 --> 4.90739).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.282322 \tValidation Loss: 4.745066\n",
      "Validation loss decreased (4.90739 --> 4.74507).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.787001 \tValidation Loss: 4.615939\n",
      "Validation loss decreased (4.74507 --> 4.61594).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.340314 \tValidation Loss: 4.520849\n",
      "Validation loss decreased (4.61594 --> 4.52085).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.950642 \tValidation Loss: 4.454875\n",
      "Validation loss decreased (4.52085 --> 4.45487).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.628755 \tValidation Loss: 4.413585\n",
      "Validation loss decreased (4.45487 --> 4.41359).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.365041 \tValidation Loss: 4.391366\n",
      "Validation loss decreased (4.41359 --> 4.39137).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.151943 \tValidation Loss: 4.384021\n",
      "Validation loss decreased (4.39137 --> 4.38402).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.979308 \tValidation Loss: 4.387598\n",
      "Epoch: 15 \tTraining Loss: 1.837583 \tValidation Loss: 4.401962\n",
      "Epoch: 16 \tTraining Loss: 1.725437 \tValidation Loss: 4.423409\n",
      "Epoch: 17 \tTraining Loss: 1.630748 \tValidation Loss: 4.450600\n",
      "Epoch: 18 \tTraining Loss: 1.552541 \tValidation Loss: 4.481134\n",
      "Epoch: 19 \tTraining Loss: 1.484198 \tValidation Loss: 4.515820\n",
      "Epoch: 20 \tTraining Loss: 1.430958 \tValidation Loss: 4.554370\n",
      "Epoch: 1 \tTraining Loss: 6.662444 \tValidation Loss: 5.692989\n",
      "Validation loss decreased (inf --> 5.69299).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.153609 \tValidation Loss: 5.597271\n",
      "Validation loss decreased (5.69299 --> 5.59727).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.962334 \tValidation Loss: 5.479266\n",
      "Validation loss decreased (5.59727 --> 5.47927).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.674609 \tValidation Loss: 5.307970\n",
      "Validation loss decreased (5.47927 --> 5.30797).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.274047 \tValidation Loss: 5.103947\n",
      "Validation loss decreased (5.30797 --> 5.10395).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.796373 \tValidation Loss: 4.904683\n",
      "Validation loss decreased (5.10395 --> 4.90468).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.288159 \tValidation Loss: 4.733309\n",
      "Validation loss decreased (4.90468 --> 4.73331).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.795749 \tValidation Loss: 4.599473\n",
      "Validation loss decreased (4.73331 --> 4.59947).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.348681 \tValidation Loss: 4.497311\n",
      "Validation loss decreased (4.59947 --> 4.49731).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.960984 \tValidation Loss: 4.425043\n",
      "Validation loss decreased (4.49731 --> 4.42504).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.638490 \tValidation Loss: 4.376664\n",
      "Validation loss decreased (4.42504 --> 4.37666).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.371714 \tValidation Loss: 4.349911\n",
      "Validation loss decreased (4.37666 --> 4.34991).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.156778 \tValidation Loss: 4.337453\n",
      "Validation loss decreased (4.34991 --> 4.33745).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.989393 \tValidation Loss: 4.340012\n",
      "Epoch: 15 \tTraining Loss: 1.846644 \tValidation Loss: 4.350686\n",
      "Epoch: 16 \tTraining Loss: 1.727288 \tValidation Loss: 4.369439\n",
      "Epoch: 17 \tTraining Loss: 1.637044 \tValidation Loss: 4.394678\n",
      "Epoch: 18 \tTraining Loss: 1.556674 \tValidation Loss: 4.424004\n",
      "Epoch: 19 \tTraining Loss: 1.489407 \tValidation Loss: 4.457652\n",
      "Epoch: 20 \tTraining Loss: 1.431122 \tValidation Loss: 4.493780\n",
      "Epoch: 1 \tTraining Loss: 6.662014 \tValidation Loss: 5.643163\n",
      "Validation loss decreased (inf --> 5.64316).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.160905 \tValidation Loss: 5.554099\n",
      "Validation loss decreased (5.64316 --> 5.55410).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.974760 \tValidation Loss: 5.442986\n",
      "Validation loss decreased (5.55410 --> 5.44299).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.689641 \tValidation Loss: 5.274390\n",
      "Validation loss decreased (5.44299 --> 5.27439).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.287720 \tValidation Loss: 5.077392\n",
      "Validation loss decreased (5.27439 --> 5.07739).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.803301 \tValidation Loss: 4.883283\n",
      "Validation loss decreased (5.07739 --> 4.88328).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.289940 \tValidation Loss: 4.716702\n",
      "Validation loss decreased (4.88328 --> 4.71670).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.793148 \tValidation Loss: 4.585271\n",
      "Validation loss decreased (4.71670 --> 4.58527).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.343712 \tValidation Loss: 4.487823\n",
      "Validation loss decreased (4.58527 --> 4.48782).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.956834 \tValidation Loss: 4.419264\n",
      "Validation loss decreased (4.48782 --> 4.41926).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.631463 \tValidation Loss: 4.375397\n",
      "Validation loss decreased (4.41926 --> 4.37540).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.365444 \tValidation Loss: 4.350046\n",
      "Validation loss decreased (4.37540 --> 4.35005).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.152059 \tValidation Loss: 4.339444\n",
      "Validation loss decreased (4.35005 --> 4.33944).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.976879 \tValidation Loss: 4.340912\n",
      "Epoch: 15 \tTraining Loss: 1.839445 \tValidation Loss: 4.350227\n",
      "Epoch: 16 \tTraining Loss: 1.726573 \tValidation Loss: 4.366374\n",
      "Epoch: 17 \tTraining Loss: 1.631388 \tValidation Loss: 4.386202\n",
      "Epoch: 18 \tTraining Loss: 1.555578 \tValidation Loss: 4.413003\n",
      "Epoch: 19 \tTraining Loss: 1.486665 \tValidation Loss: 4.442460\n",
      "Epoch: 20 \tTraining Loss: 1.434920 \tValidation Loss: 4.476195\n",
      "Epoch: 1 \tTraining Loss: 6.659530 \tValidation Loss: 5.637830\n",
      "Validation loss decreased (inf --> 5.63783).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.153960 \tValidation Loss: 5.551394\n",
      "Validation loss decreased (5.63783 --> 5.55139).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.963977 \tValidation Loss: 5.434573\n",
      "Validation loss decreased (5.55139 --> 5.43457).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.676400 \tValidation Loss: 5.263978\n",
      "Validation loss decreased (5.43457 --> 5.26398).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.272594 \tValidation Loss: 5.065140\n",
      "Validation loss decreased (5.26398 --> 5.06514).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.787693 \tValidation Loss: 4.872416\n",
      "Validation loss decreased (5.06514 --> 4.87242).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.273526 \tValidation Loss: 4.707086\n",
      "Validation loss decreased (4.87242 --> 4.70709).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.774774 \tValidation Loss: 4.578290\n",
      "Validation loss decreased (4.70709 --> 4.57829).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.320323 \tValidation Loss: 4.483125\n",
      "Validation loss decreased (4.57829 --> 4.48313).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.931291 \tValidation Loss: 4.419129\n",
      "Validation loss decreased (4.48313 --> 4.41913).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.608578 \tValidation Loss: 4.381893\n",
      "Validation loss decreased (4.41913 --> 4.38189).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.348821 \tValidation Loss: 4.363354\n",
      "Validation loss decreased (4.38189 --> 4.36335).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.135746 \tValidation Loss: 4.359302\n",
      "Validation loss decreased (4.36335 --> 4.35930).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 \tTraining Loss: 1.963426 \tValidation Loss: 4.366529\n",
      "Epoch: 15 \tTraining Loss: 1.824975 \tValidation Loss: 4.379562\n",
      "Epoch: 16 \tTraining Loss: 1.713211 \tValidation Loss: 4.401786\n",
      "Epoch: 17 \tTraining Loss: 1.618840 \tValidation Loss: 4.429549\n",
      "Epoch: 18 \tTraining Loss: 1.540535 \tValidation Loss: 4.462355\n",
      "Epoch: 19 \tTraining Loss: 1.473157 \tValidation Loss: 4.496186\n",
      "Epoch: 20 \tTraining Loss: 1.419667 \tValidation Loss: 4.534260\n",
      "Epoch: 1 \tTraining Loss: 6.660205 \tValidation Loss: 5.631426\n",
      "Validation loss decreased (inf --> 5.63143).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.163686 \tValidation Loss: 5.537653\n",
      "Validation loss decreased (5.63143 --> 5.53765).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.977683 \tValidation Loss: 5.423298\n",
      "Validation loss decreased (5.53765 --> 5.42330).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.693321 \tValidation Loss: 5.253513\n",
      "Validation loss decreased (5.42330 --> 5.25351).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.294067 \tValidation Loss: 5.055845\n",
      "Validation loss decreased (5.25351 --> 5.05584).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.809827 \tValidation Loss: 4.857808\n",
      "Validation loss decreased (5.05584 --> 4.85781).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.295665 \tValidation Loss: 4.683837\n",
      "Validation loss decreased (4.85781 --> 4.68384).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.797156 \tValidation Loss: 4.544014\n",
      "Validation loss decreased (4.68384 --> 4.54401).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.343678 \tValidation Loss: 4.439878\n",
      "Validation loss decreased (4.54401 --> 4.43988).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.956610 \tValidation Loss: 4.368621\n",
      "Validation loss decreased (4.43988 --> 4.36862).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.632532 \tValidation Loss: 4.324684\n",
      "Validation loss decreased (4.36862 --> 4.32468).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.365893 \tValidation Loss: 4.299684\n",
      "Validation loss decreased (4.32468 --> 4.29968).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.153504 \tValidation Loss: 4.291355\n",
      "Validation loss decreased (4.29968 --> 4.29136).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.977305 \tValidation Loss: 4.296343\n",
      "Epoch: 15 \tTraining Loss: 1.837643 \tValidation Loss: 4.310190\n",
      "Epoch: 16 \tTraining Loss: 1.726947 \tValidation Loss: 4.331519\n",
      "Epoch: 17 \tTraining Loss: 1.631310 \tValidation Loss: 4.357985\n",
      "Epoch: 18 \tTraining Loss: 1.548701 \tValidation Loss: 4.388313\n",
      "Epoch: 19 \tTraining Loss: 1.484954 \tValidation Loss: 4.424315\n",
      "Epoch: 20 \tTraining Loss: 1.431229 \tValidation Loss: 4.461689\n",
      "Epoch: 1 \tTraining Loss: 6.660394 \tValidation Loss: 5.686221\n",
      "Validation loss decreased (inf --> 5.68622).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.149415 \tValidation Loss: 5.595588\n",
      "Validation loss decreased (5.68622 --> 5.59559).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.960989 \tValidation Loss: 5.482207\n",
      "Validation loss decreased (5.59559 --> 5.48221).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.675777 \tValidation Loss: 5.314810\n",
      "Validation loss decreased (5.48221 --> 5.31481).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.277205 \tValidation Loss: 5.118772\n",
      "Validation loss decreased (5.31481 --> 5.11877).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.794197 \tValidation Loss: 4.925910\n",
      "Validation loss decreased (5.11877 --> 4.92591).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.279899 \tValidation Loss: 4.761671\n",
      "Validation loss decreased (4.92591 --> 4.76167).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.784487 \tValidation Loss: 4.632191\n",
      "Validation loss decreased (4.76167 --> 4.63219).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.336231 \tValidation Loss: 4.536571\n",
      "Validation loss decreased (4.63219 --> 4.53657).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.949057 \tValidation Loss: 4.470395\n",
      "Validation loss decreased (4.53657 --> 4.47039).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.624280 \tValidation Loss: 4.427366\n",
      "Validation loss decreased (4.47039 --> 4.42737).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.364505 \tValidation Loss: 4.405379\n",
      "Validation loss decreased (4.42737 --> 4.40538).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.151777 \tValidation Loss: 4.396837\n",
      "Validation loss decreased (4.40538 --> 4.39684).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.979844 \tValidation Loss: 4.399437\n",
      "Epoch: 15 \tTraining Loss: 1.840386 \tValidation Loss: 4.411659\n",
      "Epoch: 16 \tTraining Loss: 1.724905 \tValidation Loss: 4.430724\n",
      "Epoch: 17 \tTraining Loss: 1.628579 \tValidation Loss: 4.459601\n",
      "Epoch: 18 \tTraining Loss: 1.553594 \tValidation Loss: 4.489000\n",
      "Epoch: 19 \tTraining Loss: 1.489543 \tValidation Loss: 4.521867\n",
      "Epoch: 20 \tTraining Loss: 1.430043 \tValidation Loss: 4.560420\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 4 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.659137 \tValidation Loss: 6.227705\n",
      "Validation loss decreased (inf --> 6.22770).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.105490 \tValidation Loss: 6.053488\n",
      "Validation loss decreased (6.22770 --> 6.05349).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.768305 \tValidation Loss: 5.786170\n",
      "Validation loss decreased (6.05349 --> 5.78617).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.248100 \tValidation Loss: 5.433970\n",
      "Validation loss decreased (5.78617 --> 5.43397).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.586235 \tValidation Loss: 5.062316\n",
      "Validation loss decreased (5.43397 --> 5.06232).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.882051 \tValidation Loss: 4.727079\n",
      "Validation loss decreased (5.06232 --> 4.72708).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.225539 \tValidation Loss: 4.450307\n",
      "Validation loss decreased (4.72708 --> 4.45031).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.665586 \tValidation Loss: 4.233162\n",
      "Validation loss decreased (4.45031 --> 4.23316).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.220842 \tValidation Loss: 4.066686\n",
      "Validation loss decreased (4.23316 --> 4.06669).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.874264 \tValidation Loss: 3.941429\n",
      "Validation loss decreased (4.06669 --> 3.94143).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.605079 \tValidation Loss: 3.850866\n",
      "Validation loss decreased (3.94143 --> 3.85087).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.397575 \tValidation Loss: 3.786725\n",
      "Validation loss decreased (3.85087 --> 3.78672).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.233259 \tValidation Loss: 3.743265\n",
      "Validation loss decreased (3.78672 --> 3.74327).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.101386 \tValidation Loss: 3.717571\n",
      "Validation loss decreased (3.74327 --> 3.71757).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.995305 \tValidation Loss: 3.708040\n",
      "Validation loss decreased (3.71757 --> 3.70804).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.905804 \tValidation Loss: 3.708714\n",
      "Epoch: 17 \tTraining Loss: 0.833832 \tValidation Loss: 3.718849\n",
      "Epoch: 18 \tTraining Loss: 0.775590 \tValidation Loss: 3.736187\n",
      "Epoch: 19 \tTraining Loss: 0.724328 \tValidation Loss: 3.760760\n",
      "Epoch: 20 \tTraining Loss: 0.682377 \tValidation Loss: 3.790382\n",
      "Epoch: 1 \tTraining Loss: 6.663546 \tValidation Loss: 6.185839\n",
      "Validation loss decreased (inf --> 6.18584).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.114319 \tValidation Loss: 6.027024\n",
      "Validation loss decreased (6.18584 --> 6.02702).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.777828 \tValidation Loss: 5.773532\n",
      "Validation loss decreased (6.02702 --> 5.77353).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.253399 \tValidation Loss: 5.432071\n",
      "Validation loss decreased (5.77353 --> 5.43207).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.585737 \tValidation Loss: 5.068402\n",
      "Validation loss decreased (5.43207 --> 5.06840).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.872862 \tValidation Loss: 4.738992\n",
      "Validation loss decreased (5.06840 --> 4.73899).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.209302 \tValidation Loss: 4.468971\n",
      "Validation loss decreased (4.73899 --> 4.46897).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.648677 \tValidation Loss: 4.259994\n",
      "Validation loss decreased (4.46897 --> 4.25999).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.205160 \tValidation Loss: 4.101689\n",
      "Validation loss decreased (4.25999 --> 4.10169).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.859897 \tValidation Loss: 3.986026\n",
      "Validation loss decreased (4.10169 --> 3.98603).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.591555 \tValidation Loss: 3.901090\n",
      "Validation loss decreased (3.98603 --> 3.90109).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 \tTraining Loss: 1.387396 \tValidation Loss: 3.843406\n",
      "Validation loss decreased (3.90109 --> 3.84341).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.225025 \tValidation Loss: 3.807399\n",
      "Validation loss decreased (3.84341 --> 3.80740).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.094130 \tValidation Loss: 3.786634\n",
      "Validation loss decreased (3.80740 --> 3.78663).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.988730 \tValidation Loss: 3.781497\n",
      "Validation loss decreased (3.78663 --> 3.78150).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.899712 \tValidation Loss: 3.784941\n",
      "Epoch: 17 \tTraining Loss: 0.830186 \tValidation Loss: 3.799548\n",
      "Epoch: 18 \tTraining Loss: 0.772094 \tValidation Loss: 3.816843\n",
      "Epoch: 19 \tTraining Loss: 0.724545 \tValidation Loss: 3.842470\n",
      "Epoch: 20 \tTraining Loss: 0.678674 \tValidation Loss: 3.867521\n",
      "Epoch: 1 \tTraining Loss: 6.666127 \tValidation Loss: 6.177465\n",
      "Validation loss decreased (inf --> 6.17747).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.107864 \tValidation Loss: 5.994636\n",
      "Validation loss decreased (6.17747 --> 5.99464).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.768837 \tValidation Loss: 5.716166\n",
      "Validation loss decreased (5.99464 --> 5.71617).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.241377 \tValidation Loss: 5.351928\n",
      "Validation loss decreased (5.71617 --> 5.35193).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.569969 \tValidation Loss: 4.979773\n",
      "Validation loss decreased (5.35193 --> 4.97977).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.862974 \tValidation Loss: 4.645230\n",
      "Validation loss decreased (4.97977 --> 4.64523).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.208774 \tValidation Loss: 4.366027\n",
      "Validation loss decreased (4.64523 --> 4.36603).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.653303 \tValidation Loss: 4.145425\n",
      "Validation loss decreased (4.36603 --> 4.14542).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.205531 \tValidation Loss: 3.978438\n",
      "Validation loss decreased (4.14542 --> 3.97844).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.863268 \tValidation Loss: 3.856092\n",
      "Validation loss decreased (3.97844 --> 3.85609).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.594651 \tValidation Loss: 3.769673\n",
      "Validation loss decreased (3.85609 --> 3.76967).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.387661 \tValidation Loss: 3.709832\n",
      "Validation loss decreased (3.76967 --> 3.70983).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.225259 \tValidation Loss: 3.674831\n",
      "Validation loss decreased (3.70983 --> 3.67483).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.095286 \tValidation Loss: 3.654775\n",
      "Validation loss decreased (3.67483 --> 3.65477).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.990312 \tValidation Loss: 3.647874\n",
      "Validation loss decreased (3.65477 --> 3.64787).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.905025 \tValidation Loss: 3.651804\n",
      "Epoch: 17 \tTraining Loss: 0.832286 \tValidation Loss: 3.664008\n",
      "Epoch: 18 \tTraining Loss: 0.772192 \tValidation Loss: 3.685903\n",
      "Epoch: 19 \tTraining Loss: 0.723910 \tValidation Loss: 3.708552\n",
      "Epoch: 20 \tTraining Loss: 0.679869 \tValidation Loss: 3.737187\n",
      "Epoch: 1 \tTraining Loss: 6.657943 \tValidation Loss: 6.229227\n",
      "Validation loss decreased (inf --> 6.22923).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.113161 \tValidation Loss: 6.058570\n",
      "Validation loss decreased (6.22923 --> 6.05857).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.782807 \tValidation Loss: 5.787237\n",
      "Validation loss decreased (6.05857 --> 5.78724).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.264170 \tValidation Loss: 5.419020\n",
      "Validation loss decreased (5.78724 --> 5.41902).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.600293 \tValidation Loss: 5.029347\n",
      "Validation loss decreased (5.41902 --> 5.02935).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.893965 \tValidation Loss: 4.673611\n",
      "Validation loss decreased (5.02935 --> 4.67361).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.232069 \tValidation Loss: 4.377809\n",
      "Validation loss decreased (4.67361 --> 4.37781).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.666857 \tValidation Loss: 4.149575\n",
      "Validation loss decreased (4.37781 --> 4.14958).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.215086 \tValidation Loss: 3.979566\n",
      "Validation loss decreased (4.14958 --> 3.97957).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.868788 \tValidation Loss: 3.858724\n",
      "Validation loss decreased (3.97957 --> 3.85872).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.599834 \tValidation Loss: 3.775205\n",
      "Validation loss decreased (3.85872 --> 3.77521).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.391934 \tValidation Loss: 3.719286\n",
      "Validation loss decreased (3.77521 --> 3.71929).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.229547 \tValidation Loss: 3.685415\n",
      "Validation loss decreased (3.71929 --> 3.68541).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.094858 \tValidation Loss: 3.664341\n",
      "Validation loss decreased (3.68541 --> 3.66434).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.993152 \tValidation Loss: 3.657283\n",
      "Validation loss decreased (3.66434 --> 3.65728).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.905192 \tValidation Loss: 3.662987\n",
      "Epoch: 17 \tTraining Loss: 0.831607 \tValidation Loss: 3.676368\n",
      "Epoch: 18 \tTraining Loss: 0.772017 \tValidation Loss: 3.694603\n",
      "Epoch: 19 \tTraining Loss: 0.722710 \tValidation Loss: 3.720284\n",
      "Epoch: 20 \tTraining Loss: 0.681644 \tValidation Loss: 3.744926\n",
      "Epoch: 1 \tTraining Loss: 6.654369 \tValidation Loss: 6.242539\n",
      "Validation loss decreased (inf --> 6.24254).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.101939 \tValidation Loss: 6.062440\n",
      "Validation loss decreased (6.24254 --> 6.06244).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.764917 \tValidation Loss: 5.798800\n",
      "Validation loss decreased (6.06244 --> 5.79880).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.238958 \tValidation Loss: 5.449585\n",
      "Validation loss decreased (5.79880 --> 5.44959).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.574040 \tValidation Loss: 5.086653\n",
      "Validation loss decreased (5.44959 --> 5.08665).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.868736 \tValidation Loss: 4.755666\n",
      "Validation loss decreased (5.08665 --> 4.75567).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.215219 \tValidation Loss: 4.481057\n",
      "Validation loss decreased (4.75567 --> 4.48106).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.657539 \tValidation Loss: 4.265119\n",
      "Validation loss decreased (4.48106 --> 4.26512).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.208997 \tValidation Loss: 4.102663\n",
      "Validation loss decreased (4.26512 --> 4.10266).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.864679 \tValidation Loss: 3.985697\n",
      "Validation loss decreased (4.10266 --> 3.98570).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.598126 \tValidation Loss: 3.903360\n",
      "Validation loss decreased (3.98570 --> 3.90336).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.390896 \tValidation Loss: 3.847972\n",
      "Validation loss decreased (3.90336 --> 3.84797).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.227227 \tValidation Loss: 3.814659\n",
      "Validation loss decreased (3.84797 --> 3.81466).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.097488 \tValidation Loss: 3.799878\n",
      "Validation loss decreased (3.81466 --> 3.79988).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.988991 \tValidation Loss: 3.795270\n",
      "Validation loss decreased (3.79988 --> 3.79527).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.906418 \tValidation Loss: 3.800933\n",
      "Epoch: 17 \tTraining Loss: 0.834233 \tValidation Loss: 3.819696\n",
      "Epoch: 18 \tTraining Loss: 0.777594 \tValidation Loss: 3.842508\n",
      "Epoch: 19 \tTraining Loss: 0.725164 \tValidation Loss: 3.868352\n",
      "Epoch: 20 \tTraining Loss: 0.680552 \tValidation Loss: 3.898900\n",
      "Epoch: 1 \tTraining Loss: 6.658648 \tValidation Loss: 6.218198\n",
      "Validation loss decreased (inf --> 6.21820).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.111676 \tValidation Loss: 6.045487\n",
      "Validation loss decreased (6.21820 --> 6.04549).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.777642 \tValidation Loss: 5.783764\n",
      "Validation loss decreased (6.04549 --> 5.78376).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.250974 \tValidation Loss: 5.427137\n",
      "Validation loss decreased (5.78376 --> 5.42714).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.582017 \tValidation Loss: 5.053809\n",
      "Validation loss decreased (5.42714 --> 5.05381).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.875531 \tValidation Loss: 4.718497\n",
      "Validation loss decreased (5.05381 --> 4.71850).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 \tTraining Loss: 3.218101 \tValidation Loss: 4.440676\n",
      "Validation loss decreased (4.71850 --> 4.44068).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.654220 \tValidation Loss: 4.223110\n",
      "Validation loss decreased (4.44068 --> 4.22311).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.207066 \tValidation Loss: 4.060518\n",
      "Validation loss decreased (4.22311 --> 4.06052).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.858553 \tValidation Loss: 3.942239\n",
      "Validation loss decreased (4.06052 --> 3.94224).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.593363 \tValidation Loss: 3.856897\n",
      "Validation loss decreased (3.94224 --> 3.85690).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.385514 \tValidation Loss: 3.799411\n",
      "Validation loss decreased (3.85690 --> 3.79941).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.220873 \tValidation Loss: 3.762575\n",
      "Validation loss decreased (3.79941 --> 3.76257).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.093543 \tValidation Loss: 3.745122\n",
      "Validation loss decreased (3.76257 --> 3.74512).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.988745 \tValidation Loss: 3.739626\n",
      "Validation loss decreased (3.74512 --> 3.73963).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.902124 \tValidation Loss: 3.747072\n",
      "Epoch: 17 \tTraining Loss: 0.833686 \tValidation Loss: 3.757794\n",
      "Epoch: 18 \tTraining Loss: 0.772427 \tValidation Loss: 3.780031\n",
      "Epoch: 19 \tTraining Loss: 0.722737 \tValidation Loss: 3.802800\n",
      "Epoch: 20 \tTraining Loss: 0.679556 \tValidation Loss: 3.832611\n",
      "Epoch: 1 \tTraining Loss: 6.660332 \tValidation Loss: 6.154612\n",
      "Validation loss decreased (inf --> 6.15461).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.120172 \tValidation Loss: 5.986685\n",
      "Validation loss decreased (6.15461 --> 5.98668).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.794203 \tValidation Loss: 5.722275\n",
      "Validation loss decreased (5.98668 --> 5.72228).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.273705 \tValidation Loss: 5.367957\n",
      "Validation loss decreased (5.72228 --> 5.36796).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.604082 \tValidation Loss: 4.992337\n",
      "Validation loss decreased (5.36796 --> 4.99234).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.886286 \tValidation Loss: 4.649705\n",
      "Validation loss decreased (4.99234 --> 4.64971).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.218067 \tValidation Loss: 4.369717\n",
      "Validation loss decreased (4.64971 --> 4.36972).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.649984 \tValidation Loss: 4.152495\n",
      "Validation loss decreased (4.36972 --> 4.15249).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.199702 \tValidation Loss: 3.990812\n",
      "Validation loss decreased (4.15249 --> 3.99081).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.851048 \tValidation Loss: 3.872175\n",
      "Validation loss decreased (3.99081 --> 3.87218).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.584478 \tValidation Loss: 3.788934\n",
      "Validation loss decreased (3.87218 --> 3.78893).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.378045 \tValidation Loss: 3.731870\n",
      "Validation loss decreased (3.78893 --> 3.73187).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.216090 \tValidation Loss: 3.694583\n",
      "Validation loss decreased (3.73187 --> 3.69458).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.085546 \tValidation Loss: 3.676285\n",
      "Validation loss decreased (3.69458 --> 3.67629).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.981897 \tValidation Loss: 3.670041\n",
      "Validation loss decreased (3.67629 --> 3.67004).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.897727 \tValidation Loss: 3.673009\n",
      "Epoch: 17 \tTraining Loss: 0.827950 \tValidation Loss: 3.686486\n",
      "Epoch: 18 \tTraining Loss: 0.768059 \tValidation Loss: 3.704775\n",
      "Epoch: 19 \tTraining Loss: 0.720192 \tValidation Loss: 3.728212\n",
      "Epoch: 20 \tTraining Loss: 0.676681 \tValidation Loss: 3.755818\n",
      "Epoch: 1 \tTraining Loss: 6.659131 \tValidation Loss: 6.227467\n",
      "Validation loss decreased (inf --> 6.22747).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.110469 \tValidation Loss: 6.051113\n",
      "Validation loss decreased (6.22747 --> 6.05111).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.777629 \tValidation Loss: 5.783719\n",
      "Validation loss decreased (6.05111 --> 5.78372).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.255742 \tValidation Loss: 5.429627\n",
      "Validation loss decreased (5.78372 --> 5.42963).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.594343 \tValidation Loss: 5.059538\n",
      "Validation loss decreased (5.42963 --> 5.05954).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.888892 \tValidation Loss: 4.726019\n",
      "Validation loss decreased (5.05954 --> 4.72602).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.228505 \tValidation Loss: 4.451447\n",
      "Validation loss decreased (4.72602 --> 4.45145).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.666328 \tValidation Loss: 4.236730\n",
      "Validation loss decreased (4.45145 --> 4.23673).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.220464 \tValidation Loss: 4.074853\n",
      "Validation loss decreased (4.23673 --> 4.07485).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.870721 \tValidation Loss: 3.956754\n",
      "Validation loss decreased (4.07485 --> 3.95675).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.603278 \tValidation Loss: 3.871224\n",
      "Validation loss decreased (3.95675 --> 3.87122).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.394832 \tValidation Loss: 3.813492\n",
      "Validation loss decreased (3.87122 --> 3.81349).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.234476 \tValidation Loss: 3.776762\n",
      "Validation loss decreased (3.81349 --> 3.77676).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.100961 \tValidation Loss: 3.758424\n",
      "Validation loss decreased (3.77676 --> 3.75842).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.997683 \tValidation Loss: 3.754228\n",
      "Validation loss decreased (3.75842 --> 3.75423).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.909864 \tValidation Loss: 3.758557\n",
      "Epoch: 17 \tTraining Loss: 0.835693 \tValidation Loss: 3.770118\n",
      "Epoch: 18 \tTraining Loss: 0.779627 \tValidation Loss: 3.790371\n",
      "Epoch: 19 \tTraining Loss: 0.730995 \tValidation Loss: 3.816878\n",
      "Epoch: 20 \tTraining Loss: 0.685059 \tValidation Loss: 3.844967\n",
      "Epoch: 1 \tTraining Loss: 6.666114 \tValidation Loss: 6.173251\n",
      "Validation loss decreased (inf --> 6.17325).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.111535 \tValidation Loss: 5.991760\n",
      "Validation loss decreased (6.17325 --> 5.99176).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.771781 \tValidation Loss: 5.714590\n",
      "Validation loss decreased (5.99176 --> 5.71459).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.244120 \tValidation Loss: 5.346909\n",
      "Validation loss decreased (5.71459 --> 5.34691).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.573447 \tValidation Loss: 4.962758\n",
      "Validation loss decreased (5.34691 --> 4.96276).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.863936 \tValidation Loss: 4.622932\n",
      "Validation loss decreased (4.96276 --> 4.62293).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.202628 \tValidation Loss: 4.347090\n",
      "Validation loss decreased (4.62293 --> 4.34709).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.643476 \tValidation Loss: 4.130689\n",
      "Validation loss decreased (4.34709 --> 4.13069).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.196738 \tValidation Loss: 3.969199\n",
      "Validation loss decreased (4.13069 --> 3.96920).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.849166 \tValidation Loss: 3.850622\n",
      "Validation loss decreased (3.96920 --> 3.85062).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.582815 \tValidation Loss: 3.768809\n",
      "Validation loss decreased (3.85062 --> 3.76881).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.377521 \tValidation Loss: 3.714487\n",
      "Validation loss decreased (3.76881 --> 3.71449).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.210868 \tValidation Loss: 3.678976\n",
      "Validation loss decreased (3.71449 --> 3.67898).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.086334 \tValidation Loss: 3.663678\n",
      "Validation loss decreased (3.67898 --> 3.66368).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.978242 \tValidation Loss: 3.658305\n",
      "Validation loss decreased (3.66368 --> 3.65831).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.892123 \tValidation Loss: 3.667278\n",
      "Epoch: 17 \tTraining Loss: 0.830044 \tValidation Loss: 3.680706\n",
      "Epoch: 18 \tTraining Loss: 0.764437 \tValidation Loss: 3.699680\n",
      "Epoch: 19 \tTraining Loss: 0.716416 \tValidation Loss: 3.724865\n",
      "Epoch: 20 \tTraining Loss: 0.673781 \tValidation Loss: 3.755927\n",
      "Epoch: 1 \tTraining Loss: 6.664291 \tValidation Loss: 6.229265\n",
      "Validation loss decreased (inf --> 6.22927).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 6.109538 \tValidation Loss: 6.054535\n",
      "Validation loss decreased (6.22927 --> 6.05453).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.775544 \tValidation Loss: 5.785538\n",
      "Validation loss decreased (6.05453 --> 5.78554).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.250339 \tValidation Loss: 5.426163\n",
      "Validation loss decreased (5.78554 --> 5.42616).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.579677 \tValidation Loss: 5.055802\n",
      "Validation loss decreased (5.42616 --> 5.05580).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.869065 \tValidation Loss: 4.723974\n",
      "Validation loss decreased (5.05580 --> 4.72397).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.211180 \tValidation Loss: 4.447093\n",
      "Validation loss decreased (4.72397 --> 4.44709).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.653194 \tValidation Loss: 4.226247\n",
      "Validation loss decreased (4.44709 --> 4.22625).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.207624 \tValidation Loss: 4.057647\n",
      "Validation loss decreased (4.22625 --> 4.05765).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.860620 \tValidation Loss: 3.934204\n",
      "Validation loss decreased (4.05765 --> 3.93420).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.592005 \tValidation Loss: 3.849115\n",
      "Validation loss decreased (3.93420 --> 3.84911).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.384768 \tValidation Loss: 3.789789\n",
      "Validation loss decreased (3.84911 --> 3.78979).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.223258 \tValidation Loss: 3.751395\n",
      "Validation loss decreased (3.78979 --> 3.75140).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.092284 \tValidation Loss: 3.731533\n",
      "Validation loss decreased (3.75140 --> 3.73153).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.986659 \tValidation Loss: 3.726995\n",
      "Validation loss decreased (3.73153 --> 3.72699).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.899569 \tValidation Loss: 3.727524\n",
      "Epoch: 17 \tTraining Loss: 0.829166 \tValidation Loss: 3.738699\n",
      "Epoch: 18 \tTraining Loss: 0.770034 \tValidation Loss: 3.759108\n",
      "Epoch: 19 \tTraining Loss: 0.723325 \tValidation Loss: 3.781084\n",
      "Epoch: 20 \tTraining Loss: 0.675585 \tValidation Loss: 3.805812\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 5 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.555266 \tValidation Loss: 5.618459\n",
      "Validation loss decreased (inf --> 5.61846).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.958802 \tValidation Loss: 5.392050\n",
      "Validation loss decreased (5.61846 --> 5.39205).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.513147 \tValidation Loss: 5.045344\n",
      "Validation loss decreased (5.39205 --> 5.04534).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.833785 \tValidation Loss: 4.606042\n",
      "Validation loss decreased (5.04534 --> 4.60604).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.021620 \tValidation Loss: 4.167539\n",
      "Validation loss decreased (4.60604 --> 4.16754).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.222706 \tValidation Loss: 3.786264\n",
      "Validation loss decreased (4.16754 --> 3.78626).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.541428 \tValidation Loss: 3.482640\n",
      "Validation loss decreased (3.78626 --> 3.48264).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.002515 \tValidation Loss: 3.252929\n",
      "Validation loss decreased (3.48264 --> 3.25293).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.597352 \tValidation Loss: 3.080783\n",
      "Validation loss decreased (3.25293 --> 3.08078).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.298684 \tValidation Loss: 2.956149\n",
      "Validation loss decreased (3.08078 --> 2.95615).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.076193 \tValidation Loss: 2.865679\n",
      "Validation loss decreased (2.95615 --> 2.86568).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.905956 \tValidation Loss: 2.803513\n",
      "Validation loss decreased (2.86568 --> 2.80351).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.772444 \tValidation Loss: 2.761812\n",
      "Validation loss decreased (2.80351 --> 2.76181).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.666348 \tValidation Loss: 2.737762\n",
      "Validation loss decreased (2.76181 --> 2.73776).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.580967 \tValidation Loss: 2.724245\n",
      "Validation loss decreased (2.73776 --> 2.72424).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.516767 \tValidation Loss: 2.718353\n",
      "Validation loss decreased (2.72424 --> 2.71835).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.461808 \tValidation Loss: 2.726096\n",
      "Epoch: 18 \tTraining Loss: 0.417566 \tValidation Loss: 2.735615\n",
      "Epoch: 19 \tTraining Loss: 0.381594 \tValidation Loss: 2.751098\n",
      "Epoch: 20 \tTraining Loss: 0.350402 \tValidation Loss: 2.769182\n",
      "Epoch: 1 \tTraining Loss: 6.552157 \tValidation Loss: 5.608972\n",
      "Validation loss decreased (inf --> 5.60897).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.953670 \tValidation Loss: 5.398298\n",
      "Validation loss decreased (5.60897 --> 5.39830).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.510577 \tValidation Loss: 5.067441\n",
      "Validation loss decreased (5.39830 --> 5.06744).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.836492 \tValidation Loss: 4.643266\n",
      "Validation loss decreased (5.06744 --> 4.64327).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.024228 \tValidation Loss: 4.215234\n",
      "Validation loss decreased (4.64327 --> 4.21523).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.221443 \tValidation Loss: 3.849118\n",
      "Validation loss decreased (4.21523 --> 3.84912).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.538507 \tValidation Loss: 3.559152\n",
      "Validation loss decreased (3.84912 --> 3.55915).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.998811 \tValidation Loss: 3.338022\n",
      "Validation loss decreased (3.55915 --> 3.33802).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.596883 \tValidation Loss: 3.174697\n",
      "Validation loss decreased (3.33802 --> 3.17470).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.296782 \tValidation Loss: 3.058973\n",
      "Validation loss decreased (3.17470 --> 3.05897).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.073164 \tValidation Loss: 2.974838\n",
      "Validation loss decreased (3.05897 --> 2.97484).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.899034 \tValidation Loss: 2.919091\n",
      "Validation loss decreased (2.97484 --> 2.91909).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.766905 \tValidation Loss: 2.881138\n",
      "Validation loss decreased (2.91909 --> 2.88114).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.664331 \tValidation Loss: 2.857225\n",
      "Validation loss decreased (2.88114 --> 2.85723).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.581689 \tValidation Loss: 2.850007\n",
      "Validation loss decreased (2.85723 --> 2.85001).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.513759 \tValidation Loss: 2.850380\n",
      "Epoch: 17 \tTraining Loss: 0.457939 \tValidation Loss: 2.853525\n",
      "Epoch: 18 \tTraining Loss: 0.415052 \tValidation Loss: 2.869693\n",
      "Epoch: 19 \tTraining Loss: 0.379137 \tValidation Loss: 2.886204\n",
      "Epoch: 20 \tTraining Loss: 0.350033 \tValidation Loss: 2.904291\n",
      "Epoch: 1 \tTraining Loss: 6.553372 \tValidation Loss: 5.623747\n",
      "Validation loss decreased (inf --> 5.62375).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.960967 \tValidation Loss: 5.414576\n",
      "Validation loss decreased (5.62375 --> 5.41458).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.529063 \tValidation Loss: 5.084096\n",
      "Validation loss decreased (5.41458 --> 5.08410).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.864176 \tValidation Loss: 4.653754\n",
      "Validation loss decreased (5.08410 --> 4.65375).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.055897 \tValidation Loss: 4.217773\n",
      "Validation loss decreased (4.65375 --> 4.21777).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.253412 \tValidation Loss: 3.842260\n",
      "Validation loss decreased (4.21777 --> 3.84226).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.565716 \tValidation Loss: 3.541137\n",
      "Validation loss decreased (3.84226 --> 3.54114).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.026512 \tValidation Loss: 3.309228\n",
      "Validation loss decreased (3.54114 --> 3.30923).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.620647 \tValidation Loss: 3.135403\n",
      "Validation loss decreased (3.30923 --> 3.13540).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.318036 \tValidation Loss: 3.007076\n",
      "Validation loss decreased (3.13540 --> 3.00708).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.095885 \tValidation Loss: 2.915940\n",
      "Validation loss decreased (3.00708 --> 2.91594).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.918912 \tValidation Loss: 2.850858\n",
      "Validation loss decreased (2.91594 --> 2.85086).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 \tTraining Loss: 0.784805 \tValidation Loss: 2.810372\n",
      "Validation loss decreased (2.85086 --> 2.81037).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.675468 \tValidation Loss: 2.784881\n",
      "Validation loss decreased (2.81037 --> 2.78488).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.592642 \tValidation Loss: 2.775456\n",
      "Validation loss decreased (2.78488 --> 2.77546).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.524873 \tValidation Loss: 2.772684\n",
      "Validation loss decreased (2.77546 --> 2.77268).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.468786 \tValidation Loss: 2.776882\n",
      "Epoch: 18 \tTraining Loss: 0.425155 \tValidation Loss: 2.788518\n",
      "Epoch: 19 \tTraining Loss: 0.388838 \tValidation Loss: 2.803951\n",
      "Epoch: 20 \tTraining Loss: 0.356666 \tValidation Loss: 2.821713\n",
      "Epoch: 1 \tTraining Loss: 6.556334 \tValidation Loss: 5.673860\n",
      "Validation loss decreased (inf --> 5.67386).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.950475 \tValidation Loss: 5.451347\n",
      "Validation loss decreased (5.67386 --> 5.45135).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.506611 \tValidation Loss: 5.106891\n",
      "Validation loss decreased (5.45135 --> 5.10689).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.835374 \tValidation Loss: 4.666573\n",
      "Validation loss decreased (5.10689 --> 4.66657).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.020604 \tValidation Loss: 4.229937\n",
      "Validation loss decreased (4.66657 --> 4.22994).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.222311 \tValidation Loss: 3.858540\n",
      "Validation loss decreased (4.22994 --> 3.85854).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.539657 \tValidation Loss: 3.562887\n",
      "Validation loss decreased (3.85854 --> 3.56289).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.008321 \tValidation Loss: 3.334831\n",
      "Validation loss decreased (3.56289 --> 3.33483).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.607752 \tValidation Loss: 3.163464\n",
      "Validation loss decreased (3.33483 --> 3.16346).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.305731 \tValidation Loss: 3.035332\n",
      "Validation loss decreased (3.16346 --> 3.03533).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.080288 \tValidation Loss: 2.942098\n",
      "Validation loss decreased (3.03533 --> 2.94210).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.911440 \tValidation Loss: 2.876260\n",
      "Validation loss decreased (2.94210 --> 2.87626).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.774214 \tValidation Loss: 2.834759\n",
      "Validation loss decreased (2.87626 --> 2.83476).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.664936 \tValidation Loss: 2.811132\n",
      "Validation loss decreased (2.83476 --> 2.81113).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.581300 \tValidation Loss: 2.798676\n",
      "Validation loss decreased (2.81113 --> 2.79868).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.515841 \tValidation Loss: 2.794360\n",
      "Validation loss decreased (2.79868 --> 2.79436).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.461261 \tValidation Loss: 2.800676\n",
      "Epoch: 18 \tTraining Loss: 0.416034 \tValidation Loss: 2.811632\n",
      "Epoch: 19 \tTraining Loss: 0.378892 \tValidation Loss: 2.822979\n",
      "Epoch: 20 \tTraining Loss: 0.347229 \tValidation Loss: 2.846151\n",
      "Epoch: 1 \tTraining Loss: 6.550314 \tValidation Loss: 5.632243\n",
      "Validation loss decreased (inf --> 5.63224).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.952130 \tValidation Loss: 5.414167\n",
      "Validation loss decreased (5.63224 --> 5.41417).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.511012 \tValidation Loss: 5.071410\n",
      "Validation loss decreased (5.41417 --> 5.07141).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.836188 \tValidation Loss: 4.633752\n",
      "Validation loss decreased (5.07141 --> 4.63375).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.026325 \tValidation Loss: 4.195949\n",
      "Validation loss decreased (4.63375 --> 4.19595).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.231027 \tValidation Loss: 3.818143\n",
      "Validation loss decreased (4.19595 --> 3.81814).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.550427 \tValidation Loss: 3.516735\n",
      "Validation loss decreased (3.81814 --> 3.51674).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.014232 \tValidation Loss: 3.287767\n",
      "Validation loss decreased (3.51674 --> 3.28777).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.609154 \tValidation Loss: 3.116387\n",
      "Validation loss decreased (3.28777 --> 3.11639).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.311105 \tValidation Loss: 2.992084\n",
      "Validation loss decreased (3.11639 --> 2.99208).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.087122 \tValidation Loss: 2.905451\n",
      "Validation loss decreased (2.99208 --> 2.90545).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.914823 \tValidation Loss: 2.841380\n",
      "Validation loss decreased (2.90545 --> 2.84138).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.777866 \tValidation Loss: 2.802155\n",
      "Validation loss decreased (2.84138 --> 2.80216).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.674273 \tValidation Loss: 2.775873\n",
      "Validation loss decreased (2.80216 --> 2.77587).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.588694 \tValidation Loss: 2.764658\n",
      "Validation loss decreased (2.77587 --> 2.76466).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.521546 \tValidation Loss: 2.762530\n",
      "Validation loss decreased (2.76466 --> 2.76253).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.465541 \tValidation Loss: 2.768392\n",
      "Epoch: 18 \tTraining Loss: 0.421452 \tValidation Loss: 2.779830\n",
      "Epoch: 19 \tTraining Loss: 0.386714 \tValidation Loss: 2.799390\n",
      "Epoch: 20 \tTraining Loss: 0.354316 \tValidation Loss: 2.818733\n",
      "Epoch: 1 \tTraining Loss: 6.556069 \tValidation Loss: 5.625250\n",
      "Validation loss decreased (inf --> 5.62525).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.952661 \tValidation Loss: 5.407670\n",
      "Validation loss decreased (5.62525 --> 5.40767).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.507890 \tValidation Loss: 5.066112\n",
      "Validation loss decreased (5.40767 --> 5.06611).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.829870 \tValidation Loss: 4.633073\n",
      "Validation loss decreased (5.06611 --> 4.63307).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.018780 \tValidation Loss: 4.201863\n",
      "Validation loss decreased (4.63307 --> 4.20186).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.222763 \tValidation Loss: 3.831757\n",
      "Validation loss decreased (4.20186 --> 3.83176).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.532050 \tValidation Loss: 3.541168\n",
      "Validation loss decreased (3.83176 --> 3.54117).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.995570 \tValidation Loss: 3.321425\n",
      "Validation loss decreased (3.54117 --> 3.32142).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.590589 \tValidation Loss: 3.157606\n",
      "Validation loss decreased (3.32142 --> 3.15761).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.294175 \tValidation Loss: 3.038745\n",
      "Validation loss decreased (3.15761 --> 3.03874).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.071402 \tValidation Loss: 2.953888\n",
      "Validation loss decreased (3.03874 --> 2.95389).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.899260 \tValidation Loss: 2.899847\n",
      "Validation loss decreased (2.95389 --> 2.89985).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.766520 \tValidation Loss: 2.863397\n",
      "Validation loss decreased (2.89985 --> 2.86340).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.662470 \tValidation Loss: 2.842460\n",
      "Validation loss decreased (2.86340 --> 2.84246).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.582171 \tValidation Loss: 2.833349\n",
      "Validation loss decreased (2.84246 --> 2.83335).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.513351 \tValidation Loss: 2.833682\n",
      "Epoch: 17 \tTraining Loss: 0.457612 \tValidation Loss: 2.841540\n",
      "Epoch: 18 \tTraining Loss: 0.414896 \tValidation Loss: 2.856612\n",
      "Epoch: 19 \tTraining Loss: 0.377717 \tValidation Loss: 2.876903\n",
      "Epoch: 20 \tTraining Loss: 0.349021 \tValidation Loss: 2.895055\n",
      "Epoch: 1 \tTraining Loss: 6.556852 \tValidation Loss: 5.610377\n",
      "Validation loss decreased (inf --> 5.61038).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.958611 \tValidation Loss: 5.389374\n",
      "Validation loss decreased (5.61038 --> 5.38937).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.512230 \tValidation Loss: 5.056004\n",
      "Validation loss decreased (5.38937 --> 5.05600).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.835530 \tValidation Loss: 4.636584\n",
      "Validation loss decreased (5.05600 --> 4.63658).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.024289 \tValidation Loss: 4.217422\n",
      "Validation loss decreased (4.63658 --> 4.21742).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 \tTraining Loss: 3.226491 \tValidation Loss: 3.856260\n",
      "Validation loss decreased (4.21742 --> 3.85626).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.547093 \tValidation Loss: 3.566576\n",
      "Validation loss decreased (3.85626 --> 3.56658).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.013473 \tValidation Loss: 3.342928\n",
      "Validation loss decreased (3.56658 --> 3.34293).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.606528 \tValidation Loss: 3.173832\n",
      "Validation loss decreased (3.34293 --> 3.17383).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.309106 \tValidation Loss: 3.047240\n",
      "Validation loss decreased (3.17383 --> 3.04724).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.083978 \tValidation Loss: 2.954001\n",
      "Validation loss decreased (3.04724 --> 2.95400).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.910996 \tValidation Loss: 2.887933\n",
      "Validation loss decreased (2.95400 --> 2.88793).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.775294 \tValidation Loss: 2.841985\n",
      "Validation loss decreased (2.88793 --> 2.84199).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.669005 \tValidation Loss: 2.813293\n",
      "Validation loss decreased (2.84199 --> 2.81329).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.586040 \tValidation Loss: 2.796950\n",
      "Validation loss decreased (2.81329 --> 2.79695).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.517693 \tValidation Loss: 2.789068\n",
      "Validation loss decreased (2.79695 --> 2.78907).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.465569 \tValidation Loss: 2.791070\n",
      "Epoch: 18 \tTraining Loss: 0.419706 \tValidation Loss: 2.798735\n",
      "Epoch: 19 \tTraining Loss: 0.381620 \tValidation Loss: 2.810633\n",
      "Epoch: 20 \tTraining Loss: 0.351522 \tValidation Loss: 2.826551\n",
      "Epoch: 1 \tTraining Loss: 6.562247 \tValidation Loss: 5.640620\n",
      "Validation loss decreased (inf --> 5.64062).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.956029 \tValidation Loss: 5.437938\n",
      "Validation loss decreased (5.64062 --> 5.43794).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.511314 \tValidation Loss: 5.105204\n",
      "Validation loss decreased (5.43794 --> 5.10520).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.829757 \tValidation Loss: 4.674335\n",
      "Validation loss decreased (5.10520 --> 4.67433).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.009469 \tValidation Loss: 4.243473\n",
      "Validation loss decreased (4.67433 --> 4.24347).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.206014 \tValidation Loss: 3.873755\n",
      "Validation loss decreased (4.24347 --> 3.87376).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.525566 \tValidation Loss: 3.577666\n",
      "Validation loss decreased (3.87376 --> 3.57767).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.990972 \tValidation Loss: 3.347861\n",
      "Validation loss decreased (3.57767 --> 3.34786).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.590819 \tValidation Loss: 3.175606\n",
      "Validation loss decreased (3.34786 --> 3.17561).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.292287 \tValidation Loss: 3.048955\n",
      "Validation loss decreased (3.17561 --> 3.04896).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.068746 \tValidation Loss: 2.958848\n",
      "Validation loss decreased (3.04896 --> 2.95885).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.895244 \tValidation Loss: 2.894104\n",
      "Validation loss decreased (2.95885 --> 2.89410).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.763574 \tValidation Loss: 2.851233\n",
      "Validation loss decreased (2.89410 --> 2.85123).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.658001 \tValidation Loss: 2.826379\n",
      "Validation loss decreased (2.85123 --> 2.82638).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.576077 \tValidation Loss: 2.814305\n",
      "Validation loss decreased (2.82638 --> 2.81431).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.508356 \tValidation Loss: 2.811169\n",
      "Validation loss decreased (2.81431 --> 2.81117).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.455350 \tValidation Loss: 2.815347\n",
      "Epoch: 18 \tTraining Loss: 0.411031 \tValidation Loss: 2.828741\n",
      "Epoch: 19 \tTraining Loss: 0.376727 \tValidation Loss: 2.846538\n",
      "Epoch: 20 \tTraining Loss: 0.345987 \tValidation Loss: 2.867640\n",
      "Epoch: 1 \tTraining Loss: 6.562325 \tValidation Loss: 5.586673\n",
      "Validation loss decreased (inf --> 5.58667).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.955250 \tValidation Loss: 5.371760\n",
      "Validation loss decreased (5.58667 --> 5.37176).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.509130 \tValidation Loss: 5.025870\n",
      "Validation loss decreased (5.37176 --> 5.02587).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.829869 \tValidation Loss: 4.594533\n",
      "Validation loss decreased (5.02587 --> 4.59453).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.013138 \tValidation Loss: 4.175054\n",
      "Validation loss decreased (4.59453 --> 4.17505).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.215106 \tValidation Loss: 3.816587\n",
      "Validation loss decreased (4.17505 --> 3.81659).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.533661 \tValidation Loss: 3.531016\n",
      "Validation loss decreased (3.81659 --> 3.53102).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.002537 \tValidation Loss: 3.316988\n",
      "Validation loss decreased (3.53102 --> 3.31699).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.599807 \tValidation Loss: 3.161327\n",
      "Validation loss decreased (3.31699 --> 3.16133).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.301353 \tValidation Loss: 3.049473\n",
      "Validation loss decreased (3.16133 --> 3.04947).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.076117 \tValidation Loss: 2.968544\n",
      "Validation loss decreased (3.04947 --> 2.96854).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.907920 \tValidation Loss: 2.914413\n",
      "Validation loss decreased (2.96854 --> 2.91441).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.771604 \tValidation Loss: 2.879400\n",
      "Validation loss decreased (2.91441 --> 2.87940).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.668265 \tValidation Loss: 2.857066\n",
      "Validation loss decreased (2.87940 --> 2.85707).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.583022 \tValidation Loss: 2.850647\n",
      "Validation loss decreased (2.85707 --> 2.85065).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.518453 \tValidation Loss: 2.851177\n",
      "Epoch: 17 \tTraining Loss: 0.462283 \tValidation Loss: 2.858432\n",
      "Epoch: 18 \tTraining Loss: 0.415758 \tValidation Loss: 2.874696\n",
      "Epoch: 19 \tTraining Loss: 0.382577 \tValidation Loss: 2.893503\n",
      "Epoch: 20 \tTraining Loss: 0.354782 \tValidation Loss: 2.915477\n",
      "Epoch: 1 \tTraining Loss: 6.552080 \tValidation Loss: 5.606239\n",
      "Validation loss decreased (inf --> 5.60624).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.958493 \tValidation Loss: 5.393580\n",
      "Validation loss decreased (5.60624 --> 5.39358).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.516340 \tValidation Loss: 5.054247\n",
      "Validation loss decreased (5.39358 --> 5.05425).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.833028 \tValidation Loss: 4.621387\n",
      "Validation loss decreased (5.05425 --> 4.62139).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.009967 \tValidation Loss: 4.193720\n",
      "Validation loss decreased (4.62139 --> 4.19372).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.207046 \tValidation Loss: 3.832244\n",
      "Validation loss decreased (4.19372 --> 3.83224).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.525466 \tValidation Loss: 3.543750\n",
      "Validation loss decreased (3.83224 --> 3.54375).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.995968 \tValidation Loss: 3.321281\n",
      "Validation loss decreased (3.54375 --> 3.32128).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.596545 \tValidation Loss: 3.155177\n",
      "Validation loss decreased (3.32128 --> 3.15518).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.301012 \tValidation Loss: 3.031224\n",
      "Validation loss decreased (3.15518 --> 3.03122).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.074667 \tValidation Loss: 2.942988\n",
      "Validation loss decreased (3.03122 --> 2.94299).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.900441 \tValidation Loss: 2.879583\n",
      "Validation loss decreased (2.94299 --> 2.87958).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.767826 \tValidation Loss: 2.839077\n",
      "Validation loss decreased (2.87958 --> 2.83908).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.662931 \tValidation Loss: 2.812898\n",
      "Validation loss decreased (2.83908 --> 2.81290).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.580652 \tValidation Loss: 2.801676\n",
      "Validation loss decreased (2.81290 --> 2.80168).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.514264 \tValidation Loss: 2.798318\n",
      "Validation loss decreased (2.80168 --> 2.79832).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 \tTraining Loss: 0.458168 \tValidation Loss: 2.803637\n",
      "Epoch: 18 \tTraining Loss: 0.414285 \tValidation Loss: 2.818436\n",
      "Epoch: 19 \tTraining Loss: 0.378718 \tValidation Loss: 2.833052\n",
      "Epoch: 20 \tTraining Loss: 0.348162 \tValidation Loss: 2.852832\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 6 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.639942 \tValidation Loss: 6.111496\n",
      "Validation loss decreased (inf --> 6.11150).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.977563 \tValidation Loss: 5.842026\n",
      "Validation loss decreased (6.11150 --> 5.84203).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.446461 \tValidation Loss: 5.412460\n",
      "Validation loss decreased (5.84203 --> 5.41246).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.647106 \tValidation Loss: 4.865343\n",
      "Validation loss decreased (5.41246 --> 4.86534).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.724356 \tValidation Loss: 4.331803\n",
      "Validation loss decreased (4.86534 --> 4.33180).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.874869 \tValidation Loss: 3.887812\n",
      "Validation loss decreased (4.33180 --> 3.88781).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.189139 \tValidation Loss: 3.540984\n",
      "Validation loss decreased (3.88781 --> 3.54098).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.681635 \tValidation Loss: 3.285329\n",
      "Validation loss decreased (3.54098 --> 3.28533).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.312896 \tValidation Loss: 3.097837\n",
      "Validation loss decreased (3.28533 --> 3.09784).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.045068 \tValidation Loss: 2.965027\n",
      "Validation loss decreased (3.09784 --> 2.96503).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.840911 \tValidation Loss: 2.870575\n",
      "Validation loss decreased (2.96503 --> 2.87057).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.687203 \tValidation Loss: 2.806673\n",
      "Validation loss decreased (2.87057 --> 2.80667).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.568331 \tValidation Loss: 2.763269\n",
      "Validation loss decreased (2.80667 --> 2.76327).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.478308 \tValidation Loss: 2.737068\n",
      "Validation loss decreased (2.76327 --> 2.73707).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.406804 \tValidation Loss: 2.721486\n",
      "Validation loss decreased (2.73707 --> 2.72149).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.350642 \tValidation Loss: 2.718413\n",
      "Validation loss decreased (2.72149 --> 2.71841).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.306914 \tValidation Loss: 2.721392\n",
      "Epoch: 18 \tTraining Loss: 0.273098 \tValidation Loss: 2.729365\n",
      "Epoch: 19 \tTraining Loss: 0.248060 \tValidation Loss: 2.743119\n",
      "Epoch: 20 \tTraining Loss: 0.222593 \tValidation Loss: 2.758614\n",
      "Epoch: 1 \tTraining Loss: 6.637525 \tValidation Loss: 6.118555\n",
      "Validation loss decreased (inf --> 6.11856).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.987703 \tValidation Loss: 5.832892\n",
      "Validation loss decreased (6.11856 --> 5.83289).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.460746 \tValidation Loss: 5.379313\n",
      "Validation loss decreased (5.83289 --> 5.37931).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.658337 \tValidation Loss: 4.810633\n",
      "Validation loss decreased (5.37931 --> 4.81063).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.728478 \tValidation Loss: 4.262116\n",
      "Validation loss decreased (4.81063 --> 4.26212).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.873640 \tValidation Loss: 3.811026\n",
      "Validation loss decreased (4.26212 --> 3.81103).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.187814 \tValidation Loss: 3.461636\n",
      "Validation loss decreased (3.81103 --> 3.46164).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.680980 \tValidation Loss: 3.204239\n",
      "Validation loss decreased (3.46164 --> 3.20424).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.314863 \tValidation Loss: 3.017753\n",
      "Validation loss decreased (3.20424 --> 3.01775).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.042689 \tValidation Loss: 2.883248\n",
      "Validation loss decreased (3.01775 --> 2.88325).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.842617 \tValidation Loss: 2.790356\n",
      "Validation loss decreased (2.88325 --> 2.79036).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.688665 \tValidation Loss: 2.726483\n",
      "Validation loss decreased (2.79036 --> 2.72648).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.572022 \tValidation Loss: 2.682439\n",
      "Validation loss decreased (2.72648 --> 2.68244).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.478977 \tValidation Loss: 2.656226\n",
      "Validation loss decreased (2.68244 --> 2.65623).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.411786 \tValidation Loss: 2.643767\n",
      "Validation loss decreased (2.65623 --> 2.64377).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.355197 \tValidation Loss: 2.639158\n",
      "Validation loss decreased (2.64377 --> 2.63916).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.311659 \tValidation Loss: 2.645126\n",
      "Epoch: 18 \tTraining Loss: 0.276246 \tValidation Loss: 2.649876\n",
      "Epoch: 19 \tTraining Loss: 0.246012 \tValidation Loss: 2.664731\n",
      "Epoch: 20 \tTraining Loss: 0.228057 \tValidation Loss: 2.675120\n",
      "Epoch: 1 \tTraining Loss: 6.639195 \tValidation Loss: 6.152699\n",
      "Validation loss decreased (inf --> 6.15270).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.967927 \tValidation Loss: 5.867317\n",
      "Validation loss decreased (6.15270 --> 5.86732).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.426744 \tValidation Loss: 5.417791\n",
      "Validation loss decreased (5.86732 --> 5.41779).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.613130 \tValidation Loss: 4.851360\n",
      "Validation loss decreased (5.41779 --> 4.85136).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.687361 \tValidation Loss: 4.316591\n",
      "Validation loss decreased (4.85136 --> 4.31659).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.839292 \tValidation Loss: 3.877647\n",
      "Validation loss decreased (4.31659 --> 3.87765).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.165917 \tValidation Loss: 3.540865\n",
      "Validation loss decreased (3.87765 --> 3.54086).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.664601 \tValidation Loss: 3.290309\n",
      "Validation loss decreased (3.54086 --> 3.29031).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.300872 \tValidation Loss: 3.109330\n",
      "Validation loss decreased (3.29031 --> 3.10933).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.033622 \tValidation Loss: 2.977085\n",
      "Validation loss decreased (3.10933 --> 2.97708).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.835011 \tValidation Loss: 2.884294\n",
      "Validation loss decreased (2.97708 --> 2.88429).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.678310 \tValidation Loss: 2.817767\n",
      "Validation loss decreased (2.88429 --> 2.81777).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.562321 \tValidation Loss: 2.773409\n",
      "Validation loss decreased (2.81777 --> 2.77341).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.473244 \tValidation Loss: 2.748141\n",
      "Validation loss decreased (2.77341 --> 2.74814).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.402856 \tValidation Loss: 2.735031\n",
      "Validation loss decreased (2.74814 --> 2.73503).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.347822 \tValidation Loss: 2.727808\n",
      "Validation loss decreased (2.73503 --> 2.72781).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.305685 \tValidation Loss: 2.733594\n",
      "Epoch: 18 \tTraining Loss: 0.272291 \tValidation Loss: 2.744320\n",
      "Epoch: 19 \tTraining Loss: 0.245339 \tValidation Loss: 2.755902\n",
      "Epoch: 20 \tTraining Loss: 0.222322 \tValidation Loss: 2.773125\n",
      "Epoch: 1 \tTraining Loss: 6.636783 \tValidation Loss: 6.150211\n",
      "Validation loss decreased (inf --> 6.15021).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.979381 \tValidation Loss: 5.868367\n",
      "Validation loss decreased (6.15021 --> 5.86837).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.442943 \tValidation Loss: 5.419045\n",
      "Validation loss decreased (5.86837 --> 5.41904).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.638463 \tValidation Loss: 4.853269\n",
      "Validation loss decreased (5.41904 --> 4.85327).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.712449 \tValidation Loss: 4.311781\n",
      "Validation loss decreased (4.85327 --> 4.31178).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.861016 \tValidation Loss: 3.861615\n",
      "Validation loss decreased (4.31178 --> 3.86162).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.185789 \tValidation Loss: 3.511181\n",
      "Validation loss decreased (3.86162 --> 3.51118).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.680445 \tValidation Loss: 3.250136\n",
      "Validation loss decreased (3.51118 --> 3.25014).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 \tTraining Loss: 1.312716 \tValidation Loss: 3.058524\n",
      "Validation loss decreased (3.25014 --> 3.05852).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.043076 \tValidation Loss: 2.920171\n",
      "Validation loss decreased (3.05852 --> 2.92017).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.841745 \tValidation Loss: 2.822355\n",
      "Validation loss decreased (2.92017 --> 2.82236).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.687180 \tValidation Loss: 2.752936\n",
      "Validation loss decreased (2.82236 --> 2.75294).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.571771 \tValidation Loss: 2.700596\n",
      "Validation loss decreased (2.75294 --> 2.70060).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.476711 \tValidation Loss: 2.670771\n",
      "Validation loss decreased (2.70060 --> 2.67077).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.408632 \tValidation Loss: 2.657222\n",
      "Validation loss decreased (2.67077 --> 2.65722).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.352063 \tValidation Loss: 2.650416\n",
      "Validation loss decreased (2.65722 --> 2.65042).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.308509 \tValidation Loss: 2.653916\n",
      "Epoch: 18 \tTraining Loss: 0.272689 \tValidation Loss: 2.663380\n",
      "Epoch: 19 \tTraining Loss: 0.247341 \tValidation Loss: 2.675777\n",
      "Epoch: 20 \tTraining Loss: 0.222740 \tValidation Loss: 2.690069\n",
      "Epoch: 1 \tTraining Loss: 6.636518 \tValidation Loss: 6.101020\n",
      "Validation loss decreased (inf --> 6.10102).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.975215 \tValidation Loss: 5.833263\n",
      "Validation loss decreased (6.10102 --> 5.83326).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.443382 \tValidation Loss: 5.406635\n",
      "Validation loss decreased (5.83326 --> 5.40664).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.643468 \tValidation Loss: 4.862239\n",
      "Validation loss decreased (5.40664 --> 4.86224).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.722971 \tValidation Loss: 4.332929\n",
      "Validation loss decreased (4.86224 --> 4.33293).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.871830 \tValidation Loss: 3.893918\n",
      "Validation loss decreased (4.33293 --> 3.89392).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.188263 \tValidation Loss: 3.559473\n",
      "Validation loss decreased (3.89392 --> 3.55947).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.686929 \tValidation Loss: 3.312665\n",
      "Validation loss decreased (3.55947 --> 3.31267).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.319153 \tValidation Loss: 3.129808\n",
      "Validation loss decreased (3.31267 --> 3.12981).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.047992 \tValidation Loss: 2.997727\n",
      "Validation loss decreased (3.12981 --> 2.99773).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.848798 \tValidation Loss: 2.900874\n",
      "Validation loss decreased (2.99773 --> 2.90087).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.693129 \tValidation Loss: 2.831663\n",
      "Validation loss decreased (2.90087 --> 2.83166).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.574406 \tValidation Loss: 2.786227\n",
      "Validation loss decreased (2.83166 --> 2.78623).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.481708 \tValidation Loss: 2.755498\n",
      "Validation loss decreased (2.78623 --> 2.75550).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.410433 \tValidation Loss: 2.741961\n",
      "Validation loss decreased (2.75550 --> 2.74196).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.354771 \tValidation Loss: 2.737253\n",
      "Validation loss decreased (2.74196 --> 2.73725).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.310956 \tValidation Loss: 2.737084\n",
      "Validation loss decreased (2.73725 --> 2.73708).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.275537 \tValidation Loss: 2.744861\n",
      "Epoch: 19 \tTraining Loss: 0.246534 \tValidation Loss: 2.764382\n",
      "Epoch: 20 \tTraining Loss: 0.227032 \tValidation Loss: 2.778612\n",
      "Epoch: 1 \tTraining Loss: 6.636160 \tValidation Loss: 6.188717\n",
      "Validation loss decreased (inf --> 6.18872).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.969124 \tValidation Loss: 5.902965\n",
      "Validation loss decreased (6.18872 --> 5.90297).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.429197 \tValidation Loss: 5.461810\n",
      "Validation loss decreased (5.90297 --> 5.46181).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.621999 \tValidation Loss: 4.903723\n",
      "Validation loss decreased (5.46181 --> 4.90372).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.700025 \tValidation Loss: 4.361685\n",
      "Validation loss decreased (4.90372 --> 4.36168).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.858160 \tValidation Loss: 3.907365\n",
      "Validation loss decreased (4.36168 --> 3.90736).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.180247 \tValidation Loss: 3.554213\n",
      "Validation loss decreased (3.90736 --> 3.55421).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.675349 \tValidation Loss: 3.292666\n",
      "Validation loss decreased (3.55421 --> 3.29267).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.307195 \tValidation Loss: 3.101150\n",
      "Validation loss decreased (3.29267 --> 3.10115).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.037239 \tValidation Loss: 2.967283\n",
      "Validation loss decreased (3.10115 --> 2.96728).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.836614 \tValidation Loss: 2.875699\n",
      "Validation loss decreased (2.96728 --> 2.87570).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.682785 \tValidation Loss: 2.813934\n",
      "Validation loss decreased (2.87570 --> 2.81393).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.563200 \tValidation Loss: 2.776767\n",
      "Validation loss decreased (2.81393 --> 2.77677).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.476873 \tValidation Loss: 2.753076\n",
      "Validation loss decreased (2.77677 --> 2.75308).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.405893 \tValidation Loss: 2.741083\n",
      "Validation loss decreased (2.75308 --> 2.74108).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.348853 \tValidation Loss: 2.743869\n",
      "Epoch: 17 \tTraining Loss: 0.303645 \tValidation Loss: 2.748723\n",
      "Epoch: 18 \tTraining Loss: 0.270377 \tValidation Loss: 2.756652\n",
      "Epoch: 19 \tTraining Loss: 0.244094 \tValidation Loss: 2.772249\n",
      "Epoch: 20 \tTraining Loss: 0.223021 \tValidation Loss: 2.791787\n",
      "Epoch: 1 \tTraining Loss: 6.634541 \tValidation Loss: 6.135501\n",
      "Validation loss decreased (inf --> 6.13550).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.978724 \tValidation Loss: 5.860480\n",
      "Validation loss decreased (6.13550 --> 5.86048).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.448178 \tValidation Loss: 5.419382\n",
      "Validation loss decreased (5.86048 --> 5.41938).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.642494 \tValidation Loss: 4.861108\n",
      "Validation loss decreased (5.41938 --> 4.86111).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.709391 \tValidation Loss: 4.324414\n",
      "Validation loss decreased (4.86111 --> 4.32441).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.854094 \tValidation Loss: 3.884208\n",
      "Validation loss decreased (4.32441 --> 3.88421).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.171631 \tValidation Loss: 3.549149\n",
      "Validation loss decreased (3.88421 --> 3.54915).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.667321 \tValidation Loss: 3.304155\n",
      "Validation loss decreased (3.54915 --> 3.30415).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.303531 \tValidation Loss: 3.127601\n",
      "Validation loss decreased (3.30415 --> 3.12760).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.032547 \tValidation Loss: 2.999190\n",
      "Validation loss decreased (3.12760 --> 2.99919).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.833984 \tValidation Loss: 2.909923\n",
      "Validation loss decreased (2.99919 --> 2.90992).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.683410 \tValidation Loss: 2.844921\n",
      "Validation loss decreased (2.90992 --> 2.84492).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.566790 \tValidation Loss: 2.803360\n",
      "Validation loss decreased (2.84492 --> 2.80336).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.476798 \tValidation Loss: 2.777081\n",
      "Validation loss decreased (2.80336 --> 2.77708).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.408159 \tValidation Loss: 2.766496\n",
      "Validation loss decreased (2.77708 --> 2.76650).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.351409 \tValidation Loss: 2.761438\n",
      "Validation loss decreased (2.76650 --> 2.76144).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.307076 \tValidation Loss: 2.765525\n",
      "Epoch: 18 \tTraining Loss: 0.274165 \tValidation Loss: 2.775526\n",
      "Epoch: 19 \tTraining Loss: 0.247633 \tValidation Loss: 2.784663\n",
      "Epoch: 20 \tTraining Loss: 0.224424 \tValidation Loss: 2.803309\n",
      "Epoch: 1 \tTraining Loss: 6.638159 \tValidation Loss: 6.133702\n",
      "Validation loss decreased (inf --> 6.13370).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 5.981352 \tValidation Loss: 5.847090\n",
      "Validation loss decreased (6.13370 --> 5.84709).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.454782 \tValidation Loss: 5.388968\n",
      "Validation loss decreased (5.84709 --> 5.38897).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.652585 \tValidation Loss: 4.814865\n",
      "Validation loss decreased (5.38897 --> 4.81487).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.723622 \tValidation Loss: 4.271150\n",
      "Validation loss decreased (4.81487 --> 4.27115).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.871693 \tValidation Loss: 3.821336\n",
      "Validation loss decreased (4.27115 --> 3.82134).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.188113 \tValidation Loss: 3.476978\n",
      "Validation loss decreased (3.82134 --> 3.47698).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.684143 \tValidation Loss: 3.218420\n",
      "Validation loss decreased (3.47698 --> 3.21842).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.312606 \tValidation Loss: 3.030834\n",
      "Validation loss decreased (3.21842 --> 3.03083).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.045057 \tValidation Loss: 2.892611\n",
      "Validation loss decreased (3.03083 --> 2.89261).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.842942 \tValidation Loss: 2.793638\n",
      "Validation loss decreased (2.89261 --> 2.79364).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.690347 \tValidation Loss: 2.719260\n",
      "Validation loss decreased (2.79364 --> 2.71926).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.570116 \tValidation Loss: 2.673289\n",
      "Validation loss decreased (2.71926 --> 2.67329).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.479430 \tValidation Loss: 2.642946\n",
      "Validation loss decreased (2.67329 --> 2.64295).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.410659 \tValidation Loss: 2.624202\n",
      "Validation loss decreased (2.64295 --> 2.62420).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.352772 \tValidation Loss: 2.617450\n",
      "Validation loss decreased (2.62420 --> 2.61745).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.312823 \tValidation Loss: 2.615576\n",
      "Validation loss decreased (2.61745 --> 2.61558).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.277576 \tValidation Loss: 2.623202\n",
      "Epoch: 19 \tTraining Loss: 0.249549 \tValidation Loss: 2.635106\n",
      "Epoch: 20 \tTraining Loss: 0.227223 \tValidation Loss: 2.649609\n",
      "Epoch: 1 \tTraining Loss: 6.650015 \tValidation Loss: 6.073082\n",
      "Validation loss decreased (inf --> 6.07308).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.979826 \tValidation Loss: 5.799144\n",
      "Validation loss decreased (6.07308 --> 5.79914).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.446571 \tValidation Loss: 5.361082\n",
      "Validation loss decreased (5.79914 --> 5.36108).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.637326 \tValidation Loss: 4.809114\n",
      "Validation loss decreased (5.36108 --> 4.80911).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.705529 \tValidation Loss: 4.273212\n",
      "Validation loss decreased (4.80911 --> 4.27321).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.849550 \tValidation Loss: 3.829467\n",
      "Validation loss decreased (4.27321 --> 3.82947).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.167779 \tValidation Loss: 3.492784\n",
      "Validation loss decreased (3.82947 --> 3.49278).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.662327 \tValidation Loss: 3.245846\n",
      "Validation loss decreased (3.49278 --> 3.24585).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.295437 \tValidation Loss: 3.067370\n",
      "Validation loss decreased (3.24585 --> 3.06737).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.031031 \tValidation Loss: 2.938564\n",
      "Validation loss decreased (3.06737 --> 2.93856).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.831458 \tValidation Loss: 2.844743\n",
      "Validation loss decreased (2.93856 --> 2.84474).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.680953 \tValidation Loss: 2.780762\n",
      "Validation loss decreased (2.84474 --> 2.78076).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.563995 \tValidation Loss: 2.736494\n",
      "Validation loss decreased (2.78076 --> 2.73649).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.473050 \tValidation Loss: 2.714012\n",
      "Validation loss decreased (2.73649 --> 2.71401).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.404955 \tValidation Loss: 2.698357\n",
      "Validation loss decreased (2.71401 --> 2.69836).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.347691 \tValidation Loss: 2.694145\n",
      "Validation loss decreased (2.69836 --> 2.69415).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.305808 \tValidation Loss: 2.696260\n",
      "Epoch: 18 \tTraining Loss: 0.270878 \tValidation Loss: 2.702077\n",
      "Epoch: 19 \tTraining Loss: 0.243772 \tValidation Loss: 2.719849\n",
      "Epoch: 20 \tTraining Loss: 0.222870 \tValidation Loss: 2.732016\n",
      "Epoch: 1 \tTraining Loss: 6.639082 \tValidation Loss: 6.134167\n",
      "Validation loss decreased (inf --> 6.13417).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.979977 \tValidation Loss: 5.853809\n",
      "Validation loss decreased (6.13417 --> 5.85381).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.448173 \tValidation Loss: 5.415922\n",
      "Validation loss decreased (5.85381 --> 5.41592).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.644266 \tValidation Loss: 4.856709\n",
      "Validation loss decreased (5.41592 --> 4.85671).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.714320 \tValidation Loss: 4.318333\n",
      "Validation loss decreased (4.85671 --> 4.31833).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.860784 \tValidation Loss: 3.868869\n",
      "Validation loss decreased (4.31833 --> 3.86887).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.176980 \tValidation Loss: 3.523880\n",
      "Validation loss decreased (3.86887 --> 3.52388).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.668128 \tValidation Loss: 3.270157\n",
      "Validation loss decreased (3.52388 --> 3.27016).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.302980 \tValidation Loss: 3.084837\n",
      "Validation loss decreased (3.27016 --> 3.08484).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.033272 \tValidation Loss: 2.950991\n",
      "Validation loss decreased (3.08484 --> 2.95099).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.830803 \tValidation Loss: 2.856372\n",
      "Validation loss decreased (2.95099 --> 2.85637).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.681871 \tValidation Loss: 2.790702\n",
      "Validation loss decreased (2.85637 --> 2.79070).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.564393 \tValidation Loss: 2.747240\n",
      "Validation loss decreased (2.79070 --> 2.74724).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.472133 \tValidation Loss: 2.721311\n",
      "Validation loss decreased (2.74724 --> 2.72131).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.403699 \tValidation Loss: 2.704473\n",
      "Validation loss decreased (2.72131 --> 2.70447).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.348304 \tValidation Loss: 2.700035\n",
      "Validation loss decreased (2.70447 --> 2.70003).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.306530 \tValidation Loss: 2.701711\n",
      "Epoch: 18 \tTraining Loss: 0.270233 \tValidation Loss: 2.709086\n",
      "Epoch: 19 \tTraining Loss: 0.244772 \tValidation Loss: 2.719901\n",
      "Epoch: 20 \tTraining Loss: 0.222881 \tValidation Loss: 2.732943\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 7 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.563687 \tValidation Loss: 5.933230\n",
      "Validation loss decreased (inf --> 5.93323).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.874145 \tValidation Loss: 5.631723\n",
      "Validation loss decreased (5.93323 --> 5.63172).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.331326 \tValidation Loss: 5.184123\n",
      "Validation loss decreased (5.63172 --> 5.18412).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.528826 \tValidation Loss: 4.612759\n",
      "Validation loss decreased (5.18412 --> 4.61276).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.595104 \tValidation Loss: 4.059918\n",
      "Validation loss decreased (4.61276 --> 4.05992).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.730203 \tValidation Loss: 3.602613\n",
      "Validation loss decreased (4.05992 --> 3.60261).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.050127 \tValidation Loss: 3.255409\n",
      "Validation loss decreased (3.60261 --> 3.25541).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.552968 \tValidation Loss: 2.998595\n",
      "Validation loss decreased (3.25541 --> 2.99860).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.192627 \tValidation Loss: 2.812301\n",
      "Validation loss decreased (2.99860 --> 2.81230).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.931977 \tValidation Loss: 2.678282\n",
      "Validation loss decreased (2.81230 --> 2.67828).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.737031 \tValidation Loss: 2.580451\n",
      "Validation loss decreased (2.67828 --> 2.58045).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 \tTraining Loss: 0.588547 \tValidation Loss: 2.510524\n",
      "Validation loss decreased (2.58045 --> 2.51052).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.475128 \tValidation Loss: 2.461066\n",
      "Validation loss decreased (2.51052 --> 2.46107).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.389048 \tValidation Loss: 2.431495\n",
      "Validation loss decreased (2.46107 --> 2.43150).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.323849 \tValidation Loss: 2.412855\n",
      "Validation loss decreased (2.43150 --> 2.41286).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.275495 \tValidation Loss: 2.402404\n",
      "Validation loss decreased (2.41286 --> 2.40240).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.236690 \tValidation Loss: 2.398983\n",
      "Validation loss decreased (2.40240 --> 2.39898).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.208020 \tValidation Loss: 2.399777\n",
      "Epoch: 19 \tTraining Loss: 0.186320 \tValidation Loss: 2.405819\n",
      "Epoch: 20 \tTraining Loss: 0.166518 \tValidation Loss: 2.416728\n",
      "Epoch: 1 \tTraining Loss: 6.570568 \tValidation Loss: 5.912584\n",
      "Validation loss decreased (inf --> 5.91258).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.876303 \tValidation Loss: 5.624362\n",
      "Validation loss decreased (5.91258 --> 5.62436).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.330473 \tValidation Loss: 5.202338\n",
      "Validation loss decreased (5.62436 --> 5.20234).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.511166 \tValidation Loss: 4.652571\n",
      "Validation loss decreased (5.20234 --> 4.65257).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.567748 \tValidation Loss: 4.104078\n",
      "Validation loss decreased (4.65257 --> 4.10408).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.708004 \tValidation Loss: 3.645119\n",
      "Validation loss decreased (4.10408 --> 3.64512).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.031724 \tValidation Loss: 3.300310\n",
      "Validation loss decreased (3.64512 --> 3.30031).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.540086 \tValidation Loss: 3.046871\n",
      "Validation loss decreased (3.30031 --> 3.04687).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.182570 \tValidation Loss: 2.862521\n",
      "Validation loss decreased (3.04687 --> 2.86252).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.923685 \tValidation Loss: 2.726775\n",
      "Validation loss decreased (2.86252 --> 2.72677).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.726727 \tValidation Loss: 2.628160\n",
      "Validation loss decreased (2.72677 --> 2.62816).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.579814 \tValidation Loss: 2.557834\n",
      "Validation loss decreased (2.62816 --> 2.55783).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.466451 \tValidation Loss: 2.509794\n",
      "Validation loss decreased (2.55783 --> 2.50979).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.380956 \tValidation Loss: 2.480278\n",
      "Validation loss decreased (2.50979 --> 2.48028).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.315965 \tValidation Loss: 2.463918\n",
      "Validation loss decreased (2.48028 --> 2.46392).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.267200 \tValidation Loss: 2.458085\n",
      "Validation loss decreased (2.46392 --> 2.45808).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.231854 \tValidation Loss: 2.456197\n",
      "Validation loss decreased (2.45808 --> 2.45620).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.204482 \tValidation Loss: 2.459726\n",
      "Epoch: 19 \tTraining Loss: 0.179397 \tValidation Loss: 2.470971\n",
      "Epoch: 20 \tTraining Loss: 0.163810 \tValidation Loss: 2.480218\n",
      "Epoch: 1 \tTraining Loss: 6.575393 \tValidation Loss: 5.903568\n",
      "Validation loss decreased (inf --> 5.90357).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.880501 \tValidation Loss: 5.601836\n",
      "Validation loss decreased (5.90357 --> 5.60184).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.333027 \tValidation Loss: 5.150181\n",
      "Validation loss decreased (5.60184 --> 5.15018).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.518768 \tValidation Loss: 4.588331\n",
      "Validation loss decreased (5.15018 --> 4.58833).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.578444 \tValidation Loss: 4.044754\n",
      "Validation loss decreased (4.58833 --> 4.04475).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.718094 \tValidation Loss: 3.604126\n",
      "Validation loss decreased (4.04475 --> 3.60413).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.044118 \tValidation Loss: 3.272202\n",
      "Validation loss decreased (3.60413 --> 3.27220).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.549129 \tValidation Loss: 3.027286\n",
      "Validation loss decreased (3.27220 --> 3.02729).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.192516 \tValidation Loss: 2.845286\n",
      "Validation loss decreased (3.02729 --> 2.84529).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.926266 \tValidation Loss: 2.713320\n",
      "Validation loss decreased (2.84529 --> 2.71332).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.728834 \tValidation Loss: 2.614039\n",
      "Validation loss decreased (2.71332 --> 2.61404).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.582631 \tValidation Loss: 2.543511\n",
      "Validation loss decreased (2.61404 --> 2.54351).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.470544 \tValidation Loss: 2.496373\n",
      "Validation loss decreased (2.54351 --> 2.49637).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.386537 \tValidation Loss: 2.466773\n",
      "Validation loss decreased (2.49637 --> 2.46677).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.321057 \tValidation Loss: 2.453146\n",
      "Validation loss decreased (2.46677 --> 2.45315).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.272782 \tValidation Loss: 2.448526\n",
      "Validation loss decreased (2.45315 --> 2.44853).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.234287 \tValidation Loss: 2.452018\n",
      "Epoch: 18 \tTraining Loss: 0.204761 \tValidation Loss: 2.456750\n",
      "Epoch: 19 \tTraining Loss: 0.182383 \tValidation Loss: 2.461636\n",
      "Epoch: 20 \tTraining Loss: 0.164459 \tValidation Loss: 2.473039\n",
      "Epoch: 1 \tTraining Loss: 6.565658 \tValidation Loss: 5.954340\n",
      "Validation loss decreased (inf --> 5.95434).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.871976 \tValidation Loss: 5.648086\n",
      "Validation loss decreased (5.95434 --> 5.64809).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.325181 \tValidation Loss: 5.208336\n",
      "Validation loss decreased (5.64809 --> 5.20834).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.518960 \tValidation Loss: 4.653957\n",
      "Validation loss decreased (5.20834 --> 4.65396).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.585565 \tValidation Loss: 4.109918\n",
      "Validation loss decreased (4.65396 --> 4.10992).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.728572 \tValidation Loss: 3.666064\n",
      "Validation loss decreased (4.10992 --> 3.66606).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.049603 \tValidation Loss: 3.337994\n",
      "Validation loss decreased (3.66606 --> 3.33799).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.554617 \tValidation Loss: 3.099325\n",
      "Validation loss decreased (3.33799 --> 3.09933).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.198460 \tValidation Loss: 2.926389\n",
      "Validation loss decreased (3.09933 --> 2.92639).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.932354 \tValidation Loss: 2.798887\n",
      "Validation loss decreased (2.92639 --> 2.79889).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.735566 \tValidation Loss: 2.708294\n",
      "Validation loss decreased (2.79889 --> 2.70829).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.586721 \tValidation Loss: 2.642919\n",
      "Validation loss decreased (2.70829 --> 2.64292).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.474120 \tValidation Loss: 2.596402\n",
      "Validation loss decreased (2.64292 --> 2.59640).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.388349 \tValidation Loss: 2.570231\n",
      "Validation loss decreased (2.59640 --> 2.57023).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.321488 \tValidation Loss: 2.558465\n",
      "Validation loss decreased (2.57023 --> 2.55847).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.272615 \tValidation Loss: 2.549877\n",
      "Validation loss decreased (2.55847 --> 2.54988).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.236167 \tValidation Loss: 2.548798\n",
      "Validation loss decreased (2.54988 --> 2.54880).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.204676 \tValidation Loss: 2.559306\n",
      "Epoch: 19 \tTraining Loss: 0.181763 \tValidation Loss: 2.567430\n",
      "Epoch: 20 \tTraining Loss: 0.165307 \tValidation Loss: 2.580114\n",
      "Epoch: 1 \tTraining Loss: 6.563237 \tValidation Loss: 5.952177\n",
      "Validation loss decreased (inf --> 5.95218).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.880699 \tValidation Loss: 5.650414\n",
      "Validation loss decreased (5.95218 --> 5.65041).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \tTraining Loss: 5.338773 \tValidation Loss: 5.207685\n",
      "Validation loss decreased (5.65041 --> 5.20769).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.526411 \tValidation Loss: 4.644579\n",
      "Validation loss decreased (5.20769 --> 4.64458).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.580192 \tValidation Loss: 4.097191\n",
      "Validation loss decreased (4.64458 --> 4.09719).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.713473 \tValidation Loss: 3.657353\n",
      "Validation loss decreased (4.09719 --> 3.65735).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.041291 \tValidation Loss: 3.333252\n",
      "Validation loss decreased (3.65735 --> 3.33325).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.547123 \tValidation Loss: 3.098779\n",
      "Validation loss decreased (3.33325 --> 3.09878).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.188355 \tValidation Loss: 2.927815\n",
      "Validation loss decreased (3.09878 --> 2.92782).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.923082 \tValidation Loss: 2.803166\n",
      "Validation loss decreased (2.92782 --> 2.80317).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.728883 \tValidation Loss: 2.711890\n",
      "Validation loss decreased (2.80317 --> 2.71189).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.580587 \tValidation Loss: 2.649218\n",
      "Validation loss decreased (2.71189 --> 2.64922).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.471282 \tValidation Loss: 2.608201\n",
      "Validation loss decreased (2.64922 --> 2.60820).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.382220 \tValidation Loss: 2.582980\n",
      "Validation loss decreased (2.60820 --> 2.58298).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.318945 \tValidation Loss: 2.572028\n",
      "Validation loss decreased (2.58298 --> 2.57203).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.270376 \tValidation Loss: 2.567039\n",
      "Validation loss decreased (2.57203 --> 2.56704).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.232380 \tValidation Loss: 2.569439\n",
      "Epoch: 18 \tTraining Loss: 0.202256 \tValidation Loss: 2.579253\n",
      "Epoch: 19 \tTraining Loss: 0.182802 \tValidation Loss: 2.591022\n",
      "Epoch: 20 \tTraining Loss: 0.162702 \tValidation Loss: 2.600261\n",
      "Epoch: 1 \tTraining Loss: 6.573695 \tValidation Loss: 5.895305\n",
      "Validation loss decreased (inf --> 5.89530).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.877071 \tValidation Loss: 5.611335\n",
      "Validation loss decreased (5.89530 --> 5.61134).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.331012 \tValidation Loss: 5.169775\n",
      "Validation loss decreased (5.61134 --> 5.16977).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.516975 \tValidation Loss: 4.612518\n",
      "Validation loss decreased (5.16977 --> 4.61252).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.576604 \tValidation Loss: 4.065521\n",
      "Validation loss decreased (4.61252 --> 4.06552).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.720966 \tValidation Loss: 3.618865\n",
      "Validation loss decreased (4.06552 --> 3.61886).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.047603 \tValidation Loss: 3.280669\n",
      "Validation loss decreased (3.61886 --> 3.28067).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.550374 \tValidation Loss: 3.031498\n",
      "Validation loss decreased (3.28067 --> 3.03150).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.194043 \tValidation Loss: 2.850860\n",
      "Validation loss decreased (3.03150 --> 2.85086).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.927477 \tValidation Loss: 2.719635\n",
      "Validation loss decreased (2.85086 --> 2.71964).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.734825 \tValidation Loss: 2.626080\n",
      "Validation loss decreased (2.71964 --> 2.62608).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.584078 \tValidation Loss: 2.562478\n",
      "Validation loss decreased (2.62608 --> 2.56248).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.471151 \tValidation Loss: 2.520781\n",
      "Validation loss decreased (2.56248 --> 2.52078).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.384466 \tValidation Loss: 2.492353\n",
      "Validation loss decreased (2.52078 --> 2.49235).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.320135 \tValidation Loss: 2.478671\n",
      "Validation loss decreased (2.49235 --> 2.47867).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.271508 \tValidation Loss: 2.470760\n",
      "Validation loss decreased (2.47867 --> 2.47076).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.232550 \tValidation Loss: 2.469456\n",
      "Validation loss decreased (2.47076 --> 2.46946).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.203876 \tValidation Loss: 2.471473\n",
      "Epoch: 19 \tTraining Loss: 0.182753 \tValidation Loss: 2.481618\n",
      "Epoch: 20 \tTraining Loss: 0.163408 \tValidation Loss: 2.489373\n",
      "Epoch: 1 \tTraining Loss: 6.570980 \tValidation Loss: 5.987856\n",
      "Validation loss decreased (inf --> 5.98786).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.869515 \tValidation Loss: 5.685415\n",
      "Validation loss decreased (5.98786 --> 5.68541).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.318057 \tValidation Loss: 5.245118\n",
      "Validation loss decreased (5.68541 --> 5.24512).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.508421 \tValidation Loss: 4.688938\n",
      "Validation loss decreased (5.24512 --> 4.68894).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.579819 \tValidation Loss: 4.136361\n",
      "Validation loss decreased (4.68894 --> 4.13636).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.727684 \tValidation Loss: 3.665424\n",
      "Validation loss decreased (4.13636 --> 3.66542).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.054343 \tValidation Loss: 3.304187\n",
      "Validation loss decreased (3.66542 --> 3.30419).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.555186 \tValidation Loss: 3.036143\n",
      "Validation loss decreased (3.30419 --> 3.03614).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.193832 \tValidation Loss: 2.840355\n",
      "Validation loss decreased (3.03614 --> 2.84036).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.929330 \tValidation Loss: 2.699294\n",
      "Validation loss decreased (2.84036 --> 2.69929).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.735286 \tValidation Loss: 2.598787\n",
      "Validation loss decreased (2.69929 --> 2.59879).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.582380 \tValidation Loss: 2.527842\n",
      "Validation loss decreased (2.59879 --> 2.52784).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.470059 \tValidation Loss: 2.478379\n",
      "Validation loss decreased (2.52784 --> 2.47838).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.383069 \tValidation Loss: 2.446924\n",
      "Validation loss decreased (2.47838 --> 2.44692).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.318304 \tValidation Loss: 2.424420\n",
      "Validation loss decreased (2.44692 --> 2.42442).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.269323 \tValidation Loss: 2.417469\n",
      "Validation loss decreased (2.42442 --> 2.41747).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.233313 \tValidation Loss: 2.413056\n",
      "Validation loss decreased (2.41747 --> 2.41306).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.203451 \tValidation Loss: 2.414982\n",
      "Epoch: 19 \tTraining Loss: 0.181736 \tValidation Loss: 2.423018\n",
      "Epoch: 20 \tTraining Loss: 0.164496 \tValidation Loss: 2.430655\n",
      "Epoch: 1 \tTraining Loss: 6.562261 \tValidation Loss: 5.959835\n",
      "Validation loss decreased (inf --> 5.95984).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.879343 \tValidation Loss: 5.663249\n",
      "Validation loss decreased (5.95984 --> 5.66325).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.348152 \tValidation Loss: 5.214449\n",
      "Validation loss decreased (5.66325 --> 5.21445).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.545968 \tValidation Loss: 4.639768\n",
      "Validation loss decreased (5.21445 --> 4.63977).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.603594 \tValidation Loss: 4.074388\n",
      "Validation loss decreased (4.63977 --> 4.07439).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.730747 \tValidation Loss: 3.608361\n",
      "Validation loss decreased (4.07439 --> 3.60836).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.044203 \tValidation Loss: 3.265133\n",
      "Validation loss decreased (3.60836 --> 3.26513).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.542577 \tValidation Loss: 3.018511\n",
      "Validation loss decreased (3.26513 --> 3.01851).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.184770 \tValidation Loss: 2.840608\n",
      "Validation loss decreased (3.01851 --> 2.84061).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.923043 \tValidation Loss: 2.709278\n",
      "Validation loss decreased (2.84061 --> 2.70928).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.727411 \tValidation Loss: 2.613180\n",
      "Validation loss decreased (2.70928 --> 2.61318).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.578373 \tValidation Loss: 2.547809\n",
      "Validation loss decreased (2.61318 --> 2.54781).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 \tTraining Loss: 0.466556 \tValidation Loss: 2.503322\n",
      "Validation loss decreased (2.54781 --> 2.50332).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.381644 \tValidation Loss: 2.474020\n",
      "Validation loss decreased (2.50332 --> 2.47402).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.316439 \tValidation Loss: 2.461447\n",
      "Validation loss decreased (2.47402 --> 2.46145).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.268455 \tValidation Loss: 2.456055\n",
      "Validation loss decreased (2.46145 --> 2.45606).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.230959 \tValidation Loss: 2.461119\n",
      "Epoch: 18 \tTraining Loss: 0.205322 \tValidation Loss: 2.466449\n",
      "Epoch: 19 \tTraining Loss: 0.181512 \tValidation Loss: 2.475372\n",
      "Epoch: 20 \tTraining Loss: 0.162972 \tValidation Loss: 2.483633\n",
      "Epoch: 1 \tTraining Loss: 6.576874 \tValidation Loss: 5.957267\n",
      "Validation loss decreased (inf --> 5.95727).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.873601 \tValidation Loss: 5.650247\n",
      "Validation loss decreased (5.95727 --> 5.65025).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.322958 \tValidation Loss: 5.202821\n",
      "Validation loss decreased (5.65025 --> 5.20282).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.505711 \tValidation Loss: 4.632182\n",
      "Validation loss decreased (5.20282 --> 4.63218).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.564377 \tValidation Loss: 4.084751\n",
      "Validation loss decreased (4.63218 --> 4.08475).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.703278 \tValidation Loss: 3.639263\n",
      "Validation loss decreased (4.08475 --> 3.63926).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.032597 \tValidation Loss: 3.305351\n",
      "Validation loss decreased (3.63926 --> 3.30535).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.542289 \tValidation Loss: 3.061402\n",
      "Validation loss decreased (3.30535 --> 3.06140).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.184987 \tValidation Loss: 2.884707\n",
      "Validation loss decreased (3.06140 --> 2.88471).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.925922 \tValidation Loss: 2.755573\n",
      "Validation loss decreased (2.88471 --> 2.75557).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.731325 \tValidation Loss: 2.662566\n",
      "Validation loss decreased (2.75557 --> 2.66257).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.582627 \tValidation Loss: 2.597951\n",
      "Validation loss decreased (2.66257 --> 2.59795).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.471997 \tValidation Loss: 2.553739\n",
      "Validation loss decreased (2.59795 --> 2.55374).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.384864 \tValidation Loss: 2.529087\n",
      "Validation loss decreased (2.55374 --> 2.52909).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.321730 \tValidation Loss: 2.518370\n",
      "Validation loss decreased (2.52909 --> 2.51837).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.270831 \tValidation Loss: 2.510636\n",
      "Validation loss decreased (2.51837 --> 2.51064).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.231976 \tValidation Loss: 2.509278\n",
      "Validation loss decreased (2.51064 --> 2.50928).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.204112 \tValidation Loss: 2.516862\n",
      "Epoch: 19 \tTraining Loss: 0.180586 \tValidation Loss: 2.527662\n",
      "Epoch: 20 \tTraining Loss: 0.164870 \tValidation Loss: 2.539297\n",
      "Epoch: 1 \tTraining Loss: 6.566705 \tValidation Loss: 5.891208\n",
      "Validation loss decreased (inf --> 5.89121).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.876027 \tValidation Loss: 5.600237\n",
      "Validation loss decreased (5.89121 --> 5.60024).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.333788 \tValidation Loss: 5.152779\n",
      "Validation loss decreased (5.60024 --> 5.15278).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.524325 \tValidation Loss: 4.591359\n",
      "Validation loss decreased (5.15278 --> 4.59136).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.590676 \tValidation Loss: 4.050663\n",
      "Validation loss decreased (4.59136 --> 4.05066).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.728043 \tValidation Loss: 3.607952\n",
      "Validation loss decreased (4.05066 --> 3.60795).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.050219 \tValidation Loss: 3.278080\n",
      "Validation loss decreased (3.60795 --> 3.27808).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.553283 \tValidation Loss: 3.039218\n",
      "Validation loss decreased (3.27808 --> 3.03922).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.192138 \tValidation Loss: 2.865579\n",
      "Validation loss decreased (3.03922 --> 2.86558).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.927727 \tValidation Loss: 2.742530\n",
      "Validation loss decreased (2.86558 --> 2.74253).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.732637 \tValidation Loss: 2.652146\n",
      "Validation loss decreased (2.74253 --> 2.65215).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.583539 \tValidation Loss: 2.588398\n",
      "Validation loss decreased (2.65215 --> 2.58840).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.471470 \tValidation Loss: 2.546380\n",
      "Validation loss decreased (2.58840 --> 2.54638).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.383714 \tValidation Loss: 2.520476\n",
      "Validation loss decreased (2.54638 --> 2.52048).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.318983 \tValidation Loss: 2.508025\n",
      "Validation loss decreased (2.52048 --> 2.50803).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.270184 \tValidation Loss: 2.502236\n",
      "Validation loss decreased (2.50803 --> 2.50224).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.232661 \tValidation Loss: 2.503742\n",
      "Epoch: 18 \tTraining Loss: 0.204768 \tValidation Loss: 2.511082\n",
      "Epoch: 19 \tTraining Loss: 0.183137 \tValidation Loss: 2.519995\n",
      "Epoch: 20 \tTraining Loss: 0.164195 \tValidation Loss: 2.531061\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 8 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.589095 \tValidation Loss: 5.744608\n",
      "Validation loss decreased (inf --> 5.74461).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.862003 \tValidation Loss: 5.474239\n",
      "Validation loss decreased (5.74461 --> 5.47424).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.328758 \tValidation Loss: 5.051938\n",
      "Validation loss decreased (5.47424 --> 5.05194).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.522796 \tValidation Loss: 4.497301\n",
      "Validation loss decreased (5.05194 --> 4.49730).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.578972 \tValidation Loss: 3.954332\n",
      "Validation loss decreased (4.49730 --> 3.95433).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.715581 \tValidation Loss: 3.514283\n",
      "Validation loss decreased (3.95433 --> 3.51428).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.041740 \tValidation Loss: 3.187853\n",
      "Validation loss decreased (3.51428 --> 3.18785).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.546138 \tValidation Loss: 2.953237\n",
      "Validation loss decreased (3.18785 --> 2.95324).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.185645 \tValidation Loss: 2.780156\n",
      "Validation loss decreased (2.95324 --> 2.78016).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.918135 \tValidation Loss: 2.654738\n",
      "Validation loss decreased (2.78016 --> 2.65474).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.713897 \tValidation Loss: 2.562687\n",
      "Validation loss decreased (2.65474 --> 2.56269).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.562052 \tValidation Loss: 2.496527\n",
      "Validation loss decreased (2.56269 --> 2.49653).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.442867 \tValidation Loss: 2.456478\n",
      "Validation loss decreased (2.49653 --> 2.45648).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.355161 \tValidation Loss: 2.428029\n",
      "Validation loss decreased (2.45648 --> 2.42803).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.290435 \tValidation Loss: 2.415013\n",
      "Validation loss decreased (2.42803 --> 2.41501).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.243207 \tValidation Loss: 2.408296\n",
      "Validation loss decreased (2.41501 --> 2.40830).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.205345 \tValidation Loss: 2.410661\n",
      "Epoch: 18 \tTraining Loss: 0.177276 \tValidation Loss: 2.412024\n",
      "Epoch: 19 \tTraining Loss: 0.155632 \tValidation Loss: 2.421131\n",
      "Epoch: 20 \tTraining Loss: 0.140214 \tValidation Loss: 2.434058\n",
      "Epoch: 1 \tTraining Loss: 6.583042 \tValidation Loss: 5.734293\n",
      "Validation loss decreased (inf --> 5.73429).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.857236 \tValidation Loss: 5.460684\n",
      "Validation loss decreased (5.73429 --> 5.46068).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.320158 \tValidation Loss: 5.049131\n",
      "Validation loss decreased (5.46068 --> 5.04913).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.517014 \tValidation Loss: 4.504151\n",
      "Validation loss decreased (5.04913 --> 4.50415).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \tTraining Loss: 3.574864 \tValidation Loss: 3.976339\n",
      "Validation loss decreased (4.50415 --> 3.97634).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.713502 \tValidation Loss: 3.543797\n",
      "Validation loss decreased (3.97634 --> 3.54380).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.039323 \tValidation Loss: 3.212932\n",
      "Validation loss decreased (3.54380 --> 3.21293).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.544595 \tValidation Loss: 2.968204\n",
      "Validation loss decreased (3.21293 --> 2.96820).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.180699 \tValidation Loss: 2.787005\n",
      "Validation loss decreased (2.96820 --> 2.78700).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.910976 \tValidation Loss: 2.654275\n",
      "Validation loss decreased (2.78700 --> 2.65428).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.708163 \tValidation Loss: 2.555895\n",
      "Validation loss decreased (2.65428 --> 2.55590).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.554946 \tValidation Loss: 2.482664\n",
      "Validation loss decreased (2.55590 --> 2.48266).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.438206 \tValidation Loss: 2.429310\n",
      "Validation loss decreased (2.48266 --> 2.42931).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.353985 \tValidation Loss: 2.394994\n",
      "Validation loss decreased (2.42931 --> 2.39499).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.289393 \tValidation Loss: 2.374273\n",
      "Validation loss decreased (2.39499 --> 2.37427).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.239536 \tValidation Loss: 2.361455\n",
      "Validation loss decreased (2.37427 --> 2.36145).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.203941 \tValidation Loss: 2.358487\n",
      "Validation loss decreased (2.36145 --> 2.35849).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.176742 \tValidation Loss: 2.359776\n",
      "Epoch: 19 \tTraining Loss: 0.155214 \tValidation Loss: 2.363971\n",
      "Epoch: 20 \tTraining Loss: 0.138531 \tValidation Loss: 2.372532\n",
      "Epoch: 1 \tTraining Loss: 6.590001 \tValidation Loss: 5.708505\n",
      "Validation loss decreased (inf --> 5.70851).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.855948 \tValidation Loss: 5.438629\n",
      "Validation loss decreased (5.70851 --> 5.43863).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.311360 \tValidation Loss: 5.030153\n",
      "Validation loss decreased (5.43863 --> 5.03015).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.504467 \tValidation Loss: 4.498086\n",
      "Validation loss decreased (5.03015 --> 4.49809).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.562777 \tValidation Loss: 3.974903\n",
      "Validation loss decreased (4.49809 --> 3.97490).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.701298 \tValidation Loss: 3.538705\n",
      "Validation loss decreased (3.97490 --> 3.53871).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.027998 \tValidation Loss: 3.208256\n",
      "Validation loss decreased (3.53871 --> 3.20826).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.532771 \tValidation Loss: 2.966374\n",
      "Validation loss decreased (3.20826 --> 2.96637).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.168551 \tValidation Loss: 2.794077\n",
      "Validation loss decreased (2.96637 --> 2.79408).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.899788 \tValidation Loss: 2.668734\n",
      "Validation loss decreased (2.79408 --> 2.66873).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.702756 \tValidation Loss: 2.580475\n",
      "Validation loss decreased (2.66873 --> 2.58047).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.549999 \tValidation Loss: 2.519097\n",
      "Validation loss decreased (2.58047 --> 2.51910).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.434114 \tValidation Loss: 2.476644\n",
      "Validation loss decreased (2.51910 --> 2.47664).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.347904 \tValidation Loss: 2.451910\n",
      "Validation loss decreased (2.47664 --> 2.45191).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.283255 \tValidation Loss: 2.439563\n",
      "Validation loss decreased (2.45191 --> 2.43956).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.238506 \tValidation Loss: 2.431060\n",
      "Validation loss decreased (2.43956 --> 2.43106).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.200212 \tValidation Loss: 2.430127\n",
      "Validation loss decreased (2.43106 --> 2.43013).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.173702 \tValidation Loss: 2.437465\n",
      "Epoch: 19 \tTraining Loss: 0.153989 \tValidation Loss: 2.444985\n",
      "Epoch: 20 \tTraining Loss: 0.137161 \tValidation Loss: 2.454394\n",
      "Epoch: 1 \tTraining Loss: 6.583896 \tValidation Loss: 5.729414\n",
      "Validation loss decreased (inf --> 5.72941).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.854538 \tValidation Loss: 5.445303\n",
      "Validation loss decreased (5.72941 --> 5.44530).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.303705 \tValidation Loss: 5.036814\n",
      "Validation loss decreased (5.44530 --> 5.03681).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.494871 \tValidation Loss: 4.508394\n",
      "Validation loss decreased (5.03681 --> 4.50839).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.556009 \tValidation Loss: 3.989128\n",
      "Validation loss decreased (4.50839 --> 3.98913).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.700527 \tValidation Loss: 3.567317\n",
      "Validation loss decreased (3.98913 --> 3.56732).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.029137 \tValidation Loss: 3.250600\n",
      "Validation loss decreased (3.56732 --> 3.25060).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.532204 \tValidation Loss: 3.017064\n",
      "Validation loss decreased (3.25060 --> 3.01706).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.168852 \tValidation Loss: 2.849867\n",
      "Validation loss decreased (3.01706 --> 2.84987).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.903351 \tValidation Loss: 2.725947\n",
      "Validation loss decreased (2.84987 --> 2.72595).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.702796 \tValidation Loss: 2.633888\n",
      "Validation loss decreased (2.72595 --> 2.63389).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.552250 \tValidation Loss: 2.569174\n",
      "Validation loss decreased (2.63389 --> 2.56917).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.435790 \tValidation Loss: 2.527567\n",
      "Validation loss decreased (2.56917 --> 2.52757).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.350979 \tValidation Loss: 2.500415\n",
      "Validation loss decreased (2.52757 --> 2.50042).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.286944 \tValidation Loss: 2.484963\n",
      "Validation loss decreased (2.50042 --> 2.48496).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.238430 \tValidation Loss: 2.483801\n",
      "Validation loss decreased (2.48496 --> 2.48380).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.201723 \tValidation Loss: 2.481947\n",
      "Validation loss decreased (2.48380 --> 2.48195).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.175357 \tValidation Loss: 2.487072\n",
      "Epoch: 19 \tTraining Loss: 0.154020 \tValidation Loss: 2.498026\n",
      "Epoch: 20 \tTraining Loss: 0.138264 \tValidation Loss: 2.505623\n",
      "Epoch: 1 \tTraining Loss: 6.588346 \tValidation Loss: 5.701279\n",
      "Validation loss decreased (inf --> 5.70128).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.855960 \tValidation Loss: 5.423332\n",
      "Validation loss decreased (5.70128 --> 5.42333).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.317166 \tValidation Loss: 5.009389\n",
      "Validation loss decreased (5.42333 --> 5.00939).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.512200 \tValidation Loss: 4.469245\n",
      "Validation loss decreased (5.00939 --> 4.46925).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.569751 \tValidation Loss: 3.947302\n",
      "Validation loss decreased (4.46925 --> 3.94730).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.713375 \tValidation Loss: 3.510852\n",
      "Validation loss decreased (3.94730 --> 3.51085).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.042084 \tValidation Loss: 3.177679\n",
      "Validation loss decreased (3.51085 --> 3.17768).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.543451 \tValidation Loss: 2.935637\n",
      "Validation loss decreased (3.17768 --> 2.93564).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.180889 \tValidation Loss: 2.758618\n",
      "Validation loss decreased (2.93564 --> 2.75862).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.913464 \tValidation Loss: 2.629145\n",
      "Validation loss decreased (2.75862 --> 2.62914).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.709255 \tValidation Loss: 2.533213\n",
      "Validation loss decreased (2.62914 --> 2.53321).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.557223 \tValidation Loss: 2.465279\n",
      "Validation loss decreased (2.53321 --> 2.46528).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.442232 \tValidation Loss: 2.420844\n",
      "Validation loss decreased (2.46528 --> 2.42084).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 \tTraining Loss: 0.351344 \tValidation Loss: 2.392147\n",
      "Validation loss decreased (2.42084 --> 2.39215).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.290429 \tValidation Loss: 2.378437\n",
      "Validation loss decreased (2.39215 --> 2.37844).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.241018 \tValidation Loss: 2.374468\n",
      "Validation loss decreased (2.37844 --> 2.37447).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.206614 \tValidation Loss: 2.374713\n",
      "Epoch: 18 \tTraining Loss: 0.177098 \tValidation Loss: 2.378655\n",
      "Epoch: 19 \tTraining Loss: 0.154885 \tValidation Loss: 2.383805\n",
      "Epoch: 20 \tTraining Loss: 0.140536 \tValidation Loss: 2.393672\n",
      "Epoch: 1 \tTraining Loss: 6.598577 \tValidation Loss: 5.728148\n",
      "Validation loss decreased (inf --> 5.72815).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.857515 \tValidation Loss: 5.442684\n",
      "Validation loss decreased (5.72815 --> 5.44268).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.307068 \tValidation Loss: 5.018848\n",
      "Validation loss decreased (5.44268 --> 5.01885).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.489278 \tValidation Loss: 4.474170\n",
      "Validation loss decreased (5.01885 --> 4.47417).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.543025 \tValidation Loss: 3.954316\n",
      "Validation loss decreased (4.47417 --> 3.95432).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.686494 \tValidation Loss: 3.531424\n",
      "Validation loss decreased (3.95432 --> 3.53142).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.023821 \tValidation Loss: 3.212901\n",
      "Validation loss decreased (3.53142 --> 3.21290).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.533605 \tValidation Loss: 2.979759\n",
      "Validation loss decreased (3.21290 --> 2.97976).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.171873 \tValidation Loss: 2.808754\n",
      "Validation loss decreased (2.97976 --> 2.80875).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.902519 \tValidation Loss: 2.685667\n",
      "Validation loss decreased (2.80875 --> 2.68567).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.702075 \tValidation Loss: 2.596702\n",
      "Validation loss decreased (2.68567 --> 2.59670).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.548930 \tValidation Loss: 2.533261\n",
      "Validation loss decreased (2.59670 --> 2.53326).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.435722 \tValidation Loss: 2.494704\n",
      "Validation loss decreased (2.53326 --> 2.49470).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.348019 \tValidation Loss: 2.470483\n",
      "Validation loss decreased (2.49470 --> 2.47048).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.284475 \tValidation Loss: 2.457438\n",
      "Validation loss decreased (2.47048 --> 2.45744).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.234919 \tValidation Loss: 2.451852\n",
      "Validation loss decreased (2.45744 --> 2.45185).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.200546 \tValidation Loss: 2.455222\n",
      "Epoch: 18 \tTraining Loss: 0.172549 \tValidation Loss: 2.462603\n",
      "Epoch: 19 \tTraining Loss: 0.151678 \tValidation Loss: 2.467621\n",
      "Epoch: 20 \tTraining Loss: 0.135346 \tValidation Loss: 2.482157\n",
      "Epoch: 1 \tTraining Loss: 6.591434 \tValidation Loss: 5.721357\n",
      "Validation loss decreased (inf --> 5.72136).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.853405 \tValidation Loss: 5.441732\n",
      "Validation loss decreased (5.72136 --> 5.44173).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.304680 \tValidation Loss: 5.013286\n",
      "Validation loss decreased (5.44173 --> 5.01329).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.490053 \tValidation Loss: 4.464917\n",
      "Validation loss decreased (5.01329 --> 4.46492).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.551036 \tValidation Loss: 3.931297\n",
      "Validation loss decreased (4.46492 --> 3.93130).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.699659 \tValidation Loss: 3.496814\n",
      "Validation loss decreased (3.93130 --> 3.49681).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.026368 \tValidation Loss: 3.174107\n",
      "Validation loss decreased (3.49681 --> 3.17411).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.538215 \tValidation Loss: 2.943567\n",
      "Validation loss decreased (3.17411 --> 2.94357).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.178925 \tValidation Loss: 2.776508\n",
      "Validation loss decreased (2.94357 --> 2.77651).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.911972 \tValidation Loss: 2.654578\n",
      "Validation loss decreased (2.77651 --> 2.65458).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.709507 \tValidation Loss: 2.566250\n",
      "Validation loss decreased (2.65458 --> 2.56625).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.557320 \tValidation Loss: 2.504552\n",
      "Validation loss decreased (2.56625 --> 2.50455).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.440938 \tValidation Loss: 2.462429\n",
      "Validation loss decreased (2.50455 --> 2.46243).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.355216 \tValidation Loss: 2.436933\n",
      "Validation loss decreased (2.46243 --> 2.43693).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.288487 \tValidation Loss: 2.418525\n",
      "Validation loss decreased (2.43693 --> 2.41852).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.242148 \tValidation Loss: 2.412369\n",
      "Validation loss decreased (2.41852 --> 2.41237).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.205249 \tValidation Loss: 2.409418\n",
      "Validation loss decreased (2.41237 --> 2.40942).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.177919 \tValidation Loss: 2.416597\n",
      "Epoch: 19 \tTraining Loss: 0.157389 \tValidation Loss: 2.425716\n",
      "Epoch: 20 \tTraining Loss: 0.139239 \tValidation Loss: 2.433861\n",
      "Epoch: 1 \tTraining Loss: 6.595214 \tValidation Loss: 5.759918\n",
      "Validation loss decreased (inf --> 5.75992).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.847240 \tValidation Loss: 5.490751\n",
      "Validation loss decreased (5.75992 --> 5.49075).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.296744 \tValidation Loss: 5.075631\n",
      "Validation loss decreased (5.49075 --> 5.07563).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.475504 \tValidation Loss: 4.533811\n",
      "Validation loss decreased (5.07563 --> 4.53381).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.528471 \tValidation Loss: 4.013743\n",
      "Validation loss decreased (4.53381 --> 4.01374).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.674361 \tValidation Loss: 3.592941\n",
      "Validation loss decreased (4.01374 --> 3.59294).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.009955 \tValidation Loss: 3.278613\n",
      "Validation loss decreased (3.59294 --> 3.27861).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.522195 \tValidation Loss: 3.051744\n",
      "Validation loss decreased (3.27861 --> 3.05174).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.164827 \tValidation Loss: 2.886123\n",
      "Validation loss decreased (3.05174 --> 2.88612).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.899995 \tValidation Loss: 2.766581\n",
      "Validation loss decreased (2.88612 --> 2.76658).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.702066 \tValidation Loss: 2.679999\n",
      "Validation loss decreased (2.76658 --> 2.68000).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.550669 \tValidation Loss: 2.619255\n",
      "Validation loss decreased (2.68000 --> 2.61926).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.435587 \tValidation Loss: 2.577929\n",
      "Validation loss decreased (2.61926 --> 2.57793).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.351501 \tValidation Loss: 2.553529\n",
      "Validation loss decreased (2.57793 --> 2.55353).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.286511 \tValidation Loss: 2.541200\n",
      "Validation loss decreased (2.55353 --> 2.54120).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.238297 \tValidation Loss: 2.536874\n",
      "Validation loss decreased (2.54120 --> 2.53687).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.203714 \tValidation Loss: 2.541028\n",
      "Epoch: 18 \tTraining Loss: 0.177288 \tValidation Loss: 2.547809\n",
      "Epoch: 19 \tTraining Loss: 0.155738 \tValidation Loss: 2.557933\n",
      "Epoch: 20 \tTraining Loss: 0.138177 \tValidation Loss: 2.566952\n",
      "Epoch: 1 \tTraining Loss: 6.585220 \tValidation Loss: 5.739662\n",
      "Validation loss decreased (inf --> 5.73966).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.861638 \tValidation Loss: 5.465563\n",
      "Validation loss decreased (5.73966 --> 5.46556).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.327450 \tValidation Loss: 5.059720\n",
      "Validation loss decreased (5.46556 --> 5.05972).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.527568 \tValidation Loss: 4.526333\n",
      "Validation loss decreased (5.05972 --> 4.52633).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.584618 \tValidation Loss: 4.002417\n",
      "Validation loss decreased (4.52633 --> 4.00242).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 \tTraining Loss: 2.716932 \tValidation Loss: 3.577406\n",
      "Validation loss decreased (4.00242 --> 3.57741).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.036637 \tValidation Loss: 3.264864\n",
      "Validation loss decreased (3.57741 --> 3.26486).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.538178 \tValidation Loss: 3.035270\n",
      "Validation loss decreased (3.26486 --> 3.03527).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.173580 \tValidation Loss: 2.864453\n",
      "Validation loss decreased (3.03527 --> 2.86445).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.906213 \tValidation Loss: 2.739098\n",
      "Validation loss decreased (2.86445 --> 2.73910).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.709583 \tValidation Loss: 2.649291\n",
      "Validation loss decreased (2.73910 --> 2.64929).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.553630 \tValidation Loss: 2.585085\n",
      "Validation loss decreased (2.64929 --> 2.58509).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.440215 \tValidation Loss: 2.541409\n",
      "Validation loss decreased (2.58509 --> 2.54141).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.354267 \tValidation Loss: 2.514262\n",
      "Validation loss decreased (2.54141 --> 2.51426).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.289314 \tValidation Loss: 2.499915\n",
      "Validation loss decreased (2.51426 --> 2.49992).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.241302 \tValidation Loss: 2.494241\n",
      "Validation loss decreased (2.49992 --> 2.49424).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.203812 \tValidation Loss: 2.494183\n",
      "Validation loss decreased (2.49424 --> 2.49418).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.176783 \tValidation Loss: 2.497298\n",
      "Epoch: 19 \tTraining Loss: 0.155615 \tValidation Loss: 2.504534\n",
      "Epoch: 20 \tTraining Loss: 0.140118 \tValidation Loss: 2.513391\n",
      "Epoch: 1 \tTraining Loss: 6.582017 \tValidation Loss: 5.758615\n",
      "Validation loss decreased (inf --> 5.75861).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.855455 \tValidation Loss: 5.492482\n",
      "Validation loss decreased (5.75861 --> 5.49248).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.325908 \tValidation Loss: 5.091608\n",
      "Validation loss decreased (5.49248 --> 5.09161).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.533045 \tValidation Loss: 4.567887\n",
      "Validation loss decreased (5.09161 --> 4.56789).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.592159 \tValidation Loss: 4.040520\n",
      "Validation loss decreased (4.56789 --> 4.04052).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.730317 \tValidation Loss: 3.597627\n",
      "Validation loss decreased (4.04052 --> 3.59763).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.052714 \tValidation Loss: 3.258942\n",
      "Validation loss decreased (3.59763 --> 3.25894).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.549788 \tValidation Loss: 3.014156\n",
      "Validation loss decreased (3.25894 --> 3.01416).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.182287 \tValidation Loss: 2.838635\n",
      "Validation loss decreased (3.01416 --> 2.83863).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.912531 \tValidation Loss: 2.712329\n",
      "Validation loss decreased (2.83863 --> 2.71233).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.709841 \tValidation Loss: 2.622880\n",
      "Validation loss decreased (2.71233 --> 2.62288).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.557014 \tValidation Loss: 2.560686\n",
      "Validation loss decreased (2.62288 --> 2.56069).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.439500 \tValidation Loss: 2.521819\n",
      "Validation loss decreased (2.56069 --> 2.52182).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.352236 \tValidation Loss: 2.496927\n",
      "Validation loss decreased (2.52182 --> 2.49693).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.290329 \tValidation Loss: 2.480092\n",
      "Validation loss decreased (2.49693 --> 2.48009).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.239739 \tValidation Loss: 2.476686\n",
      "Validation loss decreased (2.48009 --> 2.47669).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.205296 \tValidation Loss: 2.478968\n",
      "Epoch: 18 \tTraining Loss: 0.175266 \tValidation Loss: 2.485856\n",
      "Epoch: 19 \tTraining Loss: 0.154662 \tValidation Loss: 2.496147\n",
      "Epoch: 20 \tTraining Loss: 0.138393 \tValidation Loss: 2.502880\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 9 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.637142 \tValidation Loss: 5.470328\n",
      "Validation loss decreased (inf --> 5.47033).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.856118 \tValidation Loss: 5.226191\n",
      "Validation loss decreased (5.47033 --> 5.22619).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.344184 \tValidation Loss: 4.855666\n",
      "Validation loss decreased (5.22619 --> 4.85567).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.599861 \tValidation Loss: 4.365561\n",
      "Validation loss decreased (4.85567 --> 4.36556).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.702356 \tValidation Loss: 3.869900\n",
      "Validation loss decreased (4.36556 --> 3.86990).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.851897 \tValidation Loss: 3.457647\n",
      "Validation loss decreased (3.86990 --> 3.45765).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.162291 \tValidation Loss: 3.144633\n",
      "Validation loss decreased (3.45765 --> 3.14463).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.638965 \tValidation Loss: 2.915475\n",
      "Validation loss decreased (3.14463 --> 2.91548).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.255373 \tValidation Loss: 2.750141\n",
      "Validation loss decreased (2.91548 --> 2.75014).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.965996 \tValidation Loss: 2.629713\n",
      "Validation loss decreased (2.75014 --> 2.62971).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.747873 \tValidation Loss: 2.540835\n",
      "Validation loss decreased (2.62971 --> 2.54084).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.580742 \tValidation Loss: 2.479465\n",
      "Validation loss decreased (2.54084 --> 2.47946).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.457124 \tValidation Loss: 2.434325\n",
      "Validation loss decreased (2.47946 --> 2.43433).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.363689 \tValidation Loss: 2.408932\n",
      "Validation loss decreased (2.43433 --> 2.40893).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.292383 \tValidation Loss: 2.395181\n",
      "Validation loss decreased (2.40893 --> 2.39518).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.240535 \tValidation Loss: 2.387944\n",
      "Validation loss decreased (2.39518 --> 2.38794).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.201821 \tValidation Loss: 2.386999\n",
      "Validation loss decreased (2.38794 --> 2.38700).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.172382 \tValidation Loss: 2.389421\n",
      "Epoch: 19 \tTraining Loss: 0.150789 \tValidation Loss: 2.395052\n",
      "Epoch: 20 \tTraining Loss: 0.133452 \tValidation Loss: 2.403768\n",
      "Epoch: 1 \tTraining Loss: 6.640260 \tValidation Loss: 5.507668\n",
      "Validation loss decreased (inf --> 5.50767).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.863897 \tValidation Loss: 5.268206\n",
      "Validation loss decreased (5.50767 --> 5.26821).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.358405 \tValidation Loss: 4.893768\n",
      "Validation loss decreased (5.26821 --> 4.89377).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.610885 \tValidation Loss: 4.404051\n",
      "Validation loss decreased (4.89377 --> 4.40405).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.709060 \tValidation Loss: 3.904755\n",
      "Validation loss decreased (4.40405 --> 3.90475).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.842681 \tValidation Loss: 3.487671\n",
      "Validation loss decreased (3.90475 --> 3.48767).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.146315 \tValidation Loss: 3.173708\n",
      "Validation loss decreased (3.48767 --> 3.17371).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.628141 \tValidation Loss: 2.938513\n",
      "Validation loss decreased (3.17371 --> 2.93851).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.245316 \tValidation Loss: 2.763393\n",
      "Validation loss decreased (2.93851 --> 2.76339).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.958661 \tValidation Loss: 2.631051\n",
      "Validation loss decreased (2.76339 --> 2.63105).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.742669 \tValidation Loss: 2.533420\n",
      "Validation loss decreased (2.63105 --> 2.53342).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.577625 \tValidation Loss: 2.462614\n",
      "Validation loss decreased (2.53342 --> 2.46261).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.453956 \tValidation Loss: 2.409598\n",
      "Validation loss decreased (2.46261 --> 2.40960).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.357452 \tValidation Loss: 2.374270\n",
      "Validation loss decreased (2.40960 --> 2.37427).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 \tTraining Loss: 0.288576 \tValidation Loss: 2.350000\n",
      "Validation loss decreased (2.37427 --> 2.35000).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.239028 \tValidation Loss: 2.338743\n",
      "Validation loss decreased (2.35000 --> 2.33874).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.200774 \tValidation Loss: 2.337156\n",
      "Validation loss decreased (2.33874 --> 2.33716).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.172127 \tValidation Loss: 2.336963\n",
      "Validation loss decreased (2.33716 --> 2.33696).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.149284 \tValidation Loss: 2.342214\n",
      "Epoch: 20 \tTraining Loss: 0.131656 \tValidation Loss: 2.349450\n",
      "Epoch: 1 \tTraining Loss: 6.636935 \tValidation Loss: 5.506636\n",
      "Validation loss decreased (inf --> 5.50664).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.855600 \tValidation Loss: 5.248253\n",
      "Validation loss decreased (5.50664 --> 5.24825).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.347615 \tValidation Loss: 4.866918\n",
      "Validation loss decreased (5.24825 --> 4.86692).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.599710 \tValidation Loss: 4.368780\n",
      "Validation loss decreased (4.86692 --> 4.36878).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.700783 \tValidation Loss: 3.871983\n",
      "Validation loss decreased (4.36878 --> 3.87198).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.849839 \tValidation Loss: 3.458729\n",
      "Validation loss decreased (3.87198 --> 3.45873).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.163789 \tValidation Loss: 3.143223\n",
      "Validation loss decreased (3.45873 --> 3.14322).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.648574 \tValidation Loss: 2.905901\n",
      "Validation loss decreased (3.14322 --> 2.90590).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.270480 \tValidation Loss: 2.729471\n",
      "Validation loss decreased (2.90590 --> 2.72947).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.983179 \tValidation Loss: 2.597272\n",
      "Validation loss decreased (2.72947 --> 2.59727).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.766147 \tValidation Loss: 2.499491\n",
      "Validation loss decreased (2.59727 --> 2.49949).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.597726 \tValidation Loss: 2.428749\n",
      "Validation loss decreased (2.49949 --> 2.42875).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.468762 \tValidation Loss: 2.377063\n",
      "Validation loss decreased (2.42875 --> 2.37706).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.373303 \tValidation Loss: 2.345463\n",
      "Validation loss decreased (2.37706 --> 2.34546).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.299255 \tValidation Loss: 2.325574\n",
      "Validation loss decreased (2.34546 --> 2.32557).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.245605 \tValidation Loss: 2.311805\n",
      "Validation loss decreased (2.32557 --> 2.31180).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.204953 \tValidation Loss: 2.307484\n",
      "Validation loss decreased (2.31180 --> 2.30748).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.176468 \tValidation Loss: 2.306519\n",
      "Validation loss decreased (2.30748 --> 2.30652).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.153214 \tValidation Loss: 2.306755\n",
      "Epoch: 20 \tTraining Loss: 0.135760 \tValidation Loss: 2.314279\n",
      "Epoch: 1 \tTraining Loss: 6.633860 \tValidation Loss: 5.521172\n",
      "Validation loss decreased (inf --> 5.52117).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.855740 \tValidation Loss: 5.283554\n",
      "Validation loss decreased (5.52117 --> 5.28355).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.346330 \tValidation Loss: 4.918210\n",
      "Validation loss decreased (5.28355 --> 4.91821).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.600186 \tValidation Loss: 4.437638\n",
      "Validation loss decreased (4.91821 --> 4.43764).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.691242 \tValidation Loss: 3.959877\n",
      "Validation loss decreased (4.43764 --> 3.95988).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.830589 \tValidation Loss: 3.567359\n",
      "Validation loss decreased (3.95988 --> 3.56736).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.142923 \tValidation Loss: 3.271228\n",
      "Validation loss decreased (3.56736 --> 3.27123).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.624797 \tValidation Loss: 3.052578\n",
      "Validation loss decreased (3.27123 --> 3.05258).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.247264 \tValidation Loss: 2.891148\n",
      "Validation loss decreased (3.05258 --> 2.89115).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.959176 \tValidation Loss: 2.770260\n",
      "Validation loss decreased (2.89115 --> 2.77026).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.744671 \tValidation Loss: 2.681161\n",
      "Validation loss decreased (2.77026 --> 2.68116).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.577052 \tValidation Loss: 2.618961\n",
      "Validation loss decreased (2.68116 --> 2.61896).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.454993 \tValidation Loss: 2.574272\n",
      "Validation loss decreased (2.61896 --> 2.57427).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.359520 \tValidation Loss: 2.547270\n",
      "Validation loss decreased (2.57427 --> 2.54727).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.290755 \tValidation Loss: 2.534486\n",
      "Validation loss decreased (2.54727 --> 2.53449).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.240599 \tValidation Loss: 2.525304\n",
      "Validation loss decreased (2.53449 --> 2.52530).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.199595 \tValidation Loss: 2.524213\n",
      "Validation loss decreased (2.52530 --> 2.52421).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.170755 \tValidation Loss: 2.528129\n",
      "Epoch: 19 \tTraining Loss: 0.149925 \tValidation Loss: 2.532123\n",
      "Epoch: 20 \tTraining Loss: 0.133007 \tValidation Loss: 2.539659\n",
      "Epoch: 1 \tTraining Loss: 6.637993 \tValidation Loss: 5.532212\n",
      "Validation loss decreased (inf --> 5.53221).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.864132 \tValidation Loss: 5.281148\n",
      "Validation loss decreased (5.53221 --> 5.28115).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.365098 \tValidation Loss: 4.915661\n",
      "Validation loss decreased (5.28115 --> 4.91566).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.626619 \tValidation Loss: 4.418532\n",
      "Validation loss decreased (4.91566 --> 4.41853).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.723445 \tValidation Loss: 3.904594\n",
      "Validation loss decreased (4.41853 --> 3.90459).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.866045 \tValidation Loss: 3.476400\n",
      "Validation loss decreased (3.90459 --> 3.47640).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.172311 \tValidation Loss: 3.154519\n",
      "Validation loss decreased (3.47640 --> 3.15452).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.647634 \tValidation Loss: 2.918700\n",
      "Validation loss decreased (3.15452 --> 2.91870).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.261140 \tValidation Loss: 2.742965\n",
      "Validation loss decreased (2.91870 --> 2.74296).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.973559 \tValidation Loss: 2.610996\n",
      "Validation loss decreased (2.74296 --> 2.61100).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.753639 \tValidation Loss: 2.513432\n",
      "Validation loss decreased (2.61100 --> 2.51343).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.585216 \tValidation Loss: 2.442338\n",
      "Validation loss decreased (2.51343 --> 2.44234).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.459618 \tValidation Loss: 2.392317\n",
      "Validation loss decreased (2.44234 --> 2.39232).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.365747 \tValidation Loss: 2.360079\n",
      "Validation loss decreased (2.39232 --> 2.36008).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.296364 \tValidation Loss: 2.339800\n",
      "Validation loss decreased (2.36008 --> 2.33980).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.244306 \tValidation Loss: 2.330799\n",
      "Validation loss decreased (2.33980 --> 2.33080).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.202174 \tValidation Loss: 2.327010\n",
      "Validation loss decreased (2.33080 --> 2.32701).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.175283 \tValidation Loss: 2.327012\n",
      "Epoch: 19 \tTraining Loss: 0.151634 \tValidation Loss: 2.333024\n",
      "Epoch: 20 \tTraining Loss: 0.133425 \tValidation Loss: 2.337320\n",
      "Epoch: 1 \tTraining Loss: 6.640019 \tValidation Loss: 5.510190\n",
      "Validation loss decreased (inf --> 5.51019).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.860150 \tValidation Loss: 5.270221\n",
      "Validation loss decreased (5.51019 --> 5.27022).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.354425 \tValidation Loss: 4.923474\n",
      "Validation loss decreased (5.27022 --> 4.92347).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.616291 \tValidation Loss: 4.456074\n",
      "Validation loss decreased (4.92347 --> 4.45607).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \tTraining Loss: 3.717338 \tValidation Loss: 3.966395\n",
      "Validation loss decreased (4.45607 --> 3.96640).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.857670 \tValidation Loss: 3.555504\n",
      "Validation loss decreased (3.96640 --> 3.55550).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.165052 \tValidation Loss: 3.245743\n",
      "Validation loss decreased (3.55550 --> 3.24574).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.647019 \tValidation Loss: 3.018577\n",
      "Validation loss decreased (3.24574 --> 3.01858).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.263050 \tValidation Loss: 2.847038\n",
      "Validation loss decreased (3.01858 --> 2.84704).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.974752 \tValidation Loss: 2.714245\n",
      "Validation loss decreased (2.84704 --> 2.71424).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.756496 \tValidation Loss: 2.615140\n",
      "Validation loss decreased (2.71424 --> 2.61514).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.589342 \tValidation Loss: 2.541887\n",
      "Validation loss decreased (2.61514 --> 2.54189).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.462817 \tValidation Loss: 2.491054\n",
      "Validation loss decreased (2.54189 --> 2.49105).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.367672 \tValidation Loss: 2.456204\n",
      "Validation loss decreased (2.49105 --> 2.45620).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.295324 \tValidation Loss: 2.438796\n",
      "Validation loss decreased (2.45620 --> 2.43880).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.244210 \tValidation Loss: 2.431729\n",
      "Validation loss decreased (2.43880 --> 2.43173).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.205942 \tValidation Loss: 2.428771\n",
      "Validation loss decreased (2.43173 --> 2.42877).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.175283 \tValidation Loss: 2.434669\n",
      "Epoch: 19 \tTraining Loss: 0.153136 \tValidation Loss: 2.437484\n",
      "Epoch: 20 \tTraining Loss: 0.135977 \tValidation Loss: 2.446186\n",
      "Epoch: 1 \tTraining Loss: 6.639245 \tValidation Loss: 5.526693\n",
      "Validation loss decreased (inf --> 5.52669).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.861762 \tValidation Loss: 5.283826\n",
      "Validation loss decreased (5.52669 --> 5.28383).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.353573 \tValidation Loss: 4.925347\n",
      "Validation loss decreased (5.28383 --> 4.92535).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.609302 \tValidation Loss: 4.441970\n",
      "Validation loss decreased (4.92535 --> 4.44197).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.709599 \tValidation Loss: 3.939875\n",
      "Validation loss decreased (4.44197 --> 3.93988).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.850762 \tValidation Loss: 3.516503\n",
      "Validation loss decreased (3.93988 --> 3.51650).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.156254 \tValidation Loss: 3.193342\n",
      "Validation loss decreased (3.51650 --> 3.19334).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.631742 \tValidation Loss: 2.957511\n",
      "Validation loss decreased (3.19334 --> 2.95751).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.245100 \tValidation Loss: 2.787120\n",
      "Validation loss decreased (2.95751 --> 2.78712).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.957461 \tValidation Loss: 2.661912\n",
      "Validation loss decreased (2.78712 --> 2.66191).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.741669 \tValidation Loss: 2.571526\n",
      "Validation loss decreased (2.66191 --> 2.57153).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.575891 \tValidation Loss: 2.505365\n",
      "Validation loss decreased (2.57153 --> 2.50536).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.449266 \tValidation Loss: 2.460302\n",
      "Validation loss decreased (2.50536 --> 2.46030).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.355507 \tValidation Loss: 2.435045\n",
      "Validation loss decreased (2.46030 --> 2.43504).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.285914 \tValidation Loss: 2.419925\n",
      "Validation loss decreased (2.43504 --> 2.41992).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.238655 \tValidation Loss: 2.410764\n",
      "Validation loss decreased (2.41992 --> 2.41076).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.199195 \tValidation Loss: 2.415511\n",
      "Epoch: 18 \tTraining Loss: 0.170557 \tValidation Loss: 2.415353\n",
      "Epoch: 19 \tTraining Loss: 0.147737 \tValidation Loss: 2.421960\n",
      "Epoch: 20 \tTraining Loss: 0.131498 \tValidation Loss: 2.430218\n",
      "Epoch: 1 \tTraining Loss: 6.642222 \tValidation Loss: 5.486267\n",
      "Validation loss decreased (inf --> 5.48627).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.859881 \tValidation Loss: 5.247221\n",
      "Validation loss decreased (5.48627 --> 5.24722).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.352869 \tValidation Loss: 4.886967\n",
      "Validation loss decreased (5.24722 --> 4.88697).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.607210 \tValidation Loss: 4.410710\n",
      "Validation loss decreased (4.88697 --> 4.41071).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.708614 \tValidation Loss: 3.921668\n",
      "Validation loss decreased (4.41071 --> 3.92167).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.850678 \tValidation Loss: 3.509156\n",
      "Validation loss decreased (3.92167 --> 3.50916).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.160456 \tValidation Loss: 3.194509\n",
      "Validation loss decreased (3.50916 --> 3.19451).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.639397 \tValidation Loss: 2.961626\n",
      "Validation loss decreased (3.19451 --> 2.96163).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.257130 \tValidation Loss: 2.786792\n",
      "Validation loss decreased (2.96163 --> 2.78679).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.965909 \tValidation Loss: 2.656102\n",
      "Validation loss decreased (2.78679 --> 2.65610).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.750426 \tValidation Loss: 2.556800\n",
      "Validation loss decreased (2.65610 --> 2.55680).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.584536 \tValidation Loss: 2.488205\n",
      "Validation loss decreased (2.55680 --> 2.48820).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.459459 \tValidation Loss: 2.438587\n",
      "Validation loss decreased (2.48820 --> 2.43859).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.365405 \tValidation Loss: 2.407396\n",
      "Validation loss decreased (2.43859 --> 2.40740).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.294486 \tValidation Loss: 2.388110\n",
      "Validation loss decreased (2.40740 --> 2.38811).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.243138 \tValidation Loss: 2.377485\n",
      "Validation loss decreased (2.38811 --> 2.37749).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.205809 \tValidation Loss: 2.375143\n",
      "Validation loss decreased (2.37749 --> 2.37514).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.173917 \tValidation Loss: 2.375931\n",
      "Epoch: 19 \tTraining Loss: 0.152519 \tValidation Loss: 2.379618\n",
      "Epoch: 20 \tTraining Loss: 0.134564 \tValidation Loss: 2.386944\n",
      "Epoch: 1 \tTraining Loss: 6.640000 \tValidation Loss: 5.487554\n",
      "Validation loss decreased (inf --> 5.48755).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.856707 \tValidation Loss: 5.245874\n",
      "Validation loss decreased (5.48755 --> 5.24587).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.346463 \tValidation Loss: 4.887453\n",
      "Validation loss decreased (5.24587 --> 4.88745).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.600863 \tValidation Loss: 4.414863\n",
      "Validation loss decreased (4.88745 --> 4.41486).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.697199 \tValidation Loss: 3.933581\n",
      "Validation loss decreased (4.41486 --> 3.93358).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.837874 \tValidation Loss: 3.540311\n",
      "Validation loss decreased (3.93358 --> 3.54031).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.146804 \tValidation Loss: 3.246591\n",
      "Validation loss decreased (3.54031 --> 3.24659).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.627987 \tValidation Loss: 3.030251\n",
      "Validation loss decreased (3.24659 --> 3.03025).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.246389 \tValidation Loss: 2.868992\n",
      "Validation loss decreased (3.03025 --> 2.86899).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.964465 \tValidation Loss: 2.748902\n",
      "Validation loss decreased (2.86899 --> 2.74890).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.750038 \tValidation Loss: 2.658453\n",
      "Validation loss decreased (2.74890 --> 2.65845).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.585892 \tValidation Loss: 2.596282\n",
      "Validation loss decreased (2.65845 --> 2.59628).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.457631 \tValidation Loss: 2.552481\n",
      "Validation loss decreased (2.59628 --> 2.55248).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.364642 \tValidation Loss: 2.523507\n",
      "Validation loss decreased (2.55248 --> 2.52351).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 \tTraining Loss: 0.294422 \tValidation Loss: 2.506536\n",
      "Validation loss decreased (2.52351 --> 2.50654).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.245251 \tValidation Loss: 2.496194\n",
      "Validation loss decreased (2.50654 --> 2.49619).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.203562 \tValidation Loss: 2.497854\n",
      "Epoch: 18 \tTraining Loss: 0.175022 \tValidation Loss: 2.500401\n",
      "Epoch: 19 \tTraining Loss: 0.152874 \tValidation Loss: 2.506248\n",
      "Epoch: 20 \tTraining Loss: 0.134897 \tValidation Loss: 2.513834\n",
      "Epoch: 1 \tTraining Loss: 6.632284 \tValidation Loss: 5.494806\n",
      "Validation loss decreased (inf --> 5.49481).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.864102 \tValidation Loss: 5.262905\n",
      "Validation loss decreased (5.49481 --> 5.26291).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.356933 \tValidation Loss: 4.897543\n",
      "Validation loss decreased (5.26291 --> 4.89754).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.611462 \tValidation Loss: 4.407364\n",
      "Validation loss decreased (4.89754 --> 4.40736).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.707071 \tValidation Loss: 3.915322\n",
      "Validation loss decreased (4.40736 --> 3.91532).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.846087 \tValidation Loss: 3.503051\n",
      "Validation loss decreased (3.91532 --> 3.50305).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.150402 \tValidation Loss: 3.193197\n",
      "Validation loss decreased (3.50305 --> 3.19320).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.628582 \tValidation Loss: 2.965207\n",
      "Validation loss decreased (3.19320 --> 2.96521).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.242163 \tValidation Loss: 2.793544\n",
      "Validation loss decreased (2.96521 --> 2.79354).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.958299 \tValidation Loss: 2.661568\n",
      "Validation loss decreased (2.79354 --> 2.66157).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.740576 \tValidation Loss: 2.563326\n",
      "Validation loss decreased (2.66157 --> 2.56333).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.577694 \tValidation Loss: 2.493074\n",
      "Validation loss decreased (2.56333 --> 2.49307).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.451706 \tValidation Loss: 2.443116\n",
      "Validation loss decreased (2.49307 --> 2.44312).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.358345 \tValidation Loss: 2.412613\n",
      "Validation loss decreased (2.44312 --> 2.41261).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.288612 \tValidation Loss: 2.394175\n",
      "Validation loss decreased (2.41261 --> 2.39418).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.238355 \tValidation Loss: 2.383865\n",
      "Validation loss decreased (2.39418 --> 2.38386).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.199791 \tValidation Loss: 2.383673\n",
      "Validation loss decreased (2.38386 --> 2.38367).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.169723 \tValidation Loss: 2.385470\n",
      "Epoch: 19 \tTraining Loss: 0.150212 \tValidation Loss: 2.389473\n",
      "Epoch: 20 \tTraining Loss: 0.131875 \tValidation Loss: 2.398106\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 10 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.778428 \tValidation Loss: 5.145049\n",
      "Validation loss decreased (inf --> 5.14505).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.945134 \tValidation Loss: 4.939434\n",
      "Validation loss decreased (5.14505 --> 4.93943).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.467655 \tValidation Loss: 4.665466\n",
      "Validation loss decreased (4.93943 --> 4.66547).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.785524 \tValidation Loss: 4.289049\n",
      "Validation loss decreased (4.66547 --> 4.28905).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.928934 \tValidation Loss: 3.881617\n",
      "Validation loss decreased (4.28905 --> 3.88162).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.077074 \tValidation Loss: 3.521877\n",
      "Validation loss decreased (3.88162 --> 3.52188).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.362370 \tValidation Loss: 3.237455\n",
      "Validation loss decreased (3.52188 --> 3.23745).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.808954 \tValidation Loss: 3.021632\n",
      "Validation loss decreased (3.23745 --> 3.02163).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.392438 \tValidation Loss: 2.859758\n",
      "Validation loss decreased (3.02163 --> 2.85976).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.080074 \tValidation Loss: 2.741141\n",
      "Validation loss decreased (2.85976 --> 2.74114).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.841650 \tValidation Loss: 2.651595\n",
      "Validation loss decreased (2.74114 --> 2.65159).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.653845 \tValidation Loss: 2.588693\n",
      "Validation loss decreased (2.65159 --> 2.58869).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.514462 \tValidation Loss: 2.542141\n",
      "Validation loss decreased (2.58869 --> 2.54214).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.404319 \tValidation Loss: 2.514920\n",
      "Validation loss decreased (2.54214 --> 2.51492).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.323997 \tValidation Loss: 2.498936\n",
      "Validation loss decreased (2.51492 --> 2.49894).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.264914 \tValidation Loss: 2.490276\n",
      "Validation loss decreased (2.49894 --> 2.49028).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.220040 \tValidation Loss: 2.490008\n",
      "Validation loss decreased (2.49028 --> 2.49001).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.187661 \tValidation Loss: 2.492452\n",
      "Epoch: 19 \tTraining Loss: 0.160953 \tValidation Loss: 2.496558\n",
      "Epoch: 20 \tTraining Loss: 0.140800 \tValidation Loss: 2.504849\n",
      "Epoch: 1 \tTraining Loss: 6.786377 \tValidation Loss: 5.122556\n",
      "Validation loss decreased (inf --> 5.12256).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.951231 \tValidation Loss: 4.889793\n",
      "Validation loss decreased (5.12256 --> 4.88979).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.470818 \tValidation Loss: 4.596326\n",
      "Validation loss decreased (4.88979 --> 4.59633).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.785768 \tValidation Loss: 4.185901\n",
      "Validation loss decreased (4.59633 --> 4.18590).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.932525 \tValidation Loss: 3.748050\n",
      "Validation loss decreased (4.18590 --> 3.74805).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.075902 \tValidation Loss: 3.369666\n",
      "Validation loss decreased (3.74805 --> 3.36967).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.355717 \tValidation Loss: 3.081592\n",
      "Validation loss decreased (3.36967 --> 3.08159).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.801951 \tValidation Loss: 2.870928\n",
      "Validation loss decreased (3.08159 --> 2.87093).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.390164 \tValidation Loss: 2.713958\n",
      "Validation loss decreased (2.87093 --> 2.71396).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.076416 \tValidation Loss: 2.598854\n",
      "Validation loss decreased (2.71396 --> 2.59885).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.833628 \tValidation Loss: 2.512436\n",
      "Validation loss decreased (2.59885 --> 2.51244).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.650071 \tValidation Loss: 2.452327\n",
      "Validation loss decreased (2.51244 --> 2.45233).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.509525 \tValidation Loss: 2.410181\n",
      "Validation loss decreased (2.45233 --> 2.41018).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.401081 \tValidation Loss: 2.382247\n",
      "Validation loss decreased (2.41018 --> 2.38225).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.323638 \tValidation Loss: 2.364523\n",
      "Validation loss decreased (2.38225 --> 2.36452).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.265401 \tValidation Loss: 2.356055\n",
      "Validation loss decreased (2.36452 --> 2.35606).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.220672 \tValidation Loss: 2.353986\n",
      "Validation loss decreased (2.35606 --> 2.35399).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.190038 \tValidation Loss: 2.357518\n",
      "Epoch: 19 \tTraining Loss: 0.162581 \tValidation Loss: 2.361239\n",
      "Epoch: 20 \tTraining Loss: 0.143305 \tValidation Loss: 2.367095\n",
      "Epoch: 1 \tTraining Loss: 6.793819 \tValidation Loss: 5.135275\n",
      "Validation loss decreased (inf --> 5.13528).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.953527 \tValidation Loss: 4.886177\n",
      "Validation loss decreased (5.13528 --> 4.88618).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.466776 \tValidation Loss: 4.578102\n",
      "Validation loss decreased (4.88618 --> 4.57810).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.772118 \tValidation Loss: 4.163875\n",
      "Validation loss decreased (4.57810 --> 4.16387).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.911369 \tValidation Loss: 3.728506\n",
      "Validation loss decreased (4.16387 --> 3.72851).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 \tTraining Loss: 3.060295 \tValidation Loss: 3.353585\n",
      "Validation loss decreased (3.72851 --> 3.35359).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.350071 \tValidation Loss: 3.066712\n",
      "Validation loss decreased (3.35359 --> 3.06671).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.806608 \tValidation Loss: 2.851119\n",
      "Validation loss decreased (3.06671 --> 2.85112).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.394997 \tValidation Loss: 2.687290\n",
      "Validation loss decreased (2.85112 --> 2.68729).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.084882 \tValidation Loss: 2.563933\n",
      "Validation loss decreased (2.68729 --> 2.56393).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.842349 \tValidation Loss: 2.470662\n",
      "Validation loss decreased (2.56393 --> 2.47066).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.657958 \tValidation Loss: 2.404871\n",
      "Validation loss decreased (2.47066 --> 2.40487).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.513011 \tValidation Loss: 2.359564\n",
      "Validation loss decreased (2.40487 --> 2.35956).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.404988 \tValidation Loss: 2.329117\n",
      "Validation loss decreased (2.35956 --> 2.32912).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.325069 \tValidation Loss: 2.313188\n",
      "Validation loss decreased (2.32912 --> 2.31319).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.266297 \tValidation Loss: 2.303797\n",
      "Validation loss decreased (2.31319 --> 2.30380).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.220695 \tValidation Loss: 2.304556\n",
      "Epoch: 18 \tTraining Loss: 0.188803 \tValidation Loss: 2.305641\n",
      "Epoch: 19 \tTraining Loss: 0.163522 \tValidation Loss: 2.311958\n",
      "Epoch: 20 \tTraining Loss: 0.143826 \tValidation Loss: 2.320487\n",
      "Epoch: 1 \tTraining Loss: 6.785996 \tValidation Loss: 5.143613\n",
      "Validation loss decreased (inf --> 5.14361).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.944260 \tValidation Loss: 4.911536\n",
      "Validation loss decreased (5.14361 --> 4.91154).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.454159 \tValidation Loss: 4.618383\n",
      "Validation loss decreased (4.91154 --> 4.61838).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.760960 \tValidation Loss: 4.228506\n",
      "Validation loss decreased (4.61838 --> 4.22851).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.901950 \tValidation Loss: 3.807979\n",
      "Validation loss decreased (4.22851 --> 3.80798).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.046499 \tValidation Loss: 3.434405\n",
      "Validation loss decreased (3.80798 --> 3.43441).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.332732 \tValidation Loss: 3.141480\n",
      "Validation loss decreased (3.43441 --> 3.14148).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.789125 \tValidation Loss: 2.925884\n",
      "Validation loss decreased (3.14148 --> 2.92588).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.382769 \tValidation Loss: 2.768302\n",
      "Validation loss decreased (2.92588 --> 2.76830).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.076653 \tValidation Loss: 2.650856\n",
      "Validation loss decreased (2.76830 --> 2.65086).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.838655 \tValidation Loss: 2.563455\n",
      "Validation loss decreased (2.65086 --> 2.56345).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.653897 \tValidation Loss: 2.500134\n",
      "Validation loss decreased (2.56345 --> 2.50013).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.507104 \tValidation Loss: 2.457104\n",
      "Validation loss decreased (2.50013 --> 2.45710).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.402576 \tValidation Loss: 2.429320\n",
      "Validation loss decreased (2.45710 --> 2.42932).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.322587 \tValidation Loss: 2.413260\n",
      "Validation loss decreased (2.42932 --> 2.41326).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.263130 \tValidation Loss: 2.407161\n",
      "Validation loss decreased (2.41326 --> 2.40716).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.218265 \tValidation Loss: 2.406203\n",
      "Validation loss decreased (2.40716 --> 2.40620).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.184193 \tValidation Loss: 2.407138\n",
      "Epoch: 19 \tTraining Loss: 0.159534 \tValidation Loss: 2.412745\n",
      "Epoch: 20 \tTraining Loss: 0.141820 \tValidation Loss: 2.418983\n",
      "Epoch: 1 \tTraining Loss: 6.785822 \tValidation Loss: 5.122026\n",
      "Validation loss decreased (inf --> 5.12203).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.947197 \tValidation Loss: 4.889478\n",
      "Validation loss decreased (5.12203 --> 4.88948).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.464879 \tValidation Loss: 4.601119\n",
      "Validation loss decreased (4.88948 --> 4.60112).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.778139 \tValidation Loss: 4.189057\n",
      "Validation loss decreased (4.60112 --> 4.18906).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.915207 \tValidation Loss: 3.735370\n",
      "Validation loss decreased (4.18906 --> 3.73537).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.056862 \tValidation Loss: 3.336203\n",
      "Validation loss decreased (3.73537 --> 3.33620).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.336455 \tValidation Loss: 3.027679\n",
      "Validation loss decreased (3.33620 --> 3.02768).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.788217 \tValidation Loss: 2.799403\n",
      "Validation loss decreased (3.02768 --> 2.79940).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.382949 \tValidation Loss: 2.627679\n",
      "Validation loss decreased (2.79940 --> 2.62768).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.072656 \tValidation Loss: 2.496587\n",
      "Validation loss decreased (2.62768 --> 2.49659).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.835479 \tValidation Loss: 2.397344\n",
      "Validation loss decreased (2.49659 --> 2.39734).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.651558 \tValidation Loss: 2.325093\n",
      "Validation loss decreased (2.39734 --> 2.32509).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.510113 \tValidation Loss: 2.275708\n",
      "Validation loss decreased (2.32509 --> 2.27571).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.401439 \tValidation Loss: 2.240652\n",
      "Validation loss decreased (2.27571 --> 2.24065).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.320440 \tValidation Loss: 2.219692\n",
      "Validation loss decreased (2.24065 --> 2.21969).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.263698 \tValidation Loss: 2.205839\n",
      "Validation loss decreased (2.21969 --> 2.20584).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.219660 \tValidation Loss: 2.202480\n",
      "Validation loss decreased (2.20584 --> 2.20248).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.189397 \tValidation Loss: 2.200097\n",
      "Validation loss decreased (2.20248 --> 2.20010).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.162062 \tValidation Loss: 2.198723\n",
      "Validation loss decreased (2.20010 --> 2.19872).  Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 0.142704 \tValidation Loss: 2.203756\n",
      "Epoch: 1 \tTraining Loss: 6.784590 \tValidation Loss: 5.105595\n",
      "Validation loss decreased (inf --> 5.10560).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.951219 \tValidation Loss: 4.857859\n",
      "Validation loss decreased (5.10560 --> 4.85786).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.468418 \tValidation Loss: 4.556259\n",
      "Validation loss decreased (4.85786 --> 4.55626).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.780075 \tValidation Loss: 4.152125\n",
      "Validation loss decreased (4.55626 --> 4.15212).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.916330 \tValidation Loss: 3.728431\n",
      "Validation loss decreased (4.15212 --> 3.72843).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.062227 \tValidation Loss: 3.363909\n",
      "Validation loss decreased (3.72843 --> 3.36391).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.350455 \tValidation Loss: 3.078725\n",
      "Validation loss decreased (3.36391 --> 3.07872).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.804271 \tValidation Loss: 2.860735\n",
      "Validation loss decreased (3.07872 --> 2.86073).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.395604 \tValidation Loss: 2.694592\n",
      "Validation loss decreased (2.86073 --> 2.69459).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.083745 \tValidation Loss: 2.568029\n",
      "Validation loss decreased (2.69459 --> 2.56803).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.847002 \tValidation Loss: 2.470433\n",
      "Validation loss decreased (2.56803 --> 2.47043).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.660942 \tValidation Loss: 2.398503\n",
      "Validation loss decreased (2.47043 --> 2.39850).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.516318 \tValidation Loss: 2.348403\n",
      "Validation loss decreased (2.39850 --> 2.34840).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 \tTraining Loss: 0.407918 \tValidation Loss: 2.316216\n",
      "Validation loss decreased (2.34840 --> 2.31622).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.329147 \tValidation Loss: 2.297361\n",
      "Validation loss decreased (2.31622 --> 2.29736).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.266855 \tValidation Loss: 2.286773\n",
      "Validation loss decreased (2.29736 --> 2.28677).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.223136 \tValidation Loss: 2.282102\n",
      "Validation loss decreased (2.28677 --> 2.28210).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.190588 \tValidation Loss: 2.281251\n",
      "Validation loss decreased (2.28210 --> 2.28125).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.164571 \tValidation Loss: 2.288658\n",
      "Epoch: 20 \tTraining Loss: 0.144330 \tValidation Loss: 2.292891\n",
      "Epoch: 1 \tTraining Loss: 6.793041 \tValidation Loss: 5.120508\n",
      "Validation loss decreased (inf --> 5.12051).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.944881 \tValidation Loss: 4.871764\n",
      "Validation loss decreased (5.12051 --> 4.87176).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.459559 \tValidation Loss: 4.570890\n",
      "Validation loss decreased (4.87176 --> 4.57089).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.769835 \tValidation Loss: 4.166645\n",
      "Validation loss decreased (4.57089 --> 4.16665).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.912982 \tValidation Loss: 3.734158\n",
      "Validation loss decreased (4.16665 --> 3.73416).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.056529 \tValidation Loss: 3.357305\n",
      "Validation loss decreased (3.73416 --> 3.35730).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.332714 \tValidation Loss: 3.073601\n",
      "Validation loss decreased (3.35730 --> 3.07360).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.783720 \tValidation Loss: 2.868843\n",
      "Validation loss decreased (3.07360 --> 2.86884).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.378327 \tValidation Loss: 2.719168\n",
      "Validation loss decreased (2.86884 --> 2.71917).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.073681 \tValidation Loss: 2.607053\n",
      "Validation loss decreased (2.71917 --> 2.60705).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.835275 \tValidation Loss: 2.524593\n",
      "Validation loss decreased (2.60705 --> 2.52459).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.652327 \tValidation Loss: 2.469934\n",
      "Validation loss decreased (2.52459 --> 2.46993).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.512956 \tValidation Loss: 2.431350\n",
      "Validation loss decreased (2.46993 --> 2.43135).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.403827 \tValidation Loss: 2.408956\n",
      "Validation loss decreased (2.43135 --> 2.40896).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.322354 \tValidation Loss: 2.396554\n",
      "Validation loss decreased (2.40896 --> 2.39655).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.262491 \tValidation Loss: 2.396485\n",
      "Validation loss decreased (2.39655 --> 2.39648).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.220106 \tValidation Loss: 2.397725\n",
      "Epoch: 18 \tTraining Loss: 0.186898 \tValidation Loss: 2.401563\n",
      "Epoch: 19 \tTraining Loss: 0.161968 \tValidation Loss: 2.414804\n",
      "Epoch: 20 \tTraining Loss: 0.141534 \tValidation Loss: 2.418715\n",
      "Epoch: 1 \tTraining Loss: 6.793428 \tValidation Loss: 5.133768\n",
      "Validation loss decreased (inf --> 5.13377).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.955110 \tValidation Loss: 4.904721\n",
      "Validation loss decreased (5.13377 --> 4.90472).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.468283 \tValidation Loss: 4.621730\n",
      "Validation loss decreased (4.90472 --> 4.62173).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.780456 \tValidation Loss: 4.219914\n",
      "Validation loss decreased (4.62173 --> 4.21991).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.920045 \tValidation Loss: 3.785712\n",
      "Validation loss decreased (4.21991 --> 3.78571).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.064211 \tValidation Loss: 3.410637\n",
      "Validation loss decreased (3.78571 --> 3.41064).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.345524 \tValidation Loss: 3.121720\n",
      "Validation loss decreased (3.41064 --> 3.12172).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.794722 \tValidation Loss: 2.903963\n",
      "Validation loss decreased (3.12172 --> 2.90396).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.384992 \tValidation Loss: 2.741100\n",
      "Validation loss decreased (2.90396 --> 2.74110).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.073676 \tValidation Loss: 2.616968\n",
      "Validation loss decreased (2.74110 --> 2.61697).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.835960 \tValidation Loss: 2.526607\n",
      "Validation loss decreased (2.61697 --> 2.52661).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.654010 \tValidation Loss: 2.461563\n",
      "Validation loss decreased (2.52661 --> 2.46156).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.507857 \tValidation Loss: 2.418129\n",
      "Validation loss decreased (2.46156 --> 2.41813).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.401850 \tValidation Loss: 2.389621\n",
      "Validation loss decreased (2.41813 --> 2.38962).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.323039 \tValidation Loss: 2.371315\n",
      "Validation loss decreased (2.38962 --> 2.37131).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.262805 \tValidation Loss: 2.364561\n",
      "Validation loss decreased (2.37131 --> 2.36456).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.217880 \tValidation Loss: 2.365649\n",
      "Epoch: 18 \tTraining Loss: 0.187335 \tValidation Loss: 2.368273\n",
      "Epoch: 19 \tTraining Loss: 0.160553 \tValidation Loss: 2.372195\n",
      "Epoch: 20 \tTraining Loss: 0.142345 \tValidation Loss: 2.379305\n",
      "Epoch: 1 \tTraining Loss: 6.784655 \tValidation Loss: 5.107879\n",
      "Validation loss decreased (inf --> 5.10788).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.954279 \tValidation Loss: 4.865636\n",
      "Validation loss decreased (5.10788 --> 4.86564).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.471386 \tValidation Loss: 4.572058\n",
      "Validation loss decreased (4.86564 --> 4.57206).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.777846 \tValidation Loss: 4.176749\n",
      "Validation loss decreased (4.57206 --> 4.17675).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.914910 \tValidation Loss: 3.760543\n",
      "Validation loss decreased (4.17675 --> 3.76054).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.056986 \tValidation Loss: 3.403576\n",
      "Validation loss decreased (3.76054 --> 3.40358).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.340760 \tValidation Loss: 3.128085\n",
      "Validation loss decreased (3.40358 --> 3.12809).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.791188 \tValidation Loss: 2.922512\n",
      "Validation loss decreased (3.12809 --> 2.92251).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.378728 \tValidation Loss: 2.773592\n",
      "Validation loss decreased (2.92251 --> 2.77359).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.067170 \tValidation Loss: 2.665485\n",
      "Validation loss decreased (2.77359 --> 2.66548).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.829609 \tValidation Loss: 2.584879\n",
      "Validation loss decreased (2.66548 --> 2.58488).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.646687 \tValidation Loss: 2.525059\n",
      "Validation loss decreased (2.58488 --> 2.52506).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.503661 \tValidation Loss: 2.487354\n",
      "Validation loss decreased (2.52506 --> 2.48735).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.396995 \tValidation Loss: 2.462756\n",
      "Validation loss decreased (2.48735 --> 2.46276).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.319490 \tValidation Loss: 2.450258\n",
      "Validation loss decreased (2.46276 --> 2.45026).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.260767 \tValidation Loss: 2.444262\n",
      "Validation loss decreased (2.45026 --> 2.44426).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.218165 \tValidation Loss: 2.442399\n",
      "Validation loss decreased (2.44426 --> 2.44240).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.184847 \tValidation Loss: 2.444432\n",
      "Epoch: 19 \tTraining Loss: 0.159901 \tValidation Loss: 2.450662\n",
      "Epoch: 20 \tTraining Loss: 0.140946 \tValidation Loss: 2.457539\n",
      "Epoch: 1 \tTraining Loss: 6.789648 \tValidation Loss: 5.119328\n",
      "Validation loss decreased (inf --> 5.11933).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.951724 \tValidation Loss: 4.883866\n",
      "Validation loss decreased (5.11933 --> 4.88387).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.461987 \tValidation Loss: 4.596680\n",
      "Validation loss decreased (4.88387 --> 4.59668).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.765186 \tValidation Loss: 4.206190\n",
      "Validation loss decreased (4.59668 --> 4.20619).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \tTraining Loss: 3.899493 \tValidation Loss: 3.790601\n",
      "Validation loss decreased (4.20619 --> 3.79060).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.038859 \tValidation Loss: 3.428942\n",
      "Validation loss decreased (3.79060 --> 3.42894).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.321786 \tValidation Loss: 3.155581\n",
      "Validation loss decreased (3.42894 --> 3.15558).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.775359 \tValidation Loss: 2.957193\n",
      "Validation loss decreased (3.15558 --> 2.95719).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.370769 \tValidation Loss: 2.813079\n",
      "Validation loss decreased (2.95719 --> 2.81308).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.063844 \tValidation Loss: 2.708020\n",
      "Validation loss decreased (2.81308 --> 2.70802).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.828510 \tValidation Loss: 2.632715\n",
      "Validation loss decreased (2.70802 --> 2.63272).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.646899 \tValidation Loss: 2.574733\n",
      "Validation loss decreased (2.63272 --> 2.57473).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.507435 \tValidation Loss: 2.532817\n",
      "Validation loss decreased (2.57473 --> 2.53282).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.398668 \tValidation Loss: 2.509496\n",
      "Validation loss decreased (2.53282 --> 2.50950).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.320002 \tValidation Loss: 2.493931\n",
      "Validation loss decreased (2.50950 --> 2.49393).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.261566 \tValidation Loss: 2.488511\n",
      "Validation loss decreased (2.49393 --> 2.48851).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.218604 \tValidation Loss: 2.489487\n",
      "Epoch: 18 \tTraining Loss: 0.186034 \tValidation Loss: 2.490885\n",
      "Epoch: 19 \tTraining Loss: 0.163028 \tValidation Loss: 2.499572\n",
      "Epoch: 20 \tTraining Loss: 0.140355 \tValidation Loss: 2.508278\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 3 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.074752 \tValidation Loss: 5.637559\n",
      "Validation loss decreased (inf --> 5.63756).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.595873 \tValidation Loss: 5.520740\n",
      "Validation loss decreased (5.63756 --> 5.52074).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.368915 \tValidation Loss: 5.357087\n",
      "Validation loss decreased (5.52074 --> 5.35709).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.056977 \tValidation Loss: 5.172065\n",
      "Validation loss decreased (5.35709 --> 5.17206).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.682966 \tValidation Loss: 5.000243\n",
      "Validation loss decreased (5.17206 --> 5.00024).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.291770 \tValidation Loss: 4.854565\n",
      "Validation loss decreased (5.00024 --> 4.85457).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.911919 \tValidation Loss: 4.741896\n",
      "Validation loss decreased (4.85457 --> 4.74190).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.566239 \tValidation Loss: 4.663112\n",
      "Validation loss decreased (4.74190 --> 4.66311).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.263126 \tValidation Loss: 4.614324\n",
      "Validation loss decreased (4.66311 --> 4.61432).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 3.008321 \tValidation Loss: 4.588503\n",
      "Validation loss decreased (4.61432 --> 4.58850).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.792972 \tValidation Loss: 4.580879\n",
      "Validation loss decreased (4.58850 --> 4.58088).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.614373 \tValidation Loss: 4.586958\n",
      "Epoch: 13 \tTraining Loss: 2.469771 \tValidation Loss: 4.602493\n",
      "Epoch: 14 \tTraining Loss: 2.347155 \tValidation Loss: 4.624644\n",
      "Epoch: 15 \tTraining Loss: 2.248720 \tValidation Loss: 4.654210\n",
      "Epoch: 16 \tTraining Loss: 2.165298 \tValidation Loss: 4.685157\n",
      "Epoch: 17 \tTraining Loss: 2.091714 \tValidation Loss: 4.720480\n",
      "Epoch: 18 \tTraining Loss: 2.033115 \tValidation Loss: 4.756465\n",
      "Epoch: 19 \tTraining Loss: 1.982711 \tValidation Loss: 4.796450\n",
      "Epoch: 20 \tTraining Loss: 1.937345 \tValidation Loss: 4.836573\n",
      "Epoch: 1 \tTraining Loss: 6.063963 \tValidation Loss: 5.649722\n",
      "Validation loss decreased (inf --> 5.64972).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.602473 \tValidation Loss: 5.531581\n",
      "Validation loss decreased (5.64972 --> 5.53158).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.378374 \tValidation Loss: 5.363073\n",
      "Validation loss decreased (5.53158 --> 5.36307).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.068246 \tValidation Loss: 5.178067\n",
      "Validation loss decreased (5.36307 --> 5.17807).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.701289 \tValidation Loss: 5.006373\n",
      "Validation loss decreased (5.17807 --> 5.00637).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.307260 \tValidation Loss: 4.859660\n",
      "Validation loss decreased (5.00637 --> 4.85966).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.923942 \tValidation Loss: 4.747264\n",
      "Validation loss decreased (4.85966 --> 4.74726).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.576246 \tValidation Loss: 4.669923\n",
      "Validation loss decreased (4.74726 --> 4.66992).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.274666 \tValidation Loss: 4.622939\n",
      "Validation loss decreased (4.66992 --> 4.62294).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 3.017180 \tValidation Loss: 4.599409\n",
      "Validation loss decreased (4.62294 --> 4.59941).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.804239 \tValidation Loss: 4.593705\n",
      "Validation loss decreased (4.59941 --> 4.59370).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.625396 \tValidation Loss: 4.600992\n",
      "Epoch: 13 \tTraining Loss: 2.479797 \tValidation Loss: 4.617876\n",
      "Epoch: 14 \tTraining Loss: 2.356665 \tValidation Loss: 4.642261\n",
      "Epoch: 15 \tTraining Loss: 2.255076 \tValidation Loss: 4.671542\n",
      "Epoch: 16 \tTraining Loss: 2.171198 \tValidation Loss: 4.702644\n",
      "Epoch: 17 \tTraining Loss: 2.098310 \tValidation Loss: 4.737550\n",
      "Epoch: 18 \tTraining Loss: 2.040695 \tValidation Loss: 4.775204\n",
      "Epoch: 19 \tTraining Loss: 1.988465 \tValidation Loss: 4.813035\n",
      "Epoch: 20 \tTraining Loss: 1.944011 \tValidation Loss: 4.851265\n",
      "Epoch: 1 \tTraining Loss: 6.078099 \tValidation Loss: 5.662180\n",
      "Validation loss decreased (inf --> 5.66218).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.601366 \tValidation Loss: 5.546425\n",
      "Validation loss decreased (5.66218 --> 5.54643).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.375727 \tValidation Loss: 5.383757\n",
      "Validation loss decreased (5.54643 --> 5.38376).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.066360 \tValidation Loss: 5.202542\n",
      "Validation loss decreased (5.38376 --> 5.20254).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.700416 \tValidation Loss: 5.027353\n",
      "Validation loss decreased (5.20254 --> 5.02735).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.305916 \tValidation Loss: 4.879914\n",
      "Validation loss decreased (5.02735 --> 4.87991).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.924645 \tValidation Loss: 4.768944\n",
      "Validation loss decreased (4.87991 --> 4.76894).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.575731 \tValidation Loss: 4.693085\n",
      "Validation loss decreased (4.76894 --> 4.69308).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.271973 \tValidation Loss: 4.644837\n",
      "Validation loss decreased (4.69308 --> 4.64484).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 3.017617 \tValidation Loss: 4.617895\n",
      "Validation loss decreased (4.64484 --> 4.61789).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.804118 \tValidation Loss: 4.607365\n",
      "Validation loss decreased (4.61789 --> 4.60737).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.627480 \tValidation Loss: 4.608944\n",
      "Epoch: 13 \tTraining Loss: 2.479440 \tValidation Loss: 4.621310\n",
      "Epoch: 14 \tTraining Loss: 2.359043 \tValidation Loss: 4.639847\n",
      "Epoch: 15 \tTraining Loss: 2.257329 \tValidation Loss: 4.663598\n",
      "Epoch: 16 \tTraining Loss: 2.173483 \tValidation Loss: 4.692277\n",
      "Epoch: 17 \tTraining Loss: 2.101878 \tValidation Loss: 4.725288\n",
      "Epoch: 18 \tTraining Loss: 2.043867 \tValidation Loss: 4.757946\n",
      "Epoch: 19 \tTraining Loss: 1.992247 \tValidation Loss: 4.794564\n",
      "Epoch: 20 \tTraining Loss: 1.946839 \tValidation Loss: 4.830463\n",
      "Epoch: 1 \tTraining Loss: 6.073318 \tValidation Loss: 5.601005\n",
      "Validation loss decreased (inf --> 5.60100).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.605710 \tValidation Loss: 5.473499\n",
      "Validation loss decreased (5.60100 --> 5.47350).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.383276 \tValidation Loss: 5.298464\n",
      "Validation loss decreased (5.47350 --> 5.29846).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.076616 \tValidation Loss: 5.106989\n",
      "Validation loss decreased (5.29846 --> 5.10699).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \tTraining Loss: 4.707674 \tValidation Loss: 4.927927\n",
      "Validation loss decreased (5.10699 --> 4.92793).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.311845 \tValidation Loss: 4.777057\n",
      "Validation loss decreased (4.92793 --> 4.77706).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.924250 \tValidation Loss: 4.664176\n",
      "Validation loss decreased (4.77706 --> 4.66418).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.573771 \tValidation Loss: 4.585435\n",
      "Validation loss decreased (4.66418 --> 4.58543).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.268498 \tValidation Loss: 4.537402\n",
      "Validation loss decreased (4.58543 --> 4.53740).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 3.010652 \tValidation Loss: 4.514457\n",
      "Validation loss decreased (4.53740 --> 4.51446).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.794423 \tValidation Loss: 4.509243\n",
      "Validation loss decreased (4.51446 --> 4.50924).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.617619 \tValidation Loss: 4.515278\n",
      "Epoch: 13 \tTraining Loss: 2.469409 \tValidation Loss: 4.533506\n",
      "Epoch: 14 \tTraining Loss: 2.351471 \tValidation Loss: 4.556560\n",
      "Epoch: 15 \tTraining Loss: 2.253716 \tValidation Loss: 4.587246\n",
      "Epoch: 16 \tTraining Loss: 2.164699 \tValidation Loss: 4.621018\n",
      "Epoch: 17 \tTraining Loss: 2.098187 \tValidation Loss: 4.657721\n",
      "Epoch: 18 \tTraining Loss: 2.033852 \tValidation Loss: 4.695629\n",
      "Epoch: 19 \tTraining Loss: 1.983637 \tValidation Loss: 4.734388\n",
      "Epoch: 20 \tTraining Loss: 1.936950 \tValidation Loss: 4.776267\n",
      "Epoch: 1 \tTraining Loss: 6.079164 \tValidation Loss: 5.634394\n",
      "Validation loss decreased (inf --> 5.63439).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.602465 \tValidation Loss: 5.511627\n",
      "Validation loss decreased (5.63439 --> 5.51163).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.375706 \tValidation Loss: 5.345884\n",
      "Validation loss decreased (5.51163 --> 5.34588).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.064787 \tValidation Loss: 5.156431\n",
      "Validation loss decreased (5.34588 --> 5.15643).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.696371 \tValidation Loss: 4.978904\n",
      "Validation loss decreased (5.15643 --> 4.97890).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.305991 \tValidation Loss: 4.829488\n",
      "Validation loss decreased (4.97890 --> 4.82949).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.926324 \tValidation Loss: 4.711196\n",
      "Validation loss decreased (4.82949 --> 4.71120).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.577398 \tValidation Loss: 4.626755\n",
      "Validation loss decreased (4.71120 --> 4.62676).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.276383 \tValidation Loss: 4.571061\n",
      "Validation loss decreased (4.62676 --> 4.57106).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 3.020272 \tValidation Loss: 4.538619\n",
      "Validation loss decreased (4.57106 --> 4.53862).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.805041 \tValidation Loss: 4.524177\n",
      "Validation loss decreased (4.53862 --> 4.52418).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.625077 \tValidation Loss: 4.523830\n",
      "Validation loss decreased (4.52418 --> 4.52383).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.478351 \tValidation Loss: 4.533218\n",
      "Epoch: 14 \tTraining Loss: 2.352975 \tValidation Loss: 4.550906\n",
      "Epoch: 15 \tTraining Loss: 2.253130 \tValidation Loss: 4.574386\n",
      "Epoch: 16 \tTraining Loss: 2.169934 \tValidation Loss: 4.602494\n",
      "Epoch: 17 \tTraining Loss: 2.099180 \tValidation Loss: 4.634803\n",
      "Epoch: 18 \tTraining Loss: 2.037021 \tValidation Loss: 4.670345\n",
      "Epoch: 19 \tTraining Loss: 1.987028 \tValidation Loss: 4.703693\n",
      "Epoch: 20 \tTraining Loss: 1.937186 \tValidation Loss: 4.740876\n",
      "Epoch: 1 \tTraining Loss: 6.076482 \tValidation Loss: 5.615389\n",
      "Validation loss decreased (inf --> 5.61539).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.607584 \tValidation Loss: 5.499768\n",
      "Validation loss decreased (5.61539 --> 5.49977).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.384412 \tValidation Loss: 5.331471\n",
      "Validation loss decreased (5.49977 --> 5.33147).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.075456 \tValidation Loss: 5.140830\n",
      "Validation loss decreased (5.33147 --> 5.14083).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.707524 \tValidation Loss: 4.961870\n",
      "Validation loss decreased (5.14083 --> 4.96187).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.315483 \tValidation Loss: 4.809457\n",
      "Validation loss decreased (4.96187 --> 4.80946).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.931421 \tValidation Loss: 4.692771\n",
      "Validation loss decreased (4.80946 --> 4.69277).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.580111 \tValidation Loss: 4.613779\n",
      "Validation loss decreased (4.69277 --> 4.61378).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.276403 \tValidation Loss: 4.565757\n",
      "Validation loss decreased (4.61378 --> 4.56576).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 3.016766 \tValidation Loss: 4.540262\n",
      "Validation loss decreased (4.56576 --> 4.54026).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.803265 \tValidation Loss: 4.532717\n",
      "Validation loss decreased (4.54026 --> 4.53272).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.628107 \tValidation Loss: 4.538783\n",
      "Epoch: 13 \tTraining Loss: 2.483362 \tValidation Loss: 4.552901\n",
      "Epoch: 14 \tTraining Loss: 2.363527 \tValidation Loss: 4.574755\n",
      "Epoch: 15 \tTraining Loss: 2.261205 \tValidation Loss: 4.601578\n",
      "Epoch: 16 \tTraining Loss: 2.177207 \tValidation Loss: 4.632466\n",
      "Epoch: 17 \tTraining Loss: 2.106402 \tValidation Loss: 4.665573\n",
      "Epoch: 18 \tTraining Loss: 2.045001 \tValidation Loss: 4.699239\n",
      "Epoch: 19 \tTraining Loss: 1.995310 \tValidation Loss: 4.736301\n",
      "Epoch: 20 \tTraining Loss: 1.950510 \tValidation Loss: 4.773042\n",
      "Epoch: 1 \tTraining Loss: 6.073745 \tValidation Loss: 5.597691\n",
      "Validation loss decreased (inf --> 5.59769).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.605458 \tValidation Loss: 5.476698\n",
      "Validation loss decreased (5.59769 --> 5.47670).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.379364 \tValidation Loss: 5.308953\n",
      "Validation loss decreased (5.47670 --> 5.30895).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.065993 \tValidation Loss: 5.126762\n",
      "Validation loss decreased (5.30895 --> 5.12676).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.694057 \tValidation Loss: 4.958122\n",
      "Validation loss decreased (5.12676 --> 4.95812).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.300614 \tValidation Loss: 4.814416\n",
      "Validation loss decreased (4.95812 --> 4.81442).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.917909 \tValidation Loss: 4.705065\n",
      "Validation loss decreased (4.81442 --> 4.70506).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.567739 \tValidation Loss: 4.633165\n",
      "Validation loss decreased (4.70506 --> 4.63317).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.264264 \tValidation Loss: 4.592610\n",
      "Validation loss decreased (4.63317 --> 4.59261).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 3.007940 \tValidation Loss: 4.574387\n",
      "Validation loss decreased (4.59261 --> 4.57439).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.794665 \tValidation Loss: 4.571838\n",
      "Validation loss decreased (4.57439 --> 4.57184).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.616640 \tValidation Loss: 4.581861\n",
      "Epoch: 13 \tTraining Loss: 2.473434 \tValidation Loss: 4.600601\n",
      "Epoch: 14 \tTraining Loss: 2.351282 \tValidation Loss: 4.626003\n",
      "Epoch: 15 \tTraining Loss: 2.251113 \tValidation Loss: 4.655303\n",
      "Epoch: 16 \tTraining Loss: 2.166693 \tValidation Loss: 4.687302\n",
      "Epoch: 17 \tTraining Loss: 2.094102 \tValidation Loss: 4.722275\n",
      "Epoch: 18 \tTraining Loss: 2.037435 \tValidation Loss: 4.758875\n",
      "Epoch: 19 \tTraining Loss: 1.986693 \tValidation Loss: 4.795947\n",
      "Epoch: 20 \tTraining Loss: 1.944746 \tValidation Loss: 4.835691\n",
      "Epoch: 1 \tTraining Loss: 6.071958 \tValidation Loss: 5.625768\n",
      "Validation loss decreased (inf --> 5.62577).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.603385 \tValidation Loss: 5.508273\n",
      "Validation loss decreased (5.62577 --> 5.50827).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.382815 \tValidation Loss: 5.340532\n",
      "Validation loss decreased (5.50827 --> 5.34053).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.075592 \tValidation Loss: 5.148780\n",
      "Validation loss decreased (5.34053 --> 5.14878).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.705702 \tValidation Loss: 4.968411\n",
      "Validation loss decreased (5.14878 --> 4.96841).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.312694 \tValidation Loss: 4.818611\n",
      "Validation loss decreased (4.96841 --> 4.81861).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.932150 \tValidation Loss: 4.706224\n",
      "Validation loss decreased (4.81861 --> 4.70622).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 \tTraining Loss: 3.584555 \tValidation Loss: 4.629931\n",
      "Validation loss decreased (4.70622 --> 4.62993).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.285168 \tValidation Loss: 4.585134\n",
      "Validation loss decreased (4.62993 --> 4.58513).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 3.029236 \tValidation Loss: 4.564037\n",
      "Validation loss decreased (4.58513 --> 4.56404).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.813840 \tValidation Loss: 4.560771\n",
      "Validation loss decreased (4.56404 --> 4.56077).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.634227 \tValidation Loss: 4.570369\n",
      "Epoch: 13 \tTraining Loss: 2.486609 \tValidation Loss: 4.587300\n",
      "Epoch: 14 \tTraining Loss: 2.364140 \tValidation Loss: 4.612785\n",
      "Epoch: 15 \tTraining Loss: 2.262960 \tValidation Loss: 4.643648\n",
      "Epoch: 16 \tTraining Loss: 2.177003 \tValidation Loss: 4.676544\n",
      "Epoch: 17 \tTraining Loss: 2.104776 \tValidation Loss: 4.712985\n",
      "Epoch: 18 \tTraining Loss: 2.045226 \tValidation Loss: 4.751250\n",
      "Epoch: 19 \tTraining Loss: 1.990891 \tValidation Loss: 4.788820\n",
      "Epoch: 20 \tTraining Loss: 1.945785 \tValidation Loss: 4.829213\n",
      "Epoch: 1 \tTraining Loss: 6.075832 \tValidation Loss: 5.629647\n",
      "Validation loss decreased (inf --> 5.62965).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.604878 \tValidation Loss: 5.510673\n",
      "Validation loss decreased (5.62965 --> 5.51067).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.381333 \tValidation Loss: 5.342503\n",
      "Validation loss decreased (5.51067 --> 5.34250).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.071210 \tValidation Loss: 5.150504\n",
      "Validation loss decreased (5.34250 --> 5.15050).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.700560 \tValidation Loss: 4.970957\n",
      "Validation loss decreased (5.15050 --> 4.97096).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.303960 \tValidation Loss: 4.819973\n",
      "Validation loss decreased (4.97096 --> 4.81997).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.919322 \tValidation Loss: 4.708465\n",
      "Validation loss decreased (4.81997 --> 4.70846).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.570200 \tValidation Loss: 4.631519\n",
      "Validation loss decreased (4.70846 --> 4.63152).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.268116 \tValidation Loss: 4.583241\n",
      "Validation loss decreased (4.63152 --> 4.58324).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 3.011275 \tValidation Loss: 4.556255\n",
      "Validation loss decreased (4.58324 --> 4.55626).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.799475 \tValidation Loss: 4.546745\n",
      "Validation loss decreased (4.55626 --> 4.54674).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.619866 \tValidation Loss: 4.550553\n",
      "Epoch: 13 \tTraining Loss: 2.474420 \tValidation Loss: 4.563162\n",
      "Epoch: 14 \tTraining Loss: 2.351895 \tValidation Loss: 4.582669\n",
      "Epoch: 15 \tTraining Loss: 2.252793 \tValidation Loss: 4.606064\n",
      "Epoch: 16 \tTraining Loss: 2.171375 \tValidation Loss: 4.636100\n",
      "Epoch: 17 \tTraining Loss: 2.096431 \tValidation Loss: 4.668002\n",
      "Epoch: 18 \tTraining Loss: 2.041334 \tValidation Loss: 4.701592\n",
      "Epoch: 19 \tTraining Loss: 1.989046 \tValidation Loss: 4.736710\n",
      "Epoch: 20 \tTraining Loss: 1.942795 \tValidation Loss: 4.773331\n",
      "Epoch: 1 \tTraining Loss: 6.076299 \tValidation Loss: 5.640504\n",
      "Validation loss decreased (inf --> 5.64050).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.601677 \tValidation Loss: 5.519670\n",
      "Validation loss decreased (5.64050 --> 5.51967).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.379005 \tValidation Loss: 5.350534\n",
      "Validation loss decreased (5.51967 --> 5.35053).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.068245 \tValidation Loss: 5.162715\n",
      "Validation loss decreased (5.35053 --> 5.16271).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.697244 \tValidation Loss: 4.985392\n",
      "Validation loss decreased (5.16271 --> 4.98539).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.303967 \tValidation Loss: 4.835748\n",
      "Validation loss decreased (4.98539 --> 4.83575).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.922701 \tValidation Loss: 4.723276\n",
      "Validation loss decreased (4.83575 --> 4.72328).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.574634 \tValidation Loss: 4.645813\n",
      "Validation loss decreased (4.72328 --> 4.64581).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.274522 \tValidation Loss: 4.596108\n",
      "Validation loss decreased (4.64581 --> 4.59611).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 3.019909 \tValidation Loss: 4.569379\n",
      "Validation loss decreased (4.59611 --> 4.56938).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.807062 \tValidation Loss: 4.560296\n",
      "Validation loss decreased (4.56938 --> 4.56030).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.628238 \tValidation Loss: 4.564560\n",
      "Epoch: 13 \tTraining Loss: 2.481075 \tValidation Loss: 4.577147\n",
      "Epoch: 14 \tTraining Loss: 2.360034 \tValidation Loss: 4.600019\n",
      "Epoch: 15 \tTraining Loss: 2.259590 \tValidation Loss: 4.625949\n",
      "Epoch: 16 \tTraining Loss: 2.177168 \tValidation Loss: 4.656693\n",
      "Epoch: 17 \tTraining Loss: 2.103286 \tValidation Loss: 4.690355\n",
      "Epoch: 18 \tTraining Loss: 2.043164 \tValidation Loss: 4.726587\n",
      "Epoch: 19 \tTraining Loss: 1.993476 \tValidation Loss: 4.762198\n",
      "Epoch: 20 \tTraining Loss: 1.946628 \tValidation Loss: 4.800722\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 4 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.025261 \tValidation Loss: 5.591332\n",
      "Validation loss decreased (inf --> 5.59133).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.505247 \tValidation Loss: 5.391563\n",
      "Validation loss decreased (5.59133 --> 5.39156).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.156210 \tValidation Loss: 5.101133\n",
      "Validation loss decreased (5.39156 --> 5.10113).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.682194 \tValidation Loss: 4.790998\n",
      "Validation loss decreased (5.10113 --> 4.79100).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.151134 \tValidation Loss: 4.516454\n",
      "Validation loss decreased (4.79100 --> 4.51645).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.632412 \tValidation Loss: 4.297254\n",
      "Validation loss decreased (4.51645 --> 4.29725).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.166866 \tValidation Loss: 4.130228\n",
      "Validation loss decreased (4.29725 --> 4.13023).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.775144 \tValidation Loss: 4.008727\n",
      "Validation loss decreased (4.13023 --> 4.00873).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.456564 \tValidation Loss: 3.925074\n",
      "Validation loss decreased (4.00873 --> 3.92507).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.195956 \tValidation Loss: 3.867900\n",
      "Validation loss decreased (3.92507 --> 3.86790).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.988837 \tValidation Loss: 3.831484\n",
      "Validation loss decreased (3.86790 --> 3.83148).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.822034 \tValidation Loss: 3.811296\n",
      "Validation loss decreased (3.83148 --> 3.81130).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.681646 \tValidation Loss: 3.804547\n",
      "Validation loss decreased (3.81130 --> 3.80455).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.568648 \tValidation Loss: 3.808663\n",
      "Epoch: 15 \tTraining Loss: 1.473439 \tValidation Loss: 3.819706\n",
      "Epoch: 16 \tTraining Loss: 1.393397 \tValidation Loss: 3.837851\n",
      "Epoch: 17 \tTraining Loss: 1.323346 \tValidation Loss: 3.860168\n",
      "Epoch: 18 \tTraining Loss: 1.268844 \tValidation Loss: 3.885168\n",
      "Epoch: 19 \tTraining Loss: 1.216136 \tValidation Loss: 3.917937\n",
      "Epoch: 20 \tTraining Loss: 1.173429 \tValidation Loss: 3.952668\n",
      "Epoch: 1 \tTraining Loss: 6.018936 \tValidation Loss: 5.563879\n",
      "Validation loss decreased (inf --> 5.56388).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.495880 \tValidation Loss: 5.357184\n",
      "Validation loss decreased (5.56388 --> 5.35718).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.144164 \tValidation Loss: 5.075474\n",
      "Validation loss decreased (5.35718 --> 5.07547).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.674009 \tValidation Loss: 4.778779\n",
      "Validation loss decreased (5.07547 --> 4.77878).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.144008 \tValidation Loss: 4.506412\n",
      "Validation loss decreased (4.77878 --> 4.50641).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.624077 \tValidation Loss: 4.285074\n",
      "Validation loss decreased (4.50641 --> 4.28507).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.155994 \tValidation Loss: 4.119849\n",
      "Validation loss decreased (4.28507 --> 4.11985).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.763233 \tValidation Loss: 3.998727\n",
      "Validation loss decreased (4.11985 --> 3.99873).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.440543 \tValidation Loss: 3.911453\n",
      "Validation loss decreased (3.99873 --> 3.91145).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 \tTraining Loss: 2.183466 \tValidation Loss: 3.851949\n",
      "Validation loss decreased (3.91145 --> 3.85195).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.976673 \tValidation Loss: 3.812663\n",
      "Validation loss decreased (3.85195 --> 3.81266).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.807177 \tValidation Loss: 3.791011\n",
      "Validation loss decreased (3.81266 --> 3.79101).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.671256 \tValidation Loss: 3.781110\n",
      "Validation loss decreased (3.79101 --> 3.78111).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.554718 \tValidation Loss: 3.783326\n",
      "Epoch: 15 \tTraining Loss: 1.460368 \tValidation Loss: 3.794590\n",
      "Epoch: 16 \tTraining Loss: 1.381514 \tValidation Loss: 3.813846\n",
      "Epoch: 17 \tTraining Loss: 1.311709 \tValidation Loss: 3.836524\n",
      "Epoch: 18 \tTraining Loss: 1.251670 \tValidation Loss: 3.866153\n",
      "Epoch: 19 \tTraining Loss: 1.203326 \tValidation Loss: 3.895541\n",
      "Epoch: 20 \tTraining Loss: 1.165848 \tValidation Loss: 3.928594\n",
      "Epoch: 1 \tTraining Loss: 6.020845 \tValidation Loss: 5.613579\n",
      "Validation loss decreased (inf --> 5.61358).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.501449 \tValidation Loss: 5.424479\n",
      "Validation loss decreased (5.61358 --> 5.42448).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.151586 \tValidation Loss: 5.150786\n",
      "Validation loss decreased (5.42448 --> 5.15079).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.681109 \tValidation Loss: 4.852373\n",
      "Validation loss decreased (5.15079 --> 4.85237).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.156222 \tValidation Loss: 4.573009\n",
      "Validation loss decreased (4.85237 --> 4.57301).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.635459 \tValidation Loss: 4.343607\n",
      "Validation loss decreased (4.57301 --> 4.34361).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.171046 \tValidation Loss: 4.170278\n",
      "Validation loss decreased (4.34361 --> 4.17028).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.774301 \tValidation Loss: 4.041105\n",
      "Validation loss decreased (4.17028 --> 4.04111).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.451166 \tValidation Loss: 3.951874\n",
      "Validation loss decreased (4.04111 --> 3.95187).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.192122 \tValidation Loss: 3.892611\n",
      "Validation loss decreased (3.95187 --> 3.89261).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.983773 \tValidation Loss: 3.856363\n",
      "Validation loss decreased (3.89261 --> 3.85636).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.813800 \tValidation Loss: 3.838660\n",
      "Validation loss decreased (3.85636 --> 3.83866).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.676555 \tValidation Loss: 3.834500\n",
      "Validation loss decreased (3.83866 --> 3.83450).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.563358 \tValidation Loss: 3.839605\n",
      "Epoch: 15 \tTraining Loss: 1.470082 \tValidation Loss: 3.856763\n",
      "Epoch: 16 \tTraining Loss: 1.387752 \tValidation Loss: 3.877749\n",
      "Epoch: 17 \tTraining Loss: 1.317707 \tValidation Loss: 3.904691\n",
      "Epoch: 18 \tTraining Loss: 1.265851 \tValidation Loss: 3.933556\n",
      "Epoch: 19 \tTraining Loss: 1.209730 \tValidation Loss: 3.966944\n",
      "Epoch: 20 \tTraining Loss: 1.172598 \tValidation Loss: 4.002114\n",
      "Epoch: 1 \tTraining Loss: 6.016555 \tValidation Loss: 5.600377\n",
      "Validation loss decreased (inf --> 5.60038).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.498851 \tValidation Loss: 5.403745\n",
      "Validation loss decreased (5.60038 --> 5.40374).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.145600 \tValidation Loss: 5.132024\n",
      "Validation loss decreased (5.40374 --> 5.13202).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.680064 \tValidation Loss: 4.843662\n",
      "Validation loss decreased (5.13202 --> 4.84366).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.155145 \tValidation Loss: 4.578647\n",
      "Validation loss decreased (4.84366 --> 4.57865).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.636170 \tValidation Loss: 4.359320\n",
      "Validation loss decreased (4.57865 --> 4.35932).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.169421 \tValidation Loss: 4.192785\n",
      "Validation loss decreased (4.35932 --> 4.19279).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.774370 \tValidation Loss: 4.070462\n",
      "Validation loss decreased (4.19279 --> 4.07046).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.451137 \tValidation Loss: 3.985279\n",
      "Validation loss decreased (4.07046 --> 3.98528).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.191762 \tValidation Loss: 3.926564\n",
      "Validation loss decreased (3.98528 --> 3.92656).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.981648 \tValidation Loss: 3.892242\n",
      "Validation loss decreased (3.92656 --> 3.89224).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.812996 \tValidation Loss: 3.874240\n",
      "Validation loss decreased (3.89224 --> 3.87424).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.672546 \tValidation Loss: 3.868583\n",
      "Validation loss decreased (3.87424 --> 3.86858).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.558100 \tValidation Loss: 3.873835\n",
      "Epoch: 15 \tTraining Loss: 1.464482 \tValidation Loss: 3.889339\n",
      "Epoch: 16 \tTraining Loss: 1.384170 \tValidation Loss: 3.911343\n",
      "Epoch: 17 \tTraining Loss: 1.314780 \tValidation Loss: 3.938962\n",
      "Epoch: 18 \tTraining Loss: 1.255934 \tValidation Loss: 3.971649\n",
      "Epoch: 19 \tTraining Loss: 1.207494 \tValidation Loss: 4.004554\n",
      "Epoch: 20 \tTraining Loss: 1.164251 \tValidation Loss: 4.039109\n",
      "Epoch: 1 \tTraining Loss: 6.013078 \tValidation Loss: 5.639689\n",
      "Validation loss decreased (inf --> 5.63969).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.501696 \tValidation Loss: 5.444584\n",
      "Validation loss decreased (5.63969 --> 5.44458).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.153205 \tValidation Loss: 5.163860\n",
      "Validation loss decreased (5.44458 --> 5.16386).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.680743 \tValidation Loss: 4.861886\n",
      "Validation loss decreased (5.16386 --> 4.86189).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.149695 \tValidation Loss: 4.581956\n",
      "Validation loss decreased (4.86189 --> 4.58196).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.622732 \tValidation Loss: 4.352040\n",
      "Validation loss decreased (4.58196 --> 4.35204).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.155507 \tValidation Loss: 4.176675\n",
      "Validation loss decreased (4.35204 --> 4.17668).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.763572 \tValidation Loss: 4.050039\n",
      "Validation loss decreased (4.17668 --> 4.05004).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.442897 \tValidation Loss: 3.959812\n",
      "Validation loss decreased (4.05004 --> 3.95981).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.185135 \tValidation Loss: 3.897975\n",
      "Validation loss decreased (3.95981 --> 3.89798).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.976492 \tValidation Loss: 3.860468\n",
      "Validation loss decreased (3.89798 --> 3.86047).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.811166 \tValidation Loss: 3.840995\n",
      "Validation loss decreased (3.86047 --> 3.84100).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.674963 \tValidation Loss: 3.833108\n",
      "Validation loss decreased (3.84100 --> 3.83311).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.563613 \tValidation Loss: 3.835580\n",
      "Epoch: 15 \tTraining Loss: 1.468079 \tValidation Loss: 3.846567\n",
      "Epoch: 16 \tTraining Loss: 1.388730 \tValidation Loss: 3.866094\n",
      "Epoch: 17 \tTraining Loss: 1.321801 \tValidation Loss: 3.886943\n",
      "Epoch: 18 \tTraining Loss: 1.266887 \tValidation Loss: 3.913243\n",
      "Epoch: 19 \tTraining Loss: 1.216583 \tValidation Loss: 3.944314\n",
      "Epoch: 20 \tTraining Loss: 1.165989 \tValidation Loss: 3.977923\n",
      "Epoch: 1 \tTraining Loss: 6.017863 \tValidation Loss: 5.571393\n",
      "Validation loss decreased (inf --> 5.57139).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.506201 \tValidation Loss: 5.379642\n",
      "Validation loss decreased (5.57139 --> 5.37964).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.152978 \tValidation Loss: 5.112021\n",
      "Validation loss decreased (5.37964 --> 5.11202).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.679617 \tValidation Loss: 4.829417\n",
      "Validation loss decreased (5.11202 --> 4.82942).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.153563 \tValidation Loss: 4.575329\n",
      "Validation loss decreased (4.82942 --> 4.57533).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.632310 \tValidation Loss: 4.367768\n",
      "Validation loss decreased (4.57533 --> 4.36777).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.168460 \tValidation Loss: 4.206516\n",
      "Validation loss decreased (4.36777 --> 4.20652).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.772342 \tValidation Loss: 4.085439\n",
      "Validation loss decreased (4.20652 --> 4.08544).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 \tTraining Loss: 2.451962 \tValidation Loss: 3.999836\n",
      "Validation loss decreased (4.08544 --> 3.99984).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.190390 \tValidation Loss: 3.939546\n",
      "Validation loss decreased (3.99984 --> 3.93955).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.981123 \tValidation Loss: 3.902749\n",
      "Validation loss decreased (3.93955 --> 3.90275).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.813876 \tValidation Loss: 3.881820\n",
      "Validation loss decreased (3.90275 --> 3.88182).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.674679 \tValidation Loss: 3.872987\n",
      "Validation loss decreased (3.88182 --> 3.87299).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.562355 \tValidation Loss: 3.875246\n",
      "Epoch: 15 \tTraining Loss: 1.466259 \tValidation Loss: 3.886449\n",
      "Epoch: 16 \tTraining Loss: 1.383259 \tValidation Loss: 3.906047\n",
      "Epoch: 17 \tTraining Loss: 1.318300 \tValidation Loss: 3.927704\n",
      "Epoch: 18 \tTraining Loss: 1.257765 \tValidation Loss: 3.954971\n",
      "Epoch: 19 \tTraining Loss: 1.212005 \tValidation Loss: 3.984851\n",
      "Epoch: 20 \tTraining Loss: 1.166509 \tValidation Loss: 4.017183\n",
      "Epoch: 1 \tTraining Loss: 6.022500 \tValidation Loss: 5.561461\n",
      "Validation loss decreased (inf --> 5.56146).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.505941 \tValidation Loss: 5.358685\n",
      "Validation loss decreased (5.56146 --> 5.35868).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.151061 \tValidation Loss: 5.069813\n",
      "Validation loss decreased (5.35868 --> 5.06981).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.673333 \tValidation Loss: 4.767822\n",
      "Validation loss decreased (5.06981 --> 4.76782).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.139505 \tValidation Loss: 4.498060\n",
      "Validation loss decreased (4.76782 --> 4.49806).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.615441 \tValidation Loss: 4.279775\n",
      "Validation loss decreased (4.49806 --> 4.27978).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.153703 \tValidation Loss: 4.114341\n",
      "Validation loss decreased (4.27978 --> 4.11434).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.762772 \tValidation Loss: 3.991586\n",
      "Validation loss decreased (4.11434 --> 3.99159).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.441615 \tValidation Loss: 3.908028\n",
      "Validation loss decreased (3.99159 --> 3.90803).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.186539 \tValidation Loss: 3.852517\n",
      "Validation loss decreased (3.90803 --> 3.85252).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.980211 \tValidation Loss: 3.818007\n",
      "Validation loss decreased (3.85252 --> 3.81801).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.810689 \tValidation Loss: 3.801312\n",
      "Validation loss decreased (3.81801 --> 3.80131).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.674851 \tValidation Loss: 3.794075\n",
      "Validation loss decreased (3.80131 --> 3.79407).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.562298 \tValidation Loss: 3.798300\n",
      "Epoch: 15 \tTraining Loss: 1.467948 \tValidation Loss: 3.811624\n",
      "Epoch: 16 \tTraining Loss: 1.387784 \tValidation Loss: 3.831260\n",
      "Epoch: 17 \tTraining Loss: 1.318883 \tValidation Loss: 3.852965\n",
      "Epoch: 18 \tTraining Loss: 1.261759 \tValidation Loss: 3.881380\n",
      "Epoch: 19 \tTraining Loss: 1.210594 \tValidation Loss: 3.912561\n",
      "Epoch: 20 \tTraining Loss: 1.168073 \tValidation Loss: 3.944303\n",
      "Epoch: 1 \tTraining Loss: 6.011943 \tValidation Loss: 5.584237\n",
      "Validation loss decreased (inf --> 5.58424).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.498794 \tValidation Loss: 5.386111\n",
      "Validation loss decreased (5.58424 --> 5.38611).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.143499 \tValidation Loss: 5.113293\n",
      "Validation loss decreased (5.38611 --> 5.11329).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.668186 \tValidation Loss: 4.824341\n",
      "Validation loss decreased (5.11329 --> 4.82434).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.135584 \tValidation Loss: 4.563668\n",
      "Validation loss decreased (4.82434 --> 4.56367).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.611946 \tValidation Loss: 4.349576\n",
      "Validation loss decreased (4.56367 --> 4.34958).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.149259 \tValidation Loss: 4.183315\n",
      "Validation loss decreased (4.34958 --> 4.18332).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.761006 \tValidation Loss: 4.059009\n",
      "Validation loss decreased (4.18332 --> 4.05901).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.441910 \tValidation Loss: 3.968886\n",
      "Validation loss decreased (4.05901 --> 3.96889).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.185522 \tValidation Loss: 3.906038\n",
      "Validation loss decreased (3.96889 --> 3.90604).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.979115 \tValidation Loss: 3.864466\n",
      "Validation loss decreased (3.90604 --> 3.86447).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.812195 \tValidation Loss: 3.840351\n",
      "Validation loss decreased (3.86447 --> 3.84035).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.673434 \tValidation Loss: 3.831376\n",
      "Validation loss decreased (3.84035 --> 3.83138).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.559683 \tValidation Loss: 3.833139\n",
      "Epoch: 15 \tTraining Loss: 1.463204 \tValidation Loss: 3.842547\n",
      "Epoch: 16 \tTraining Loss: 1.383129 \tValidation Loss: 3.861070\n",
      "Epoch: 17 \tTraining Loss: 1.317306 \tValidation Loss: 3.883006\n",
      "Epoch: 18 \tTraining Loss: 1.261059 \tValidation Loss: 3.909987\n",
      "Epoch: 19 \tTraining Loss: 1.209012 \tValidation Loss: 3.941413\n",
      "Epoch: 20 \tTraining Loss: 1.161346 \tValidation Loss: 3.973320\n",
      "Epoch: 1 \tTraining Loss: 6.019294 \tValidation Loss: 5.573995\n",
      "Validation loss decreased (inf --> 5.57400).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.497317 \tValidation Loss: 5.370646\n",
      "Validation loss decreased (5.57400 --> 5.37065).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.140081 \tValidation Loss: 5.093641\n",
      "Validation loss decreased (5.37065 --> 5.09364).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.665344 \tValidation Loss: 4.799510\n",
      "Validation loss decreased (5.09364 --> 4.79951).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.134572 \tValidation Loss: 4.531527\n",
      "Validation loss decreased (4.79951 --> 4.53153).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.617390 \tValidation Loss: 4.314259\n",
      "Validation loss decreased (4.53153 --> 4.31426).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.154160 \tValidation Loss: 4.148692\n",
      "Validation loss decreased (4.31426 --> 4.14869).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.764330 \tValidation Loss: 4.025925\n",
      "Validation loss decreased (4.14869 --> 4.02592).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.448236 \tValidation Loss: 3.937515\n",
      "Validation loss decreased (4.02592 --> 3.93751).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.191115 \tValidation Loss: 3.877219\n",
      "Validation loss decreased (3.93751 --> 3.87722).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.984830 \tValidation Loss: 3.836998\n",
      "Validation loss decreased (3.87722 --> 3.83700).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.816181 \tValidation Loss: 3.813516\n",
      "Validation loss decreased (3.83700 --> 3.81352).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.677417 \tValidation Loss: 3.803161\n",
      "Validation loss decreased (3.81352 --> 3.80316).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.563978 \tValidation Loss: 3.805001\n",
      "Epoch: 15 \tTraining Loss: 1.468007 \tValidation Loss: 3.814441\n",
      "Epoch: 16 \tTraining Loss: 1.388371 \tValidation Loss: 3.831389\n",
      "Epoch: 17 \tTraining Loss: 1.319754 \tValidation Loss: 3.851032\n",
      "Epoch: 18 \tTraining Loss: 1.258965 \tValidation Loss: 3.879810\n",
      "Epoch: 19 \tTraining Loss: 1.213098 \tValidation Loss: 3.909275\n",
      "Epoch: 20 \tTraining Loss: 1.166272 \tValidation Loss: 3.939939\n",
      "Epoch: 1 \tTraining Loss: 6.009772 \tValidation Loss: 5.583927\n",
      "Validation loss decreased (inf --> 5.58393).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.498976 \tValidation Loss: 5.390244\n",
      "Validation loss decreased (5.58393 --> 5.39024).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.148115 \tValidation Loss: 5.119066\n",
      "Validation loss decreased (5.39024 --> 5.11907).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.675089 \tValidation Loss: 4.828105\n",
      "Validation loss decreased (5.11907 --> 4.82811).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.143037 \tValidation Loss: 4.568483\n",
      "Validation loss decreased (4.82811 --> 4.56848).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.622225 \tValidation Loss: 4.361151\n",
      "Validation loss decreased (4.56848 --> 4.36115).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.157641 \tValidation Loss: 4.204650\n",
      "Validation loss decreased (4.36115 --> 4.20465).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 \tTraining Loss: 2.767731 \tValidation Loss: 4.089214\n",
      "Validation loss decreased (4.20465 --> 4.08921).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.448627 \tValidation Loss: 4.007661\n",
      "Validation loss decreased (4.08921 --> 4.00766).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.191296 \tValidation Loss: 3.952000\n",
      "Validation loss decreased (4.00766 --> 3.95200).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.982125 \tValidation Loss: 3.919387\n",
      "Validation loss decreased (3.95200 --> 3.91939).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.813589 \tValidation Loss: 3.901702\n",
      "Validation loss decreased (3.91939 --> 3.90170).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.676990 \tValidation Loss: 3.895827\n",
      "Validation loss decreased (3.90170 --> 3.89583).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.565366 \tValidation Loss: 3.900522\n",
      "Epoch: 15 \tTraining Loss: 1.469715 \tValidation Loss: 3.914260\n",
      "Epoch: 16 \tTraining Loss: 1.388080 \tValidation Loss: 3.933488\n",
      "Epoch: 17 \tTraining Loss: 1.321421 \tValidation Loss: 3.958807\n",
      "Epoch: 18 \tTraining Loss: 1.262454 \tValidation Loss: 3.986787\n",
      "Epoch: 19 \tTraining Loss: 1.213510 \tValidation Loss: 4.019499\n",
      "Epoch: 20 \tTraining Loss: 1.168082 \tValidation Loss: 4.054395\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 5 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.013609 \tValidation Loss: 5.258808\n",
      "Validation loss decreased (inf --> 5.25881).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.441426 \tValidation Loss: 5.012858\n",
      "Validation loss decreased (5.25881 --> 5.01286).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.996770 \tValidation Loss: 4.679538\n",
      "Validation loss decreased (5.01286 --> 4.67954).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.413800 \tValidation Loss: 4.337725\n",
      "Validation loss decreased (4.67954 --> 4.33773).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.784063 \tValidation Loss: 4.029911\n",
      "Validation loss decreased (4.33773 --> 4.02991).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.191835 \tValidation Loss: 3.779866\n",
      "Validation loss decreased (4.02991 --> 3.77987).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.687396 \tValidation Loss: 3.590489\n",
      "Validation loss decreased (3.77987 --> 3.59049).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.281660 \tValidation Loss: 3.453841\n",
      "Validation loss decreased (3.59049 --> 3.45384).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.958791 \tValidation Loss: 3.355390\n",
      "Validation loss decreased (3.45384 --> 3.35539).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.707121 \tValidation Loss: 3.288611\n",
      "Validation loss decreased (3.35539 --> 3.28861).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.505559 \tValidation Loss: 3.243597\n",
      "Validation loss decreased (3.28861 --> 3.24360).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.343236 \tValidation Loss: 3.217506\n",
      "Validation loss decreased (3.24360 --> 3.21751).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.208963 \tValidation Loss: 3.206429\n",
      "Validation loss decreased (3.21751 --> 3.20643).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.100087 \tValidation Loss: 3.206438\n",
      "Epoch: 15 \tTraining Loss: 1.007901 \tValidation Loss: 3.216285\n",
      "Epoch: 16 \tTraining Loss: 0.935914 \tValidation Loss: 3.231036\n",
      "Epoch: 17 \tTraining Loss: 0.864546 \tValidation Loss: 3.252242\n",
      "Epoch: 18 \tTraining Loss: 0.814588 \tValidation Loss: 3.277399\n",
      "Epoch: 19 \tTraining Loss: 0.765323 \tValidation Loss: 3.305417\n",
      "Epoch: 20 \tTraining Loss: 0.725897 \tValidation Loss: 3.341705\n",
      "Epoch: 1 \tTraining Loss: 6.022454 \tValidation Loss: 5.272633\n",
      "Validation loss decreased (inf --> 5.27263).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.442197 \tValidation Loss: 5.040960\n",
      "Validation loss decreased (5.27263 --> 5.04096).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.996876 \tValidation Loss: 4.721818\n",
      "Validation loss decreased (5.04096 --> 4.72182).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.411872 \tValidation Loss: 4.384593\n",
      "Validation loss decreased (4.72182 --> 4.38459).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.782108 \tValidation Loss: 4.076548\n",
      "Validation loss decreased (4.38459 --> 4.07655).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.190866 \tValidation Loss: 3.822658\n",
      "Validation loss decreased (4.07655 --> 3.82266).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.687417 \tValidation Loss: 3.628326\n",
      "Validation loss decreased (3.82266 --> 3.62833).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.282433 \tValidation Loss: 3.484690\n",
      "Validation loss decreased (3.62833 --> 3.48469).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.962870 \tValidation Loss: 3.379574\n",
      "Validation loss decreased (3.48469 --> 3.37957).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.709572 \tValidation Loss: 3.307416\n",
      "Validation loss decreased (3.37957 --> 3.30742).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.509269 \tValidation Loss: 3.257772\n",
      "Validation loss decreased (3.30742 --> 3.25777).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.345487 \tValidation Loss: 3.225296\n",
      "Validation loss decreased (3.25777 --> 3.22530).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.213895 \tValidation Loss: 3.209170\n",
      "Validation loss decreased (3.22530 --> 3.20917).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.100386 \tValidation Loss: 3.207357\n",
      "Validation loss decreased (3.20917 --> 3.20736).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.010949 \tValidation Loss: 3.209908\n",
      "Epoch: 16 \tTraining Loss: 0.936550 \tValidation Loss: 3.221503\n",
      "Epoch: 17 \tTraining Loss: 0.869597 \tValidation Loss: 3.240764\n",
      "Epoch: 18 \tTraining Loss: 0.817491 \tValidation Loss: 3.262459\n",
      "Epoch: 19 \tTraining Loss: 0.767408 \tValidation Loss: 3.288090\n",
      "Epoch: 20 \tTraining Loss: 0.725012 \tValidation Loss: 3.316501\n",
      "Epoch: 1 \tTraining Loss: 6.015347 \tValidation Loss: 5.279996\n",
      "Validation loss decreased (inf --> 5.28000).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.442582 \tValidation Loss: 5.054872\n",
      "Validation loss decreased (5.28000 --> 5.05487).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.999122 \tValidation Loss: 4.737566\n",
      "Validation loss decreased (5.05487 --> 4.73757).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.412237 \tValidation Loss: 4.397073\n",
      "Validation loss decreased (4.73757 --> 4.39707).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.775691 \tValidation Loss: 4.094387\n",
      "Validation loss decreased (4.39707 --> 4.09439).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.179989 \tValidation Loss: 3.849617\n",
      "Validation loss decreased (4.09439 --> 3.84962).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.676006 \tValidation Loss: 3.664246\n",
      "Validation loss decreased (3.84962 --> 3.66425).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.272200 \tValidation Loss: 3.529542\n",
      "Validation loss decreased (3.66425 --> 3.52954).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.954536 \tValidation Loss: 3.432484\n",
      "Validation loss decreased (3.52954 --> 3.43248).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.701663 \tValidation Loss: 3.364087\n",
      "Validation loss decreased (3.43248 --> 3.36409).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.499379 \tValidation Loss: 3.317007\n",
      "Validation loss decreased (3.36409 --> 3.31701).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.339228 \tValidation Loss: 3.290865\n",
      "Validation loss decreased (3.31701 --> 3.29086).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.207371 \tValidation Loss: 3.276904\n",
      "Validation loss decreased (3.29086 --> 3.27690).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.100017 \tValidation Loss: 3.274078\n",
      "Validation loss decreased (3.27690 --> 3.27408).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.006638 \tValidation Loss: 3.282880\n",
      "Epoch: 16 \tTraining Loss: 0.933690 \tValidation Loss: 3.295781\n",
      "Epoch: 17 \tTraining Loss: 0.867029 \tValidation Loss: 3.317541\n",
      "Epoch: 18 \tTraining Loss: 0.808600 \tValidation Loss: 3.344837\n",
      "Epoch: 19 \tTraining Loss: 0.765783 \tValidation Loss: 3.373554\n",
      "Epoch: 20 \tTraining Loss: 0.724759 \tValidation Loss: 3.406845\n",
      "Epoch: 1 \tTraining Loss: 6.018885 \tValidation Loss: 5.244342\n",
      "Validation loss decreased (inf --> 5.24434).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.446714 \tValidation Loss: 5.005977\n",
      "Validation loss decreased (5.24434 --> 5.00598).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.006934 \tValidation Loss: 4.673443\n",
      "Validation loss decreased (5.00598 --> 4.67344).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.425925 \tValidation Loss: 4.322759\n",
      "Validation loss decreased (4.67344 --> 4.32276).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.799218 \tValidation Loss: 4.008894\n",
      "Validation loss decreased (4.32276 --> 4.00889).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 \tTraining Loss: 3.208036 \tValidation Loss: 3.749294\n",
      "Validation loss decreased (4.00889 --> 3.74929).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.702768 \tValidation Loss: 3.548075\n",
      "Validation loss decreased (3.74929 --> 3.54808).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.297145 \tValidation Loss: 3.400636\n",
      "Validation loss decreased (3.54808 --> 3.40064).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.973665 \tValidation Loss: 3.294626\n",
      "Validation loss decreased (3.40064 --> 3.29463).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.716746 \tValidation Loss: 3.219729\n",
      "Validation loss decreased (3.29463 --> 3.21973).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.513202 \tValidation Loss: 3.170381\n",
      "Validation loss decreased (3.21973 --> 3.17038).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.350858 \tValidation Loss: 3.138918\n",
      "Validation loss decreased (3.17038 --> 3.13892).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.217632 \tValidation Loss: 3.124370\n",
      "Validation loss decreased (3.13892 --> 3.12437).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.110270 \tValidation Loss: 3.122173\n",
      "Validation loss decreased (3.12437 --> 3.12217).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.015671 \tValidation Loss: 3.126070\n",
      "Epoch: 16 \tTraining Loss: 0.939772 \tValidation Loss: 3.135853\n",
      "Epoch: 17 \tTraining Loss: 0.876087 \tValidation Loss: 3.156178\n",
      "Epoch: 18 \tTraining Loss: 0.820428 \tValidation Loss: 3.176511\n",
      "Epoch: 19 \tTraining Loss: 0.769849 \tValidation Loss: 3.202126\n",
      "Epoch: 20 \tTraining Loss: 0.728434 \tValidation Loss: 3.227999\n",
      "Epoch: 1 \tTraining Loss: 6.011837 \tValidation Loss: 5.273283\n",
      "Validation loss decreased (inf --> 5.27328).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.440351 \tValidation Loss: 5.033514\n",
      "Validation loss decreased (5.27328 --> 5.03351).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.991900 \tValidation Loss: 4.700443\n",
      "Validation loss decreased (5.03351 --> 4.70044).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.404096 \tValidation Loss: 4.360070\n",
      "Validation loss decreased (4.70044 --> 4.36007).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.769647 \tValidation Loss: 4.064062\n",
      "Validation loss decreased (4.36007 --> 4.06406).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.178225 \tValidation Loss: 3.828607\n",
      "Validation loss decreased (4.06406 --> 3.82861).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.680090 \tValidation Loss: 3.648739\n",
      "Validation loss decreased (3.82861 --> 3.64874).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.277799 \tValidation Loss: 3.516921\n",
      "Validation loss decreased (3.64874 --> 3.51692).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.955562 \tValidation Loss: 3.420534\n",
      "Validation loss decreased (3.51692 --> 3.42053).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.708492 \tValidation Loss: 3.351944\n",
      "Validation loss decreased (3.42053 --> 3.35194).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.504036 \tValidation Loss: 3.307860\n",
      "Validation loss decreased (3.35194 --> 3.30786).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.341007 \tValidation Loss: 3.283279\n",
      "Validation loss decreased (3.30786 --> 3.28328).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.208891 \tValidation Loss: 3.272146\n",
      "Validation loss decreased (3.28328 --> 3.27215).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.102495 \tValidation Loss: 3.271154\n",
      "Validation loss decreased (3.27215 --> 3.27115).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.011626 \tValidation Loss: 3.280259\n",
      "Epoch: 16 \tTraining Loss: 0.930749 \tValidation Loss: 3.296661\n",
      "Epoch: 17 \tTraining Loss: 0.869275 \tValidation Loss: 3.320365\n",
      "Epoch: 18 \tTraining Loss: 0.815434 \tValidation Loss: 3.345091\n",
      "Epoch: 19 \tTraining Loss: 0.767967 \tValidation Loss: 3.377262\n",
      "Epoch: 20 \tTraining Loss: 0.726566 \tValidation Loss: 3.406302\n",
      "Epoch: 1 \tTraining Loss: 6.011351 \tValidation Loss: 5.277784\n",
      "Validation loss decreased (inf --> 5.27778).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.439676 \tValidation Loss: 5.038286\n",
      "Validation loss decreased (5.27778 --> 5.03829).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.002676 \tValidation Loss: 4.710929\n",
      "Validation loss decreased (5.03829 --> 4.71093).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.423493 \tValidation Loss: 4.358469\n",
      "Validation loss decreased (4.71093 --> 4.35847).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.790400 \tValidation Loss: 4.035440\n",
      "Validation loss decreased (4.35847 --> 4.03544).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.193196 \tValidation Loss: 3.775138\n",
      "Validation loss decreased (4.03544 --> 3.77514).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.690116 \tValidation Loss: 3.579855\n",
      "Validation loss decreased (3.77514 --> 3.57985).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.283488 \tValidation Loss: 3.435872\n",
      "Validation loss decreased (3.57985 --> 3.43587).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.961498 \tValidation Loss: 3.333360\n",
      "Validation loss decreased (3.43587 --> 3.33336).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.711420 \tValidation Loss: 3.260887\n",
      "Validation loss decreased (3.33336 --> 3.26089).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.507838 \tValidation Loss: 3.211881\n",
      "Validation loss decreased (3.26089 --> 3.21188).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.348265 \tValidation Loss: 3.181894\n",
      "Validation loss decreased (3.21188 --> 3.18189).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.215036 \tValidation Loss: 3.165738\n",
      "Validation loss decreased (3.18189 --> 3.16574).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.106703 \tValidation Loss: 3.162487\n",
      "Validation loss decreased (3.16574 --> 3.16249).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.017077 \tValidation Loss: 3.166558\n",
      "Epoch: 16 \tTraining Loss: 0.940088 \tValidation Loss: 3.177704\n",
      "Epoch: 17 \tTraining Loss: 0.877329 \tValidation Loss: 3.194959\n",
      "Epoch: 18 \tTraining Loss: 0.821338 \tValidation Loss: 3.219106\n",
      "Epoch: 19 \tTraining Loss: 0.772312 \tValidation Loss: 3.243997\n",
      "Epoch: 20 \tTraining Loss: 0.732283 \tValidation Loss: 3.270876\n",
      "Epoch: 1 \tTraining Loss: 6.015732 \tValidation Loss: 5.245426\n",
      "Validation loss decreased (inf --> 5.24543).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.436607 \tValidation Loss: 5.014090\n",
      "Validation loss decreased (5.24543 --> 5.01409).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.989241 \tValidation Loss: 4.689723\n",
      "Validation loss decreased (5.01409 --> 4.68972).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.403825 \tValidation Loss: 4.346474\n",
      "Validation loss decreased (4.68972 --> 4.34647).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.771043 \tValidation Loss: 4.036427\n",
      "Validation loss decreased (4.34647 --> 4.03643).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.180884 \tValidation Loss: 3.790444\n",
      "Validation loss decreased (4.03643 --> 3.79044).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.679650 \tValidation Loss: 3.607924\n",
      "Validation loss decreased (3.79044 --> 3.60792).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.275940 \tValidation Loss: 3.476881\n",
      "Validation loss decreased (3.60792 --> 3.47688).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.959652 \tValidation Loss: 3.382180\n",
      "Validation loss decreased (3.47688 --> 3.38218).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.703670 \tValidation Loss: 3.315787\n",
      "Validation loss decreased (3.38218 --> 3.31579).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.504118 \tValidation Loss: 3.271184\n",
      "Validation loss decreased (3.31579 --> 3.27118).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.342738 \tValidation Loss: 3.245159\n",
      "Validation loss decreased (3.27118 --> 3.24516).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.210853 \tValidation Loss: 3.233539\n",
      "Validation loss decreased (3.24516 --> 3.23354).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.103414 \tValidation Loss: 3.233737\n",
      "Epoch: 15 \tTraining Loss: 1.013449 \tValidation Loss: 3.237389\n",
      "Epoch: 16 \tTraining Loss: 0.936040 \tValidation Loss: 3.252474\n",
      "Epoch: 17 \tTraining Loss: 0.870783 \tValidation Loss: 3.270928\n",
      "Epoch: 18 \tTraining Loss: 0.812571 \tValidation Loss: 3.294113\n",
      "Epoch: 19 \tTraining Loss: 0.767444 \tValidation Loss: 3.322621\n",
      "Epoch: 20 \tTraining Loss: 0.726906 \tValidation Loss: 3.350787\n",
      "Epoch: 1 \tTraining Loss: 6.004789 \tValidation Loss: 5.253237\n",
      "Validation loss decreased (inf --> 5.25324).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.446230 \tValidation Loss: 5.018736\n",
      "Validation loss decreased (5.25324 --> 5.01874).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \tTraining Loss: 5.008299 \tValidation Loss: 4.691967\n",
      "Validation loss decreased (5.01874 --> 4.69197).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.428162 \tValidation Loss: 4.345648\n",
      "Validation loss decreased (4.69197 --> 4.34565).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.795660 \tValidation Loss: 4.030912\n",
      "Validation loss decreased (4.34565 --> 4.03091).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.197144 \tValidation Loss: 3.775673\n",
      "Validation loss decreased (4.03091 --> 3.77567).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.691725 \tValidation Loss: 3.581750\n",
      "Validation loss decreased (3.77567 --> 3.58175).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.284141 \tValidation Loss: 3.438748\n",
      "Validation loss decreased (3.58175 --> 3.43875).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.961296 \tValidation Loss: 3.335901\n",
      "Validation loss decreased (3.43875 --> 3.33590).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.708631 \tValidation Loss: 3.264133\n",
      "Validation loss decreased (3.33590 --> 3.26413).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.506840 \tValidation Loss: 3.217863\n",
      "Validation loss decreased (3.26413 --> 3.21786).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.344965 \tValidation Loss: 3.190248\n",
      "Validation loss decreased (3.21786 --> 3.19025).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.213203 \tValidation Loss: 3.178108\n",
      "Validation loss decreased (3.19025 --> 3.17811).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.105485 \tValidation Loss: 3.176852\n",
      "Validation loss decreased (3.17811 --> 3.17685).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.012327 \tValidation Loss: 3.187278\n",
      "Epoch: 16 \tTraining Loss: 0.935085 \tValidation Loss: 3.204182\n",
      "Epoch: 17 \tTraining Loss: 0.873801 \tValidation Loss: 3.227356\n",
      "Epoch: 18 \tTraining Loss: 0.816413 \tValidation Loss: 3.251584\n",
      "Epoch: 19 \tTraining Loss: 0.767187 \tValidation Loss: 3.281540\n",
      "Epoch: 20 \tTraining Loss: 0.727539 \tValidation Loss: 3.310235\n",
      "Epoch: 1 \tTraining Loss: 6.009079 \tValidation Loss: 5.259933\n",
      "Validation loss decreased (inf --> 5.25993).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.437686 \tValidation Loss: 5.013107\n",
      "Validation loss decreased (5.25993 --> 5.01311).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.994342 \tValidation Loss: 4.667742\n",
      "Validation loss decreased (5.01311 --> 4.66774).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.409719 \tValidation Loss: 4.308644\n",
      "Validation loss decreased (4.66774 --> 4.30864).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.776067 \tValidation Loss: 3.993591\n",
      "Validation loss decreased (4.30864 --> 3.99359).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.181580 \tValidation Loss: 3.744775\n",
      "Validation loss decreased (3.99359 --> 3.74478).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.678402 \tValidation Loss: 3.557887\n",
      "Validation loss decreased (3.74478 --> 3.55789).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.273371 \tValidation Loss: 3.422283\n",
      "Validation loss decreased (3.55789 --> 3.42228).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.955889 \tValidation Loss: 3.325999\n",
      "Validation loss decreased (3.42228 --> 3.32600).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.702921 \tValidation Loss: 3.258297\n",
      "Validation loss decreased (3.32600 --> 3.25830).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.502172 \tValidation Loss: 3.213017\n",
      "Validation loss decreased (3.25830 --> 3.21302).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.341310 \tValidation Loss: 3.187206\n",
      "Validation loss decreased (3.21302 --> 3.18721).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.208933 \tValidation Loss: 3.175832\n",
      "Validation loss decreased (3.18721 --> 3.17583).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.102629 \tValidation Loss: 3.175789\n",
      "Validation loss decreased (3.17583 --> 3.17579).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.010500 \tValidation Loss: 3.184381\n",
      "Epoch: 16 \tTraining Loss: 0.935506 \tValidation Loss: 3.196994\n",
      "Epoch: 17 \tTraining Loss: 0.871354 \tValidation Loss: 3.218531\n",
      "Epoch: 18 \tTraining Loss: 0.811985 \tValidation Loss: 3.242688\n",
      "Epoch: 19 \tTraining Loss: 0.765607 \tValidation Loss: 3.272775\n",
      "Epoch: 20 \tTraining Loss: 0.724942 \tValidation Loss: 3.300928\n",
      "Epoch: 1 \tTraining Loss: 6.009277 \tValidation Loss: 5.252344\n",
      "Validation loss decreased (inf --> 5.25234).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.444421 \tValidation Loss: 5.022611\n",
      "Validation loss decreased (5.25234 --> 5.02261).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.004371 \tValidation Loss: 4.699887\n",
      "Validation loss decreased (5.02261 --> 4.69989).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.423074 \tValidation Loss: 4.359895\n",
      "Validation loss decreased (4.69989 --> 4.35989).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.789360 \tValidation Loss: 4.058476\n",
      "Validation loss decreased (4.35989 --> 4.05848).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.191449 \tValidation Loss: 3.818756\n",
      "Validation loss decreased (4.05848 --> 3.81876).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.684147 \tValidation Loss: 3.641940\n",
      "Validation loss decreased (3.81876 --> 3.64194).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.277297 \tValidation Loss: 3.513917\n",
      "Validation loss decreased (3.64194 --> 3.51392).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.954847 \tValidation Loss: 3.422167\n",
      "Validation loss decreased (3.51392 --> 3.42217).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.703405 \tValidation Loss: 3.359168\n",
      "Validation loss decreased (3.42217 --> 3.35917).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.500636 \tValidation Loss: 3.319115\n",
      "Validation loss decreased (3.35917 --> 3.31912).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.337795 \tValidation Loss: 3.293173\n",
      "Validation loss decreased (3.31912 --> 3.29317).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.205879 \tValidation Loss: 3.282683\n",
      "Validation loss decreased (3.29317 --> 3.28268).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.096890 \tValidation Loss: 3.282963\n",
      "Epoch: 15 \tTraining Loss: 1.008750 \tValidation Loss: 3.292739\n",
      "Epoch: 16 \tTraining Loss: 0.930083 \tValidation Loss: 3.309703\n",
      "Epoch: 17 \tTraining Loss: 0.868113 \tValidation Loss: 3.329636\n",
      "Epoch: 18 \tTraining Loss: 0.809164 \tValidation Loss: 3.352802\n",
      "Epoch: 19 \tTraining Loss: 0.762714 \tValidation Loss: 3.381726\n",
      "Epoch: 20 \tTraining Loss: 0.722000 \tValidation Loss: 3.414370\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 6 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 5.986972 \tValidation Loss: 5.097924\n",
      "Validation loss decreased (inf --> 5.09792).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.382981 \tValidation Loss: 4.845416\n",
      "Validation loss decreased (5.09792 --> 4.84542).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.901299 \tValidation Loss: 4.499959\n",
      "Validation loss decreased (4.84542 --> 4.49996).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.265406 \tValidation Loss: 4.125470\n",
      "Validation loss decreased (4.49996 --> 4.12547).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.580482 \tValidation Loss: 3.789198\n",
      "Validation loss decreased (4.12547 --> 3.78920).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.949726 \tValidation Loss: 3.525329\n",
      "Validation loss decreased (3.78920 --> 3.52533).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.430705 \tValidation Loss: 3.328672\n",
      "Validation loss decreased (3.52533 --> 3.32867).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.018872 \tValidation Loss: 3.185588\n",
      "Validation loss decreased (3.32867 --> 3.18559).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.693413 \tValidation Loss: 3.082729\n",
      "Validation loss decreased (3.18559 --> 3.08273).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.441808 \tValidation Loss: 3.012880\n",
      "Validation loss decreased (3.08273 --> 3.01288).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.237144 \tValidation Loss: 2.961754\n",
      "Validation loss decreased (3.01288 --> 2.96175).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.076974 \tValidation Loss: 2.935267\n",
      "Validation loss decreased (2.96175 --> 2.93527).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.943377 \tValidation Loss: 2.918950\n",
      "Validation loss decreased (2.93527 --> 2.91895).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.834201 \tValidation Loss: 2.916633\n",
      "Validation loss decreased (2.91895 --> 2.91663).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.744006 \tValidation Loss: 2.921712\n",
      "Epoch: 16 \tTraining Loss: 0.669342 \tValidation Loss: 2.937151\n",
      "Epoch: 17 \tTraining Loss: 0.608402 \tValidation Loss: 2.953521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 \tTraining Loss: 0.554079 \tValidation Loss: 2.979979\n",
      "Epoch: 19 \tTraining Loss: 0.510698 \tValidation Loss: 3.009810\n",
      "Epoch: 20 \tTraining Loss: 0.474580 \tValidation Loss: 3.040810\n",
      "Epoch: 1 \tTraining Loss: 5.982676 \tValidation Loss: 5.082710\n",
      "Validation loss decreased (inf --> 5.08271).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.382921 \tValidation Loss: 4.825329\n",
      "Validation loss decreased (5.08271 --> 4.82533).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.907364 \tValidation Loss: 4.467643\n",
      "Validation loss decreased (4.82533 --> 4.46764).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.272073 \tValidation Loss: 4.091232\n",
      "Validation loss decreased (4.46764 --> 4.09123).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.585416 \tValidation Loss: 3.756690\n",
      "Validation loss decreased (4.09123 --> 3.75669).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.951242 \tValidation Loss: 3.491900\n",
      "Validation loss decreased (3.75669 --> 3.49190).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.429864 \tValidation Loss: 3.294633\n",
      "Validation loss decreased (3.49190 --> 3.29463).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.018771 \tValidation Loss: 3.150182\n",
      "Validation loss decreased (3.29463 --> 3.15018).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.697105 \tValidation Loss: 3.046000\n",
      "Validation loss decreased (3.15018 --> 3.04600).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.443771 \tValidation Loss: 2.972099\n",
      "Validation loss decreased (3.04600 --> 2.97210).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.242100 \tValidation Loss: 2.920587\n",
      "Validation loss decreased (2.97210 --> 2.92059).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.080606 \tValidation Loss: 2.886262\n",
      "Validation loss decreased (2.92059 --> 2.88626).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.945815 \tValidation Loss: 2.869987\n",
      "Validation loss decreased (2.88626 --> 2.86999).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.841854 \tValidation Loss: 2.860359\n",
      "Validation loss decreased (2.86999 --> 2.86036).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.750502 \tValidation Loss: 2.863457\n",
      "Epoch: 16 \tTraining Loss: 0.677695 \tValidation Loss: 2.872711\n",
      "Epoch: 17 \tTraining Loss: 0.615254 \tValidation Loss: 2.889689\n",
      "Epoch: 18 \tTraining Loss: 0.564912 \tValidation Loss: 2.909966\n",
      "Epoch: 19 \tTraining Loss: 0.520333 \tValidation Loss: 2.936342\n",
      "Epoch: 20 \tTraining Loss: 0.480401 \tValidation Loss: 2.965462\n",
      "Epoch: 1 \tTraining Loss: 5.982403 \tValidation Loss: 5.127488\n",
      "Validation loss decreased (inf --> 5.12749).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.378137 \tValidation Loss: 4.885803\n",
      "Validation loss decreased (5.12749 --> 4.88580).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.900429 \tValidation Loss: 4.546815\n",
      "Validation loss decreased (4.88580 --> 4.54681).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.265308 \tValidation Loss: 4.182438\n",
      "Validation loss decreased (4.54681 --> 4.18244).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.575182 \tValidation Loss: 3.853781\n",
      "Validation loss decreased (4.18244 --> 3.85378).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.946038 \tValidation Loss: 3.588021\n",
      "Validation loss decreased (3.85378 --> 3.58802).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.421743 \tValidation Loss: 3.387018\n",
      "Validation loss decreased (3.58802 --> 3.38702).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.007255 \tValidation Loss: 3.239811\n",
      "Validation loss decreased (3.38702 --> 3.23981).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.684788 \tValidation Loss: 3.132811\n",
      "Validation loss decreased (3.23981 --> 3.13281).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.432430 \tValidation Loss: 3.054989\n",
      "Validation loss decreased (3.13281 --> 3.05499).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.231794 \tValidation Loss: 3.001838\n",
      "Validation loss decreased (3.05499 --> 3.00184).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.069884 \tValidation Loss: 2.965627\n",
      "Validation loss decreased (3.00184 --> 2.96563).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.937980 \tValidation Loss: 2.945425\n",
      "Validation loss decreased (2.96563 --> 2.94542).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.829387 \tValidation Loss: 2.936665\n",
      "Validation loss decreased (2.94542 --> 2.93666).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.740204 \tValidation Loss: 2.936990\n",
      "Epoch: 16 \tTraining Loss: 0.670512 \tValidation Loss: 2.945882\n",
      "Epoch: 17 \tTraining Loss: 0.608045 \tValidation Loss: 2.963087\n",
      "Epoch: 18 \tTraining Loss: 0.558303 \tValidation Loss: 2.980844\n",
      "Epoch: 19 \tTraining Loss: 0.509967 \tValidation Loss: 3.003859\n",
      "Epoch: 20 \tTraining Loss: 0.473649 \tValidation Loss: 3.035605\n",
      "Epoch: 1 \tTraining Loss: 5.984515 \tValidation Loss: 5.117782\n",
      "Validation loss decreased (inf --> 5.11778).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.372577 \tValidation Loss: 4.869270\n",
      "Validation loss decreased (5.11778 --> 4.86927).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.901096 \tValidation Loss: 4.520410\n",
      "Validation loss decreased (4.86927 --> 4.52041).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.270864 \tValidation Loss: 4.144440\n",
      "Validation loss decreased (4.52041 --> 4.14444).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.584025 \tValidation Loss: 3.804216\n",
      "Validation loss decreased (4.14444 --> 3.80422).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.950783 \tValidation Loss: 3.532813\n",
      "Validation loss decreased (3.80422 --> 3.53281).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.429769 \tValidation Loss: 3.328647\n",
      "Validation loss decreased (3.53281 --> 3.32865).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.014531 \tValidation Loss: 3.181181\n",
      "Validation loss decreased (3.32865 --> 3.18118).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.690363 \tValidation Loss: 3.075756\n",
      "Validation loss decreased (3.18118 --> 3.07576).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.438250 \tValidation Loss: 3.002676\n",
      "Validation loss decreased (3.07576 --> 3.00268).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.233302 \tValidation Loss: 2.954535\n",
      "Validation loss decreased (3.00268 --> 2.95454).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.073956 \tValidation Loss: 2.922620\n",
      "Validation loss decreased (2.95454 --> 2.92262).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.942744 \tValidation Loss: 2.903083\n",
      "Validation loss decreased (2.92262 --> 2.90308).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.833660 \tValidation Loss: 2.898409\n",
      "Validation loss decreased (2.90308 --> 2.89841).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.744854 \tValidation Loss: 2.901352\n",
      "Epoch: 16 \tTraining Loss: 0.668178 \tValidation Loss: 2.909915\n",
      "Epoch: 17 \tTraining Loss: 0.607751 \tValidation Loss: 2.927132\n",
      "Epoch: 18 \tTraining Loss: 0.558272 \tValidation Loss: 2.946579\n",
      "Epoch: 19 \tTraining Loss: 0.512634 \tValidation Loss: 2.973194\n",
      "Epoch: 20 \tTraining Loss: 0.477404 \tValidation Loss: 2.999840\n",
      "Epoch: 1 \tTraining Loss: 5.987597 \tValidation Loss: 5.117982\n",
      "Validation loss decreased (inf --> 5.11798).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.384827 \tValidation Loss: 4.879085\n",
      "Validation loss decreased (5.11798 --> 4.87908).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.909056 \tValidation Loss: 4.540369\n",
      "Validation loss decreased (4.87908 --> 4.54037).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.279002 \tValidation Loss: 4.167654\n",
      "Validation loss decreased (4.54037 --> 4.16765).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.593384 \tValidation Loss: 3.829225\n",
      "Validation loss decreased (4.16765 --> 3.82922).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.958737 \tValidation Loss: 3.560756\n",
      "Validation loss decreased (3.82922 --> 3.56076).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.433351 \tValidation Loss: 3.360257\n",
      "Validation loss decreased (3.56076 --> 3.36026).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.017350 \tValidation Loss: 3.213477\n",
      "Validation loss decreased (3.36026 --> 3.21348).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.694274 \tValidation Loss: 3.109372\n",
      "Validation loss decreased (3.21348 --> 3.10937).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.440879 \tValidation Loss: 3.036602\n",
      "Validation loss decreased (3.10937 --> 3.03660).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.239480 \tValidation Loss: 2.986421\n",
      "Validation loss decreased (3.03660 --> 2.98642).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.073253 \tValidation Loss: 2.955311\n",
      "Validation loss decreased (2.98642 --> 2.95531).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 \tTraining Loss: 0.942049 \tValidation Loss: 2.938486\n",
      "Validation loss decreased (2.95531 --> 2.93849).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.833940 \tValidation Loss: 2.932346\n",
      "Validation loss decreased (2.93849 --> 2.93235).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.746695 \tValidation Loss: 2.933889\n",
      "Epoch: 16 \tTraining Loss: 0.672646 \tValidation Loss: 2.943291\n",
      "Epoch: 17 \tTraining Loss: 0.608967 \tValidation Loss: 2.959695\n",
      "Epoch: 18 \tTraining Loss: 0.559506 \tValidation Loss: 2.984984\n",
      "Epoch: 19 \tTraining Loss: 0.514922 \tValidation Loss: 3.015043\n",
      "Epoch: 20 \tTraining Loss: 0.477532 \tValidation Loss: 3.042070\n",
      "Epoch: 1 \tTraining Loss: 5.980385 \tValidation Loss: 5.130228\n",
      "Validation loss decreased (inf --> 5.13023).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.368583 \tValidation Loss: 4.890485\n",
      "Validation loss decreased (5.13023 --> 4.89049).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.883723 \tValidation Loss: 4.553851\n",
      "Validation loss decreased (4.89049 --> 4.55385).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.249861 \tValidation Loss: 4.184825\n",
      "Validation loss decreased (4.55385 --> 4.18483).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.572080 \tValidation Loss: 3.847265\n",
      "Validation loss decreased (4.18483 --> 3.84727).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.942450 \tValidation Loss: 3.579084\n",
      "Validation loss decreased (3.84727 --> 3.57908).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.427749 \tValidation Loss: 3.380350\n",
      "Validation loss decreased (3.57908 --> 3.38035).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.014915 \tValidation Loss: 3.236763\n",
      "Validation loss decreased (3.38035 --> 3.23676).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.691745 \tValidation Loss: 3.135738\n",
      "Validation loss decreased (3.23676 --> 3.13574).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.436700 \tValidation Loss: 3.064237\n",
      "Validation loss decreased (3.13574 --> 3.06424).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.235579 \tValidation Loss: 3.016553\n",
      "Validation loss decreased (3.06424 --> 3.01655).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.073461 \tValidation Loss: 2.984155\n",
      "Validation loss decreased (3.01655 --> 2.98415).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.944824 \tValidation Loss: 2.965758\n",
      "Validation loss decreased (2.98415 --> 2.96576).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.836007 \tValidation Loss: 2.958246\n",
      "Validation loss decreased (2.96576 --> 2.95825).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.745642 \tValidation Loss: 2.964075\n",
      "Epoch: 16 \tTraining Loss: 0.671678 \tValidation Loss: 2.978311\n",
      "Epoch: 17 \tTraining Loss: 0.610484 \tValidation Loss: 2.992992\n",
      "Epoch: 18 \tTraining Loss: 0.557943 \tValidation Loss: 3.017163\n",
      "Epoch: 19 \tTraining Loss: 0.513785 \tValidation Loss: 3.041716\n",
      "Epoch: 20 \tTraining Loss: 0.475841 \tValidation Loss: 3.071868\n",
      "Epoch: 1 \tTraining Loss: 5.976256 \tValidation Loss: 5.102445\n",
      "Validation loss decreased (inf --> 5.10245).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.372533 \tValidation Loss: 4.863687\n",
      "Validation loss decreased (5.10245 --> 4.86369).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.895549 \tValidation Loss: 4.529573\n",
      "Validation loss decreased (4.86369 --> 4.52957).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.265128 \tValidation Loss: 4.170442\n",
      "Validation loss decreased (4.52957 --> 4.17044).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.584296 \tValidation Loss: 3.837938\n",
      "Validation loss decreased (4.17044 --> 3.83794).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.956404 \tValidation Loss: 3.564951\n",
      "Validation loss decreased (3.83794 --> 3.56495).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.434939 \tValidation Loss: 3.357592\n",
      "Validation loss decreased (3.56495 --> 3.35759).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.019938 \tValidation Loss: 3.202875\n",
      "Validation loss decreased (3.35759 --> 3.20287).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.692487 \tValidation Loss: 3.092647\n",
      "Validation loss decreased (3.20287 --> 3.09265).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.436308 \tValidation Loss: 3.013561\n",
      "Validation loss decreased (3.09265 --> 3.01356).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.233416 \tValidation Loss: 2.957903\n",
      "Validation loss decreased (3.01356 --> 2.95790).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.073451 \tValidation Loss: 2.925382\n",
      "Validation loss decreased (2.95790 --> 2.92538).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.941257 \tValidation Loss: 2.904490\n",
      "Validation loss decreased (2.92538 --> 2.90449).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.830029 \tValidation Loss: 2.897718\n",
      "Validation loss decreased (2.90449 --> 2.89772).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.745165 \tValidation Loss: 2.902810\n",
      "Epoch: 16 \tTraining Loss: 0.668273 \tValidation Loss: 2.917709\n",
      "Epoch: 17 \tTraining Loss: 0.607309 \tValidation Loss: 2.938113\n",
      "Epoch: 18 \tTraining Loss: 0.556800 \tValidation Loss: 2.960439\n",
      "Epoch: 19 \tTraining Loss: 0.511906 \tValidation Loss: 2.990539\n",
      "Epoch: 20 \tTraining Loss: 0.474488 \tValidation Loss: 3.016728\n",
      "Epoch: 1 \tTraining Loss: 5.987831 \tValidation Loss: 5.100642\n",
      "Validation loss decreased (inf --> 5.10064).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.370775 \tValidation Loss: 4.851539\n",
      "Validation loss decreased (5.10064 --> 4.85154).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.885122 \tValidation Loss: 4.506416\n",
      "Validation loss decreased (4.85154 --> 4.50642).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.247453 \tValidation Loss: 4.136456\n",
      "Validation loss decreased (4.50642 --> 4.13646).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.561832 \tValidation Loss: 3.805684\n",
      "Validation loss decreased (4.13646 --> 3.80568).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.936980 \tValidation Loss: 3.542279\n",
      "Validation loss decreased (3.80568 --> 3.54228).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.419104 \tValidation Loss: 3.341387\n",
      "Validation loss decreased (3.54228 --> 3.34139).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.009673 \tValidation Loss: 3.193079\n",
      "Validation loss decreased (3.34139 --> 3.19308).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.690682 \tValidation Loss: 3.085392\n",
      "Validation loss decreased (3.19308 --> 3.08539).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.439523 \tValidation Loss: 3.005885\n",
      "Validation loss decreased (3.08539 --> 3.00589).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.234729 \tValidation Loss: 2.955632\n",
      "Validation loss decreased (3.00589 --> 2.95563).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.074295 \tValidation Loss: 2.920757\n",
      "Validation loss decreased (2.95563 --> 2.92076).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.944458 \tValidation Loss: 2.899122\n",
      "Validation loss decreased (2.92076 --> 2.89912).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.836539 \tValidation Loss: 2.895885\n",
      "Validation loss decreased (2.89912 --> 2.89589).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.748243 \tValidation Loss: 2.901291\n",
      "Epoch: 16 \tTraining Loss: 0.675876 \tValidation Loss: 2.909001\n",
      "Epoch: 17 \tTraining Loss: 0.614531 \tValidation Loss: 2.922842\n",
      "Epoch: 18 \tTraining Loss: 0.561436 \tValidation Loss: 2.947331\n",
      "Epoch: 19 \tTraining Loss: 0.516593 \tValidation Loss: 2.971543\n",
      "Epoch: 20 \tTraining Loss: 0.482027 \tValidation Loss: 2.999208\n",
      "Epoch: 1 \tTraining Loss: 5.983485 \tValidation Loss: 5.111689\n",
      "Validation loss decreased (inf --> 5.11169).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.373824 \tValidation Loss: 4.863605\n",
      "Validation loss decreased (5.11169 --> 4.86360).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.895821 \tValidation Loss: 4.526479\n",
      "Validation loss decreased (4.86360 --> 4.52648).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.262797 \tValidation Loss: 4.163963\n",
      "Validation loss decreased (4.52648 --> 4.16396).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.580118 \tValidation Loss: 3.833988\n",
      "Validation loss decreased (4.16396 --> 3.83399).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.955631 \tValidation Loss: 3.566493\n",
      "Validation loss decreased (3.83399 --> 3.56649).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.438498 \tValidation Loss: 3.359679\n",
      "Validation loss decreased (3.56649 --> 3.35968).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.027309 \tValidation Loss: 3.202275\n",
      "Validation loss decreased (3.35968 --> 3.20227).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.701436 \tValidation Loss: 3.083385\n",
      "Validation loss decreased (3.20227 --> 3.08339).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 \tTraining Loss: 1.447258 \tValidation Loss: 2.998825\n",
      "Validation loss decreased (3.08339 --> 2.99882).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.248064 \tValidation Loss: 2.936882\n",
      "Validation loss decreased (2.99882 --> 2.93688).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.084412 \tValidation Loss: 2.894242\n",
      "Validation loss decreased (2.93688 --> 2.89424).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.953697 \tValidation Loss: 2.866197\n",
      "Validation loss decreased (2.89424 --> 2.86620).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.846167 \tValidation Loss: 2.853401\n",
      "Validation loss decreased (2.86620 --> 2.85340).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.752274 \tValidation Loss: 2.849213\n",
      "Validation loss decreased (2.85340 --> 2.84921).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.678493 \tValidation Loss: 2.852894\n",
      "Epoch: 17 \tTraining Loss: 0.614863 \tValidation Loss: 2.865150\n",
      "Epoch: 18 \tTraining Loss: 0.566195 \tValidation Loss: 2.881802\n",
      "Epoch: 19 \tTraining Loss: 0.521951 \tValidation Loss: 2.900630\n",
      "Epoch: 20 \tTraining Loss: 0.480173 \tValidation Loss: 2.925715\n",
      "Epoch: 1 \tTraining Loss: 5.989044 \tValidation Loss: 5.121719\n",
      "Validation loss decreased (inf --> 5.12172).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.378672 \tValidation Loss: 4.878148\n",
      "Validation loss decreased (5.12172 --> 4.87815).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.902280 \tValidation Loss: 4.534806\n",
      "Validation loss decreased (4.87815 --> 4.53481).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.267958 \tValidation Loss: 4.165516\n",
      "Validation loss decreased (4.53481 --> 4.16552).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.583382 \tValidation Loss: 3.833048\n",
      "Validation loss decreased (4.16552 --> 3.83305).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.952338 \tValidation Loss: 3.563911\n",
      "Validation loss decreased (3.83305 --> 3.56391).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.432953 \tValidation Loss: 3.359558\n",
      "Validation loss decreased (3.56391 --> 3.35956).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.022506 \tValidation Loss: 3.207122\n",
      "Validation loss decreased (3.35956 --> 3.20712).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.695778 \tValidation Loss: 3.099417\n",
      "Validation loss decreased (3.20712 --> 3.09942).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.443162 \tValidation Loss: 3.022671\n",
      "Validation loss decreased (3.09942 --> 3.02267).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.241062 \tValidation Loss: 2.967439\n",
      "Validation loss decreased (3.02267 --> 2.96744).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.078705 \tValidation Loss: 2.934283\n",
      "Validation loss decreased (2.96744 --> 2.93428).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.944229 \tValidation Loss: 2.916214\n",
      "Validation loss decreased (2.93428 --> 2.91621).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.838101 \tValidation Loss: 2.911125\n",
      "Validation loss decreased (2.91621 --> 2.91112).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.748085 \tValidation Loss: 2.911898\n",
      "Epoch: 16 \tTraining Loss: 0.675615 \tValidation Loss: 2.918513\n",
      "Epoch: 17 \tTraining Loss: 0.611724 \tValidation Loss: 2.936413\n",
      "Epoch: 18 \tTraining Loss: 0.560555 \tValidation Loss: 2.953452\n",
      "Epoch: 19 \tTraining Loss: 0.516095 \tValidation Loss: 2.979362\n",
      "Epoch: 20 \tTraining Loss: 0.477749 \tValidation Loss: 3.008131\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 7 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.060671 \tValidation Loss: 4.977334\n",
      "Validation loss decreased (inf --> 4.97733).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.414822 \tValidation Loss: 4.728940\n",
      "Validation loss decreased (4.97733 --> 4.72894).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.914085 \tValidation Loss: 4.386916\n",
      "Validation loss decreased (4.72894 --> 4.38692).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.242487 \tValidation Loss: 4.011585\n",
      "Validation loss decreased (4.38692 --> 4.01159).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.509498 \tValidation Loss: 3.676011\n",
      "Validation loss decreased (4.01159 --> 3.67601).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.848185 \tValidation Loss: 3.407528\n",
      "Validation loss decreased (3.67601 --> 3.40753).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.304112 \tValidation Loss: 3.201253\n",
      "Validation loss decreased (3.40753 --> 3.20125).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.877365 \tValidation Loss: 3.044991\n",
      "Validation loss decreased (3.20125 --> 3.04499).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.547047 \tValidation Loss: 2.931428\n",
      "Validation loss decreased (3.04499 --> 2.93143).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.287570 \tValidation Loss: 2.852381\n",
      "Validation loss decreased (2.93143 --> 2.85238).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.083800 \tValidation Loss: 2.794556\n",
      "Validation loss decreased (2.85238 --> 2.79456).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.919892 \tValidation Loss: 2.756571\n",
      "Validation loss decreased (2.79456 --> 2.75657).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.786194 \tValidation Loss: 2.736318\n",
      "Validation loss decreased (2.75657 --> 2.73632).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.680051 \tValidation Loss: 2.727155\n",
      "Validation loss decreased (2.73632 --> 2.72716).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.596919 \tValidation Loss: 2.724880\n",
      "Validation loss decreased (2.72716 --> 2.72488).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.522804 \tValidation Loss: 2.729656\n",
      "Epoch: 17 \tTraining Loss: 0.462921 \tValidation Loss: 2.744733\n",
      "Epoch: 18 \tTraining Loss: 0.414152 \tValidation Loss: 2.759802\n",
      "Epoch: 19 \tTraining Loss: 0.374816 \tValidation Loss: 2.784092\n",
      "Epoch: 20 \tTraining Loss: 0.340959 \tValidation Loss: 2.808804\n",
      "Epoch: 1 \tTraining Loss: 6.065825 \tValidation Loss: 5.018431\n",
      "Validation loss decreased (inf --> 5.01843).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.411459 \tValidation Loss: 4.772951\n",
      "Validation loss decreased (5.01843 --> 4.77295).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.904308 \tValidation Loss: 4.413843\n",
      "Validation loss decreased (4.77295 --> 4.41384).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.237399 \tValidation Loss: 4.015562\n",
      "Validation loss decreased (4.41384 --> 4.01556).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.511910 \tValidation Loss: 3.662855\n",
      "Validation loss decreased (4.01556 --> 3.66286).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.848425 \tValidation Loss: 3.389669\n",
      "Validation loss decreased (3.66286 --> 3.38967).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.307487 \tValidation Loss: 3.188270\n",
      "Validation loss decreased (3.38967 --> 3.18827).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.886086 \tValidation Loss: 3.039716\n",
      "Validation loss decreased (3.18827 --> 3.03972).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.561452 \tValidation Loss: 2.931511\n",
      "Validation loss decreased (3.03972 --> 2.93151).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.301357 \tValidation Loss: 2.850608\n",
      "Validation loss decreased (2.93151 --> 2.85061).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.096403 \tValidation Loss: 2.794963\n",
      "Validation loss decreased (2.85061 --> 2.79496).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.932134 \tValidation Loss: 2.760755\n",
      "Validation loss decreased (2.79496 --> 2.76075).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.803195 \tValidation Loss: 2.741370\n",
      "Validation loss decreased (2.76075 --> 2.74137).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.690939 \tValidation Loss: 2.734375\n",
      "Validation loss decreased (2.74137 --> 2.73438).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.608237 \tValidation Loss: 2.735281\n",
      "Epoch: 16 \tTraining Loss: 0.534886 \tValidation Loss: 2.747093\n",
      "Epoch: 17 \tTraining Loss: 0.474783 \tValidation Loss: 2.760796\n",
      "Epoch: 18 \tTraining Loss: 0.425042 \tValidation Loss: 2.780099\n",
      "Epoch: 19 \tTraining Loss: 0.380654 \tValidation Loss: 2.806768\n",
      "Epoch: 20 \tTraining Loss: 0.350265 \tValidation Loss: 2.833646\n",
      "Epoch: 1 \tTraining Loss: 6.056413 \tValidation Loss: 5.006339\n",
      "Validation loss decreased (inf --> 5.00634).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.409714 \tValidation Loss: 4.752111\n",
      "Validation loss decreased (5.00634 --> 4.75211).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.903677 \tValidation Loss: 4.402353\n",
      "Validation loss decreased (4.75211 --> 4.40235).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.234790 \tValidation Loss: 4.025460\n",
      "Validation loss decreased (4.40235 --> 4.02546).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \tTraining Loss: 3.513986 \tValidation Loss: 3.684108\n",
      "Validation loss decreased (4.02546 --> 3.68411).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.856560 \tValidation Loss: 3.409787\n",
      "Validation loss decreased (3.68411 --> 3.40979).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.318699 \tValidation Loss: 3.199944\n",
      "Validation loss decreased (3.40979 --> 3.19994).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.893299 \tValidation Loss: 3.041786\n",
      "Validation loss decreased (3.19994 --> 3.04179).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.563836 \tValidation Loss: 2.925943\n",
      "Validation loss decreased (3.04179 --> 2.92594).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.305771 \tValidation Loss: 2.842021\n",
      "Validation loss decreased (2.92594 --> 2.84202).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.100688 \tValidation Loss: 2.782682\n",
      "Validation loss decreased (2.84202 --> 2.78268).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.938467 \tValidation Loss: 2.746837\n",
      "Validation loss decreased (2.78268 --> 2.74684).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.804280 \tValidation Loss: 2.724183\n",
      "Validation loss decreased (2.74684 --> 2.72418).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.695953 \tValidation Loss: 2.712289\n",
      "Validation loss decreased (2.72418 --> 2.71229).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.607019 \tValidation Loss: 2.710993\n",
      "Validation loss decreased (2.71229 --> 2.71099).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.533302 \tValidation Loss: 2.722590\n",
      "Epoch: 17 \tTraining Loss: 0.474858 \tValidation Loss: 2.736116\n",
      "Epoch: 18 \tTraining Loss: 0.422943 \tValidation Loss: 2.760070\n",
      "Epoch: 19 \tTraining Loss: 0.387126 \tValidation Loss: 2.782103\n",
      "Epoch: 20 \tTraining Loss: 0.349818 \tValidation Loss: 2.808653\n",
      "Epoch: 1 \tTraining Loss: 6.058390 \tValidation Loss: 5.013524\n",
      "Validation loss decreased (inf --> 5.01352).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.409389 \tValidation Loss: 4.774416\n",
      "Validation loss decreased (5.01352 --> 4.77442).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.903499 \tValidation Loss: 4.427774\n",
      "Validation loss decreased (4.77442 --> 4.42777).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.230765 \tValidation Loss: 4.049336\n",
      "Validation loss decreased (4.42777 --> 4.04934).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.506796 \tValidation Loss: 3.705722\n",
      "Validation loss decreased (4.04934 --> 3.70572).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.848903 \tValidation Loss: 3.428707\n",
      "Validation loss decreased (3.70572 --> 3.42871).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.313135 \tValidation Loss: 3.214519\n",
      "Validation loss decreased (3.42871 --> 3.21452).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.892240 \tValidation Loss: 3.052920\n",
      "Validation loss decreased (3.21452 --> 3.05292).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.563787 \tValidation Loss: 2.932319\n",
      "Validation loss decreased (3.05292 --> 2.93232).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.302937 \tValidation Loss: 2.843571\n",
      "Validation loss decreased (2.93232 --> 2.84357).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.100218 \tValidation Loss: 2.781143\n",
      "Validation loss decreased (2.84357 --> 2.78114).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.936772 \tValidation Loss: 2.741504\n",
      "Validation loss decreased (2.78114 --> 2.74150).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.803959 \tValidation Loss: 2.716899\n",
      "Validation loss decreased (2.74150 --> 2.71690).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.693746 \tValidation Loss: 2.707067\n",
      "Validation loss decreased (2.71690 --> 2.70707).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.604183 \tValidation Loss: 2.706593\n",
      "Validation loss decreased (2.70707 --> 2.70659).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.535307 \tValidation Loss: 2.713453\n",
      "Epoch: 17 \tTraining Loss: 0.474664 \tValidation Loss: 2.727689\n",
      "Epoch: 18 \tTraining Loss: 0.424452 \tValidation Loss: 2.745263\n",
      "Epoch: 19 \tTraining Loss: 0.386571 \tValidation Loss: 2.769094\n",
      "Epoch: 20 \tTraining Loss: 0.349320 \tValidation Loss: 2.794690\n",
      "Epoch: 1 \tTraining Loss: 6.067965 \tValidation Loss: 4.968931\n",
      "Validation loss decreased (inf --> 4.96893).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.418955 \tValidation Loss: 4.724787\n",
      "Validation loss decreased (4.96893 --> 4.72479).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.911503 \tValidation Loss: 4.391343\n",
      "Validation loss decreased (4.72479 --> 4.39134).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.239492 \tValidation Loss: 4.029204\n",
      "Validation loss decreased (4.39134 --> 4.02920).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.511254 \tValidation Loss: 3.701075\n",
      "Validation loss decreased (4.02920 --> 3.70107).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.849658 \tValidation Loss: 3.436008\n",
      "Validation loss decreased (3.70107 --> 3.43601).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.313050 \tValidation Loss: 3.233998\n",
      "Validation loss decreased (3.43601 --> 3.23400).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.888306 \tValidation Loss: 3.080684\n",
      "Validation loss decreased (3.23400 --> 3.08068).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.558940 \tValidation Loss: 2.967307\n",
      "Validation loss decreased (3.08068 --> 2.96731).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.300031 \tValidation Loss: 2.883901\n",
      "Validation loss decreased (2.96731 --> 2.88390).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.095436 \tValidation Loss: 2.824319\n",
      "Validation loss decreased (2.88390 --> 2.82432).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.930123 \tValidation Loss: 2.784982\n",
      "Validation loss decreased (2.82432 --> 2.78498).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.800595 \tValidation Loss: 2.759477\n",
      "Validation loss decreased (2.78498 --> 2.75948).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.689735 \tValidation Loss: 2.749073\n",
      "Validation loss decreased (2.75948 --> 2.74907).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.602288 \tValidation Loss: 2.752316\n",
      "Epoch: 16 \tTraining Loss: 0.531977 \tValidation Loss: 2.758526\n",
      "Epoch: 17 \tTraining Loss: 0.469808 \tValidation Loss: 2.772667\n",
      "Epoch: 18 \tTraining Loss: 0.421940 \tValidation Loss: 2.790691\n",
      "Epoch: 19 \tTraining Loss: 0.379772 \tValidation Loss: 2.812488\n",
      "Epoch: 20 \tTraining Loss: 0.346582 \tValidation Loss: 2.836147\n",
      "Epoch: 1 \tTraining Loss: 6.055298 \tValidation Loss: 4.986270\n",
      "Validation loss decreased (inf --> 4.98627).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.420519 \tValidation Loss: 4.743858\n",
      "Validation loss decreased (4.98627 --> 4.74386).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.927324 \tValidation Loss: 4.395426\n",
      "Validation loss decreased (4.74386 --> 4.39543).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.261298 \tValidation Loss: 4.009515\n",
      "Validation loss decreased (4.39543 --> 4.00951).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.536299 \tValidation Loss: 3.657840\n",
      "Validation loss decreased (4.00951 --> 3.65784).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.875290 \tValidation Loss: 3.371644\n",
      "Validation loss decreased (3.65784 --> 3.37164).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.327652 \tValidation Loss: 3.152076\n",
      "Validation loss decreased (3.37164 --> 3.15208).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.901072 \tValidation Loss: 2.990132\n",
      "Validation loss decreased (3.15208 --> 2.99013).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.569718 \tValidation Loss: 2.869724\n",
      "Validation loss decreased (2.99013 --> 2.86972).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.309130 \tValidation Loss: 2.780842\n",
      "Validation loss decreased (2.86972 --> 2.78084).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.104826 \tValidation Loss: 2.715675\n",
      "Validation loss decreased (2.78084 --> 2.71568).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.937744 \tValidation Loss: 2.671809\n",
      "Validation loss decreased (2.71568 --> 2.67181).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.803392 \tValidation Loss: 2.643582\n",
      "Validation loss decreased (2.67181 --> 2.64358).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.696595 \tValidation Loss: 2.627855\n",
      "Validation loss decreased (2.64358 --> 2.62786).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.605129 \tValidation Loss: 2.621375\n",
      "Validation loss decreased (2.62786 --> 2.62138).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.534692 \tValidation Loss: 2.626107\n",
      "Epoch: 17 \tTraining Loss: 0.474203 \tValidation Loss: 2.635429\n",
      "Epoch: 18 \tTraining Loss: 0.421918 \tValidation Loss: 2.648642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 \tTraining Loss: 0.383273 \tValidation Loss: 2.669851\n",
      "Epoch: 20 \tTraining Loss: 0.348855 \tValidation Loss: 2.689721\n",
      "Epoch: 1 \tTraining Loss: 6.063649 \tValidation Loss: 5.042500\n",
      "Validation loss decreased (inf --> 5.04250).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.404717 \tValidation Loss: 4.790917\n",
      "Validation loss decreased (5.04250 --> 4.79092).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.901730 \tValidation Loss: 4.436692\n",
      "Validation loss decreased (4.79092 --> 4.43669).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.237550 \tValidation Loss: 4.043547\n",
      "Validation loss decreased (4.43669 --> 4.04355).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.520226 \tValidation Loss: 3.682987\n",
      "Validation loss decreased (4.04355 --> 3.68299).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.867515 \tValidation Loss: 3.384917\n",
      "Validation loss decreased (3.68299 --> 3.38492).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.326141 \tValidation Loss: 3.154979\n",
      "Validation loss decreased (3.38492 --> 3.15498).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.904564 \tValidation Loss: 2.982580\n",
      "Validation loss decreased (3.15498 --> 2.98258).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.572953 \tValidation Loss: 2.856474\n",
      "Validation loss decreased (2.98258 --> 2.85647).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.313177 \tValidation Loss: 2.767501\n",
      "Validation loss decreased (2.85647 --> 2.76750).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.106953 \tValidation Loss: 2.703648\n",
      "Validation loss decreased (2.76750 --> 2.70365).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.941615 \tValidation Loss: 2.660626\n",
      "Validation loss decreased (2.70365 --> 2.66063).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.807503 \tValidation Loss: 2.636788\n",
      "Validation loss decreased (2.66063 --> 2.63679).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.697033 \tValidation Loss: 2.621227\n",
      "Validation loss decreased (2.63679 --> 2.62123).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.611299 \tValidation Loss: 2.617337\n",
      "Validation loss decreased (2.62123 --> 2.61734).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.535669 \tValidation Loss: 2.623355\n",
      "Epoch: 17 \tTraining Loss: 0.476935 \tValidation Loss: 2.631489\n",
      "Epoch: 18 \tTraining Loss: 0.426095 \tValidation Loss: 2.649926\n",
      "Epoch: 19 \tTraining Loss: 0.384884 \tValidation Loss: 2.671031\n",
      "Epoch: 20 \tTraining Loss: 0.349354 \tValidation Loss: 2.694714\n",
      "Epoch: 1 \tTraining Loss: 6.062574 \tValidation Loss: 5.000985\n",
      "Validation loss decreased (inf --> 5.00098).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.410218 \tValidation Loss: 4.745964\n",
      "Validation loss decreased (5.00098 --> 4.74596).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.910203 \tValidation Loss: 4.391320\n",
      "Validation loss decreased (4.74596 --> 4.39132).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.242511 \tValidation Loss: 4.006717\n",
      "Validation loss decreased (4.39132 --> 4.00672).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.517549 \tValidation Loss: 3.660363\n",
      "Validation loss decreased (4.00672 --> 3.66036).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.857763 \tValidation Loss: 3.384821\n",
      "Validation loss decreased (3.66036 --> 3.38482).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.317451 \tValidation Loss: 3.176475\n",
      "Validation loss decreased (3.38482 --> 3.17648).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.891062 \tValidation Loss: 3.021952\n",
      "Validation loss decreased (3.17648 --> 3.02195).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.562868 \tValidation Loss: 2.910926\n",
      "Validation loss decreased (3.02195 --> 2.91093).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.302171 \tValidation Loss: 2.834855\n",
      "Validation loss decreased (2.91093 --> 2.83485).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.097963 \tValidation Loss: 2.781618\n",
      "Validation loss decreased (2.83485 --> 2.78162).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.931355 \tValidation Loss: 2.746692\n",
      "Validation loss decreased (2.78162 --> 2.74669).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.799510 \tValidation Loss: 2.729550\n",
      "Validation loss decreased (2.74669 --> 2.72955).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.690903 \tValidation Loss: 2.723225\n",
      "Validation loss decreased (2.72955 --> 2.72323).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.604811 \tValidation Loss: 2.726207\n",
      "Epoch: 16 \tTraining Loss: 0.533771 \tValidation Loss: 2.731992\n",
      "Epoch: 17 \tTraining Loss: 0.472093 \tValidation Loss: 2.748894\n",
      "Epoch: 18 \tTraining Loss: 0.422470 \tValidation Loss: 2.771437\n",
      "Epoch: 19 \tTraining Loss: 0.379779 \tValidation Loss: 2.794909\n",
      "Epoch: 20 \tTraining Loss: 0.346829 \tValidation Loss: 2.820216\n",
      "Epoch: 1 \tTraining Loss: 6.058767 \tValidation Loss: 4.961610\n",
      "Validation loss decreased (inf --> 4.96161).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.420616 \tValidation Loss: 4.710861\n",
      "Validation loss decreased (4.96161 --> 4.71086).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.913224 \tValidation Loss: 4.352150\n",
      "Validation loss decreased (4.71086 --> 4.35215).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.237609 \tValidation Loss: 3.974900\n",
      "Validation loss decreased (4.35215 --> 3.97490).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.509649 \tValidation Loss: 3.639567\n",
      "Validation loss decreased (3.97490 --> 3.63957).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.851491 \tValidation Loss: 3.372740\n",
      "Validation loss decreased (3.63957 --> 3.37274).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.315133 \tValidation Loss: 3.174463\n",
      "Validation loss decreased (3.37274 --> 3.17446).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.893541 \tValidation Loss: 3.025037\n",
      "Validation loss decreased (3.17446 --> 3.02504).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.562954 \tValidation Loss: 2.914295\n",
      "Validation loss decreased (3.02504 --> 2.91430).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.307263 \tValidation Loss: 2.835416\n",
      "Validation loss decreased (2.91430 --> 2.83542).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.102850 \tValidation Loss: 2.780568\n",
      "Validation loss decreased (2.83542 --> 2.78057).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.936063 \tValidation Loss: 2.745526\n",
      "Validation loss decreased (2.78057 --> 2.74553).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.803166 \tValidation Loss: 2.727293\n",
      "Validation loss decreased (2.74553 --> 2.72729).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.692825 \tValidation Loss: 2.718483\n",
      "Validation loss decreased (2.72729 --> 2.71848).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.605900 \tValidation Loss: 2.721662\n",
      "Epoch: 16 \tTraining Loss: 0.532059 \tValidation Loss: 2.732117\n",
      "Epoch: 17 \tTraining Loss: 0.472650 \tValidation Loss: 2.747231\n",
      "Epoch: 18 \tTraining Loss: 0.424524 \tValidation Loss: 2.767663\n",
      "Epoch: 19 \tTraining Loss: 0.384438 \tValidation Loss: 2.793354\n",
      "Epoch: 20 \tTraining Loss: 0.345623 \tValidation Loss: 2.819346\n",
      "Epoch: 1 \tTraining Loss: 6.058243 \tValidation Loss: 4.978540\n",
      "Validation loss decreased (inf --> 4.97854).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.409770 \tValidation Loss: 4.721749\n",
      "Validation loss decreased (4.97854 --> 4.72175).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.901136 \tValidation Loss: 4.373832\n",
      "Validation loss decreased (4.72175 --> 4.37383).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.230616 \tValidation Loss: 4.006490\n",
      "Validation loss decreased (4.37383 --> 4.00649).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.504411 \tValidation Loss: 3.680731\n",
      "Validation loss decreased (4.00649 --> 3.68073).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.848908 \tValidation Loss: 3.417455\n",
      "Validation loss decreased (3.68073 --> 3.41745).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.308290 \tValidation Loss: 3.216116\n",
      "Validation loss decreased (3.41745 --> 3.21612).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.884883 \tValidation Loss: 3.066349\n",
      "Validation loss decreased (3.21612 --> 3.06635).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.554149 \tValidation Loss: 2.960264\n",
      "Validation loss decreased (3.06635 --> 2.96026).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.298683 \tValidation Loss: 2.885560\n",
      "Validation loss decreased (2.96026 --> 2.88556).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.093637 \tValidation Loss: 2.834190\n",
      "Validation loss decreased (2.88556 --> 2.83419).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.930060 \tValidation Loss: 2.802262\n",
      "Validation loss decreased (2.83419 --> 2.80226).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 \tTraining Loss: 0.797535 \tValidation Loss: 2.787556\n",
      "Validation loss decreased (2.80226 --> 2.78756).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.692773 \tValidation Loss: 2.782059\n",
      "Validation loss decreased (2.78756 --> 2.78206).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.603696 \tValidation Loss: 2.786016\n",
      "Epoch: 16 \tTraining Loss: 0.533588 \tValidation Loss: 2.796758\n",
      "Epoch: 17 \tTraining Loss: 0.471875 \tValidation Loss: 2.815723\n",
      "Epoch: 18 \tTraining Loss: 0.426231 \tValidation Loss: 2.836172\n",
      "Epoch: 19 \tTraining Loss: 0.383709 \tValidation Loss: 2.860898\n",
      "Epoch: 20 \tTraining Loss: 0.349214 \tValidation Loss: 2.886900\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 8 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.097589 \tValidation Loss: 4.876963\n",
      "Validation loss decreased (inf --> 4.87696).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.416290 \tValidation Loss: 4.628160\n",
      "Validation loss decreased (4.87696 --> 4.62816).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.925245 \tValidation Loss: 4.290087\n",
      "Validation loss decreased (4.62816 --> 4.29009).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.265044 \tValidation Loss: 3.922254\n",
      "Validation loss decreased (4.29009 --> 3.92225).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.537559 \tValidation Loss: 3.584606\n",
      "Validation loss decreased (3.92225 --> 3.58461).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.866726 \tValidation Loss: 3.317479\n",
      "Validation loss decreased (3.58461 --> 3.31748).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.312940 \tValidation Loss: 3.115813\n",
      "Validation loss decreased (3.31748 --> 3.11581).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.874065 \tValidation Loss: 2.963874\n",
      "Validation loss decreased (3.11581 --> 2.96387).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.528351 \tValidation Loss: 2.847525\n",
      "Validation loss decreased (2.96387 --> 2.84752).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.259900 \tValidation Loss: 2.758219\n",
      "Validation loss decreased (2.84752 --> 2.75822).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.040122 \tValidation Loss: 2.690264\n",
      "Validation loss decreased (2.75822 --> 2.69026).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.867707 \tValidation Loss: 2.644307\n",
      "Validation loss decreased (2.69026 --> 2.64431).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.726846 \tValidation Loss: 2.614455\n",
      "Validation loss decreased (2.64431 --> 2.61446).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.615374 \tValidation Loss: 2.597138\n",
      "Validation loss decreased (2.61446 --> 2.59714).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.521000 \tValidation Loss: 2.590629\n",
      "Validation loss decreased (2.59714 --> 2.59063).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.446998 \tValidation Loss: 2.593612\n",
      "Epoch: 17 \tTraining Loss: 0.389336 \tValidation Loss: 2.601104\n",
      "Epoch: 18 \tTraining Loss: 0.342497 \tValidation Loss: 2.614060\n",
      "Epoch: 19 \tTraining Loss: 0.302400 \tValidation Loss: 2.627611\n",
      "Epoch: 20 \tTraining Loss: 0.271944 \tValidation Loss: 2.649320\n",
      "Epoch: 1 \tTraining Loss: 6.096332 \tValidation Loss: 4.919917\n",
      "Validation loss decreased (inf --> 4.91992).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.415787 \tValidation Loss: 4.676514\n",
      "Validation loss decreased (4.91992 --> 4.67651).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.925494 \tValidation Loss: 4.341223\n",
      "Validation loss decreased (4.67651 --> 4.34122).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.264641 \tValidation Loss: 3.966132\n",
      "Validation loss decreased (4.34122 --> 3.96613).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.538912 \tValidation Loss: 3.619726\n",
      "Validation loss decreased (3.96613 --> 3.61973).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.865782 \tValidation Loss: 3.336660\n",
      "Validation loss decreased (3.61973 --> 3.33666).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.312595 \tValidation Loss: 3.121465\n",
      "Validation loss decreased (3.33666 --> 3.12147).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.870419 \tValidation Loss: 2.962472\n",
      "Validation loss decreased (3.12147 --> 2.96247).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.522568 \tValidation Loss: 2.844162\n",
      "Validation loss decreased (2.96247 --> 2.84416).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.250383 \tValidation Loss: 2.757843\n",
      "Validation loss decreased (2.84416 --> 2.75784).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.033397 \tValidation Loss: 2.698959\n",
      "Validation loss decreased (2.75784 --> 2.69896).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.858814 \tValidation Loss: 2.658562\n",
      "Validation loss decreased (2.69896 --> 2.65856).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.720022 \tValidation Loss: 2.635314\n",
      "Validation loss decreased (2.65856 --> 2.63531).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.608196 \tValidation Loss: 2.620571\n",
      "Validation loss decreased (2.63531 --> 2.62057).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.521205 \tValidation Loss: 2.619667\n",
      "Validation loss decreased (2.62057 --> 2.61967).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.444039 \tValidation Loss: 2.623027\n",
      "Epoch: 17 \tTraining Loss: 0.385098 \tValidation Loss: 2.636237\n",
      "Epoch: 18 \tTraining Loss: 0.339532 \tValidation Loss: 2.651566\n",
      "Epoch: 19 \tTraining Loss: 0.303459 \tValidation Loss: 2.669291\n",
      "Epoch: 20 \tTraining Loss: 0.268935 \tValidation Loss: 2.690887\n",
      "Epoch: 1 \tTraining Loss: 6.102799 \tValidation Loss: 4.894195\n",
      "Validation loss decreased (inf --> 4.89420).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.415444 \tValidation Loss: 4.636991\n",
      "Validation loss decreased (4.89420 --> 4.63699).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.921797 \tValidation Loss: 4.295408\n",
      "Validation loss decreased (4.63699 --> 4.29541).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.263205 \tValidation Loss: 3.922499\n",
      "Validation loss decreased (4.29541 --> 3.92250).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.541325 \tValidation Loss: 3.579683\n",
      "Validation loss decreased (3.92250 --> 3.57968).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.866857 \tValidation Loss: 3.300474\n",
      "Validation loss decreased (3.57968 --> 3.30047).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.310884 \tValidation Loss: 3.088396\n",
      "Validation loss decreased (3.30047 --> 3.08840).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.873356 \tValidation Loss: 2.930364\n",
      "Validation loss decreased (3.08840 --> 2.93036).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.532113 \tValidation Loss: 2.813863\n",
      "Validation loss decreased (2.93036 --> 2.81386).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.262171 \tValidation Loss: 2.725708\n",
      "Validation loss decreased (2.81386 --> 2.72571).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.044523 \tValidation Loss: 2.660176\n",
      "Validation loss decreased (2.72571 --> 2.66018).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.869909 \tValidation Loss: 2.612583\n",
      "Validation loss decreased (2.66018 --> 2.61258).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.732386 \tValidation Loss: 2.576323\n",
      "Validation loss decreased (2.61258 --> 2.57632).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.620190 \tValidation Loss: 2.556310\n",
      "Validation loss decreased (2.57632 --> 2.55631).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.527634 \tValidation Loss: 2.543268\n",
      "Validation loss decreased (2.55631 --> 2.54327).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.453327 \tValidation Loss: 2.540037\n",
      "Validation loss decreased (2.54327 --> 2.54004).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.393445 \tValidation Loss: 2.545076\n",
      "Epoch: 18 \tTraining Loss: 0.346313 \tValidation Loss: 2.555812\n",
      "Epoch: 19 \tTraining Loss: 0.308575 \tValidation Loss: 2.569732\n",
      "Epoch: 20 \tTraining Loss: 0.277086 \tValidation Loss: 2.585301\n",
      "Epoch: 1 \tTraining Loss: 6.094844 \tValidation Loss: 4.884853\n",
      "Validation loss decreased (inf --> 4.88485).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.420923 \tValidation Loss: 4.641969\n",
      "Validation loss decreased (4.88485 --> 4.64197).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.934003 \tValidation Loss: 4.305564\n",
      "Validation loss decreased (4.64197 --> 4.30556).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.273815 \tValidation Loss: 3.932800\n",
      "Validation loss decreased (4.30556 --> 3.93280).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.544439 \tValidation Loss: 3.591105\n",
      "Validation loss decreased (3.93280 --> 3.59110).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.870133 \tValidation Loss: 3.318807\n",
      "Validation loss decreased (3.59110 --> 3.31881).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 \tTraining Loss: 2.316546 \tValidation Loss: 3.111647\n",
      "Validation loss decreased (3.31881 --> 3.11165).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.873322 \tValidation Loss: 2.957577\n",
      "Validation loss decreased (3.11165 --> 2.95758).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.528790 \tValidation Loss: 2.842001\n",
      "Validation loss decreased (2.95758 --> 2.84200).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.257014 \tValidation Loss: 2.758316\n",
      "Validation loss decreased (2.84200 --> 2.75832).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.040765 \tValidation Loss: 2.695130\n",
      "Validation loss decreased (2.75832 --> 2.69513).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.866688 \tValidation Loss: 2.655566\n",
      "Validation loss decreased (2.69513 --> 2.65557).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.727363 \tValidation Loss: 2.628092\n",
      "Validation loss decreased (2.65557 --> 2.62809).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.614284 \tValidation Loss: 2.612723\n",
      "Validation loss decreased (2.62809 --> 2.61272).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.522554 \tValidation Loss: 2.607034\n",
      "Validation loss decreased (2.61272 --> 2.60703).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.448967 \tValidation Loss: 2.610523\n",
      "Epoch: 17 \tTraining Loss: 0.390135 \tValidation Loss: 2.616897\n",
      "Epoch: 18 \tTraining Loss: 0.341893 \tValidation Loss: 2.632152\n",
      "Epoch: 19 \tTraining Loss: 0.302713 \tValidation Loss: 2.651102\n",
      "Epoch: 20 \tTraining Loss: 0.272186 \tValidation Loss: 2.674610\n",
      "Epoch: 1 \tTraining Loss: 6.094354 \tValidation Loss: 4.895958\n",
      "Validation loss decreased (inf --> 4.89596).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.418696 \tValidation Loss: 4.644139\n",
      "Validation loss decreased (4.89596 --> 4.64414).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.930349 \tValidation Loss: 4.301546\n",
      "Validation loss decreased (4.64414 --> 4.30155).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.270120 \tValidation Loss: 3.924016\n",
      "Validation loss decreased (4.30155 --> 3.92402).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.549077 \tValidation Loss: 3.567722\n",
      "Validation loss decreased (3.92402 --> 3.56772).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.876034 \tValidation Loss: 3.270933\n",
      "Validation loss decreased (3.56772 --> 3.27093).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.315632 \tValidation Loss: 3.048849\n",
      "Validation loss decreased (3.27093 --> 3.04885).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.871261 \tValidation Loss: 2.885791\n",
      "Validation loss decreased (3.04885 --> 2.88579).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.525878 \tValidation Loss: 2.764687\n",
      "Validation loss decreased (2.88579 --> 2.76469).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.254061 \tValidation Loss: 2.674388\n",
      "Validation loss decreased (2.76469 --> 2.67439).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.040582 \tValidation Loss: 2.609876\n",
      "Validation loss decreased (2.67439 --> 2.60988).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.863929 \tValidation Loss: 2.562218\n",
      "Validation loss decreased (2.60988 --> 2.56222).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.723731 \tValidation Loss: 2.532598\n",
      "Validation loss decreased (2.56222 --> 2.53260).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.610916 \tValidation Loss: 2.515611\n",
      "Validation loss decreased (2.53260 --> 2.51561).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.519394 \tValidation Loss: 2.509468\n",
      "Validation loss decreased (2.51561 --> 2.50947).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.443808 \tValidation Loss: 2.510601\n",
      "Epoch: 17 \tTraining Loss: 0.385725 \tValidation Loss: 2.519382\n",
      "Epoch: 18 \tTraining Loss: 0.338570 \tValidation Loss: 2.530771\n",
      "Epoch: 19 \tTraining Loss: 0.300960 \tValidation Loss: 2.546670\n",
      "Epoch: 20 \tTraining Loss: 0.267766 \tValidation Loss: 2.565899\n",
      "Epoch: 1 \tTraining Loss: 6.099010 \tValidation Loss: 4.834798\n",
      "Validation loss decreased (inf --> 4.83480).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.416499 \tValidation Loss: 4.599161\n",
      "Validation loss decreased (4.83480 --> 4.59916).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.922328 \tValidation Loss: 4.261054\n",
      "Validation loss decreased (4.59916 --> 4.26105).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.260542 \tValidation Loss: 3.886673\n",
      "Validation loss decreased (4.26105 --> 3.88667).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.536928 \tValidation Loss: 3.544151\n",
      "Validation loss decreased (3.88667 --> 3.54415).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.870939 \tValidation Loss: 3.269180\n",
      "Validation loss decreased (3.54415 --> 3.26918).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.315890 \tValidation Loss: 3.059349\n",
      "Validation loss decreased (3.26918 --> 3.05935).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.876961 \tValidation Loss: 2.904794\n",
      "Validation loss decreased (3.05935 --> 2.90479).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.530452 \tValidation Loss: 2.791658\n",
      "Validation loss decreased (2.90479 --> 2.79166).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.255590 \tValidation Loss: 2.708722\n",
      "Validation loss decreased (2.79166 --> 2.70872).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.039854 \tValidation Loss: 2.649213\n",
      "Validation loss decreased (2.70872 --> 2.64921).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.864844 \tValidation Loss: 2.611125\n",
      "Validation loss decreased (2.64921 --> 2.61112).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.722669 \tValidation Loss: 2.583071\n",
      "Validation loss decreased (2.61112 --> 2.58307).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.611226 \tValidation Loss: 2.569077\n",
      "Validation loss decreased (2.58307 --> 2.56908).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.519724 \tValidation Loss: 2.566192\n",
      "Validation loss decreased (2.56908 --> 2.56619).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.445899 \tValidation Loss: 2.571056\n",
      "Epoch: 17 \tTraining Loss: 0.386813 \tValidation Loss: 2.578763\n",
      "Epoch: 18 \tTraining Loss: 0.340945 \tValidation Loss: 2.593286\n",
      "Epoch: 19 \tTraining Loss: 0.303737 \tValidation Loss: 2.611340\n",
      "Epoch: 20 \tTraining Loss: 0.272342 \tValidation Loss: 2.628135\n",
      "Epoch: 1 \tTraining Loss: 6.101092 \tValidation Loss: 4.954615\n",
      "Validation loss decreased (inf --> 4.95461).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.409285 \tValidation Loss: 4.706610\n",
      "Validation loss decreased (4.95461 --> 4.70661).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.910607 \tValidation Loss: 4.373734\n",
      "Validation loss decreased (4.70661 --> 4.37373).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.241340 \tValidation Loss: 4.010903\n",
      "Validation loss decreased (4.37373 --> 4.01090).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.513996 \tValidation Loss: 3.676620\n",
      "Validation loss decreased (4.01090 --> 3.67662).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.849316 \tValidation Loss: 3.403124\n",
      "Validation loss decreased (3.67662 --> 3.40312).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.298708 \tValidation Loss: 3.193320\n",
      "Validation loss decreased (3.40312 --> 3.19332).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.860405 \tValidation Loss: 3.036822\n",
      "Validation loss decreased (3.19332 --> 3.03682).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.516687 \tValidation Loss: 2.921520\n",
      "Validation loss decreased (3.03682 --> 2.92152).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.244628 \tValidation Loss: 2.835418\n",
      "Validation loss decreased (2.92152 --> 2.83542).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.030228 \tValidation Loss: 2.774434\n",
      "Validation loss decreased (2.83542 --> 2.77443).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.857355 \tValidation Loss: 2.736239\n",
      "Validation loss decreased (2.77443 --> 2.73624).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.717472 \tValidation Loss: 2.708859\n",
      "Validation loss decreased (2.73624 --> 2.70886).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.606676 \tValidation Loss: 2.695919\n",
      "Validation loss decreased (2.70886 --> 2.69592).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.516508 \tValidation Loss: 2.692745\n",
      "Validation loss decreased (2.69592 --> 2.69274).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.445355 \tValidation Loss: 2.696305\n",
      "Epoch: 17 \tTraining Loss: 0.386113 \tValidation Loss: 2.708070\n",
      "Epoch: 18 \tTraining Loss: 0.338727 \tValidation Loss: 2.723318\n",
      "Epoch: 19 \tTraining Loss: 0.299023 \tValidation Loss: 2.742756\n",
      "Epoch: 20 \tTraining Loss: 0.268548 \tValidation Loss: 2.762422\n",
      "Epoch: 1 \tTraining Loss: 6.095518 \tValidation Loss: 4.860863\n",
      "Validation loss decreased (inf --> 4.86086).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 5.419703 \tValidation Loss: 4.623196\n",
      "Validation loss decreased (4.86086 --> 4.62320).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.929125 \tValidation Loss: 4.294623\n",
      "Validation loss decreased (4.62320 --> 4.29462).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.267414 \tValidation Loss: 3.935422\n",
      "Validation loss decreased (4.29462 --> 3.93542).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.541380 \tValidation Loss: 3.599710\n",
      "Validation loss decreased (3.93542 --> 3.59971).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.868867 \tValidation Loss: 3.322728\n",
      "Validation loss decreased (3.59971 --> 3.32273).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.311924 \tValidation Loss: 3.109640\n",
      "Validation loss decreased (3.32273 --> 3.10964).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.873186 \tValidation Loss: 2.948548\n",
      "Validation loss decreased (3.10964 --> 2.94855).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.528652 \tValidation Loss: 2.826523\n",
      "Validation loss decreased (2.94855 --> 2.82652).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.252451 \tValidation Loss: 2.737662\n",
      "Validation loss decreased (2.82652 --> 2.73766).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.038903 \tValidation Loss: 2.670700\n",
      "Validation loss decreased (2.73766 --> 2.67070).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.863547 \tValidation Loss: 2.625093\n",
      "Validation loss decreased (2.67070 --> 2.62509).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.725897 \tValidation Loss: 2.596130\n",
      "Validation loss decreased (2.62509 --> 2.59613).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.615222 \tValidation Loss: 2.581598\n",
      "Validation loss decreased (2.59613 --> 2.58160).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.522171 \tValidation Loss: 2.577184\n",
      "Validation loss decreased (2.58160 --> 2.57718).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.445983 \tValidation Loss: 2.579066\n",
      "Epoch: 17 \tTraining Loss: 0.388476 \tValidation Loss: 2.589697\n",
      "Epoch: 18 \tTraining Loss: 0.340335 \tValidation Loss: 2.605981\n",
      "Epoch: 19 \tTraining Loss: 0.302677 \tValidation Loss: 2.626088\n",
      "Epoch: 20 \tTraining Loss: 0.269774 \tValidation Loss: 2.650378\n",
      "Epoch: 1 \tTraining Loss: 6.093819 \tValidation Loss: 4.901105\n",
      "Validation loss decreased (inf --> 4.90111).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.417047 \tValidation Loss: 4.660233\n",
      "Validation loss decreased (4.90111 --> 4.66023).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.929851 \tValidation Loss: 4.323882\n",
      "Validation loss decreased (4.66023 --> 4.32388).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.271677 \tValidation Loss: 3.940915\n",
      "Validation loss decreased (4.32388 --> 3.94091).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.548221 \tValidation Loss: 3.581895\n",
      "Validation loss decreased (3.94091 --> 3.58189).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.873238 \tValidation Loss: 3.286033\n",
      "Validation loss decreased (3.58189 --> 3.28603).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.313993 \tValidation Loss: 3.058948\n",
      "Validation loss decreased (3.28603 --> 3.05895).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.874479 \tValidation Loss: 2.890559\n",
      "Validation loss decreased (3.05895 --> 2.89056).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.531320 \tValidation Loss: 2.764946\n",
      "Validation loss decreased (2.89056 --> 2.76495).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.257754 \tValidation Loss: 2.671902\n",
      "Validation loss decreased (2.76495 --> 2.67190).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.040044 \tValidation Loss: 2.605709\n",
      "Validation loss decreased (2.67190 --> 2.60571).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.865880 \tValidation Loss: 2.556678\n",
      "Validation loss decreased (2.60571 --> 2.55668).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.724805 \tValidation Loss: 2.523504\n",
      "Validation loss decreased (2.55668 --> 2.52350).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.611458 \tValidation Loss: 2.503182\n",
      "Validation loss decreased (2.52350 --> 2.50318).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.519861 \tValidation Loss: 2.494831\n",
      "Validation loss decreased (2.50318 --> 2.49483).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.448605 \tValidation Loss: 2.493910\n",
      "Validation loss decreased (2.49483 --> 2.49391).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.389669 \tValidation Loss: 2.498184\n",
      "Epoch: 18 \tTraining Loss: 0.342155 \tValidation Loss: 2.504681\n",
      "Epoch: 19 \tTraining Loss: 0.303876 \tValidation Loss: 2.522248\n",
      "Epoch: 20 \tTraining Loss: 0.270403 \tValidation Loss: 2.536255\n",
      "Epoch: 1 \tTraining Loss: 6.091416 \tValidation Loss: 4.857180\n",
      "Validation loss decreased (inf --> 4.85718).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.430477 \tValidation Loss: 4.612003\n",
      "Validation loss decreased (4.85718 --> 4.61200).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.950181 \tValidation Loss: 4.267431\n",
      "Validation loss decreased (4.61200 --> 4.26743).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.293375 \tValidation Loss: 3.885721\n",
      "Validation loss decreased (4.26743 --> 3.88572).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.565933 \tValidation Loss: 3.537268\n",
      "Validation loss decreased (3.88572 --> 3.53727).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.893391 \tValidation Loss: 3.259015\n",
      "Validation loss decreased (3.53727 --> 3.25901).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.334396 \tValidation Loss: 3.044560\n",
      "Validation loss decreased (3.25901 --> 3.04456).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.892158 \tValidation Loss: 2.878950\n",
      "Validation loss decreased (3.04456 --> 2.87895).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.543419 \tValidation Loss: 2.754366\n",
      "Validation loss decreased (2.87895 --> 2.75437).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.266409 \tValidation Loss: 2.658154\n",
      "Validation loss decreased (2.75437 --> 2.65815).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.048039 \tValidation Loss: 2.590286\n",
      "Validation loss decreased (2.65815 --> 2.59029).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.871045 \tValidation Loss: 2.540412\n",
      "Validation loss decreased (2.59029 --> 2.54041).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.728817 \tValidation Loss: 2.507829\n",
      "Validation loss decreased (2.54041 --> 2.50783).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.617276 \tValidation Loss: 2.488228\n",
      "Validation loss decreased (2.50783 --> 2.48823).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.522817 \tValidation Loss: 2.480362\n",
      "Validation loss decreased (2.48823 --> 2.48036).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.448511 \tValidation Loss: 2.481096\n",
      "Epoch: 17 \tTraining Loss: 0.390738 \tValidation Loss: 2.486721\n",
      "Epoch: 18 \tTraining Loss: 0.340434 \tValidation Loss: 2.498582\n",
      "Epoch: 19 \tTraining Loss: 0.299427 \tValidation Loss: 2.515261\n",
      "Epoch: 20 \tTraining Loss: 0.269526 \tValidation Loss: 2.535189\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 9 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.112832 \tValidation Loss: 4.725982\n",
      "Validation loss decreased (inf --> 4.72598).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.415510 \tValidation Loss: 4.523945\n",
      "Validation loss decreased (4.72598 --> 4.52394).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.985495 \tValidation Loss: 4.242635\n",
      "Validation loss decreased (4.52394 --> 4.24263).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.387813 \tValidation Loss: 3.908502\n",
      "Validation loss decreased (4.24263 --> 3.90850).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.692335 \tValidation Loss: 3.578796\n",
      "Validation loss decreased (3.90850 --> 3.57880).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.014800 \tValidation Loss: 3.300120\n",
      "Validation loss decreased (3.57880 --> 3.30012).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.435101 \tValidation Loss: 3.084123\n",
      "Validation loss decreased (3.30012 --> 3.08412).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.961942 \tValidation Loss: 2.921325\n",
      "Validation loss decreased (3.08412 --> 2.92133).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.591809 \tValidation Loss: 2.798151\n",
      "Validation loss decreased (2.92133 --> 2.79815).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.298953 \tValidation Loss: 2.701897\n",
      "Validation loss decreased (2.79815 --> 2.70190).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.062206 \tValidation Loss: 2.630803\n",
      "Validation loss decreased (2.70190 --> 2.63080).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.872714 \tValidation Loss: 2.579963\n",
      "Validation loss decreased (2.63080 --> 2.57996).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 \tTraining Loss: 0.719660 \tValidation Loss: 2.542712\n",
      "Validation loss decreased (2.57996 --> 2.54271).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.596144 \tValidation Loss: 2.520128\n",
      "Validation loss decreased (2.54271 --> 2.52013).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.498207 \tValidation Loss: 2.509909\n",
      "Validation loss decreased (2.52013 --> 2.50991).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.417180 \tValidation Loss: 2.507866\n",
      "Validation loss decreased (2.50991 --> 2.50787).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.355605 \tValidation Loss: 2.510718\n",
      "Epoch: 18 \tTraining Loss: 0.306512 \tValidation Loss: 2.520785\n",
      "Epoch: 19 \tTraining Loss: 0.265211 \tValidation Loss: 2.535253\n",
      "Epoch: 20 \tTraining Loss: 0.234289 \tValidation Loss: 2.551016\n",
      "Epoch: 1 \tTraining Loss: 6.130063 \tValidation Loss: 4.681938\n",
      "Validation loss decreased (inf --> 4.68194).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.414842 \tValidation Loss: 4.481820\n",
      "Validation loss decreased (4.68194 --> 4.48182).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.969581 \tValidation Loss: 4.198383\n",
      "Validation loss decreased (4.48182 --> 4.19838).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.360686 \tValidation Loss: 3.875634\n",
      "Validation loss decreased (4.19838 --> 3.87563).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.665185 \tValidation Loss: 3.563174\n",
      "Validation loss decreased (3.87563 --> 3.56317).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.992805 \tValidation Loss: 3.305478\n",
      "Validation loss decreased (3.56317 --> 3.30548).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.416927 \tValidation Loss: 3.104487\n",
      "Validation loss decreased (3.30548 --> 3.10449).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.954083 \tValidation Loss: 2.948206\n",
      "Validation loss decreased (3.10449 --> 2.94821).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.587377 \tValidation Loss: 2.828499\n",
      "Validation loss decreased (2.94821 --> 2.82850).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.297537 \tValidation Loss: 2.736361\n",
      "Validation loss decreased (2.82850 --> 2.73636).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.062498 \tValidation Loss: 2.665835\n",
      "Validation loss decreased (2.73636 --> 2.66584).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.872598 \tValidation Loss: 2.614201\n",
      "Validation loss decreased (2.66584 --> 2.61420).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.721163 \tValidation Loss: 2.576641\n",
      "Validation loss decreased (2.61420 --> 2.57664).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.599419 \tValidation Loss: 2.552141\n",
      "Validation loss decreased (2.57664 --> 2.55214).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.500951 \tValidation Loss: 2.538333\n",
      "Validation loss decreased (2.55214 --> 2.53833).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.422610 \tValidation Loss: 2.535608\n",
      "Validation loss decreased (2.53833 --> 2.53561).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.360717 \tValidation Loss: 2.537968\n",
      "Epoch: 18 \tTraining Loss: 0.312314 \tValidation Loss: 2.545036\n",
      "Epoch: 19 \tTraining Loss: 0.271996 \tValidation Loss: 2.558167\n",
      "Epoch: 20 \tTraining Loss: 0.240418 \tValidation Loss: 2.568780\n",
      "Epoch: 1 \tTraining Loss: 6.121527 \tValidation Loss: 4.702738\n",
      "Validation loss decreased (inf --> 4.70274).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.418105 \tValidation Loss: 4.493682\n",
      "Validation loss decreased (4.70274 --> 4.49368).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.979073 \tValidation Loss: 4.207030\n",
      "Validation loss decreased (4.49368 --> 4.20703).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.370054 \tValidation Loss: 3.883216\n",
      "Validation loss decreased (4.20703 --> 3.88322).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.668711 \tValidation Loss: 3.578170\n",
      "Validation loss decreased (3.88322 --> 3.57817).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.994655 \tValidation Loss: 3.319207\n",
      "Validation loss decreased (3.57817 --> 3.31921).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.418197 \tValidation Loss: 3.111464\n",
      "Validation loss decreased (3.31921 --> 3.11146).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.953570 \tValidation Loss: 2.949282\n",
      "Validation loss decreased (3.11146 --> 2.94928).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.586923 \tValidation Loss: 2.822604\n",
      "Validation loss decreased (2.94928 --> 2.82260).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.293901 \tValidation Loss: 2.725662\n",
      "Validation loss decreased (2.82260 --> 2.72566).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.057897 \tValidation Loss: 2.651683\n",
      "Validation loss decreased (2.72566 --> 2.65168).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.872847 \tValidation Loss: 2.600361\n",
      "Validation loss decreased (2.65168 --> 2.60036).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.718943 \tValidation Loss: 2.565014\n",
      "Validation loss decreased (2.60036 --> 2.56501).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.599540 \tValidation Loss: 2.543383\n",
      "Validation loss decreased (2.56501 --> 2.54338).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.496188 \tValidation Loss: 2.533147\n",
      "Validation loss decreased (2.54338 --> 2.53315).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.419866 \tValidation Loss: 2.530804\n",
      "Validation loss decreased (2.53315 --> 2.53080).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.356725 \tValidation Loss: 2.536711\n",
      "Epoch: 18 \tTraining Loss: 0.310112 \tValidation Loss: 2.545158\n",
      "Epoch: 19 \tTraining Loss: 0.268395 \tValidation Loss: 2.565219\n",
      "Epoch: 20 \tTraining Loss: 0.238369 \tValidation Loss: 2.578701\n",
      "Epoch: 1 \tTraining Loss: 6.112415 \tValidation Loss: 4.723088\n",
      "Validation loss decreased (inf --> 4.72309).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.427601 \tValidation Loss: 4.525189\n",
      "Validation loss decreased (4.72309 --> 4.52519).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.996205 \tValidation Loss: 4.256315\n",
      "Validation loss decreased (4.52519 --> 4.25632).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.395674 \tValidation Loss: 3.931108\n",
      "Validation loss decreased (4.25632 --> 3.93111).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.692973 \tValidation Loss: 3.616341\n",
      "Validation loss decreased (3.93111 --> 3.61634).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.014564 \tValidation Loss: 3.353826\n",
      "Validation loss decreased (3.61634 --> 3.35383).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.433063 \tValidation Loss: 3.151643\n",
      "Validation loss decreased (3.35383 --> 3.15164).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.964503 \tValidation Loss: 3.000241\n",
      "Validation loss decreased (3.15164 --> 3.00024).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.592824 \tValidation Loss: 2.885197\n",
      "Validation loss decreased (3.00024 --> 2.88520).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.296213 \tValidation Loss: 2.797044\n",
      "Validation loss decreased (2.88520 --> 2.79704).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.062916 \tValidation Loss: 2.731948\n",
      "Validation loss decreased (2.79704 --> 2.73195).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.871485 \tValidation Loss: 2.683251\n",
      "Validation loss decreased (2.73195 --> 2.68325).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.720937 \tValidation Loss: 2.652532\n",
      "Validation loss decreased (2.68325 --> 2.65253).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.597441 \tValidation Loss: 2.637110\n",
      "Validation loss decreased (2.65253 --> 2.63711).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.495969 \tValidation Loss: 2.628575\n",
      "Validation loss decreased (2.63711 --> 2.62858).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.419098 \tValidation Loss: 2.631838\n",
      "Epoch: 17 \tTraining Loss: 0.355950 \tValidation Loss: 2.641865\n",
      "Epoch: 18 \tTraining Loss: 0.308255 \tValidation Loss: 2.655115\n",
      "Epoch: 19 \tTraining Loss: 0.269337 \tValidation Loss: 2.669787\n",
      "Epoch: 20 \tTraining Loss: 0.237310 \tValidation Loss: 2.690831\n",
      "Epoch: 1 \tTraining Loss: 6.125266 \tValidation Loss: 4.674855\n",
      "Validation loss decreased (inf --> 4.67485).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.429611 \tValidation Loss: 4.479028\n",
      "Validation loss decreased (4.67485 --> 4.47903).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.992923 \tValidation Loss: 4.203393\n",
      "Validation loss decreased (4.47903 --> 4.20339).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.388731 \tValidation Loss: 3.879732\n",
      "Validation loss decreased (4.20339 --> 3.87973).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.690381 \tValidation Loss: 3.568710\n",
      "Validation loss decreased (3.87973 --> 3.56871).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 \tTraining Loss: 3.006772 \tValidation Loss: 3.311056\n",
      "Validation loss decreased (3.56871 --> 3.31106).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.425168 \tValidation Loss: 3.113022\n",
      "Validation loss decreased (3.31106 --> 3.11302).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.958811 \tValidation Loss: 2.960991\n",
      "Validation loss decreased (3.11302 --> 2.96099).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.587063 \tValidation Loss: 2.841682\n",
      "Validation loss decreased (2.96099 --> 2.84168).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.292502 \tValidation Loss: 2.750277\n",
      "Validation loss decreased (2.84168 --> 2.75028).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.059166 \tValidation Loss: 2.679879\n",
      "Validation loss decreased (2.75028 --> 2.67988).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.867660 \tValidation Loss: 2.627695\n",
      "Validation loss decreased (2.67988 --> 2.62769).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.718006 \tValidation Loss: 2.590357\n",
      "Validation loss decreased (2.62769 --> 2.59036).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.591864 \tValidation Loss: 2.568596\n",
      "Validation loss decreased (2.59036 --> 2.56860).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.495693 \tValidation Loss: 2.556919\n",
      "Validation loss decreased (2.56860 --> 2.55692).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.419239 \tValidation Loss: 2.556434\n",
      "Validation loss decreased (2.55692 --> 2.55643).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.355836 \tValidation Loss: 2.561351\n",
      "Epoch: 18 \tTraining Loss: 0.306806 \tValidation Loss: 2.572395\n",
      "Epoch: 19 \tTraining Loss: 0.266596 \tValidation Loss: 2.584928\n",
      "Epoch: 20 \tTraining Loss: 0.235180 \tValidation Loss: 2.601400\n",
      "Epoch: 1 \tTraining Loss: 6.118771 \tValidation Loss: 4.728533\n",
      "Validation loss decreased (inf --> 4.72853).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.417233 \tValidation Loss: 4.535372\n",
      "Validation loss decreased (4.72853 --> 4.53537).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.979160 \tValidation Loss: 4.268214\n",
      "Validation loss decreased (4.53537 --> 4.26821).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.376007 \tValidation Loss: 3.942754\n",
      "Validation loss decreased (4.26821 --> 3.94275).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.684287 \tValidation Loss: 3.620164\n",
      "Validation loss decreased (3.94275 --> 3.62016).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.008537 \tValidation Loss: 3.346487\n",
      "Validation loss decreased (3.62016 --> 3.34649).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.429920 \tValidation Loss: 3.133436\n",
      "Validation loss decreased (3.34649 --> 3.13344).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.960352 \tValidation Loss: 2.968521\n",
      "Validation loss decreased (3.13344 --> 2.96852).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.590139 \tValidation Loss: 2.842407\n",
      "Validation loss decreased (2.96852 --> 2.84241).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.294581 \tValidation Loss: 2.750742\n",
      "Validation loss decreased (2.84241 --> 2.75074).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.056203 \tValidation Loss: 2.686120\n",
      "Validation loss decreased (2.75074 --> 2.68612).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.865835 \tValidation Loss: 2.638483\n",
      "Validation loss decreased (2.68612 --> 2.63848).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.713420 \tValidation Loss: 2.606733\n",
      "Validation loss decreased (2.63848 --> 2.60673).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.592393 \tValidation Loss: 2.588587\n",
      "Validation loss decreased (2.60673 --> 2.58859).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.492853 \tValidation Loss: 2.581146\n",
      "Validation loss decreased (2.58859 --> 2.58115).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.415358 \tValidation Loss: 2.582010\n",
      "Epoch: 17 \tTraining Loss: 0.353698 \tValidation Loss: 2.589259\n",
      "Epoch: 18 \tTraining Loss: 0.305592 \tValidation Loss: 2.600736\n",
      "Epoch: 19 \tTraining Loss: 0.267180 \tValidation Loss: 2.616349\n",
      "Epoch: 20 \tTraining Loss: 0.236483 \tValidation Loss: 2.634038\n",
      "Epoch: 1 \tTraining Loss: 6.108113 \tValidation Loss: 4.723788\n",
      "Validation loss decreased (inf --> 4.72379).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.417273 \tValidation Loss: 4.521574\n",
      "Validation loss decreased (4.72379 --> 4.52157).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.976057 \tValidation Loss: 4.244409\n",
      "Validation loss decreased (4.52157 --> 4.24441).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.372794 \tValidation Loss: 3.924120\n",
      "Validation loss decreased (4.24441 --> 3.92412).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.687254 \tValidation Loss: 3.608806\n",
      "Validation loss decreased (3.92412 --> 3.60881).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.020293 \tValidation Loss: 3.339532\n",
      "Validation loss decreased (3.60881 --> 3.33953).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.443240 \tValidation Loss: 3.131937\n",
      "Validation loss decreased (3.33953 --> 3.13194).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.977816 \tValidation Loss: 2.974198\n",
      "Validation loss decreased (3.13194 --> 2.97420).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.605771 \tValidation Loss: 2.851525\n",
      "Validation loss decreased (2.97420 --> 2.85152).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.311469 \tValidation Loss: 2.758965\n",
      "Validation loss decreased (2.85152 --> 2.75896).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.073008 \tValidation Loss: 2.689232\n",
      "Validation loss decreased (2.75896 --> 2.68923).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.880864 \tValidation Loss: 2.639926\n",
      "Validation loss decreased (2.68923 --> 2.63993).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.726310 \tValidation Loss: 2.609433\n",
      "Validation loss decreased (2.63993 --> 2.60943).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.601687 \tValidation Loss: 2.590000\n",
      "Validation loss decreased (2.60943 --> 2.59000).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.502358 \tValidation Loss: 2.579795\n",
      "Validation loss decreased (2.59000 --> 2.57980).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.424906 \tValidation Loss: 2.582673\n",
      "Epoch: 17 \tTraining Loss: 0.360329 \tValidation Loss: 2.587004\n",
      "Epoch: 18 \tTraining Loss: 0.310493 \tValidation Loss: 2.599110\n",
      "Epoch: 19 \tTraining Loss: 0.268902 \tValidation Loss: 2.612491\n",
      "Epoch: 20 \tTraining Loss: 0.239123 \tValidation Loss: 2.630080\n",
      "Epoch: 1 \tTraining Loss: 6.122917 \tValidation Loss: 4.699151\n",
      "Validation loss decreased (inf --> 4.69915).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.420342 \tValidation Loss: 4.502980\n",
      "Validation loss decreased (4.69915 --> 4.50298).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.972586 \tValidation Loss: 4.220543\n",
      "Validation loss decreased (4.50298 --> 4.22054).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.359854 \tValidation Loss: 3.893374\n",
      "Validation loss decreased (4.22054 --> 3.89337).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.657988 \tValidation Loss: 3.573755\n",
      "Validation loss decreased (3.89337 --> 3.57376).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.973373 \tValidation Loss: 3.310364\n",
      "Validation loss decreased (3.57376 --> 3.31036).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.397619 \tValidation Loss: 3.104334\n",
      "Validation loss decreased (3.31036 --> 3.10433).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.937803 \tValidation Loss: 2.944973\n",
      "Validation loss decreased (3.10433 --> 2.94497).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.570328 \tValidation Loss: 2.823755\n",
      "Validation loss decreased (2.94497 --> 2.82375).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.283724 \tValidation Loss: 2.729893\n",
      "Validation loss decreased (2.82375 --> 2.72989).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.050447 \tValidation Loss: 2.658003\n",
      "Validation loss decreased (2.72989 --> 2.65800).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.863548 \tValidation Loss: 2.606733\n",
      "Validation loss decreased (2.65800 --> 2.60673).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.711614 \tValidation Loss: 2.570497\n",
      "Validation loss decreased (2.60673 --> 2.57050).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.590285 \tValidation Loss: 2.548608\n",
      "Validation loss decreased (2.57050 --> 2.54861).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.492260 \tValidation Loss: 2.533043\n",
      "Validation loss decreased (2.54861 --> 2.53304).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.414984 \tValidation Loss: 2.528251\n",
      "Validation loss decreased (2.53304 --> 2.52825).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.354396 \tValidation Loss: 2.531257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 \tTraining Loss: 0.304489 \tValidation Loss: 2.538402\n",
      "Epoch: 19 \tTraining Loss: 0.263758 \tValidation Loss: 2.548203\n",
      "Epoch: 20 \tTraining Loss: 0.234210 \tValidation Loss: 2.562739\n",
      "Epoch: 1 \tTraining Loss: 6.119083 \tValidation Loss: 4.737137\n",
      "Validation loss decreased (inf --> 4.73714).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.412817 \tValidation Loss: 4.535795\n",
      "Validation loss decreased (4.73714 --> 4.53580).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.976649 \tValidation Loss: 4.264071\n",
      "Validation loss decreased (4.53580 --> 4.26407).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.377496 \tValidation Loss: 3.939354\n",
      "Validation loss decreased (4.26407 --> 3.93935).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.692305 \tValidation Loss: 3.616826\n",
      "Validation loss decreased (3.93935 --> 3.61683).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.017692 \tValidation Loss: 3.340704\n",
      "Validation loss decreased (3.61683 --> 3.34070).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.442298 \tValidation Loss: 3.122021\n",
      "Validation loss decreased (3.34070 --> 3.12202).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.975159 \tValidation Loss: 2.954477\n",
      "Validation loss decreased (3.12202 --> 2.95448).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.604325 \tValidation Loss: 2.828896\n",
      "Validation loss decreased (2.95448 --> 2.82890).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.308243 \tValidation Loss: 2.735994\n",
      "Validation loss decreased (2.82890 --> 2.73599).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.073164 \tValidation Loss: 2.668510\n",
      "Validation loss decreased (2.73599 --> 2.66851).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.881912 \tValidation Loss: 2.620014\n",
      "Validation loss decreased (2.66851 --> 2.62001).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.727475 \tValidation Loss: 2.589045\n",
      "Validation loss decreased (2.62001 --> 2.58904).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.601744 \tValidation Loss: 2.571370\n",
      "Validation loss decreased (2.58904 --> 2.57137).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.505979 \tValidation Loss: 2.560245\n",
      "Validation loss decreased (2.57137 --> 2.56024).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.425303 \tValidation Loss: 2.561306\n",
      "Epoch: 17 \tTraining Loss: 0.361767 \tValidation Loss: 2.565006\n",
      "Epoch: 18 \tTraining Loss: 0.311381 \tValidation Loss: 2.572303\n",
      "Epoch: 19 \tTraining Loss: 0.272343 \tValidation Loss: 2.587409\n",
      "Epoch: 20 \tTraining Loss: 0.241156 \tValidation Loss: 2.606567\n",
      "Epoch: 1 \tTraining Loss: 6.114049 \tValidation Loss: 4.696492\n",
      "Validation loss decreased (inf --> 4.69649).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.418631 \tValidation Loss: 4.503924\n",
      "Validation loss decreased (4.69649 --> 4.50392).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.984529 \tValidation Loss: 4.222115\n",
      "Validation loss decreased (4.50392 --> 4.22211).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.377666 \tValidation Loss: 3.901016\n",
      "Validation loss decreased (4.22211 --> 3.90102).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.681507 \tValidation Loss: 3.595946\n",
      "Validation loss decreased (3.90102 --> 3.59595).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.011453 \tValidation Loss: 3.341029\n",
      "Validation loss decreased (3.59595 --> 3.34103).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.433972 \tValidation Loss: 3.142086\n",
      "Validation loss decreased (3.34103 --> 3.14209).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.969786 \tValidation Loss: 2.988444\n",
      "Validation loss decreased (3.14209 --> 2.98844).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.596766 \tValidation Loss: 2.871436\n",
      "Validation loss decreased (2.98844 --> 2.87144).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.302350 \tValidation Loss: 2.781422\n",
      "Validation loss decreased (2.87144 --> 2.78142).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.067142 \tValidation Loss: 2.715639\n",
      "Validation loss decreased (2.78142 --> 2.71564).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.875506 \tValidation Loss: 2.670104\n",
      "Validation loss decreased (2.71564 --> 2.67010).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.722190 \tValidation Loss: 2.640269\n",
      "Validation loss decreased (2.67010 --> 2.64027).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.598912 \tValidation Loss: 2.621620\n",
      "Validation loss decreased (2.64027 --> 2.62162).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.500330 \tValidation Loss: 2.616541\n",
      "Validation loss decreased (2.62162 --> 2.61654).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.420782 \tValidation Loss: 2.617606\n",
      "Epoch: 17 \tTraining Loss: 0.360118 \tValidation Loss: 2.624403\n",
      "Epoch: 18 \tTraining Loss: 0.306133 \tValidation Loss: 2.635516\n",
      "Epoch: 19 \tTraining Loss: 0.267425 \tValidation Loss: 2.651218\n",
      "Epoch: 20 \tTraining Loss: 0.237114 \tValidation Loss: 2.669656\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 10 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.201310 \tValidation Loss: 4.286594\n",
      "Validation loss decreased (inf --> 4.28659).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.458066 \tValidation Loss: 4.136627\n",
      "Validation loss decreased (4.28659 --> 4.13663).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.063615 \tValidation Loss: 3.904674\n",
      "Validation loss decreased (4.13663 --> 3.90467).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.513828 \tValidation Loss: 3.619546\n",
      "Validation loss decreased (3.90467 --> 3.61955).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.858071 \tValidation Loss: 3.333328\n",
      "Validation loss decreased (3.61955 --> 3.33333).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.196552 \tValidation Loss: 3.084332\n",
      "Validation loss decreased (3.33333 --> 3.08433).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.606126 \tValidation Loss: 2.885965\n",
      "Validation loss decreased (3.08433 --> 2.88596).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.114635 \tValidation Loss: 2.735115\n",
      "Validation loss decreased (2.88596 --> 2.73511).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.721448 \tValidation Loss: 2.620864\n",
      "Validation loss decreased (2.73511 --> 2.62086).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.399288 \tValidation Loss: 2.533133\n",
      "Validation loss decreased (2.62086 --> 2.53313).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.140822 \tValidation Loss: 2.466572\n",
      "Validation loss decreased (2.53313 --> 2.46657).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.931927 \tValidation Loss: 2.419077\n",
      "Validation loss decreased (2.46657 --> 2.41908).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.759780 \tValidation Loss: 2.385771\n",
      "Validation loss decreased (2.41908 --> 2.38577).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.624942 \tValidation Loss: 2.366352\n",
      "Validation loss decreased (2.38577 --> 2.36635).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.511138 \tValidation Loss: 2.354747\n",
      "Validation loss decreased (2.36635 --> 2.35475).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.428413 \tValidation Loss: 2.350211\n",
      "Validation loss decreased (2.35475 --> 2.35021).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.358652 \tValidation Loss: 2.353936\n",
      "Epoch: 18 \tTraining Loss: 0.304950 \tValidation Loss: 2.362852\n",
      "Epoch: 19 \tTraining Loss: 0.261774 \tValidation Loss: 2.374011\n",
      "Epoch: 20 \tTraining Loss: 0.230493 \tValidation Loss: 2.388311\n",
      "Epoch: 1 \tTraining Loss: 6.212236 \tValidation Loss: 4.340862\n",
      "Validation loss decreased (inf --> 4.34086).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.454879 \tValidation Loss: 4.188508\n",
      "Validation loss decreased (4.34086 --> 4.18851).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.052338 \tValidation Loss: 3.963707\n",
      "Validation loss decreased (4.18851 --> 3.96371).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.494084 \tValidation Loss: 3.688425\n",
      "Validation loss decreased (3.96371 --> 3.68843).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.828986 \tValidation Loss: 3.412369\n",
      "Validation loss decreased (3.68843 --> 3.41237).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.162282 \tValidation Loss: 3.171215\n",
      "Validation loss decreased (3.41237 --> 3.17121).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.575593 \tValidation Loss: 2.975871\n",
      "Validation loss decreased (3.17121 --> 2.97587).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.088913 \tValidation Loss: 2.820597\n",
      "Validation loss decreased (2.97587 --> 2.82060).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.699458 \tValidation Loss: 2.701242\n",
      "Validation loss decreased (2.82060 --> 2.70124).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.382835 \tValidation Loss: 2.608671\n",
      "Validation loss decreased (2.70124 --> 2.60867).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 \tTraining Loss: 1.126323 \tValidation Loss: 2.536678\n",
      "Validation loss decreased (2.60867 --> 2.53668).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.920921 \tValidation Loss: 2.483755\n",
      "Validation loss decreased (2.53668 --> 2.48375).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.754546 \tValidation Loss: 2.444984\n",
      "Validation loss decreased (2.48375 --> 2.44498).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.615925 \tValidation Loss: 2.420016\n",
      "Validation loss decreased (2.44498 --> 2.42002).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.510398 \tValidation Loss: 2.404182\n",
      "Validation loss decreased (2.42002 --> 2.40418).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.426140 \tValidation Loss: 2.398903\n",
      "Validation loss decreased (2.40418 --> 2.39890).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.355805 \tValidation Loss: 2.399734\n",
      "Epoch: 18 \tTraining Loss: 0.304416 \tValidation Loss: 2.404137\n",
      "Epoch: 19 \tTraining Loss: 0.260696 \tValidation Loss: 2.414492\n",
      "Epoch: 20 \tTraining Loss: 0.228290 \tValidation Loss: 2.424778\n",
      "Epoch: 1 \tTraining Loss: 6.211528 \tValidation Loss: 4.381052\n",
      "Validation loss decreased (inf --> 4.38105).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.450902 \tValidation Loss: 4.227938\n",
      "Validation loss decreased (4.38105 --> 4.22794).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.049100 \tValidation Loss: 4.002819\n",
      "Validation loss decreased (4.22794 --> 4.00282).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.491549 \tValidation Loss: 3.723991\n",
      "Validation loss decreased (4.00282 --> 3.72399).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.831936 \tValidation Loss: 3.438554\n",
      "Validation loss decreased (3.72399 --> 3.43855).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.162130 \tValidation Loss: 3.188415\n",
      "Validation loss decreased (3.43855 --> 3.18841).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.568803 \tValidation Loss: 2.991274\n",
      "Validation loss decreased (3.18841 --> 2.99127).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.081636 \tValidation Loss: 2.840341\n",
      "Validation loss decreased (2.99127 --> 2.84034).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.688219 \tValidation Loss: 2.722918\n",
      "Validation loss decreased (2.84034 --> 2.72292).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.374808 \tValidation Loss: 2.631598\n",
      "Validation loss decreased (2.72292 --> 2.63160).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.121024 \tValidation Loss: 2.560512\n",
      "Validation loss decreased (2.63160 --> 2.56051).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.912726 \tValidation Loss: 2.505363\n",
      "Validation loss decreased (2.56051 --> 2.50536).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.744953 \tValidation Loss: 2.469647\n",
      "Validation loss decreased (2.50536 --> 2.46965).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.607287 \tValidation Loss: 2.442981\n",
      "Validation loss decreased (2.46965 --> 2.44298).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.505430 \tValidation Loss: 2.427007\n",
      "Validation loss decreased (2.44298 --> 2.42701).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.419671 \tValidation Loss: 2.419362\n",
      "Validation loss decreased (2.42701 --> 2.41936).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.350920 \tValidation Loss: 2.417541\n",
      "Validation loss decreased (2.41936 --> 2.41754).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.297740 \tValidation Loss: 2.421561\n",
      "Epoch: 19 \tTraining Loss: 0.258048 \tValidation Loss: 2.429234\n",
      "Epoch: 20 \tTraining Loss: 0.224411 \tValidation Loss: 2.438047\n",
      "Epoch: 1 \tTraining Loss: 6.204416 \tValidation Loss: 4.358693\n",
      "Validation loss decreased (inf --> 4.35869).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.451172 \tValidation Loss: 4.205292\n",
      "Validation loss decreased (4.35869 --> 4.20529).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.045068 \tValidation Loss: 3.979793\n",
      "Validation loss decreased (4.20529 --> 3.97979).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.487259 \tValidation Loss: 3.709181\n",
      "Validation loss decreased (3.97979 --> 3.70918).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.829450 \tValidation Loss: 3.434654\n",
      "Validation loss decreased (3.70918 --> 3.43465).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.167942 \tValidation Loss: 3.191893\n",
      "Validation loss decreased (3.43465 --> 3.19189).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.580776 \tValidation Loss: 2.995587\n",
      "Validation loss decreased (3.19189 --> 2.99559).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.102564 \tValidation Loss: 2.838711\n",
      "Validation loss decreased (2.99559 --> 2.83871).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.706236 \tValidation Loss: 2.710297\n",
      "Validation loss decreased (2.83871 --> 2.71030).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.390349 \tValidation Loss: 2.609965\n",
      "Validation loss decreased (2.71030 --> 2.60997).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.130681 \tValidation Loss: 2.529970\n",
      "Validation loss decreased (2.60997 --> 2.52997).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.922515 \tValidation Loss: 2.471408\n",
      "Validation loss decreased (2.52997 --> 2.47141).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.752816 \tValidation Loss: 2.429432\n",
      "Validation loss decreased (2.47141 --> 2.42943).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.618184 \tValidation Loss: 2.400066\n",
      "Validation loss decreased (2.42943 --> 2.40007).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.505645 \tValidation Loss: 2.383225\n",
      "Validation loss decreased (2.40007 --> 2.38322).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.419252 \tValidation Loss: 2.377997\n",
      "Validation loss decreased (2.38322 --> 2.37800).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.352964 \tValidation Loss: 2.377259\n",
      "Validation loss decreased (2.37800 --> 2.37726).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.300956 \tValidation Loss: 2.385059\n",
      "Epoch: 19 \tTraining Loss: 0.256834 \tValidation Loss: 2.394540\n",
      "Epoch: 20 \tTraining Loss: 0.224227 \tValidation Loss: 2.407661\n",
      "Epoch: 1 \tTraining Loss: 6.215017 \tValidation Loss: 4.336063\n",
      "Validation loss decreased (inf --> 4.33606).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.456414 \tValidation Loss: 4.179219\n",
      "Validation loss decreased (4.33606 --> 4.17922).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.056345 \tValidation Loss: 3.938150\n",
      "Validation loss decreased (4.17922 --> 3.93815).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.500094 \tValidation Loss: 3.653926\n",
      "Validation loss decreased (3.93815 --> 3.65393).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.840669 \tValidation Loss: 3.370273\n",
      "Validation loss decreased (3.65393 --> 3.37027).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.171468 \tValidation Loss: 3.118058\n",
      "Validation loss decreased (3.37027 --> 3.11806).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.582956 \tValidation Loss: 2.915266\n",
      "Validation loss decreased (3.11806 --> 2.91527).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.096455 \tValidation Loss: 2.758757\n",
      "Validation loss decreased (2.91527 --> 2.75876).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.704645 \tValidation Loss: 2.640027\n",
      "Validation loss decreased (2.75876 --> 2.64003).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.387287 \tValidation Loss: 2.548290\n",
      "Validation loss decreased (2.64003 --> 2.54829).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.130884 \tValidation Loss: 2.479406\n",
      "Validation loss decreased (2.54829 --> 2.47941).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.924683 \tValidation Loss: 2.427113\n",
      "Validation loss decreased (2.47941 --> 2.42711).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.755350 \tValidation Loss: 2.391560\n",
      "Validation loss decreased (2.42711 --> 2.39156).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.616947 \tValidation Loss: 2.365865\n",
      "Validation loss decreased (2.39156 --> 2.36587).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.509807 \tValidation Loss: 2.352329\n",
      "Validation loss decreased (2.36587 --> 2.35233).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.424882 \tValidation Loss: 2.346313\n",
      "Validation loss decreased (2.35233 --> 2.34631).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.355633 \tValidation Loss: 2.351126\n",
      "Epoch: 18 \tTraining Loss: 0.301588 \tValidation Loss: 2.355636\n",
      "Epoch: 19 \tTraining Loss: 0.258450 \tValidation Loss: 2.365076\n",
      "Epoch: 20 \tTraining Loss: 0.224607 \tValidation Loss: 2.378749\n",
      "Epoch: 1 \tTraining Loss: 6.199779 \tValidation Loss: 4.353034\n",
      "Validation loss decreased (inf --> 4.35303).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.448800 \tValidation Loss: 4.189936\n",
      "Validation loss decreased (4.35303 --> 4.18994).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \tTraining Loss: 5.048429 \tValidation Loss: 3.951525\n",
      "Validation loss decreased (4.18994 --> 3.95152).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.494802 \tValidation Loss: 3.661372\n",
      "Validation loss decreased (3.95152 --> 3.66137).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.832210 \tValidation Loss: 3.373621\n",
      "Validation loss decreased (3.66137 --> 3.37362).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.163189 \tValidation Loss: 3.125148\n",
      "Validation loss decreased (3.37362 --> 3.12515).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.573868 \tValidation Loss: 2.927255\n",
      "Validation loss decreased (3.12515 --> 2.92726).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.087283 \tValidation Loss: 2.771778\n",
      "Validation loss decreased (2.92726 --> 2.77178).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.692783 \tValidation Loss: 2.649552\n",
      "Validation loss decreased (2.77178 --> 2.64955).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.374612 \tValidation Loss: 2.555465\n",
      "Validation loss decreased (2.64955 --> 2.55547).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.123523 \tValidation Loss: 2.483288\n",
      "Validation loss decreased (2.55547 --> 2.48329).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.910857 \tValidation Loss: 2.431151\n",
      "Validation loss decreased (2.48329 --> 2.43115).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.745405 \tValidation Loss: 2.392085\n",
      "Validation loss decreased (2.43115 --> 2.39208).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.611118 \tValidation Loss: 2.366163\n",
      "Validation loss decreased (2.39208 --> 2.36616).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.501266 \tValidation Loss: 2.351585\n",
      "Validation loss decreased (2.36616 --> 2.35158).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.416179 \tValidation Loss: 2.346780\n",
      "Validation loss decreased (2.35158 --> 2.34678).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.350257 \tValidation Loss: 2.347540\n",
      "Epoch: 18 \tTraining Loss: 0.296971 \tValidation Loss: 2.353656\n",
      "Epoch: 19 \tTraining Loss: 0.255415 \tValidation Loss: 2.363074\n",
      "Epoch: 20 \tTraining Loss: 0.223922 \tValidation Loss: 2.372258\n",
      "Epoch: 1 \tTraining Loss: 6.203422 \tValidation Loss: 4.376231\n",
      "Validation loss decreased (inf --> 4.37623).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.457854 \tValidation Loss: 4.238543\n",
      "Validation loss decreased (4.37623 --> 4.23854).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.062264 \tValidation Loss: 4.020529\n",
      "Validation loss decreased (4.23854 --> 4.02053).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.511994 \tValidation Loss: 3.747972\n",
      "Validation loss decreased (4.02053 --> 3.74797).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.847301 \tValidation Loss: 3.466955\n",
      "Validation loss decreased (3.74797 --> 3.46695).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.176850 \tValidation Loss: 3.223003\n",
      "Validation loss decreased (3.46695 --> 3.22300).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.580464 \tValidation Loss: 3.029995\n",
      "Validation loss decreased (3.22300 --> 3.03000).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.094575 \tValidation Loss: 2.880871\n",
      "Validation loss decreased (3.03000 --> 2.88087).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.699752 \tValidation Loss: 2.767544\n",
      "Validation loss decreased (2.88087 --> 2.76754).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.388233 \tValidation Loss: 2.682150\n",
      "Validation loss decreased (2.76754 --> 2.68215).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.127599 \tValidation Loss: 2.614944\n",
      "Validation loss decreased (2.68215 --> 2.61494).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.921417 \tValidation Loss: 2.565026\n",
      "Validation loss decreased (2.61494 --> 2.56503).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.751532 \tValidation Loss: 2.528170\n",
      "Validation loss decreased (2.56503 --> 2.52817).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.615049 \tValidation Loss: 2.504476\n",
      "Validation loss decreased (2.52817 --> 2.50448).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.506026 \tValidation Loss: 2.491633\n",
      "Validation loss decreased (2.50448 --> 2.49163).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.420727 \tValidation Loss: 2.485235\n",
      "Validation loss decreased (2.49163 --> 2.48523).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.349878 \tValidation Loss: 2.486765\n",
      "Epoch: 18 \tTraining Loss: 0.297260 \tValidation Loss: 2.493103\n",
      "Epoch: 19 \tTraining Loss: 0.257613 \tValidation Loss: 2.504585\n",
      "Epoch: 20 \tTraining Loss: 0.224200 \tValidation Loss: 2.517777\n",
      "Epoch: 1 \tTraining Loss: 6.204128 \tValidation Loss: 4.371727\n",
      "Validation loss decreased (inf --> 4.37173).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.453437 \tValidation Loss: 4.224483\n",
      "Validation loss decreased (4.37173 --> 4.22448).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.049445 \tValidation Loss: 4.006972\n",
      "Validation loss decreased (4.22448 --> 4.00697).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.485795 \tValidation Loss: 3.738640\n",
      "Validation loss decreased (4.00697 --> 3.73864).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.818578 \tValidation Loss: 3.472633\n",
      "Validation loss decreased (3.73864 --> 3.47263).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.150662 \tValidation Loss: 3.239915\n",
      "Validation loss decreased (3.47263 --> 3.23991).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.562974 \tValidation Loss: 3.054223\n",
      "Validation loss decreased (3.23991 --> 3.05422).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.083323 \tValidation Loss: 2.909783\n",
      "Validation loss decreased (3.05422 --> 2.90978).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.690032 \tValidation Loss: 2.798587\n",
      "Validation loss decreased (2.90978 --> 2.79859).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.374856 \tValidation Loss: 2.713741\n",
      "Validation loss decreased (2.79859 --> 2.71374).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.121141 \tValidation Loss: 2.646479\n",
      "Validation loss decreased (2.71374 --> 2.64648).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.912611 \tValidation Loss: 2.597085\n",
      "Validation loss decreased (2.64648 --> 2.59709).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.744409 \tValidation Loss: 2.562755\n",
      "Validation loss decreased (2.59709 --> 2.56276).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.611445 \tValidation Loss: 2.541783\n",
      "Validation loss decreased (2.56276 --> 2.54178).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.501559 \tValidation Loss: 2.529811\n",
      "Validation loss decreased (2.54178 --> 2.52981).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.420115 \tValidation Loss: 2.527626\n",
      "Validation loss decreased (2.52981 --> 2.52763).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.352096 \tValidation Loss: 2.532740\n",
      "Epoch: 18 \tTraining Loss: 0.299577 \tValidation Loss: 2.543275\n",
      "Epoch: 19 \tTraining Loss: 0.255803 \tValidation Loss: 2.555380\n",
      "Epoch: 20 \tTraining Loss: 0.224174 \tValidation Loss: 2.568030\n",
      "Epoch: 1 \tTraining Loss: 6.209098 \tValidation Loss: 4.341272\n",
      "Validation loss decreased (inf --> 4.34127).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.455108 \tValidation Loss: 4.183017\n",
      "Validation loss decreased (4.34127 --> 4.18302).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.056618 \tValidation Loss: 3.953755\n",
      "Validation loss decreased (4.18302 --> 3.95376).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.500774 \tValidation Loss: 3.671898\n",
      "Validation loss decreased (3.95376 --> 3.67190).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.837015 \tValidation Loss: 3.386157\n",
      "Validation loss decreased (3.67190 --> 3.38616).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.164130 \tValidation Loss: 3.138719\n",
      "Validation loss decreased (3.38616 --> 3.13872).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.572601 \tValidation Loss: 2.940812\n",
      "Validation loss decreased (3.13872 --> 2.94081).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.084229 \tValidation Loss: 2.790092\n",
      "Validation loss decreased (2.94081 --> 2.79009).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.688522 \tValidation Loss: 2.675335\n",
      "Validation loss decreased (2.79009 --> 2.67534).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.370558 \tValidation Loss: 2.590963\n",
      "Validation loss decreased (2.67534 --> 2.59096).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.118671 \tValidation Loss: 2.525952\n",
      "Validation loss decreased (2.59096 --> 2.52595).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.913034 \tValidation Loss: 2.478485\n",
      "Validation loss decreased (2.52595 --> 2.47848).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.745336 \tValidation Loss: 2.443903\n",
      "Validation loss decreased (2.47848 --> 2.44390).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 \tTraining Loss: 0.610958 \tValidation Loss: 2.423430\n",
      "Validation loss decreased (2.44390 --> 2.42343).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.503670 \tValidation Loss: 2.408809\n",
      "Validation loss decreased (2.42343 --> 2.40881).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.418604 \tValidation Loss: 2.403882\n",
      "Validation loss decreased (2.40881 --> 2.40388).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.349179 \tValidation Loss: 2.406882\n",
      "Epoch: 18 \tTraining Loss: 0.297323 \tValidation Loss: 2.411294\n",
      "Epoch: 19 \tTraining Loss: 0.257801 \tValidation Loss: 2.420206\n",
      "Epoch: 20 \tTraining Loss: 0.223973 \tValidation Loss: 2.433082\n",
      "Epoch: 1 \tTraining Loss: 6.203069 \tValidation Loss: 4.367530\n",
      "Validation loss decreased (inf --> 4.36753).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.446525 \tValidation Loss: 4.213299\n",
      "Validation loss decreased (4.36753 --> 4.21330).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.056578 \tValidation Loss: 3.987539\n",
      "Validation loss decreased (4.21330 --> 3.98754).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.512754 \tValidation Loss: 3.709477\n",
      "Validation loss decreased (3.98754 --> 3.70948).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.859773 \tValidation Loss: 3.422419\n",
      "Validation loss decreased (3.70948 --> 3.42242).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.190910 \tValidation Loss: 3.168990\n",
      "Validation loss decreased (3.42242 --> 3.16899).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.594236 \tValidation Loss: 2.962906\n",
      "Validation loss decreased (3.16899 --> 2.96291).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.108047 \tValidation Loss: 2.800710\n",
      "Validation loss decreased (2.96291 --> 2.80071).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.714758 \tValidation Loss: 2.672927\n",
      "Validation loss decreased (2.80071 --> 2.67293).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.391676 \tValidation Loss: 2.576611\n",
      "Validation loss decreased (2.67293 --> 2.57661).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.141029 \tValidation Loss: 2.501524\n",
      "Validation loss decreased (2.57661 --> 2.50152).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.926910 \tValidation Loss: 2.447866\n",
      "Validation loss decreased (2.50152 --> 2.44787).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.760935 \tValidation Loss: 2.406438\n",
      "Validation loss decreased (2.44787 --> 2.40644).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.622528 \tValidation Loss: 2.377483\n",
      "Validation loss decreased (2.40644 --> 2.37748).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.512691 \tValidation Loss: 2.357937\n",
      "Validation loss decreased (2.37748 --> 2.35794).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.426433 \tValidation Loss: 2.350225\n",
      "Validation loss decreased (2.35794 --> 2.35022).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.359708 \tValidation Loss: 2.345365\n",
      "Validation loss decreased (2.35022 --> 2.34537).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.303718 \tValidation Loss: 2.346523\n",
      "Epoch: 19 \tTraining Loss: 0.262480 \tValidation Loss: 2.352154\n",
      "Epoch: 20 \tTraining Loss: 0.228140 \tValidation Loss: 2.361903\n"
     ]
    }
   ],
   "source": [
    "# Preparing the results dataframes:\n",
    "windows = list(range(3,11))\n",
    "columns = ['Predicted_top5_mean', 'Predicted_top5_std', 'Predicted_top10_mean', 'Predicted_top10_std']\n",
    "Results_Nolemmatize = pd.DataFrame(index=index, columns=columns)\n",
    "Results_lemmatize = pd.DataFrame(index=index, columns=columns)\n",
    "\n",
    "# Getting some results:\n",
    "for lemmatize in [False , True]:\n",
    "    \n",
    "    # Building the corpus\n",
    "    corpus = Corpus(meta = 'Corpus BBC '+category+' News, only verbs as target, no stopwords.')\n",
    "    import_bbc_folder(category,corpus , lemmatize = lemmatize)\n",
    "    \n",
    "    for window in windows:\n",
    "                \n",
    "        # Building the dataset:\n",
    "        sentences , verbs = Build_Dataset([category], corpus, window, one_hot=True , lemmatize=lemmatize)\n",
    "        \n",
    "        print('\\n Starting:...-> Lemmatize =',lemmatize,', window =', window , '\\n')\n",
    "        \n",
    "        lr=0.001\n",
    "        batch_size = 512\n",
    "        n_epochs = 20\n",
    "        file_name = 'CBOW_BBC_'+category+'_lemmatize='+str(lemmatize)+'_window='+str(window)+'_crossval.pt'\n",
    "        random_state = 123\n",
    "        K = 10\n",
    "        \n",
    "        # Cross validating the model:\n",
    "        training_losses, validation_losses, predicted_intop5, predicted_intop10 = K_fold_Cross_validate(K , sentences , verbs,\n",
    "                                                                                                corpus, lr,batch_size ,n_epochs,\n",
    "                                                                                                file_name, random_state)\n",
    "        \n",
    "        # Getting the prediction measures mean and standard deviation:\n",
    "        predicted_intop5_mean , predicted_intop5_std  = np.mean(predicted_intop5) , np.std(predicted_intop5)\n",
    "        predicted_intop10_mean , predicted_intop10_std  = np.mean(predicted_intop10) , np.std(predicted_intop10)\n",
    "        \n",
    "        # Adding the measures to the corresponding dataframe:\n",
    "        if lemmatize:\n",
    "            Results_lemmatize.loc[window , 'Predicted_top5_mean'] = predicted_intop5_mean\n",
    "            Results_lemmatize.loc[window , 'Predicted_top5_std'] = predicted_intop5_std\n",
    "            Results_lemmatize.loc[window , 'Predicted_top10_mean'] = predicted_intop10_mean\n",
    "            Results_lemmatize.loc[window , 'Predicted_top10_std'] = predicted_intop10_std\n",
    "        else:\n",
    "            Results_Nolemmatize.loc[window , 'Predicted_top5_mean'] = predicted_intop5_mean\n",
    "            Results_Nolemmatize.loc[window , 'Predicted_top5_std'] = predicted_intop5_std\n",
    "            Results_Nolemmatize.loc[window , 'Predicted_top10_mean'] = predicted_intop10_mean\n",
    "            Results_Nolemmatize.loc[window , 'Predicted_top10_std'] = predicted_intop10_std\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(category+'results.pkl', 'wb') as f:\n",
    "    pickle.dump((Results_lemmatize , Results_Nolemmatize),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(category+'results.pkl', 'rb') as f:\n",
    "    Results_lemmatize , Results_Nolemmatize = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_top5_mean</th>\n",
       "      <th>Predicted_top5_std</th>\n",
       "      <th>Predicted_top10_mean</th>\n",
       "      <th>Predicted_top10_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.354883</td>\n",
       "      <td>0.00562758</td>\n",
       "      <td>0.454277</td>\n",
       "      <td>0.00431764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.500586</td>\n",
       "      <td>0.00717199</td>\n",
       "      <td>0.60043</td>\n",
       "      <td>0.00764209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5977</td>\n",
       "      <td>0.00917422</td>\n",
       "      <td>0.684462</td>\n",
       "      <td>0.00653064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.64646</td>\n",
       "      <td>0.00415964</td>\n",
       "      <td>0.718237</td>\n",
       "      <td>0.00570835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.67832</td>\n",
       "      <td>0.00340688</td>\n",
       "      <td>0.73697</td>\n",
       "      <td>0.00455586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.687207</td>\n",
       "      <td>0.00521738</td>\n",
       "      <td>0.736979</td>\n",
       "      <td>0.00478194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.676602</td>\n",
       "      <td>0.00799675</td>\n",
       "      <td>0.722773</td>\n",
       "      <td>0.00806818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.672021</td>\n",
       "      <td>0.00568612</td>\n",
       "      <td>0.711182</td>\n",
       "      <td>0.00560674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted_top5_mean Predicted_top5_std Predicted_top10_mean  \\\n",
       "3             0.354883         0.00562758             0.454277   \n",
       "4             0.500586         0.00717199              0.60043   \n",
       "5               0.5977         0.00917422             0.684462   \n",
       "6              0.64646         0.00415964             0.718237   \n",
       "7              0.67832         0.00340688              0.73697   \n",
       "8             0.687207         0.00521738             0.736979   \n",
       "9             0.676602         0.00799675             0.722773   \n",
       "10            0.672021         0.00568612             0.711182   \n",
       "\n",
       "   Predicted_top10_std  \n",
       "3           0.00431764  \n",
       "4           0.00764209  \n",
       "5           0.00653064  \n",
       "6           0.00570835  \n",
       "7           0.00455586  \n",
       "8           0.00478194  \n",
       "9           0.00806818  \n",
       "10          0.00560674  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Results_lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_top5_mean</th>\n",
       "      <th>Predicted_top5_std</th>\n",
       "      <th>Predicted_top10_mean</th>\n",
       "      <th>Predicted_top10_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.356812</td>\n",
       "      <td>0.00891648</td>\n",
       "      <td>0.451465</td>\n",
       "      <td>0.00978928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.566471</td>\n",
       "      <td>0.00670292</td>\n",
       "      <td>0.65842</td>\n",
       "      <td>0.00757002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.680518</td>\n",
       "      <td>0.00642716</td>\n",
       "      <td>0.745337</td>\n",
       "      <td>0.00404338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.743443</td>\n",
       "      <td>0.005869</td>\n",
       "      <td>0.789983</td>\n",
       "      <td>0.0071464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.758761</td>\n",
       "      <td>0.00703789</td>\n",
       "      <td>0.794196</td>\n",
       "      <td>0.00588748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.752767</td>\n",
       "      <td>0.00473574</td>\n",
       "      <td>0.782357</td>\n",
       "      <td>0.00505596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.740195</td>\n",
       "      <td>0.0087459</td>\n",
       "      <td>0.766719</td>\n",
       "      <td>0.00655226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.724121</td>\n",
       "      <td>0.00867713</td>\n",
       "      <td>0.750244</td>\n",
       "      <td>0.00835018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted_top5_mean Predicted_top5_std Predicted_top10_mean  \\\n",
       "3             0.356812         0.00891648             0.451465   \n",
       "4             0.566471         0.00670292              0.65842   \n",
       "5             0.680518         0.00642716             0.745337   \n",
       "6             0.743443           0.005869             0.789983   \n",
       "7             0.758761         0.00703789             0.794196   \n",
       "8             0.752767         0.00473574             0.782357   \n",
       "9             0.740195          0.0087459             0.766719   \n",
       "10            0.724121         0.00867713             0.750244   \n",
       "\n",
       "   Predicted_top10_std  \n",
       "3           0.00978928  \n",
       "4           0.00757002  \n",
       "5           0.00404338  \n",
       "6            0.0071464  \n",
       "7           0.00588748  \n",
       "8           0.00505596  \n",
       "9           0.00655226  \n",
       "10          0.00835018  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Results_Nolemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.bar(Results_lemmatize.index.values, Results_lemmatize['Predicted_top10_mean'].values, yerr=Results_lemmatize['Predicted_top10_std'].values, width=-0.4, align='edge', alpha=0.8, ecolor='black', capsize=4,  label='Top 10 +L')\n",
    "ax.bar(Results_lemmatize.index.values, Results_lemmatize['Predicted_top5_mean'].values, yerr=Results_lemmatize['Predicted_top5_std'].values, color='green', width=-0.4, align='edge', alpha=0.7, ecolor='black', capsize=4, label='Top 5 +L')\n",
    "ax.bar(Results_Nolemmatize.index.values, Results_Nolemmatize['Predicted_top10_mean'].values, yerr=Results_Nolemmatize['Predicted_top10_std'].values, width=0.4, align='edge', alpha=0.8, ecolor='black', capsize=4,  label='Top 10')\n",
    "ax.bar(Results_Nolemmatize.index.values, Results_Nolemmatize['Predicted_top5_mean'].values, yerr=Results_Nolemmatize['Predicted_top5_std'].values, color='purple', width=0.4, align='edge', alpha=0.7, ecolor='black', capsize=4, label='Top 5')\n",
    "ax.set_ylabel('Accuracy of Prediction')\n",
    "ax.set_xlabel('Window Size')\n",
    "ax.set_xticks(Results_lemmatize.index.values)\n",
    "ax.set_yticks(np.arange(0,1.1,0.1))\n",
    "ax.yaxis.grid(True)\n",
    "ax.legend()\n",
    "plt.savefig(category+'-bars.pdf', dpi=500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking a look at the predicted probabilities of the best setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 6.578046 \tValidation Loss: 5.933753\n",
      "Validation loss decreased (inf --> 5.93375).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.880662 \tValidation Loss: 5.641151\n",
      "Validation loss decreased (5.93375 --> 5.64115).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.328329 \tValidation Loss: 5.192880\n",
      "Validation loss decreased (5.64115 --> 5.19288).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.503368 \tValidation Loss: 4.626440\n",
      "Validation loss decreased (5.19288 --> 4.62644).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.559255 \tValidation Loss: 4.085675\n",
      "Validation loss decreased (4.62644 --> 4.08567).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.704724 \tValidation Loss: 3.648505\n",
      "Validation loss decreased (4.08567 --> 3.64850).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.035357 \tValidation Loss: 3.320251\n",
      "Validation loss decreased (3.64850 --> 3.32025).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.542706 \tValidation Loss: 3.080491\n",
      "Validation loss decreased (3.32025 --> 3.08049).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.186265 \tValidation Loss: 2.906181\n",
      "Validation loss decreased (3.08049 --> 2.90618).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.920630 \tValidation Loss: 2.779571\n",
      "Validation loss decreased (2.90618 --> 2.77957).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.727775 \tValidation Loss: 2.689923\n",
      "Validation loss decreased (2.77957 --> 2.68992).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.577345 \tValidation Loss: 2.628902\n",
      "Validation loss decreased (2.68992 --> 2.62890).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.464741 \tValidation Loss: 2.589802\n",
      "Validation loss decreased (2.62890 --> 2.58980).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.381533 \tValidation Loss: 2.565352\n",
      "Validation loss decreased (2.58980 --> 2.56535).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.316045 \tValidation Loss: 2.556968\n",
      "Validation loss decreased (2.56535 --> 2.55697).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.268767 \tValidation Loss: 2.555920\n",
      "Validation loss decreased (2.55697 --> 2.55592).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.232022 \tValidation Loss: 2.559743\n",
      "Epoch: 18 \tTraining Loss: 0.203232 \tValidation Loss: 2.564719\n",
      "Epoch: 19 \tTraining Loss: 0.179776 \tValidation Loss: 2.575885\n",
      "Epoch: 20 \tTraining Loss: 0.161860 \tValidation Loss: 2.589154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize = False\n",
    "window = 7\n",
    "\n",
    "# Building the corpus\n",
    "corpus = Corpus(meta = 'Corpus BBC '+category+' News, only verbs as target, no stopwords.')\n",
    "import_bbc_folder(category,corpus , lemmatize = lemmatize)\n",
    "\n",
    "# Building the dataset\n",
    "sentences , verbs = Build_Dataset([category], corpus, window, one_hot=True , lemmatize=lemmatize)\n",
    "\n",
    "# Getting the train_valid_test data:\n",
    "x_train, x_test, y_train, y_test = train_test_split(sentences, verbs, test_size=0.1, random_state=123)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.1, random_state=123)\n",
    "\n",
    "# Building the model\n",
    "vocab_size = len(corpus.get_vocabs_to_learn())\n",
    "verbs_size = len(corpus.get_verbs_to_learn())\n",
    "hidden_dim = 500\n",
    "\n",
    "model = CBOW(vocab_size, hidden_dim, verbs_size)\n",
    "model.cuda()\n",
    "\n",
    "# Training the model\n",
    "lr=0.001\n",
    "batch_size = 512\n",
    "n_epochs = 20\n",
    "file_name = 'CBOW_BBC'+category+'_window='+str(window)+'_forevaluation.pt'\n",
    "\n",
    "train_losses, valid_losses = Train_model(model, lr, batch_size, n_epochs, file_name, x_train, y_train, x_valid, y_valid)\n",
    "\n",
    "# Loading the best model parameters\n",
    "model.load_state_dict(torch.load(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1dbb8727e08>"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label = 'Training loss')\n",
    "plt.plot(valid_losses, label = 'Validation loss')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking into a sample of predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "getbatch = iter(get_batch(x_test, y_test , 16))\n",
    "sentences, verbs = next(getbatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "output = model(sentences.cuda().float())\n",
    "ps = torch.exp(output)\n",
    "top_p, top_class = ps.topk(10, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sold\n",
      "\tsold\tbid\tdropped\treport\tpay\tproduced\tclose\twent\tstarted\tseem\t\n",
      "came\n",
      "\tbuying\tholds\tprofit\tbought\tsold\tcame\tannounced\trevealed\towned\tfell\t\n",
      "euro\n",
      "\teuro\thelp\tmakes\tremained\tgiven\taccounts\tfocusing\tfund\tstrengthened\tsaid\t\n",
      "represent\n",
      "\tclaims\twants\tholding\tclaim\tmaking\tbuy\tgain\tcontrol\tbacking\tbid\t\n",
      "added\n",
      "\tsee\tadded\texpects\tstart\texpected\tback\treported\thit\tclosed\tholding\t\n",
      "help\n",
      "\tincrease\tneeded\tuse\tsent\tprogramme\tcuts\tlinked\treturn\tsolve\trecommended\t\n",
      "including\n",
      "\tincluding\thelped\tenjoyed\tsaid\tboosting\tincludes\trise\tmobile\tdemand\temployed\t\n",
      "called\n",
      "\tleft\tcalled\tyukos\ttrying\tfollowing\tinvestigate\tsaid\tconfirmed\tsaying\treturn\t\n",
      "dominate\n",
      "\tbuild\tprovide\tdominate\tprefer\tstarting\tdemand\tsaid\trecall\tincluding\tlaunch\t\n",
      "slowed\n",
      "\tslowed\tgrown\tfuelled\testimate\tback\taccelerated\tmarked\tfell\tbounced\tseeing\t\n",
      "force\n",
      "\tshow\tsaid\tforce\tcreated\tfollowing\tpursue\tbuy\tattend\topened\tincluding\t\n",
      "remains\n",
      "\tremains\tseen\tfalling\tslowing\tfell\tmeans\tgrowing\tgoing\tsaid\tstruggling\t\n",
      "shown\n",
      "\tshown\tsurrounding\treject\toffer\tmade\tsays\tgive\tsucceed\tbid\tagreed\t\n",
      "cuts\n",
      "\tblamed\tcuts\tgiven\tremain\tmeant\tused\tboost\texpect\traising\toffer\t\n",
      "cannot\n",
      "\tmeet\taccording\tmaking\tsaid\tseen\traise\taccount\tuse\tcreate\tfuel\t\n",
      "rising\n",
      "\tcosts\tcost\texplained\teuros\tthink\toffset\tsays\tlooking\tseek\tsaid\t\n"
     ]
    }
   ],
   "source": [
    "for clas, t in zip(top_class, verbs):\n",
    "    print(corpus.get_verb_from_index(t.item()) , ': ')\n",
    "    print('\\t' ,  end='' )\n",
    "    for val in clas:\n",
    "        print(corpus.get_verb_from_index(val.item()), end='\\t' )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['increase', 'rising', 'prices', 'product', 'able', 'ore']\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = -1\n",
    "sent = np.where(np.array(sentences[i]) != 0)[0]\n",
    "corpus.get_vocab_from_index(sent.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = top_p[i].tolist()\n",
    "vrbs = corpus.get_verb_from_index(top_class[i].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "props = dict(boxstyle='round', facecolor='grey', alpha=0.2)\n",
    "ax.text(0.05, 0.95, 'Input: '+str(corpus.get_vocab_from_index(sent.tolist())), transform=ax.transAxes, fontsize=10, verticalalignment='top', bbox=props)\n",
    "ax.text(0.05, 0.85, 'Target: '+corpus.get_verb_from_index(verbs[i].item()), transform=ax.transAxes, fontsize=10, verticalalignment='top', bbox=props)\n",
    "ax.barh(vrbs, probs, align='center')\n",
    "plt.xlabel('Probabilities')\n",
    "plt.ylabel('Predicted Verbs')\n",
    "ax.set_xticks(np.arange(0,1.1,0.1))\n",
    "ax.xaxis.grid(True)\n",
    "plt.savefig(category+'-probs.pdf', dpi=500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Obtaining prediction results when learning the verbs in entertainment articles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'entertainment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting:...-> Lemmatize = False , window = 3 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.443262 \tValidation Loss: 5.268994\n",
      "Validation loss decreased (inf --> 5.26899).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.846994 \tValidation Loss: 5.169582\n",
      "Validation loss decreased (5.26899 --> 5.16958).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.652926 \tValidation Loss: 5.057024\n",
      "Validation loss decreased (5.16958 --> 5.05702).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.388341 \tValidation Loss: 4.900677\n",
      "Validation loss decreased (5.05702 --> 4.90068).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.031251 \tValidation Loss: 4.718679\n",
      "Validation loss decreased (4.90068 --> 4.71868).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.611068 \tValidation Loss: 4.531679\n",
      "Validation loss decreased (4.71868 --> 4.53168).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.153723 \tValidation Loss: 4.356729\n",
      "Validation loss decreased (4.53168 --> 4.35673).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.693818 \tValidation Loss: 4.208071\n",
      "Validation loss decreased (4.35673 --> 4.20807).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.263184 \tValidation Loss: 4.089712\n",
      "Validation loss decreased (4.20807 --> 4.08971).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.875264 \tValidation Loss: 4.000900\n",
      "Validation loss decreased (4.08971 --> 4.00090).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.547998 \tValidation Loss: 3.937242\n",
      "Validation loss decreased (4.00090 --> 3.93724).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.266726 \tValidation Loss: 3.895121\n",
      "Validation loss decreased (3.93724 --> 3.89512).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.039293 \tValidation Loss: 3.870998\n",
      "Validation loss decreased (3.89512 --> 3.87100).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.853044 \tValidation Loss: 3.859206\n",
      "Validation loss decreased (3.87100 --> 3.85921).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.701366 \tValidation Loss: 3.858401\n",
      "Validation loss decreased (3.85921 --> 3.85840).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 1.574900 \tValidation Loss: 3.865852\n",
      "Epoch: 17 \tTraining Loss: 1.476407 \tValidation Loss: 3.879700\n",
      "Epoch: 18 \tTraining Loss: 1.386271 \tValidation Loss: 3.899320\n",
      "Epoch: 19 \tTraining Loss: 1.319676 \tValidation Loss: 3.922116\n",
      "Epoch: 20 \tTraining Loss: 1.256141 \tValidation Loss: 3.947917\n",
      "Epoch: 1 \tTraining Loss: 6.451831 \tValidation Loss: 5.280603\n",
      "Validation loss decreased (inf --> 5.28060).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.839877 \tValidation Loss: 5.165571\n",
      "Validation loss decreased (5.28060 --> 5.16557).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.642430 \tValidation Loss: 5.055519\n",
      "Validation loss decreased (5.16557 --> 5.05552).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.374632 \tValidation Loss: 4.901486\n",
      "Validation loss decreased (5.05552 --> 4.90149).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.014167 \tValidation Loss: 4.725528\n",
      "Validation loss decreased (4.90149 --> 4.72553).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.591115 \tValidation Loss: 4.552899\n",
      "Validation loss decreased (4.72553 --> 4.55290).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.136155 \tValidation Loss: 4.394125\n",
      "Validation loss decreased (4.55290 --> 4.39412).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.679401 \tValidation Loss: 4.255485\n",
      "Validation loss decreased (4.39412 --> 4.25549).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.249923 \tValidation Loss: 4.142823\n",
      "Validation loss decreased (4.25549 --> 4.14282).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.865882 \tValidation Loss: 4.056209\n",
      "Validation loss decreased (4.14282 --> 4.05621).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.536102 \tValidation Loss: 3.993396\n",
      "Validation loss decreased (4.05621 --> 3.99340).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.258662 \tValidation Loss: 3.950929\n",
      "Validation loss decreased (3.99340 --> 3.95093).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.030659 \tValidation Loss: 3.927753\n",
      "Validation loss decreased (3.95093 --> 3.92775).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.844250 \tValidation Loss: 3.917023\n",
      "Validation loss decreased (3.92775 --> 3.91702).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.694571 \tValidation Loss: 3.918652\n",
      "Epoch: 16 \tTraining Loss: 1.568257 \tValidation Loss: 3.928992\n",
      "Epoch: 17 \tTraining Loss: 1.468577 \tValidation Loss: 3.945180\n",
      "Epoch: 18 \tTraining Loss: 1.383444 \tValidation Loss: 3.968692\n",
      "Epoch: 19 \tTraining Loss: 1.313279 \tValidation Loss: 3.994718\n",
      "Epoch: 20 \tTraining Loss: 1.252143 \tValidation Loss: 4.024325\n",
      "Epoch: 1 \tTraining Loss: 6.445551 \tValidation Loss: 5.260011\n",
      "Validation loss decreased (inf --> 5.26001).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.851045 \tValidation Loss: 5.138602\n",
      "Validation loss decreased (5.26001 --> 5.13860).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.659090 \tValidation Loss: 5.021183\n",
      "Validation loss decreased (5.13860 --> 5.02118).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.394488 \tValidation Loss: 4.858503\n",
      "Validation loss decreased (5.02118 --> 4.85850).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.032787 \tValidation Loss: 4.672730\n",
      "Validation loss decreased (4.85850 --> 4.67273).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.601720 \tValidation Loss: 4.490361\n",
      "Validation loss decreased (4.67273 --> 4.49036).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.136258 \tValidation Loss: 4.325237\n",
      "Validation loss decreased (4.49036 --> 4.32524).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.673416 \tValidation Loss: 4.183915\n",
      "Validation loss decreased (4.32524 --> 4.18391).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.243076 \tValidation Loss: 4.070182\n",
      "Validation loss decreased (4.18391 --> 4.07018).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.857906 \tValidation Loss: 3.983997\n",
      "Validation loss decreased (4.07018 --> 3.98400).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.529708 \tValidation Loss: 3.921771\n",
      "Validation loss decreased (3.98400 --> 3.92177).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.254760 \tValidation Loss: 3.879365\n",
      "Validation loss decreased (3.92177 --> 3.87937).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.028398 \tValidation Loss: 3.855477\n",
      "Validation loss decreased (3.87937 --> 3.85548).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.845300 \tValidation Loss: 3.844580\n",
      "Validation loss decreased (3.85548 --> 3.84458).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.694312 \tValidation Loss: 3.845213\n",
      "Epoch: 16 \tTraining Loss: 1.572036 \tValidation Loss: 3.854684\n",
      "Epoch: 17 \tTraining Loss: 1.468629 \tValidation Loss: 3.871416\n",
      "Epoch: 18 \tTraining Loss: 1.387472 \tValidation Loss: 3.893081\n",
      "Epoch: 19 \tTraining Loss: 1.315724 \tValidation Loss: 3.920416\n",
      "Epoch: 20 \tTraining Loss: 1.257224 \tValidation Loss: 3.950607\n",
      "Epoch: 1 \tTraining Loss: 6.448734 \tValidation Loss: 5.264651\n",
      "Validation loss decreased (inf --> 5.26465).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.842235 \tValidation Loss: 5.150633\n",
      "Validation loss decreased (5.26465 --> 5.15063).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.652931 \tValidation Loss: 5.036242\n",
      "Validation loss decreased (5.15063 --> 5.03624).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.392756 \tValidation Loss: 4.875072\n",
      "Validation loss decreased (5.03624 --> 4.87507).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.035517 \tValidation Loss: 4.691071\n",
      "Validation loss decreased (4.87507 --> 4.69107).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.606293 \tValidation Loss: 4.508905\n",
      "Validation loss decreased (4.69107 --> 4.50890).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.144905 \tValidation Loss: 4.343117\n",
      "Validation loss decreased (4.50890 --> 4.34312).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.680369 \tValidation Loss: 4.200686\n",
      "Validation loss decreased (4.34312 --> 4.20069).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.246361 \tValidation Loss: 4.085937\n",
      "Validation loss decreased (4.20069 --> 4.08594).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.862856 \tValidation Loss: 3.999916\n",
      "Validation loss decreased (4.08594 --> 3.99992).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.530484 \tValidation Loss: 3.939902\n",
      "Validation loss decreased (3.99992 --> 3.93990).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.252918 \tValidation Loss: 3.901949\n",
      "Validation loss decreased (3.93990 --> 3.90195).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.025193 \tValidation Loss: 3.882507\n",
      "Validation loss decreased (3.90195 --> 3.88251).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 \tTraining Loss: 1.838676 \tValidation Loss: 3.878027\n",
      "Validation loss decreased (3.88251 --> 3.87803).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.687105 \tValidation Loss: 3.884712\n",
      "Epoch: 16 \tTraining Loss: 1.564241 \tValidation Loss: 3.898528\n",
      "Epoch: 17 \tTraining Loss: 1.463798 \tValidation Loss: 3.917621\n",
      "Epoch: 18 \tTraining Loss: 1.378163 \tValidation Loss: 3.941279\n",
      "Epoch: 19 \tTraining Loss: 1.307734 \tValidation Loss: 3.969736\n",
      "Epoch: 20 \tTraining Loss: 1.249341 \tValidation Loss: 3.999980\n",
      "Epoch: 1 \tTraining Loss: 6.445588 \tValidation Loss: 5.269687\n",
      "Validation loss decreased (inf --> 5.26969).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.847068 \tValidation Loss: 5.165260\n",
      "Validation loss decreased (5.26969 --> 5.16526).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.654934 \tValidation Loss: 5.056477\n",
      "Validation loss decreased (5.16526 --> 5.05648).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.393125 \tValidation Loss: 4.904117\n",
      "Validation loss decreased (5.05648 --> 4.90412).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.036696 \tValidation Loss: 4.725133\n",
      "Validation loss decreased (4.90412 --> 4.72513).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.614513 \tValidation Loss: 4.542357\n",
      "Validation loss decreased (4.72513 --> 4.54236).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.156985 \tValidation Loss: 4.372907\n",
      "Validation loss decreased (4.54236 --> 4.37291).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.695122 \tValidation Loss: 4.224492\n",
      "Validation loss decreased (4.37291 --> 4.22449).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.261818 \tValidation Loss: 4.103693\n",
      "Validation loss decreased (4.22449 --> 4.10369).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.873822 \tValidation Loss: 4.012781\n",
      "Validation loss decreased (4.10369 --> 4.01278).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.541374 \tValidation Loss: 3.947736\n",
      "Validation loss decreased (4.01278 --> 3.94774).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.261719 \tValidation Loss: 3.905783\n",
      "Validation loss decreased (3.94774 --> 3.90578).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.029233 \tValidation Loss: 3.881039\n",
      "Validation loss decreased (3.90578 --> 3.88104).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.841857 \tValidation Loss: 3.872423\n",
      "Validation loss decreased (3.88104 --> 3.87242).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.692591 \tValidation Loss: 3.875868\n",
      "Epoch: 16 \tTraining Loss: 1.567917 \tValidation Loss: 3.888825\n",
      "Epoch: 17 \tTraining Loss: 1.464152 \tValidation Loss: 3.908129\n",
      "Epoch: 18 \tTraining Loss: 1.382137 \tValidation Loss: 3.931968\n",
      "Epoch: 19 \tTraining Loss: 1.310290 \tValidation Loss: 3.961859\n",
      "Epoch: 20 \tTraining Loss: 1.252973 \tValidation Loss: 3.995307\n",
      "Epoch: 1 \tTraining Loss: 6.448397 \tValidation Loss: 5.291794\n",
      "Validation loss decreased (inf --> 5.29179).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.845939 \tValidation Loss: 5.182530\n",
      "Validation loss decreased (5.29179 --> 5.18253).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.651983 \tValidation Loss: 5.074375\n",
      "Validation loss decreased (5.18253 --> 5.07437).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.384837 \tValidation Loss: 4.921647\n",
      "Validation loss decreased (5.07437 --> 4.92165).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.026513 \tValidation Loss: 4.742390\n",
      "Validation loss decreased (4.92165 --> 4.74239).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.604277 \tValidation Loss: 4.560441\n",
      "Validation loss decreased (4.74239 --> 4.56044).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.146805 \tValidation Loss: 4.391910\n",
      "Validation loss decreased (4.56044 --> 4.39191).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.685097 \tValidation Loss: 4.247585\n",
      "Validation loss decreased (4.39191 --> 4.24759).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.251158 \tValidation Loss: 4.129877\n",
      "Validation loss decreased (4.24759 --> 4.12988).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.866766 \tValidation Loss: 4.040978\n",
      "Validation loss decreased (4.12988 --> 4.04098).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.533763 \tValidation Loss: 3.980696\n",
      "Validation loss decreased (4.04098 --> 3.98070).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.255756 \tValidation Loss: 3.940489\n",
      "Validation loss decreased (3.98070 --> 3.94049).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.029244 \tValidation Loss: 3.919454\n",
      "Validation loss decreased (3.94049 --> 3.91945).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.841298 \tValidation Loss: 3.913048\n",
      "Validation loss decreased (3.91945 --> 3.91305).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.690789 \tValidation Loss: 3.916777\n",
      "Epoch: 16 \tTraining Loss: 1.566600 \tValidation Loss: 3.929542\n",
      "Epoch: 17 \tTraining Loss: 1.468582 \tValidation Loss: 3.948504\n",
      "Epoch: 18 \tTraining Loss: 1.382299 \tValidation Loss: 3.973441\n",
      "Epoch: 19 \tTraining Loss: 1.311208 \tValidation Loss: 4.001099\n",
      "Epoch: 20 \tTraining Loss: 1.251691 \tValidation Loss: 4.029045\n",
      "Epoch: 1 \tTraining Loss: 6.443570 \tValidation Loss: 5.269868\n",
      "Validation loss decreased (inf --> 5.26987).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.843349 \tValidation Loss: 5.166490\n",
      "Validation loss decreased (5.26987 --> 5.16649).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.650335 \tValidation Loss: 5.055545\n",
      "Validation loss decreased (5.16649 --> 5.05555).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.386281 \tValidation Loss: 4.898754\n",
      "Validation loss decreased (5.05555 --> 4.89875).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.026893 \tValidation Loss: 4.719708\n",
      "Validation loss decreased (4.89875 --> 4.71971).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.602741 \tValidation Loss: 4.544301\n",
      "Validation loss decreased (4.71971 --> 4.54430).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.146479 \tValidation Loss: 4.380549\n",
      "Validation loss decreased (4.54430 --> 4.38055).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.686320 \tValidation Loss: 4.237792\n",
      "Validation loss decreased (4.38055 --> 4.23779).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.258262 \tValidation Loss: 4.121926\n",
      "Validation loss decreased (4.23779 --> 4.12193).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.875148 \tValidation Loss: 4.032827\n",
      "Validation loss decreased (4.12193 --> 4.03283).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.547139 \tValidation Loss: 3.968345\n",
      "Validation loss decreased (4.03283 --> 3.96834).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.271130 \tValidation Loss: 3.924468\n",
      "Validation loss decreased (3.96834 --> 3.92447).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.040979 \tValidation Loss: 3.897975\n",
      "Validation loss decreased (3.92447 --> 3.89798).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.855262 \tValidation Loss: 3.884893\n",
      "Validation loss decreased (3.89798 --> 3.88489).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.705291 \tValidation Loss: 3.884278\n",
      "Validation loss decreased (3.88489 --> 3.88428).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 1.577670 \tValidation Loss: 3.892524\n",
      "Epoch: 17 \tTraining Loss: 1.478872 \tValidation Loss: 3.905071\n",
      "Epoch: 18 \tTraining Loss: 1.392450 \tValidation Loss: 3.924621\n",
      "Epoch: 19 \tTraining Loss: 1.322098 \tValidation Loss: 3.947879\n",
      "Epoch: 20 \tTraining Loss: 1.262120 \tValidation Loss: 3.975734\n",
      "Epoch: 1 \tTraining Loss: 6.445077 \tValidation Loss: 5.293702\n",
      "Validation loss decreased (inf --> 5.29370).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.839293 \tValidation Loss: 5.181434\n",
      "Validation loss decreased (5.29370 --> 5.18143).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.645857 \tValidation Loss: 5.064135\n",
      "Validation loss decreased (5.18143 --> 5.06413).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.380844 \tValidation Loss: 4.902381\n",
      "Validation loss decreased (5.06413 --> 4.90238).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.020857 \tValidation Loss: 4.717263\n",
      "Validation loss decreased (4.90238 --> 4.71726).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.597702 \tValidation Loss: 4.535784\n",
      "Validation loss decreased (4.71726 --> 4.53578).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.144047 \tValidation Loss: 4.371616\n",
      "Validation loss decreased (4.53578 --> 4.37162).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.685769 \tValidation Loss: 4.230855\n",
      "Validation loss decreased (4.37162 --> 4.23086).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.256911 \tValidation Loss: 4.116390\n",
      "Validation loss decreased (4.23086 --> 4.11639).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 \tTraining Loss: 2.873787 \tValidation Loss: 4.029783\n",
      "Validation loss decreased (4.11639 --> 4.02978).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.543343 \tValidation Loss: 3.967442\n",
      "Validation loss decreased (4.02978 --> 3.96744).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.268788 \tValidation Loss: 3.926887\n",
      "Validation loss decreased (3.96744 --> 3.92689).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.036691 \tValidation Loss: 3.904898\n",
      "Validation loss decreased (3.92689 --> 3.90490).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.849844 \tValidation Loss: 3.896637\n",
      "Validation loss decreased (3.90490 --> 3.89664).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.698958 \tValidation Loss: 3.898015\n",
      "Epoch: 16 \tTraining Loss: 1.571944 \tValidation Loss: 3.908695\n",
      "Epoch: 17 \tTraining Loss: 1.472975 \tValidation Loss: 3.926372\n",
      "Epoch: 18 \tTraining Loss: 1.386191 \tValidation Loss: 3.950348\n",
      "Epoch: 19 \tTraining Loss: 1.318562 \tValidation Loss: 3.978226\n",
      "Epoch: 20 \tTraining Loss: 1.258217 \tValidation Loss: 4.008469\n",
      "Epoch: 1 \tTraining Loss: 6.452537 \tValidation Loss: 5.265556\n",
      "Validation loss decreased (inf --> 5.26556).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.840107 \tValidation Loss: 5.149189\n",
      "Validation loss decreased (5.26556 --> 5.14919).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.645688 \tValidation Loss: 5.026863\n",
      "Validation loss decreased (5.14919 --> 5.02686).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.381720 \tValidation Loss: 4.856081\n",
      "Validation loss decreased (5.02686 --> 4.85608).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.024452 \tValidation Loss: 4.661099\n",
      "Validation loss decreased (4.85608 --> 4.66110).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.599059 \tValidation Loss: 4.468166\n",
      "Validation loss decreased (4.66110 --> 4.46817).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.141861 \tValidation Loss: 4.289970\n",
      "Validation loss decreased (4.46817 --> 4.28997).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.679768 \tValidation Loss: 4.136281\n",
      "Validation loss decreased (4.28997 --> 4.13628).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.247245 \tValidation Loss: 4.015190\n",
      "Validation loss decreased (4.13628 --> 4.01519).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.863687 \tValidation Loss: 3.924000\n",
      "Validation loss decreased (4.01519 --> 3.92400).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.535645 \tValidation Loss: 3.859275\n",
      "Validation loss decreased (3.92400 --> 3.85928).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.259801 \tValidation Loss: 3.814138\n",
      "Validation loss decreased (3.85928 --> 3.81414).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.035089 \tValidation Loss: 3.786752\n",
      "Validation loss decreased (3.81414 --> 3.78675).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.849123 \tValidation Loss: 3.772877\n",
      "Validation loss decreased (3.78675 --> 3.77288).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.698680 \tValidation Loss: 3.769040\n",
      "Validation loss decreased (3.77288 --> 3.76904).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 1.576865 \tValidation Loss: 3.774401\n",
      "Epoch: 17 \tTraining Loss: 1.473894 \tValidation Loss: 3.784916\n",
      "Epoch: 18 \tTraining Loss: 1.391657 \tValidation Loss: 3.802289\n",
      "Epoch: 19 \tTraining Loss: 1.321278 \tValidation Loss: 3.821888\n",
      "Epoch: 20 \tTraining Loss: 1.261460 \tValidation Loss: 3.845209\n",
      "Epoch: 1 \tTraining Loss: 6.441140 \tValidation Loss: 5.286548\n",
      "Validation loss decreased (inf --> 5.28655).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.843614 \tValidation Loss: 5.185969\n",
      "Validation loss decreased (5.28655 --> 5.18597).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.654495 \tValidation Loss: 5.078647\n",
      "Validation loss decreased (5.18597 --> 5.07865).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.395113 \tValidation Loss: 4.923858\n",
      "Validation loss decreased (5.07865 --> 4.92386).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.041066 \tValidation Loss: 4.740151\n",
      "Validation loss decreased (4.92386 --> 4.74015).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.615227 \tValidation Loss: 4.556104\n",
      "Validation loss decreased (4.74015 --> 4.55610).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.156198 \tValidation Loss: 4.388246\n",
      "Validation loss decreased (4.55610 --> 4.38825).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.693748 \tValidation Loss: 4.240289\n",
      "Validation loss decreased (4.38825 --> 4.24029).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.262539 \tValidation Loss: 4.118944\n",
      "Validation loss decreased (4.24029 --> 4.11894).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.875322 \tValidation Loss: 4.024833\n",
      "Validation loss decreased (4.11894 --> 4.02483).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.546339 \tValidation Loss: 3.957642\n",
      "Validation loss decreased (4.02483 --> 3.95764).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.264412 \tValidation Loss: 3.913982\n",
      "Validation loss decreased (3.95764 --> 3.91398).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.035649 \tValidation Loss: 3.888549\n",
      "Validation loss decreased (3.91398 --> 3.88855).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.848683 \tValidation Loss: 3.877342\n",
      "Validation loss decreased (3.88855 --> 3.87734).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.697244 \tValidation Loss: 3.876998\n",
      "Validation loss decreased (3.87734 --> 3.87700).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 1.569777 \tValidation Loss: 3.886064\n",
      "Epoch: 17 \tTraining Loss: 1.469796 \tValidation Loss: 3.899286\n",
      "Epoch: 18 \tTraining Loss: 1.386069 \tValidation Loss: 3.917816\n",
      "Epoch: 19 \tTraining Loss: 1.316481 \tValidation Loss: 3.940484\n",
      "Epoch: 20 \tTraining Loss: 1.254750 \tValidation Loss: 3.966016\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 4 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.420540 \tValidation Loss: 5.068248\n",
      "Validation loss decreased (inf --> 5.06825).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.779147 \tValidation Loss: 4.897454\n",
      "Validation loss decreased (5.06825 --> 4.89745).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.450545 \tValidation Loss: 4.668592\n",
      "Validation loss decreased (4.89745 --> 4.66859).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.977062 \tValidation Loss: 4.383552\n",
      "Validation loss decreased (4.66859 --> 4.38355).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.390767 \tValidation Loss: 4.084823\n",
      "Validation loss decreased (4.38355 --> 4.08482).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.758030 \tValidation Loss: 3.798242\n",
      "Validation loss decreased (4.08482 --> 3.79824).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.148057 \tValidation Loss: 3.546982\n",
      "Validation loss decreased (3.79824 --> 3.54698).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.610147 \tValidation Loss: 3.342459\n",
      "Validation loss decreased (3.54698 --> 3.34246).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.164617 \tValidation Loss: 3.182086\n",
      "Validation loss decreased (3.34246 --> 3.18209).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.813654 \tValidation Loss: 3.060062\n",
      "Validation loss decreased (3.18209 --> 3.06006).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.535536 \tValidation Loss: 2.970236\n",
      "Validation loss decreased (3.06006 --> 2.97024).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.321132 \tValidation Loss: 2.903715\n",
      "Validation loss decreased (2.97024 --> 2.90372).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.150586 \tValidation Loss: 2.858146\n",
      "Validation loss decreased (2.90372 --> 2.85815).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.019038 \tValidation Loss: 2.827493\n",
      "Validation loss decreased (2.85815 --> 2.82749).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.911633 \tValidation Loss: 2.808959\n",
      "Validation loss decreased (2.82749 --> 2.80896).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.824348 \tValidation Loss: 2.799910\n",
      "Validation loss decreased (2.80896 --> 2.79991).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.752460 \tValidation Loss: 2.798237\n",
      "Validation loss decreased (2.79991 --> 2.79824).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.693017 \tValidation Loss: 2.802253\n",
      "Epoch: 19 \tTraining Loss: 0.645188 \tValidation Loss: 2.812397\n",
      "Epoch: 20 \tTraining Loss: 0.601245 \tValidation Loss: 2.826596\n",
      "Epoch: 1 \tTraining Loss: 6.424587 \tValidation Loss: 5.037802\n",
      "Validation loss decreased (inf --> 5.03780).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.769967 \tValidation Loss: 4.875932\n",
      "Validation loss decreased (5.03780 --> 4.87593).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.442808 \tValidation Loss: 4.655314\n",
      "Validation loss decreased (4.87593 --> 4.65531).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 \tTraining Loss: 4.973702 \tValidation Loss: 4.371941\n",
      "Validation loss decreased (4.65531 --> 4.37194).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.388835 \tValidation Loss: 4.077193\n",
      "Validation loss decreased (4.37194 --> 4.07719).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.761088 \tValidation Loss: 3.801445\n",
      "Validation loss decreased (4.07719 --> 3.80145).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.155813 \tValidation Loss: 3.564599\n",
      "Validation loss decreased (3.80145 --> 3.56460).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.619701 \tValidation Loss: 3.374505\n",
      "Validation loss decreased (3.56460 --> 3.37450).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.180665 \tValidation Loss: 3.227003\n",
      "Validation loss decreased (3.37450 --> 3.22700).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.824287 \tValidation Loss: 3.116391\n",
      "Validation loss decreased (3.22700 --> 3.11639).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.546304 \tValidation Loss: 3.036792\n",
      "Validation loss decreased (3.11639 --> 3.03679).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.331376 \tValidation Loss: 2.980946\n",
      "Validation loss decreased (3.03679 --> 2.98095).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.162532 \tValidation Loss: 2.944149\n",
      "Validation loss decreased (2.98095 --> 2.94415).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.027242 \tValidation Loss: 2.922834\n",
      "Validation loss decreased (2.94415 --> 2.92283).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.921704 \tValidation Loss: 2.913894\n",
      "Validation loss decreased (2.92283 --> 2.91389).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.834843 \tValidation Loss: 2.913925\n",
      "Epoch: 17 \tTraining Loss: 0.763282 \tValidation Loss: 2.920977\n",
      "Epoch: 18 \tTraining Loss: 0.703326 \tValidation Loss: 2.935047\n",
      "Epoch: 19 \tTraining Loss: 0.657644 \tValidation Loss: 2.950243\n",
      "Epoch: 20 \tTraining Loss: 0.612554 \tValidation Loss: 2.971846\n",
      "Epoch: 1 \tTraining Loss: 6.420745 \tValidation Loss: 5.066318\n",
      "Validation loss decreased (inf --> 5.06632).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.772642 \tValidation Loss: 4.906937\n",
      "Validation loss decreased (5.06632 --> 4.90694).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.446142 \tValidation Loss: 4.688149\n",
      "Validation loss decreased (4.90694 --> 4.68815).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.977872 \tValidation Loss: 4.407823\n",
      "Validation loss decreased (4.68815 --> 4.40782).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.393510 \tValidation Loss: 4.115684\n",
      "Validation loss decreased (4.40782 --> 4.11568).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.761797 \tValidation Loss: 3.837543\n",
      "Validation loss decreased (4.11568 --> 3.83754).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.152307 \tValidation Loss: 3.592951\n",
      "Validation loss decreased (3.83754 --> 3.59295).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.613171 \tValidation Loss: 3.392556\n",
      "Validation loss decreased (3.59295 --> 3.39256).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.167741 \tValidation Loss: 3.235307\n",
      "Validation loss decreased (3.39256 --> 3.23531).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.811247 \tValidation Loss: 3.116784\n",
      "Validation loss decreased (3.23531 --> 3.11678).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.532903 \tValidation Loss: 3.031083\n",
      "Validation loss decreased (3.11678 --> 3.03108).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.318849 \tValidation Loss: 2.970791\n",
      "Validation loss decreased (3.03108 --> 2.97079).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.149426 \tValidation Loss: 2.928308\n",
      "Validation loss decreased (2.97079 --> 2.92831).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.013597 \tValidation Loss: 2.903605\n",
      "Validation loss decreased (2.92831 --> 2.90361).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.903771 \tValidation Loss: 2.889615\n",
      "Validation loss decreased (2.90361 --> 2.88961).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.821870 \tValidation Loss: 2.886541\n",
      "Validation loss decreased (2.88961 --> 2.88654).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.748927 \tValidation Loss: 2.892333\n",
      "Epoch: 18 \tTraining Loss: 0.690969 \tValidation Loss: 2.900736\n",
      "Epoch: 19 \tTraining Loss: 0.641435 \tValidation Loss: 2.914688\n",
      "Epoch: 20 \tTraining Loss: 0.600943 \tValidation Loss: 2.936761\n",
      "Epoch: 1 \tTraining Loss: 6.414201 \tValidation Loss: 5.058090\n",
      "Validation loss decreased (inf --> 5.05809).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.769545 \tValidation Loss: 4.917223\n",
      "Validation loss decreased (5.05809 --> 4.91722).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.441110 \tValidation Loss: 4.713079\n",
      "Validation loss decreased (4.91722 --> 4.71308).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.970924 \tValidation Loss: 4.443863\n",
      "Validation loss decreased (4.71308 --> 4.44386).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.385670 \tValidation Loss: 4.151459\n",
      "Validation loss decreased (4.44386 --> 4.15146).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.753522 \tValidation Loss: 3.873344\n",
      "Validation loss decreased (4.15146 --> 3.87334).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.142516 \tValidation Loss: 3.631388\n",
      "Validation loss decreased (3.87334 --> 3.63139).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.602959 \tValidation Loss: 3.436426\n",
      "Validation loss decreased (3.63139 --> 3.43643).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.159458 \tValidation Loss: 3.287226\n",
      "Validation loss decreased (3.43643 --> 3.28723).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.807543 \tValidation Loss: 3.173961\n",
      "Validation loss decreased (3.28723 --> 3.17396).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.535665 \tValidation Loss: 3.089186\n",
      "Validation loss decreased (3.17396 --> 3.08919).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.319349 \tValidation Loss: 3.028368\n",
      "Validation loss decreased (3.08919 --> 3.02837).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.150680 \tValidation Loss: 2.985279\n",
      "Validation loss decreased (3.02837 --> 2.98528).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.019982 \tValidation Loss: 2.960215\n",
      "Validation loss decreased (2.98528 --> 2.96021).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.910116 \tValidation Loss: 2.945785\n",
      "Validation loss decreased (2.96021 --> 2.94578).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.827286 \tValidation Loss: 2.940628\n",
      "Validation loss decreased (2.94578 --> 2.94063).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.752490 \tValidation Loss: 2.945876\n",
      "Epoch: 18 \tTraining Loss: 0.695825 \tValidation Loss: 2.957537\n",
      "Epoch: 19 \tTraining Loss: 0.646105 \tValidation Loss: 2.971615\n",
      "Epoch: 20 \tTraining Loss: 0.602291 \tValidation Loss: 2.991456\n",
      "Epoch: 1 \tTraining Loss: 6.423293 \tValidation Loss: 5.039284\n",
      "Validation loss decreased (inf --> 5.03928).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.776292 \tValidation Loss: 4.883868\n",
      "Validation loss decreased (5.03928 --> 4.88387).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.446809 \tValidation Loss: 4.664831\n",
      "Validation loss decreased (4.88387 --> 4.66483).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.975300 \tValidation Loss: 4.388983\n",
      "Validation loss decreased (4.66483 --> 4.38898).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.385928 \tValidation Loss: 4.101572\n",
      "Validation loss decreased (4.38898 --> 4.10157).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.752501 \tValidation Loss: 3.829875\n",
      "Validation loss decreased (4.10157 --> 3.82988).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.148867 \tValidation Loss: 3.589512\n",
      "Validation loss decreased (3.82988 --> 3.58951).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.611189 \tValidation Loss: 3.391821\n",
      "Validation loss decreased (3.58951 --> 3.39182).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.168735 \tValidation Loss: 3.237875\n",
      "Validation loss decreased (3.39182 --> 3.23787).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.814258 \tValidation Loss: 3.121950\n",
      "Validation loss decreased (3.23787 --> 3.12195).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.536301 \tValidation Loss: 3.037196\n",
      "Validation loss decreased (3.12195 --> 3.03720).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.321041 \tValidation Loss: 2.976874\n",
      "Validation loss decreased (3.03720 --> 2.97687).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.151897 \tValidation Loss: 2.935267\n",
      "Validation loss decreased (2.97687 --> 2.93527).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.020786 \tValidation Loss: 2.908838\n",
      "Validation loss decreased (2.93527 --> 2.90884).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 \tTraining Loss: 0.911894 \tValidation Loss: 2.894554\n",
      "Validation loss decreased (2.90884 --> 2.89455).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.823913 \tValidation Loss: 2.889777\n",
      "Validation loss decreased (2.89455 --> 2.88978).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.758705 \tValidation Loss: 2.891303\n",
      "Epoch: 18 \tTraining Loss: 0.696156 \tValidation Loss: 2.899735\n",
      "Epoch: 19 \tTraining Loss: 0.644134 \tValidation Loss: 2.913717\n",
      "Epoch: 20 \tTraining Loss: 0.607707 \tValidation Loss: 2.930686\n",
      "Epoch: 1 \tTraining Loss: 6.425081 \tValidation Loss: 5.039090\n",
      "Validation loss decreased (inf --> 5.03909).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.772487 \tValidation Loss: 4.893992\n",
      "Validation loss decreased (5.03909 --> 4.89399).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.445103 \tValidation Loss: 4.680194\n",
      "Validation loss decreased (4.89399 --> 4.68019).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.976732 \tValidation Loss: 4.403187\n",
      "Validation loss decreased (4.68019 --> 4.40319).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.397693 \tValidation Loss: 4.111926\n",
      "Validation loss decreased (4.40319 --> 4.11193).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.771337 \tValidation Loss: 3.830262\n",
      "Validation loss decreased (4.11193 --> 3.83026).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.165471 \tValidation Loss: 3.578174\n",
      "Validation loss decreased (3.83026 --> 3.57817).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.625195 \tValidation Loss: 3.373399\n",
      "Validation loss decreased (3.57817 --> 3.37340).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.176518 \tValidation Loss: 3.216080\n",
      "Validation loss decreased (3.37340 --> 3.21608).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.820565 \tValidation Loss: 3.097097\n",
      "Validation loss decreased (3.21608 --> 3.09710).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.538933 \tValidation Loss: 3.011247\n",
      "Validation loss decreased (3.09710 --> 3.01125).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.326337 \tValidation Loss: 2.950867\n",
      "Validation loss decreased (3.01125 --> 2.95087).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.155214 \tValidation Loss: 2.909945\n",
      "Validation loss decreased (2.95087 --> 2.90994).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.023213 \tValidation Loss: 2.883979\n",
      "Validation loss decreased (2.90994 --> 2.88398).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.914426 \tValidation Loss: 2.868995\n",
      "Validation loss decreased (2.88398 --> 2.86900).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.827057 \tValidation Loss: 2.864420\n",
      "Validation loss decreased (2.86900 --> 2.86442).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.755000 \tValidation Loss: 2.868582\n",
      "Epoch: 18 \tTraining Loss: 0.699583 \tValidation Loss: 2.877803\n",
      "Epoch: 19 \tTraining Loss: 0.649322 \tValidation Loss: 2.890831\n",
      "Epoch: 20 \tTraining Loss: 0.606647 \tValidation Loss: 2.904434\n",
      "Epoch: 1 \tTraining Loss: 6.419574 \tValidation Loss: 5.029404\n",
      "Validation loss decreased (inf --> 5.02940).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.774727 \tValidation Loss: 4.867738\n",
      "Validation loss decreased (5.02940 --> 4.86774).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.444612 \tValidation Loss: 4.638172\n",
      "Validation loss decreased (4.86774 --> 4.63817).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.973809 \tValidation Loss: 4.347455\n",
      "Validation loss decreased (4.63817 --> 4.34745).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.383697 \tValidation Loss: 4.045945\n",
      "Validation loss decreased (4.34745 --> 4.04594).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.745186 \tValidation Loss: 3.767571\n",
      "Validation loss decreased (4.04594 --> 3.76757).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.131655 \tValidation Loss: 3.530368\n",
      "Validation loss decreased (3.76757 --> 3.53037).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.597278 \tValidation Loss: 3.341912\n",
      "Validation loss decreased (3.53037 --> 3.34191).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.156128 \tValidation Loss: 3.197907\n",
      "Validation loss decreased (3.34191 --> 3.19791).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.805271 \tValidation Loss: 3.090136\n",
      "Validation loss decreased (3.19791 --> 3.09014).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.529504 \tValidation Loss: 3.010401\n",
      "Validation loss decreased (3.09014 --> 3.01040).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.316181 \tValidation Loss: 2.955153\n",
      "Validation loss decreased (3.01040 --> 2.95515).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.148071 \tValidation Loss: 2.919945\n",
      "Validation loss decreased (2.95515 --> 2.91995).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.017363 \tValidation Loss: 2.897986\n",
      "Validation loss decreased (2.91995 --> 2.89799).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.912505 \tValidation Loss: 2.888122\n",
      "Validation loss decreased (2.89799 --> 2.88812).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.824623 \tValidation Loss: 2.888061\n",
      "Validation loss decreased (2.88812 --> 2.88806).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.754530 \tValidation Loss: 2.896040\n",
      "Epoch: 18 \tTraining Loss: 0.696108 \tValidation Loss: 2.910581\n",
      "Epoch: 19 \tTraining Loss: 0.648799 \tValidation Loss: 2.928339\n",
      "Epoch: 20 \tTraining Loss: 0.610065 \tValidation Loss: 2.946839\n",
      "Epoch: 1 \tTraining Loss: 6.427676 \tValidation Loss: 5.028990\n",
      "Validation loss decreased (inf --> 5.02899).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.783021 \tValidation Loss: 4.870311\n",
      "Validation loss decreased (5.02899 --> 4.87031).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.457856 \tValidation Loss: 4.650025\n",
      "Validation loss decreased (4.87031 --> 4.65003).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.987019 \tValidation Loss: 4.371174\n",
      "Validation loss decreased (4.65003 --> 4.37117).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.398863 \tValidation Loss: 4.073681\n",
      "Validation loss decreased (4.37117 --> 4.07368).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.765149 \tValidation Loss: 3.789173\n",
      "Validation loss decreased (4.07368 --> 3.78917).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.152582 \tValidation Loss: 3.542309\n",
      "Validation loss decreased (3.78917 --> 3.54231).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.612890 \tValidation Loss: 3.341896\n",
      "Validation loss decreased (3.54231 --> 3.34190).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.166335 \tValidation Loss: 3.186971\n",
      "Validation loss decreased (3.34190 --> 3.18697).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.810088 \tValidation Loss: 3.070258\n",
      "Validation loss decreased (3.18697 --> 3.07026).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.534275 \tValidation Loss: 2.983561\n",
      "Validation loss decreased (3.07026 --> 2.98356).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.319644 \tValidation Loss: 2.923058\n",
      "Validation loss decreased (2.98356 --> 2.92306).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.151242 \tValidation Loss: 2.881215\n",
      "Validation loss decreased (2.92306 --> 2.88122).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.018115 \tValidation Loss: 2.854546\n",
      "Validation loss decreased (2.88122 --> 2.85455).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.912666 \tValidation Loss: 2.838965\n",
      "Validation loss decreased (2.85455 --> 2.83896).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.827659 \tValidation Loss: 2.833300\n",
      "Validation loss decreased (2.83896 --> 2.83330).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.755728 \tValidation Loss: 2.834797\n",
      "Epoch: 18 \tTraining Loss: 0.698718 \tValidation Loss: 2.843694\n",
      "Epoch: 19 \tTraining Loss: 0.648760 \tValidation Loss: 2.853669\n",
      "Epoch: 20 \tTraining Loss: 0.607069 \tValidation Loss: 2.869760\n",
      "Epoch: 1 \tTraining Loss: 6.422154 \tValidation Loss: 5.037333\n",
      "Validation loss decreased (inf --> 5.03733).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.777270 \tValidation Loss: 4.879827\n",
      "Validation loss decreased (5.03733 --> 4.87983).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.448160 \tValidation Loss: 4.663648\n",
      "Validation loss decreased (4.87983 --> 4.66365).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.978883 \tValidation Loss: 4.385964\n",
      "Validation loss decreased (4.66365 --> 4.38596).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.399257 \tValidation Loss: 4.088106\n",
      "Validation loss decreased (4.38596 --> 4.08811).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.769610 \tValidation Loss: 3.803261\n",
      "Validation loss decreased (4.08811 --> 3.80326).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.151765 \tValidation Loss: 3.556676\n",
      "Validation loss decreased (3.80326 --> 3.55668).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 \tTraining Loss: 2.609166 \tValidation Loss: 3.358015\n",
      "Validation loss decreased (3.55668 --> 3.35802).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.159240 \tValidation Loss: 3.205641\n",
      "Validation loss decreased (3.35802 --> 3.20564).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.802886 \tValidation Loss: 3.092874\n",
      "Validation loss decreased (3.20564 --> 3.09287).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.524324 \tValidation Loss: 3.012784\n",
      "Validation loss decreased (3.09287 --> 3.01278).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.309410 \tValidation Loss: 2.954679\n",
      "Validation loss decreased (3.01278 --> 2.95468).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.136570 \tValidation Loss: 2.918747\n",
      "Validation loss decreased (2.95468 --> 2.91875).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.008025 \tValidation Loss: 2.897926\n",
      "Validation loss decreased (2.91875 --> 2.89793).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.902717 \tValidation Loss: 2.886384\n",
      "Validation loss decreased (2.89793 --> 2.88638).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.817575 \tValidation Loss: 2.885654\n",
      "Validation loss decreased (2.88638 --> 2.88565).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.747761 \tValidation Loss: 2.892039\n",
      "Epoch: 18 \tTraining Loss: 0.690955 \tValidation Loss: 2.904262\n",
      "Epoch: 19 \tTraining Loss: 0.643004 \tValidation Loss: 2.921254\n",
      "Epoch: 20 \tTraining Loss: 0.599209 \tValidation Loss: 2.941973\n",
      "Epoch: 1 \tTraining Loss: 6.414346 \tValidation Loss: 5.064986\n",
      "Validation loss decreased (inf --> 5.06499).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.776483 \tValidation Loss: 4.908189\n",
      "Validation loss decreased (5.06499 --> 4.90819).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.451617 \tValidation Loss: 4.690404\n",
      "Validation loss decreased (4.90819 --> 4.69040).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.983788 \tValidation Loss: 4.409370\n",
      "Validation loss decreased (4.69040 --> 4.40937).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.397908 \tValidation Loss: 4.114997\n",
      "Validation loss decreased (4.40937 --> 4.11500).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.764729 \tValidation Loss: 3.838487\n",
      "Validation loss decreased (4.11500 --> 3.83849).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.153989 \tValidation Loss: 3.598667\n",
      "Validation loss decreased (3.83849 --> 3.59867).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.609792 \tValidation Loss: 3.404124\n",
      "Validation loss decreased (3.59867 --> 3.40412).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.160812 \tValidation Loss: 3.253041\n",
      "Validation loss decreased (3.40412 --> 3.25304).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.805273 \tValidation Loss: 3.141116\n",
      "Validation loss decreased (3.25304 --> 3.14112).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.526910 \tValidation Loss: 3.059239\n",
      "Validation loss decreased (3.14112 --> 3.05924).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.312905 \tValidation Loss: 3.000986\n",
      "Validation loss decreased (3.05924 --> 3.00099).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.146151 \tValidation Loss: 2.963063\n",
      "Validation loss decreased (3.00099 --> 2.96306).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.015133 \tValidation Loss: 2.941329\n",
      "Validation loss decreased (2.96306 --> 2.94133).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.909081 \tValidation Loss: 2.931135\n",
      "Validation loss decreased (2.94133 --> 2.93113).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.824538 \tValidation Loss: 2.930982\n",
      "Validation loss decreased (2.93113 --> 2.93098).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.754729 \tValidation Loss: 2.936780\n",
      "Epoch: 18 \tTraining Loss: 0.693806 \tValidation Loss: 2.948421\n",
      "Epoch: 19 \tTraining Loss: 0.649027 \tValidation Loss: 2.966949\n",
      "Epoch: 20 \tTraining Loss: 0.607875 \tValidation Loss: 2.988067\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 5 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.399240 \tValidation Loss: 5.224075\n",
      "Validation loss decreased (inf --> 5.22408).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.703784 \tValidation Loss: 5.003493\n",
      "Validation loss decreased (5.22408 --> 5.00349).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.265255 \tValidation Loss: 4.686043\n",
      "Validation loss decreased (5.00349 --> 4.68604).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.645867 \tValidation Loss: 4.291551\n",
      "Validation loss decreased (4.68604 --> 4.29155).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.913926 \tValidation Loss: 3.884941\n",
      "Validation loss decreased (4.29155 --> 3.88494).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.175662 \tValidation Loss: 3.522787\n",
      "Validation loss decreased (3.88494 --> 3.52279).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.522681 \tValidation Loss: 3.227607\n",
      "Validation loss decreased (3.52279 --> 3.22761).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.995362 \tValidation Loss: 2.994644\n",
      "Validation loss decreased (3.22761 --> 2.99464).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.590831 \tValidation Loss: 2.816924\n",
      "Validation loss decreased (2.99464 --> 2.81692).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.286787 \tValidation Loss: 2.683673\n",
      "Validation loss decreased (2.81692 --> 2.68367).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.059736 \tValidation Loss: 2.584752\n",
      "Validation loss decreased (2.68367 --> 2.58475).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.886557 \tValidation Loss: 2.514640\n",
      "Validation loss decreased (2.58475 --> 2.51464).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.751796 \tValidation Loss: 2.467421\n",
      "Validation loss decreased (2.51464 --> 2.46742).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.645766 \tValidation Loss: 2.437049\n",
      "Validation loss decreased (2.46742 --> 2.43705).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.561302 \tValidation Loss: 2.420255\n",
      "Validation loss decreased (2.43705 --> 2.42025).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.499259 \tValidation Loss: 2.413890\n",
      "Validation loss decreased (2.42025 --> 2.41389).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.446067 \tValidation Loss: 2.413344\n",
      "Validation loss decreased (2.41389 --> 2.41334).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.403149 \tValidation Loss: 2.420247\n",
      "Epoch: 19 \tTraining Loss: 0.366782 \tValidation Loss: 2.433384\n",
      "Epoch: 20 \tTraining Loss: 0.339257 \tValidation Loss: 2.445410\n",
      "Epoch: 1 \tTraining Loss: 6.413554 \tValidation Loss: 5.198801\n",
      "Validation loss decreased (inf --> 5.19880).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.709762 \tValidation Loss: 4.968884\n",
      "Validation loss decreased (5.19880 --> 4.96888).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.269481 \tValidation Loss: 4.643642\n",
      "Validation loss decreased (4.96888 --> 4.64364).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.658873 \tValidation Loss: 4.248995\n",
      "Validation loss decreased (4.64364 --> 4.24899).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.934600 \tValidation Loss: 3.850224\n",
      "Validation loss decreased (4.24899 --> 3.85022).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.196622 \tValidation Loss: 3.493108\n",
      "Validation loss decreased (3.85022 --> 3.49311).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.540482 \tValidation Loss: 3.199950\n",
      "Validation loss decreased (3.49311 --> 3.19995).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.009998 \tValidation Loss: 2.970916\n",
      "Validation loss decreased (3.19995 --> 2.97092).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.601484 \tValidation Loss: 2.798443\n",
      "Validation loss decreased (2.97092 --> 2.79844).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.297576 \tValidation Loss: 2.668555\n",
      "Validation loss decreased (2.79844 --> 2.66856).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.064951 \tValidation Loss: 2.573799\n",
      "Validation loss decreased (2.66856 --> 2.57380).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.890902 \tValidation Loss: 2.504838\n",
      "Validation loss decreased (2.57380 --> 2.50484).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.756207 \tValidation Loss: 2.456441\n",
      "Validation loss decreased (2.50484 --> 2.45644).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.650622 \tValidation Loss: 2.426619\n",
      "Validation loss decreased (2.45644 --> 2.42662).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.568966 \tValidation Loss: 2.407661\n",
      "Validation loss decreased (2.42662 --> 2.40766).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.499701 \tValidation Loss: 2.398885\n",
      "Validation loss decreased (2.40766 --> 2.39888).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.447948 \tValidation Loss: 2.397412\n",
      "Validation loss decreased (2.39888 --> 2.39741).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 \tTraining Loss: 0.404219 \tValidation Loss: 2.401777\n",
      "Epoch: 19 \tTraining Loss: 0.371802 \tValidation Loss: 2.408976\n",
      "Epoch: 20 \tTraining Loss: 0.338461 \tValidation Loss: 2.422838\n",
      "Epoch: 1 \tTraining Loss: 6.411038 \tValidation Loss: 5.221544\n",
      "Validation loss decreased (inf --> 5.22154).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.698214 \tValidation Loss: 5.000460\n",
      "Validation loss decreased (5.22154 --> 5.00046).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.251827 \tValidation Loss: 4.678883\n",
      "Validation loss decreased (5.00046 --> 4.67888).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.633882 \tValidation Loss: 4.280340\n",
      "Validation loss decreased (4.67888 --> 4.28034).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.908574 \tValidation Loss: 3.865809\n",
      "Validation loss decreased (4.28034 --> 3.86581).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.179275 \tValidation Loss: 3.494167\n",
      "Validation loss decreased (3.86581 --> 3.49417).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.529831 \tValidation Loss: 3.188182\n",
      "Validation loss decreased (3.49417 --> 3.18818).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.004510 \tValidation Loss: 2.948340\n",
      "Validation loss decreased (3.18818 --> 2.94834).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.599488 \tValidation Loss: 2.770142\n",
      "Validation loss decreased (2.94834 --> 2.77014).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.295059 \tValidation Loss: 2.641301\n",
      "Validation loss decreased (2.77014 --> 2.64130).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.064549 \tValidation Loss: 2.549228\n",
      "Validation loss decreased (2.64130 --> 2.54923).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.889084 \tValidation Loss: 2.484570\n",
      "Validation loss decreased (2.54923 --> 2.48457).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.755587 \tValidation Loss: 2.441597\n",
      "Validation loss decreased (2.48457 --> 2.44160).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.649514 \tValidation Loss: 2.413395\n",
      "Validation loss decreased (2.44160 --> 2.41339).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.566667 \tValidation Loss: 2.399103\n",
      "Validation loss decreased (2.41339 --> 2.39910).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.499880 \tValidation Loss: 2.392494\n",
      "Validation loss decreased (2.39910 --> 2.39249).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.447021 \tValidation Loss: 2.392101\n",
      "Validation loss decreased (2.39249 --> 2.39210).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.404013 \tValidation Loss: 2.400242\n",
      "Epoch: 19 \tTraining Loss: 0.369452 \tValidation Loss: 2.411123\n",
      "Epoch: 20 \tTraining Loss: 0.339692 \tValidation Loss: 2.425985\n",
      "Epoch: 1 \tTraining Loss: 6.399779 \tValidation Loss: 5.192128\n",
      "Validation loss decreased (inf --> 5.19213).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.700756 \tValidation Loss: 4.966511\n",
      "Validation loss decreased (5.19213 --> 4.96651).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.255744 \tValidation Loss: 4.640310\n",
      "Validation loss decreased (4.96651 --> 4.64031).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.633661 \tValidation Loss: 4.248217\n",
      "Validation loss decreased (4.64031 --> 4.24822).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.908775 \tValidation Loss: 3.859575\n",
      "Validation loss decreased (4.24822 --> 3.85958).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.173659 \tValidation Loss: 3.515214\n",
      "Validation loss decreased (3.85958 --> 3.51521).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.518860 \tValidation Loss: 3.238321\n",
      "Validation loss decreased (3.51521 --> 3.23832).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.989602 \tValidation Loss: 3.025642\n",
      "Validation loss decreased (3.23832 --> 3.02564).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.588328 \tValidation Loss: 2.866045\n",
      "Validation loss decreased (3.02564 --> 2.86604).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.283591 \tValidation Loss: 2.749561\n",
      "Validation loss decreased (2.86604 --> 2.74956).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.055616 \tValidation Loss: 2.664349\n",
      "Validation loss decreased (2.74956 --> 2.66435).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.885115 \tValidation Loss: 2.605745\n",
      "Validation loss decreased (2.66435 --> 2.60575).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.752253 \tValidation Loss: 2.568134\n",
      "Validation loss decreased (2.60575 --> 2.56813).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.646991 \tValidation Loss: 2.543506\n",
      "Validation loss decreased (2.56813 --> 2.54351).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.563235 \tValidation Loss: 2.528298\n",
      "Validation loss decreased (2.54351 --> 2.52830).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.498430 \tValidation Loss: 2.521246\n",
      "Validation loss decreased (2.52830 --> 2.52125).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.446201 \tValidation Loss: 2.524950\n",
      "Epoch: 18 \tTraining Loss: 0.402678 \tValidation Loss: 2.534381\n",
      "Epoch: 19 \tTraining Loss: 0.366503 \tValidation Loss: 2.545882\n",
      "Epoch: 20 \tTraining Loss: 0.336716 \tValidation Loss: 2.560527\n",
      "Epoch: 1 \tTraining Loss: 6.406867 \tValidation Loss: 5.202419\n",
      "Validation loss decreased (inf --> 5.20242).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.697500 \tValidation Loss: 4.972824\n",
      "Validation loss decreased (5.20242 --> 4.97282).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.255008 \tValidation Loss: 4.655439\n",
      "Validation loss decreased (4.97282 --> 4.65544).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.640515 \tValidation Loss: 4.262935\n",
      "Validation loss decreased (4.65544 --> 4.26294).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.911811 \tValidation Loss: 3.857716\n",
      "Validation loss decreased (4.26294 --> 3.85772).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.179279 \tValidation Loss: 3.493545\n",
      "Validation loss decreased (3.85772 --> 3.49354).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.523470 \tValidation Loss: 3.195005\n",
      "Validation loss decreased (3.49354 --> 3.19500).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.995290 \tValidation Loss: 2.961744\n",
      "Validation loss decreased (3.19500 --> 2.96174).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.591241 \tValidation Loss: 2.786301\n",
      "Validation loss decreased (2.96174 --> 2.78630).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.287846 \tValidation Loss: 2.654674\n",
      "Validation loss decreased (2.78630 --> 2.65467).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.060165 \tValidation Loss: 2.558185\n",
      "Validation loss decreased (2.65467 --> 2.55818).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.885759 \tValidation Loss: 2.487122\n",
      "Validation loss decreased (2.55818 --> 2.48712).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.752766 \tValidation Loss: 2.436978\n",
      "Validation loss decreased (2.48712 --> 2.43698).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.649937 \tValidation Loss: 2.401455\n",
      "Validation loss decreased (2.43698 --> 2.40145).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.566391 \tValidation Loss: 2.377501\n",
      "Validation loss decreased (2.40145 --> 2.37750).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.501426 \tValidation Loss: 2.363445\n",
      "Validation loss decreased (2.37750 --> 2.36344).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.445709 \tValidation Loss: 2.360466\n",
      "Validation loss decreased (2.36344 --> 2.36047).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.403928 \tValidation Loss: 2.360383\n",
      "Validation loss decreased (2.36047 --> 2.36038).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.369549 \tValidation Loss: 2.366726\n",
      "Epoch: 20 \tTraining Loss: 0.339314 \tValidation Loss: 2.378524\n",
      "Epoch: 1 \tTraining Loss: 6.413834 \tValidation Loss: 5.186992\n",
      "Validation loss decreased (inf --> 5.18699).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.699318 \tValidation Loss: 4.947413\n",
      "Validation loss decreased (5.18699 --> 4.94741).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.255150 \tValidation Loss: 4.615338\n",
      "Validation loss decreased (4.94741 --> 4.61534).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.641367 \tValidation Loss: 4.224215\n",
      "Validation loss decreased (4.61534 --> 4.22421).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.916394 \tValidation Loss: 3.827553\n",
      "Validation loss decreased (4.22421 --> 3.82755).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.184295 \tValidation Loss: 3.468480\n",
      "Validation loss decreased (3.82755 --> 3.46848).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.528324 \tValidation Loss: 3.175070\n",
      "Validation loss decreased (3.46848 --> 3.17507).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.999215 \tValidation Loss: 2.946497\n",
      "Validation loss decreased (3.17507 --> 2.94650).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 \tTraining Loss: 1.594464 \tValidation Loss: 2.770271\n",
      "Validation loss decreased (2.94650 --> 2.77027).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.290777 \tValidation Loss: 2.639330\n",
      "Validation loss decreased (2.77027 --> 2.63933).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.063094 \tValidation Loss: 2.541730\n",
      "Validation loss decreased (2.63933 --> 2.54173).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.888238 \tValidation Loss: 2.472136\n",
      "Validation loss decreased (2.54173 --> 2.47214).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.754671 \tValidation Loss: 2.422423\n",
      "Validation loss decreased (2.47214 --> 2.42242).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.651902 \tValidation Loss: 2.388282\n",
      "Validation loss decreased (2.42242 --> 2.38828).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.569800 \tValidation Loss: 2.367029\n",
      "Validation loss decreased (2.38828 --> 2.36703).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.504353 \tValidation Loss: 2.354838\n",
      "Validation loss decreased (2.36703 --> 2.35484).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.452227 \tValidation Loss: 2.352951\n",
      "Validation loss decreased (2.35484 --> 2.35295).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.408670 \tValidation Loss: 2.354650\n",
      "Epoch: 19 \tTraining Loss: 0.371399 \tValidation Loss: 2.361155\n",
      "Epoch: 20 \tTraining Loss: 0.342917 \tValidation Loss: 2.371272\n",
      "Epoch: 1 \tTraining Loss: 6.404915 \tValidation Loss: 5.153858\n",
      "Validation loss decreased (inf --> 5.15386).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.703518 \tValidation Loss: 4.935264\n",
      "Validation loss decreased (5.15386 --> 4.93526).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.267312 \tValidation Loss: 4.613527\n",
      "Validation loss decreased (4.93526 --> 4.61353).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.654542 \tValidation Loss: 4.222826\n",
      "Validation loss decreased (4.61353 --> 4.22283).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.928373 \tValidation Loss: 3.834786\n",
      "Validation loss decreased (4.22283 --> 3.83479).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.192019 \tValidation Loss: 3.489664\n",
      "Validation loss decreased (3.83479 --> 3.48966).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.537893 \tValidation Loss: 3.205448\n",
      "Validation loss decreased (3.48966 --> 3.20545).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.006259 \tValidation Loss: 2.984218\n",
      "Validation loss decreased (3.20545 --> 2.98422).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.599140 \tValidation Loss: 2.819455\n",
      "Validation loss decreased (2.98422 --> 2.81945).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.296356 \tValidation Loss: 2.698542\n",
      "Validation loss decreased (2.81945 --> 2.69854).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.066845 \tValidation Loss: 2.610565\n",
      "Validation loss decreased (2.69854 --> 2.61056).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.890477 \tValidation Loss: 2.548795\n",
      "Validation loss decreased (2.61056 --> 2.54880).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.755300 \tValidation Loss: 2.507945\n",
      "Validation loss decreased (2.54880 --> 2.50795).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.652133 \tValidation Loss: 2.480762\n",
      "Validation loss decreased (2.50795 --> 2.48076).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.568955 \tValidation Loss: 2.465067\n",
      "Validation loss decreased (2.48076 --> 2.46507).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.505208 \tValidation Loss: 2.459820\n",
      "Validation loss decreased (2.46507 --> 2.45982).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.450039 \tValidation Loss: 2.459005\n",
      "Validation loss decreased (2.45982 --> 2.45900).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.409195 \tValidation Loss: 2.467791\n",
      "Epoch: 19 \tTraining Loss: 0.371781 \tValidation Loss: 2.477305\n",
      "Epoch: 20 \tTraining Loss: 0.345144 \tValidation Loss: 2.489660\n",
      "Epoch: 1 \tTraining Loss: 6.418526 \tValidation Loss: 5.206175\n",
      "Validation loss decreased (inf --> 5.20617).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.704048 \tValidation Loss: 4.978814\n",
      "Validation loss decreased (5.20617 --> 4.97881).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.261382 \tValidation Loss: 4.662815\n",
      "Validation loss decreased (4.97881 --> 4.66281).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.650792 \tValidation Loss: 4.270344\n",
      "Validation loss decreased (4.66281 --> 4.27034).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.923942 \tValidation Loss: 3.866508\n",
      "Validation loss decreased (4.27034 --> 3.86651).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.188801 \tValidation Loss: 3.505410\n",
      "Validation loss decreased (3.86651 --> 3.50541).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.537810 \tValidation Loss: 3.206578\n",
      "Validation loss decreased (3.50541 --> 3.20658).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.010003 \tValidation Loss: 2.971981\n",
      "Validation loss decreased (3.20658 --> 2.97198).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.603007 \tValidation Loss: 2.794301\n",
      "Validation loss decreased (2.97198 --> 2.79430).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.300535 \tValidation Loss: 2.663302\n",
      "Validation loss decreased (2.79430 --> 2.66330).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.069077 \tValidation Loss: 2.568647\n",
      "Validation loss decreased (2.66330 --> 2.56865).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.894903 \tValidation Loss: 2.500522\n",
      "Validation loss decreased (2.56865 --> 2.50052).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.762202 \tValidation Loss: 2.451693\n",
      "Validation loss decreased (2.50052 --> 2.45169).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.654755 \tValidation Loss: 2.419772\n",
      "Validation loss decreased (2.45169 --> 2.41977).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.572050 \tValidation Loss: 2.399605\n",
      "Validation loss decreased (2.41977 --> 2.39960).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.506498 \tValidation Loss: 2.387190\n",
      "Validation loss decreased (2.39960 --> 2.38719).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.452724 \tValidation Loss: 2.385926\n",
      "Validation loss decreased (2.38719 --> 2.38593).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.408549 \tValidation Loss: 2.389696\n",
      "Epoch: 19 \tTraining Loss: 0.373571 \tValidation Loss: 2.396938\n",
      "Epoch: 20 \tTraining Loss: 0.343902 \tValidation Loss: 2.409705\n",
      "Epoch: 1 \tTraining Loss: 6.408081 \tValidation Loss: 5.192324\n",
      "Validation loss decreased (inf --> 5.19232).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.707563 \tValidation Loss: 4.966535\n",
      "Validation loss decreased (5.19232 --> 4.96654).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.264889 \tValidation Loss: 4.639892\n",
      "Validation loss decreased (4.96654 --> 4.63989).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.649295 \tValidation Loss: 4.245424\n",
      "Validation loss decreased (4.63989 --> 4.24542).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.921304 \tValidation Loss: 3.850422\n",
      "Validation loss decreased (4.24542 --> 3.85042).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.183124 \tValidation Loss: 3.497544\n",
      "Validation loss decreased (3.85042 --> 3.49754).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.529280 \tValidation Loss: 3.206766\n",
      "Validation loss decreased (3.49754 --> 3.20677).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.002246 \tValidation Loss: 2.979138\n",
      "Validation loss decreased (3.20677 --> 2.97914).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.598917 \tValidation Loss: 2.803685\n",
      "Validation loss decreased (2.97914 --> 2.80369).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.294014 \tValidation Loss: 2.673198\n",
      "Validation loss decreased (2.80369 --> 2.67320).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.065749 \tValidation Loss: 2.577150\n",
      "Validation loss decreased (2.67320 --> 2.57715).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.891211 \tValidation Loss: 2.507647\n",
      "Validation loss decreased (2.57715 --> 2.50765).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.752606 \tValidation Loss: 2.461819\n",
      "Validation loss decreased (2.50765 --> 2.46182).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.652299 \tValidation Loss: 2.432800\n",
      "Validation loss decreased (2.46182 --> 2.43280).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.568472 \tValidation Loss: 2.412496\n",
      "Validation loss decreased (2.43280 --> 2.41250).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.503509 \tValidation Loss: 2.404283\n",
      "Validation loss decreased (2.41250 --> 2.40428).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.450325 \tValidation Loss: 2.404549\n",
      "Epoch: 18 \tTraining Loss: 0.402908 \tValidation Loss: 2.409166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 \tTraining Loss: 0.370756 \tValidation Loss: 2.418752\n",
      "Epoch: 20 \tTraining Loss: 0.339604 \tValidation Loss: 2.430356\n",
      "Epoch: 1 \tTraining Loss: 6.406526 \tValidation Loss: 5.200338\n",
      "Validation loss decreased (inf --> 5.20034).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.700178 \tValidation Loss: 4.973012\n",
      "Validation loss decreased (5.20034 --> 4.97301).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.256714 \tValidation Loss: 4.648941\n",
      "Validation loss decreased (4.97301 --> 4.64894).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.641194 \tValidation Loss: 4.255426\n",
      "Validation loss decreased (4.64894 --> 4.25543).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.916275 \tValidation Loss: 3.856235\n",
      "Validation loss decreased (4.25543 --> 3.85624).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.181852 \tValidation Loss: 3.496875\n",
      "Validation loss decreased (3.85624 --> 3.49688).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.531318 \tValidation Loss: 3.200084\n",
      "Validation loss decreased (3.49688 --> 3.20008).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.005895 \tValidation Loss: 2.966500\n",
      "Validation loss decreased (3.20008 --> 2.96650).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.603632 \tValidation Loss: 2.787690\n",
      "Validation loss decreased (2.96650 --> 2.78769).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.299873 \tValidation Loss: 2.654519\n",
      "Validation loss decreased (2.78769 --> 2.65452).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.070117 \tValidation Loss: 2.556462\n",
      "Validation loss decreased (2.65452 --> 2.55646).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.895647 \tValidation Loss: 2.485248\n",
      "Validation loss decreased (2.55646 --> 2.48525).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.759364 \tValidation Loss: 2.433053\n",
      "Validation loss decreased (2.48525 --> 2.43305).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.653071 \tValidation Loss: 2.399256\n",
      "Validation loss decreased (2.43305 --> 2.39926).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.572349 \tValidation Loss: 2.379195\n",
      "Validation loss decreased (2.39926 --> 2.37920).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.507642 \tValidation Loss: 2.368701\n",
      "Validation loss decreased (2.37920 --> 2.36870).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.450215 \tValidation Loss: 2.364047\n",
      "Validation loss decreased (2.36870 --> 2.36405).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.412722 \tValidation Loss: 2.367721\n",
      "Epoch: 19 \tTraining Loss: 0.377606 \tValidation Loss: 2.373451\n",
      "Epoch: 20 \tTraining Loss: 0.346520 \tValidation Loss: 2.387320\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 6 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.304505 \tValidation Loss: 5.618431\n",
      "Validation loss decreased (inf --> 5.61843).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.548499 \tValidation Loss: 5.338633\n",
      "Validation loss decreased (5.61843 --> 5.33863).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.057346 \tValidation Loss: 4.951894\n",
      "Validation loss decreased (5.33863 --> 4.95189).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.384292 \tValidation Loss: 4.490747\n",
      "Validation loss decreased (4.95189 --> 4.49075).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.606658 \tValidation Loss: 4.034122\n",
      "Validation loss decreased (4.49075 --> 4.03412).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.852581 \tValidation Loss: 3.626061\n",
      "Validation loss decreased (4.03412 --> 3.62606).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.208126 \tValidation Loss: 3.289790\n",
      "Validation loss decreased (3.62606 --> 3.28979).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.704146 \tValidation Loss: 3.030095\n",
      "Validation loss decreased (3.28979 --> 3.03010).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.329913 \tValidation Loss: 2.839133\n",
      "Validation loss decreased (3.03010 --> 2.83913).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.052893 \tValidation Loss: 2.699966\n",
      "Validation loss decreased (2.83913 --> 2.69997).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.843908 \tValidation Loss: 2.597190\n",
      "Validation loss decreased (2.69997 --> 2.59719).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.686880 \tValidation Loss: 2.523132\n",
      "Validation loss decreased (2.59719 --> 2.52313).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.568651 \tValidation Loss: 2.471161\n",
      "Validation loss decreased (2.52313 --> 2.47116).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.476163 \tValidation Loss: 2.437430\n",
      "Validation loss decreased (2.47116 --> 2.43743).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.406445 \tValidation Loss: 2.415759\n",
      "Validation loss decreased (2.43743 --> 2.41576).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.351990 \tValidation Loss: 2.406390\n",
      "Validation loss decreased (2.41576 --> 2.40639).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.307172 \tValidation Loss: 2.402812\n",
      "Validation loss decreased (2.40639 --> 2.40281).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.272252 \tValidation Loss: 2.403614\n",
      "Epoch: 19 \tTraining Loss: 0.244097 \tValidation Loss: 2.411274\n",
      "Epoch: 20 \tTraining Loss: 0.222247 \tValidation Loss: 2.421828\n",
      "Epoch: 1 \tTraining Loss: 6.298114 \tValidation Loss: 5.662470\n",
      "Validation loss decreased (inf --> 5.66247).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.541185 \tValidation Loss: 5.397207\n",
      "Validation loss decreased (5.66247 --> 5.39721).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.052567 \tValidation Loss: 5.007111\n",
      "Validation loss decreased (5.39721 --> 5.00711).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.387363 \tValidation Loss: 4.526742\n",
      "Validation loss decreased (5.00711 --> 4.52674).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.620430 \tValidation Loss: 4.041449\n",
      "Validation loss decreased (4.52674 --> 4.04145).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.873475 \tValidation Loss: 3.618990\n",
      "Validation loss decreased (4.04145 --> 3.61899).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.232225 \tValidation Loss: 3.279785\n",
      "Validation loss decreased (3.61899 --> 3.27979).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.726067 \tValidation Loss: 3.021554\n",
      "Validation loss decreased (3.27979 --> 3.02155).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.349065 \tValidation Loss: 2.831169\n",
      "Validation loss decreased (3.02155 --> 2.83117).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.068200 \tValidation Loss: 2.691624\n",
      "Validation loss decreased (2.83117 --> 2.69162).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.861612 \tValidation Loss: 2.589868\n",
      "Validation loss decreased (2.69162 --> 2.58987).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.705451 \tValidation Loss: 2.515528\n",
      "Validation loss decreased (2.58987 --> 2.51553).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.581390 \tValidation Loss: 2.462209\n",
      "Validation loss decreased (2.51553 --> 2.46221).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.488368 \tValidation Loss: 2.427872\n",
      "Validation loss decreased (2.46221 --> 2.42787).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.415019 \tValidation Loss: 2.407598\n",
      "Validation loss decreased (2.42787 --> 2.40760).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.357851 \tValidation Loss: 2.394962\n",
      "Validation loss decreased (2.40760 --> 2.39496).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.311886 \tValidation Loss: 2.390766\n",
      "Validation loss decreased (2.39496 --> 2.39077).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.274415 \tValidation Loss: 2.394838\n",
      "Epoch: 19 \tTraining Loss: 0.247705 \tValidation Loss: 2.402365\n",
      "Epoch: 20 \tTraining Loss: 0.226384 \tValidation Loss: 2.412703\n",
      "Epoch: 1 \tTraining Loss: 6.309011 \tValidation Loss: 5.623572\n",
      "Validation loss decreased (inf --> 5.62357).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.546669 \tValidation Loss: 5.331015\n",
      "Validation loss decreased (5.62357 --> 5.33102).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.049733 \tValidation Loss: 4.929040\n",
      "Validation loss decreased (5.33102 --> 4.92904).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.372186 \tValidation Loss: 4.460924\n",
      "Validation loss decreased (4.92904 --> 4.46092).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.589554 \tValidation Loss: 4.003268\n",
      "Validation loss decreased (4.46092 --> 4.00327).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.826007 \tValidation Loss: 3.605360\n",
      "Validation loss decreased (4.00327 --> 3.60536).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.181352 \tValidation Loss: 3.288201\n",
      "Validation loss decreased (3.60536 --> 3.28820).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.681683 \tValidation Loss: 3.046134\n",
      "Validation loss decreased (3.28820 --> 3.04613).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 \tTraining Loss: 1.312194 \tValidation Loss: 2.867143\n",
      "Validation loss decreased (3.04613 --> 2.86714).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.043715 \tValidation Loss: 2.733992\n",
      "Validation loss decreased (2.86714 --> 2.73399).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.837503 \tValidation Loss: 2.637111\n",
      "Validation loss decreased (2.73399 --> 2.63711).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.683203 \tValidation Loss: 2.568385\n",
      "Validation loss decreased (2.63711 --> 2.56838).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.565238 \tValidation Loss: 2.522262\n",
      "Validation loss decreased (2.56838 --> 2.52226).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.477261 \tValidation Loss: 2.492817\n",
      "Validation loss decreased (2.52226 --> 2.49282).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.405475 \tValidation Loss: 2.473931\n",
      "Validation loss decreased (2.49282 --> 2.47393).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.350946 \tValidation Loss: 2.465400\n",
      "Validation loss decreased (2.47393 --> 2.46540).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.305994 \tValidation Loss: 2.465500\n",
      "Epoch: 18 \tTraining Loss: 0.273327 \tValidation Loss: 2.473528\n",
      "Epoch: 19 \tTraining Loss: 0.245745 \tValidation Loss: 2.480091\n",
      "Epoch: 20 \tTraining Loss: 0.222492 \tValidation Loss: 2.489482\n",
      "Epoch: 1 \tTraining Loss: 6.301281 \tValidation Loss: 5.617584\n",
      "Validation loss decreased (inf --> 5.61758).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.549993 \tValidation Loss: 5.343438\n",
      "Validation loss decreased (5.61758 --> 5.34344).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.063305 \tValidation Loss: 4.953518\n",
      "Validation loss decreased (5.34344 --> 4.95352).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.393980 \tValidation Loss: 4.478661\n",
      "Validation loss decreased (4.95352 --> 4.47866).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.607373 \tValidation Loss: 4.001297\n",
      "Validation loss decreased (4.47866 --> 4.00130).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.841608 \tValidation Loss: 3.590714\n",
      "Validation loss decreased (4.00130 --> 3.59071).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.199132 \tValidation Loss: 3.260682\n",
      "Validation loss decreased (3.59071 --> 3.26068).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.699440 \tValidation Loss: 3.013389\n",
      "Validation loss decreased (3.26068 --> 3.01339).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.325618 \tValidation Loss: 2.832104\n",
      "Validation loss decreased (3.01339 --> 2.83210).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.050092 \tValidation Loss: 2.703927\n",
      "Validation loss decreased (2.83210 --> 2.70393).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.842224 \tValidation Loss: 2.614332\n",
      "Validation loss decreased (2.70393 --> 2.61433).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.684452 \tValidation Loss: 2.549871\n",
      "Validation loss decreased (2.61433 --> 2.54987).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.568395 \tValidation Loss: 2.505979\n",
      "Validation loss decreased (2.54987 --> 2.50598).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.473285 \tValidation Loss: 2.477611\n",
      "Validation loss decreased (2.50598 --> 2.47761).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.402458 \tValidation Loss: 2.460619\n",
      "Validation loss decreased (2.47761 --> 2.46062).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.347581 \tValidation Loss: 2.452546\n",
      "Validation loss decreased (2.46062 --> 2.45255).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.302477 \tValidation Loss: 2.452563\n",
      "Epoch: 18 \tTraining Loss: 0.269700 \tValidation Loss: 2.452843\n",
      "Epoch: 19 \tTraining Loss: 0.241061 \tValidation Loss: 2.459407\n",
      "Epoch: 20 \tTraining Loss: 0.217273 \tValidation Loss: 2.470241\n",
      "Epoch: 1 \tTraining Loss: 6.310831 \tValidation Loss: 5.665662\n",
      "Validation loss decreased (inf --> 5.66566).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.541516 \tValidation Loss: 5.386541\n",
      "Validation loss decreased (5.66566 --> 5.38654).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.043895 \tValidation Loss: 4.989932\n",
      "Validation loss decreased (5.38654 --> 4.98993).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.364010 \tValidation Loss: 4.513879\n",
      "Validation loss decreased (4.98993 --> 4.51388).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.581377 \tValidation Loss: 4.045027\n",
      "Validation loss decreased (4.51388 --> 4.04503).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.829329 \tValidation Loss: 3.636145\n",
      "Validation loss decreased (4.04503 --> 3.63615).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.188919 \tValidation Loss: 3.307590\n",
      "Validation loss decreased (3.63615 --> 3.30759).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.691677 \tValidation Loss: 3.056419\n",
      "Validation loss decreased (3.30759 --> 3.05642).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.322352 \tValidation Loss: 2.870130\n",
      "Validation loss decreased (3.05642 --> 2.87013).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.048386 \tValidation Loss: 2.729575\n",
      "Validation loss decreased (2.87013 --> 2.72958).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.845228 \tValidation Loss: 2.625091\n",
      "Validation loss decreased (2.72958 --> 2.62509).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.688862 \tValidation Loss: 2.548953\n",
      "Validation loss decreased (2.62509 --> 2.54895).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.569421 \tValidation Loss: 2.497703\n",
      "Validation loss decreased (2.54895 --> 2.49770).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.478212 \tValidation Loss: 2.461590\n",
      "Validation loss decreased (2.49770 --> 2.46159).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.405004 \tValidation Loss: 2.439698\n",
      "Validation loss decreased (2.46159 --> 2.43970).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.350373 \tValidation Loss: 2.426562\n",
      "Validation loss decreased (2.43970 --> 2.42656).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.307630 \tValidation Loss: 2.422991\n",
      "Validation loss decreased (2.42656 --> 2.42299).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.275009 \tValidation Loss: 2.425356\n",
      "Epoch: 19 \tTraining Loss: 0.244266 \tValidation Loss: 2.434584\n",
      "Epoch: 20 \tTraining Loss: 0.221834 \tValidation Loss: 2.441246\n",
      "Epoch: 1 \tTraining Loss: 6.305392 \tValidation Loss: 5.670881\n",
      "Validation loss decreased (inf --> 5.67088).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.549383 \tValidation Loss: 5.387245\n",
      "Validation loss decreased (5.67088 --> 5.38724).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.057951 \tValidation Loss: 4.986861\n",
      "Validation loss decreased (5.38724 --> 4.98686).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.392338 \tValidation Loss: 4.498086\n",
      "Validation loss decreased (4.98686 --> 4.49809).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.622840 \tValidation Loss: 4.001791\n",
      "Validation loss decreased (4.49809 --> 4.00179).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.864134 \tValidation Loss: 3.562480\n",
      "Validation loss decreased (4.00179 --> 3.56248).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.218939 \tValidation Loss: 3.210621\n",
      "Validation loss decreased (3.56248 --> 3.21062).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.721660 \tValidation Loss: 2.944700\n",
      "Validation loss decreased (3.21062 --> 2.94470).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.345299 \tValidation Loss: 2.745733\n",
      "Validation loss decreased (2.94470 --> 2.74573).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.068699 \tValidation Loss: 2.598373\n",
      "Validation loss decreased (2.74573 --> 2.59837).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.859953 \tValidation Loss: 2.487497\n",
      "Validation loss decreased (2.59837 --> 2.48750).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.701414 \tValidation Loss: 2.406177\n",
      "Validation loss decreased (2.48750 --> 2.40618).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.581877 \tValidation Loss: 2.345363\n",
      "Validation loss decreased (2.40618 --> 2.34536).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.489544 \tValidation Loss: 2.305010\n",
      "Validation loss decreased (2.34536 --> 2.30501).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.416187 \tValidation Loss: 2.276655\n",
      "Validation loss decreased (2.30501 --> 2.27665).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.359533 \tValidation Loss: 2.258550\n",
      "Validation loss decreased (2.27665 --> 2.25855).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.314561 \tValidation Loss: 2.249815\n",
      "Validation loss decreased (2.25855 --> 2.24982).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.278816 \tValidation Loss: 2.247408\n",
      "Validation loss decreased (2.24982 --> 2.24741).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 \tTraining Loss: 0.251724 \tValidation Loss: 2.251362\n",
      "Epoch: 20 \tTraining Loss: 0.227524 \tValidation Loss: 2.256171\n",
      "Epoch: 1 \tTraining Loss: 6.303171 \tValidation Loss: 5.628332\n",
      "Validation loss decreased (inf --> 5.62833).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.549041 \tValidation Loss: 5.360211\n",
      "Validation loss decreased (5.62833 --> 5.36021).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.056272 \tValidation Loss: 4.969088\n",
      "Validation loss decreased (5.36021 --> 4.96909).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.385559 \tValidation Loss: 4.492105\n",
      "Validation loss decreased (4.96909 --> 4.49211).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.606486 \tValidation Loss: 4.020398\n",
      "Validation loss decreased (4.49211 --> 4.02040).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.849228 \tValidation Loss: 3.616761\n",
      "Validation loss decreased (4.02040 --> 3.61676).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.203077 \tValidation Loss: 3.296696\n",
      "Validation loss decreased (3.61676 --> 3.29670).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.705642 \tValidation Loss: 3.055312\n",
      "Validation loss decreased (3.29670 --> 3.05531).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.334424 \tValidation Loss: 2.876448\n",
      "Validation loss decreased (3.05531 --> 2.87645).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.056281 \tValidation Loss: 2.747041\n",
      "Validation loss decreased (2.87645 --> 2.74704).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.849268 \tValidation Loss: 2.653335\n",
      "Validation loss decreased (2.74704 --> 2.65333).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.693283 \tValidation Loss: 2.589633\n",
      "Validation loss decreased (2.65333 --> 2.58963).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.573015 \tValidation Loss: 2.550799\n",
      "Validation loss decreased (2.58963 --> 2.55080).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.480116 \tValidation Loss: 2.522050\n",
      "Validation loss decreased (2.55080 --> 2.52205).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.407709 \tValidation Loss: 2.507377\n",
      "Validation loss decreased (2.52205 --> 2.50738).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.352467 \tValidation Loss: 2.500355\n",
      "Validation loss decreased (2.50738 --> 2.50036).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.307854 \tValidation Loss: 2.502961\n",
      "Epoch: 18 \tTraining Loss: 0.273482 \tValidation Loss: 2.510237\n",
      "Epoch: 19 \tTraining Loss: 0.245441 \tValidation Loss: 2.518370\n",
      "Epoch: 20 \tTraining Loss: 0.223280 \tValidation Loss: 2.531958\n",
      "Epoch: 1 \tTraining Loss: 6.306986 \tValidation Loss: 5.641163\n",
      "Validation loss decreased (inf --> 5.64116).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.537404 \tValidation Loss: 5.352168\n",
      "Validation loss decreased (5.64116 --> 5.35217).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.042793 \tValidation Loss: 4.945831\n",
      "Validation loss decreased (5.35217 --> 4.94583).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.372843 \tValidation Loss: 4.455623\n",
      "Validation loss decreased (4.94583 --> 4.45562).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.595677 \tValidation Loss: 3.966661\n",
      "Validation loss decreased (4.45562 --> 3.96666).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.839060 \tValidation Loss: 3.543218\n",
      "Validation loss decreased (3.96666 --> 3.54322).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.198422 \tValidation Loss: 3.215750\n",
      "Validation loss decreased (3.54322 --> 3.21575).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.701778 \tValidation Loss: 2.972749\n",
      "Validation loss decreased (3.21575 --> 2.97275).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.335952 \tValidation Loss: 2.796568\n",
      "Validation loss decreased (2.97275 --> 2.79657).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.060063 \tValidation Loss: 2.666800\n",
      "Validation loss decreased (2.79657 --> 2.66680).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.852970 \tValidation Loss: 2.570058\n",
      "Validation loss decreased (2.66680 --> 2.57006).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.696503 \tValidation Loss: 2.502528\n",
      "Validation loss decreased (2.57006 --> 2.50253).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.574444 \tValidation Loss: 2.453487\n",
      "Validation loss decreased (2.50253 --> 2.45349).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.484557 \tValidation Loss: 2.421486\n",
      "Validation loss decreased (2.45349 --> 2.42149).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.410701 \tValidation Loss: 2.406134\n",
      "Validation loss decreased (2.42149 --> 2.40613).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.354463 \tValidation Loss: 2.396985\n",
      "Validation loss decreased (2.40613 --> 2.39699).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.308304 \tValidation Loss: 2.395868\n",
      "Validation loss decreased (2.39699 --> 2.39587).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.275797 \tValidation Loss: 2.400102\n",
      "Epoch: 19 \tTraining Loss: 0.246396 \tValidation Loss: 2.410053\n",
      "Epoch: 20 \tTraining Loss: 0.224782 \tValidation Loss: 2.422858\n",
      "Epoch: 1 \tTraining Loss: 6.296085 \tValidation Loss: 5.619302\n",
      "Validation loss decreased (inf --> 5.61930).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.551651 \tValidation Loss: 5.339805\n",
      "Validation loss decreased (5.61930 --> 5.33980).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.062162 \tValidation Loss: 4.943129\n",
      "Validation loss decreased (5.33980 --> 4.94313).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.391884 \tValidation Loss: 4.476803\n",
      "Validation loss decreased (4.94313 --> 4.47680).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.613031 \tValidation Loss: 4.014271\n",
      "Validation loss decreased (4.47680 --> 4.01427).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.859147 \tValidation Loss: 3.606465\n",
      "Validation loss decreased (4.01427 --> 3.60647).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.215682 \tValidation Loss: 3.273343\n",
      "Validation loss decreased (3.60647 --> 3.27334).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.716270 \tValidation Loss: 3.013793\n",
      "Validation loss decreased (3.27334 --> 3.01379).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.341391 \tValidation Loss: 2.821369\n",
      "Validation loss decreased (3.01379 --> 2.82137).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.067167 \tValidation Loss: 2.680103\n",
      "Validation loss decreased (2.82137 --> 2.68010).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.857748 \tValidation Loss: 2.577976\n",
      "Validation loss decreased (2.68010 --> 2.57798).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.700529 \tValidation Loss: 2.505986\n",
      "Validation loss decreased (2.57798 --> 2.50599).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.579258 \tValidation Loss: 2.457647\n",
      "Validation loss decreased (2.50599 --> 2.45765).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.484965 \tValidation Loss: 2.424829\n",
      "Validation loss decreased (2.45765 --> 2.42483).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.413858 \tValidation Loss: 2.407694\n",
      "Validation loss decreased (2.42483 --> 2.40769).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.355991 \tValidation Loss: 2.394946\n",
      "Validation loss decreased (2.40769 --> 2.39495).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.311738 \tValidation Loss: 2.391571\n",
      "Validation loss decreased (2.39495 --> 2.39157).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.277671 \tValidation Loss: 2.394490\n",
      "Epoch: 19 \tTraining Loss: 0.246943 \tValidation Loss: 2.403825\n",
      "Epoch: 20 \tTraining Loss: 0.226932 \tValidation Loss: 2.413220\n",
      "Epoch: 1 \tTraining Loss: 6.307761 \tValidation Loss: 5.644592\n",
      "Validation loss decreased (inf --> 5.64459).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.540681 \tValidation Loss: 5.379986\n",
      "Validation loss decreased (5.64459 --> 5.37999).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.041988 \tValidation Loss: 4.996771\n",
      "Validation loss decreased (5.37999 --> 4.99677).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.364975 \tValidation Loss: 4.532457\n",
      "Validation loss decreased (4.99677 --> 4.53246).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.587910 \tValidation Loss: 4.067368\n",
      "Validation loss decreased (4.53246 --> 4.06737).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.835438 \tValidation Loss: 3.664038\n",
      "Validation loss decreased (4.06737 --> 3.66404).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.191762 \tValidation Loss: 3.341896\n",
      "Validation loss decreased (3.66404 --> 3.34190).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.691550 \tValidation Loss: 3.096991\n",
      "Validation loss decreased (3.34190 --> 3.09699).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.321249 \tValidation Loss: 2.917949\n",
      "Validation loss decreased (3.09699 --> 2.91795).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 \tTraining Loss: 1.047234 \tValidation Loss: 2.786700\n",
      "Validation loss decreased (2.91795 --> 2.78670).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.838759 \tValidation Loss: 2.694300\n",
      "Validation loss decreased (2.78670 --> 2.69430).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.683625 \tValidation Loss: 2.627280\n",
      "Validation loss decreased (2.69430 --> 2.62728).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.566771 \tValidation Loss: 2.578432\n",
      "Validation loss decreased (2.62728 --> 2.57843).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.473671 \tValidation Loss: 2.545999\n",
      "Validation loss decreased (2.57843 --> 2.54600).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.405412 \tValidation Loss: 2.525173\n",
      "Validation loss decreased (2.54600 --> 2.52517).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.348517 \tValidation Loss: 2.515751\n",
      "Validation loss decreased (2.52517 --> 2.51575).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.307565 \tValidation Loss: 2.513163\n",
      "Validation loss decreased (2.51575 --> 2.51316).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.272605 \tValidation Loss: 2.512845\n",
      "Validation loss decreased (2.51316 --> 2.51285).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.244148 \tValidation Loss: 2.519757\n",
      "Epoch: 20 \tTraining Loss: 0.223914 \tValidation Loss: 2.527600\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 7 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.339274 \tValidation Loss: 5.072759\n",
      "Validation loss decreased (inf --> 5.07276).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.514806 \tValidation Loss: 4.797054\n",
      "Validation loss decreased (5.07276 --> 4.79705).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.984465 \tValidation Loss: 4.432596\n",
      "Validation loss decreased (4.79705 --> 4.43260).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.277475 \tValidation Loss: 4.004194\n",
      "Validation loss decreased (4.43260 --> 4.00419).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.481553 \tValidation Loss: 3.573763\n",
      "Validation loss decreased (4.00419 --> 3.57376).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.725343 \tValidation Loss: 3.194610\n",
      "Validation loss decreased (3.57376 --> 3.19461).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.091593 \tValidation Loss: 2.891022\n",
      "Validation loss decreased (3.19461 --> 2.89102).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.606301 \tValidation Loss: 2.663186\n",
      "Validation loss decreased (2.89102 --> 2.66319).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.241149 \tValidation Loss: 2.495811\n",
      "Validation loss decreased (2.66319 --> 2.49581).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.975350 \tValidation Loss: 2.374068\n",
      "Validation loss decreased (2.49581 --> 2.37407).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.772160 \tValidation Loss: 2.285832\n",
      "Validation loss decreased (2.37407 --> 2.28583).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.621099 \tValidation Loss: 2.223612\n",
      "Validation loss decreased (2.28583 --> 2.22361).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.503191 \tValidation Loss: 2.178900\n",
      "Validation loss decreased (2.22361 --> 2.17890).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.415162 \tValidation Loss: 2.150414\n",
      "Validation loss decreased (2.17890 --> 2.15041).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.343385 \tValidation Loss: 2.132830\n",
      "Validation loss decreased (2.15041 --> 2.13283).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.295349 \tValidation Loss: 2.124190\n",
      "Validation loss decreased (2.13283 --> 2.12419).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.252548 \tValidation Loss: 2.121904\n",
      "Validation loss decreased (2.12419 --> 2.12190).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.221008 \tValidation Loss: 2.121396\n",
      "Validation loss decreased (2.12190 --> 2.12140).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.195724 \tValidation Loss: 2.127348\n",
      "Epoch: 20 \tTraining Loss: 0.175547 \tValidation Loss: 2.136361\n",
      "Epoch: 1 \tTraining Loss: 6.343851 \tValidation Loss: 5.086871\n",
      "Validation loss decreased (inf --> 5.08687).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.517758 \tValidation Loss: 4.814801\n",
      "Validation loss decreased (5.08687 --> 4.81480).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.994471 \tValidation Loss: 4.440836\n",
      "Validation loss decreased (4.81480 --> 4.44084).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.288512 \tValidation Loss: 3.991853\n",
      "Validation loss decreased (4.44084 --> 3.99185).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.484240 \tValidation Loss: 3.552361\n",
      "Validation loss decreased (3.99185 --> 3.55236).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.726939 \tValidation Loss: 3.174552\n",
      "Validation loss decreased (3.55236 --> 3.17455).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.091834 \tValidation Loss: 2.871722\n",
      "Validation loss decreased (3.17455 --> 2.87172).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.607443 \tValidation Loss: 2.640722\n",
      "Validation loss decreased (2.87172 --> 2.64072).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.246395 \tValidation Loss: 2.469008\n",
      "Validation loss decreased (2.64072 --> 2.46901).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.977917 \tValidation Loss: 2.345001\n",
      "Validation loss decreased (2.46901 --> 2.34500).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.772898 \tValidation Loss: 2.252707\n",
      "Validation loss decreased (2.34500 --> 2.25271).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.621123 \tValidation Loss: 2.185739\n",
      "Validation loss decreased (2.25271 --> 2.18574).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.503167 \tValidation Loss: 2.137615\n",
      "Validation loss decreased (2.18574 --> 2.13761).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.413184 \tValidation Loss: 2.105978\n",
      "Validation loss decreased (2.13761 --> 2.10598).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.344891 \tValidation Loss: 2.085557\n",
      "Validation loss decreased (2.10598 --> 2.08556).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.294227 \tValidation Loss: 2.072019\n",
      "Validation loss decreased (2.08556 --> 2.07202).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.252695 \tValidation Loss: 2.068335\n",
      "Validation loss decreased (2.07202 --> 2.06834).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.220203 \tValidation Loss: 2.067974\n",
      "Validation loss decreased (2.06834 --> 2.06797).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.195818 \tValidation Loss: 2.068918\n",
      "Epoch: 20 \tTraining Loss: 0.176091 \tValidation Loss: 2.075918\n",
      "Epoch: 1 \tTraining Loss: 6.346281 \tValidation Loss: 5.048823\n",
      "Validation loss decreased (inf --> 5.04882).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.512780 \tValidation Loss: 4.768460\n",
      "Validation loss decreased (5.04882 --> 4.76846).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.984270 \tValidation Loss: 4.400435\n",
      "Validation loss decreased (4.76846 --> 4.40043).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.269957 \tValidation Loss: 3.961990\n",
      "Validation loss decreased (4.40043 --> 3.96199).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.464303 \tValidation Loss: 3.531311\n",
      "Validation loss decreased (3.96199 --> 3.53131).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.706785 \tValidation Loss: 3.158364\n",
      "Validation loss decreased (3.53131 --> 3.15836).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.073005 \tValidation Loss: 2.866591\n",
      "Validation loss decreased (3.15836 --> 2.86659).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.591672 \tValidation Loss: 2.646703\n",
      "Validation loss decreased (2.86659 --> 2.64670).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.235133 \tValidation Loss: 2.481856\n",
      "Validation loss decreased (2.64670 --> 2.48186).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.968610 \tValidation Loss: 2.357286\n",
      "Validation loss decreased (2.48186 --> 2.35729).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.773132 \tValidation Loss: 2.265078\n",
      "Validation loss decreased (2.35729 --> 2.26508).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.619722 \tValidation Loss: 2.195787\n",
      "Validation loss decreased (2.26508 --> 2.19579).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.506608 \tValidation Loss: 2.144867\n",
      "Validation loss decreased (2.19579 --> 2.14487).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.415973 \tValidation Loss: 2.111537\n",
      "Validation loss decreased (2.14487 --> 2.11154).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.347916 \tValidation Loss: 2.089112\n",
      "Validation loss decreased (2.11154 --> 2.08911).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.296826 \tValidation Loss: 2.074319\n",
      "Validation loss decreased (2.08911 --> 2.07432).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 \tTraining Loss: 0.256267 \tValidation Loss: 2.069509\n",
      "Validation loss decreased (2.07432 --> 2.06951).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.223129 \tValidation Loss: 2.070531\n",
      "Epoch: 19 \tTraining Loss: 0.201584 \tValidation Loss: 2.072565\n",
      "Epoch: 20 \tTraining Loss: 0.179806 \tValidation Loss: 2.076944\n",
      "Epoch: 1 \tTraining Loss: 6.339262 \tValidation Loss: 5.030840\n",
      "Validation loss decreased (inf --> 5.03084).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.518342 \tValidation Loss: 4.743910\n",
      "Validation loss decreased (5.03084 --> 4.74391).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.993498 \tValidation Loss: 4.366017\n",
      "Validation loss decreased (4.74391 --> 4.36602).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.288981 \tValidation Loss: 3.926275\n",
      "Validation loss decreased (4.36602 --> 3.92628).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.489031 \tValidation Loss: 3.490188\n",
      "Validation loss decreased (3.92628 --> 3.49019).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.728749 \tValidation Loss: 3.107122\n",
      "Validation loss decreased (3.49019 --> 3.10712).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.094553 \tValidation Loss: 2.802451\n",
      "Validation loss decreased (3.10712 --> 2.80245).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.609719 \tValidation Loss: 2.573198\n",
      "Validation loss decreased (2.80245 --> 2.57320).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.245473 \tValidation Loss: 2.404905\n",
      "Validation loss decreased (2.57320 --> 2.40490).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.977447 \tValidation Loss: 2.282642\n",
      "Validation loss decreased (2.40490 --> 2.28264).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.778726 \tValidation Loss: 2.193296\n",
      "Validation loss decreased (2.28264 --> 2.19330).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.623763 \tValidation Loss: 2.127409\n",
      "Validation loss decreased (2.19330 --> 2.12741).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.507844 \tValidation Loss: 2.082435\n",
      "Validation loss decreased (2.12741 --> 2.08243).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.416067 \tValidation Loss: 2.049855\n",
      "Validation loss decreased (2.08243 --> 2.04986).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.349478 \tValidation Loss: 2.030247\n",
      "Validation loss decreased (2.04986 --> 2.03025).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.297911 \tValidation Loss: 2.019502\n",
      "Validation loss decreased (2.03025 --> 2.01950).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.257301 \tValidation Loss: 2.014626\n",
      "Validation loss decreased (2.01950 --> 2.01463).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.224337 \tValidation Loss: 2.015944\n",
      "Epoch: 19 \tTraining Loss: 0.200359 \tValidation Loss: 2.020678\n",
      "Epoch: 20 \tTraining Loss: 0.181260 \tValidation Loss: 2.024898\n",
      "Epoch: 1 \tTraining Loss: 6.343985 \tValidation Loss: 5.080713\n",
      "Validation loss decreased (inf --> 5.08071).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.512879 \tValidation Loss: 4.811955\n",
      "Validation loss decreased (5.08071 --> 4.81195).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.985795 \tValidation Loss: 4.440454\n",
      "Validation loss decreased (4.81195 --> 4.44045).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.280530 \tValidation Loss: 4.005071\n",
      "Validation loss decreased (4.44045 --> 4.00507).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.483167 \tValidation Loss: 3.581737\n",
      "Validation loss decreased (4.00507 --> 3.58174).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.725169 \tValidation Loss: 3.221964\n",
      "Validation loss decreased (3.58174 --> 3.22196).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.090449 \tValidation Loss: 2.935212\n",
      "Validation loss decreased (3.22196 --> 2.93521).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.606377 \tValidation Loss: 2.714511\n",
      "Validation loss decreased (2.93521 --> 2.71451).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.246080 \tValidation Loss: 2.545756\n",
      "Validation loss decreased (2.71451 --> 2.54576).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.976876 \tValidation Loss: 2.419936\n",
      "Validation loss decreased (2.54576 --> 2.41994).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.775442 \tValidation Loss: 2.329852\n",
      "Validation loss decreased (2.41994 --> 2.32985).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.622588 \tValidation Loss: 2.264856\n",
      "Validation loss decreased (2.32985 --> 2.26486).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.506382 \tValidation Loss: 2.221219\n",
      "Validation loss decreased (2.26486 --> 2.22122).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.416932 \tValidation Loss: 2.193502\n",
      "Validation loss decreased (2.22122 --> 2.19350).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.348703 \tValidation Loss: 2.178125\n",
      "Validation loss decreased (2.19350 --> 2.17812).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.297443 \tValidation Loss: 2.169496\n",
      "Validation loss decreased (2.17812 --> 2.16950).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.254690 \tValidation Loss: 2.166537\n",
      "Validation loss decreased (2.16950 --> 2.16654).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.224255 \tValidation Loss: 2.167535\n",
      "Epoch: 19 \tTraining Loss: 0.197778 \tValidation Loss: 2.172941\n",
      "Epoch: 20 \tTraining Loss: 0.180020 \tValidation Loss: 2.182410\n",
      "Epoch: 1 \tTraining Loss: 6.344551 \tValidation Loss: 5.078308\n",
      "Validation loss decreased (inf --> 5.07831).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.528383 \tValidation Loss: 4.807520\n",
      "Validation loss decreased (5.07831 --> 4.80752).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.008240 \tValidation Loss: 4.433271\n",
      "Validation loss decreased (4.80752 --> 4.43327).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.302685 \tValidation Loss: 3.985429\n",
      "Validation loss decreased (4.43327 --> 3.98543).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.499721 \tValidation Loss: 3.539127\n",
      "Validation loss decreased (3.98543 --> 3.53913).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.734257 \tValidation Loss: 3.156895\n",
      "Validation loss decreased (3.53913 --> 3.15689).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.101285 \tValidation Loss: 2.862034\n",
      "Validation loss decreased (3.15689 --> 2.86203).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.609052 \tValidation Loss: 2.639289\n",
      "Validation loss decreased (2.86203 --> 2.63929).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.249219 \tValidation Loss: 2.471877\n",
      "Validation loss decreased (2.63929 --> 2.47188).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.980383 \tValidation Loss: 2.346579\n",
      "Validation loss decreased (2.47188 --> 2.34658).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.778411 \tValidation Loss: 2.253936\n",
      "Validation loss decreased (2.34658 --> 2.25394).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.627096 \tValidation Loss: 2.185605\n",
      "Validation loss decreased (2.25394 --> 2.18561).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.507563 \tValidation Loss: 2.137245\n",
      "Validation loss decreased (2.18561 --> 2.13724).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.418124 \tValidation Loss: 2.105863\n",
      "Validation loss decreased (2.13724 --> 2.10586).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.350705 \tValidation Loss: 2.086555\n",
      "Validation loss decreased (2.10586 --> 2.08655).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.297588 \tValidation Loss: 2.075471\n",
      "Validation loss decreased (2.08655 --> 2.07547).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.257668 \tValidation Loss: 2.069384\n",
      "Validation loss decreased (2.07547 --> 2.06938).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.225354 \tValidation Loss: 2.070011\n",
      "Epoch: 19 \tTraining Loss: 0.200912 \tValidation Loss: 2.071377\n",
      "Epoch: 20 \tTraining Loss: 0.181092 \tValidation Loss: 2.076416\n",
      "Epoch: 1 \tTraining Loss: 6.336662 \tValidation Loss: 5.079552\n",
      "Validation loss decreased (inf --> 5.07955).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.513722 \tValidation Loss: 4.817664\n",
      "Validation loss decreased (5.07955 --> 4.81766).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.986617 \tValidation Loss: 4.455042\n",
      "Validation loss decreased (4.81766 --> 4.45504).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.278351 \tValidation Loss: 4.015680\n",
      "Validation loss decreased (4.45504 --> 4.01568).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.475961 \tValidation Loss: 3.579805\n",
      "Validation loss decreased (4.01568 --> 3.57981).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.712047 \tValidation Loss: 3.199061\n",
      "Validation loss decreased (3.57981 --> 3.19906).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.079549 \tValidation Loss: 2.895379\n",
      "Validation loss decreased (3.19906 --> 2.89538).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 \tTraining Loss: 1.593859 \tValidation Loss: 2.665739\n",
      "Validation loss decreased (2.89538 --> 2.66574).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.233966 \tValidation Loss: 2.495978\n",
      "Validation loss decreased (2.66574 --> 2.49598).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.969818 \tValidation Loss: 2.373312\n",
      "Validation loss decreased (2.49598 --> 2.37331).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.769462 \tValidation Loss: 2.285052\n",
      "Validation loss decreased (2.37331 --> 2.28505).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.619366 \tValidation Loss: 2.220429\n",
      "Validation loss decreased (2.28505 --> 2.22043).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.503519 \tValidation Loss: 2.177197\n",
      "Validation loss decreased (2.22043 --> 2.17720).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.417106 \tValidation Loss: 2.147879\n",
      "Validation loss decreased (2.17720 --> 2.14788).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.344991 \tValidation Loss: 2.131225\n",
      "Validation loss decreased (2.14788 --> 2.13123).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.293405 \tValidation Loss: 2.119266\n",
      "Validation loss decreased (2.13123 --> 2.11927).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.253024 \tValidation Loss: 2.116184\n",
      "Validation loss decreased (2.11927 --> 2.11618).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.221640 \tValidation Loss: 2.117060\n",
      "Epoch: 19 \tTraining Loss: 0.198145 \tValidation Loss: 2.125271\n",
      "Epoch: 20 \tTraining Loss: 0.177943 \tValidation Loss: 2.131705\n",
      "Epoch: 1 \tTraining Loss: 6.341130 \tValidation Loss: 5.073585\n",
      "Validation loss decreased (inf --> 5.07359).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.522273 \tValidation Loss: 4.810571\n",
      "Validation loss decreased (5.07359 --> 4.81057).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.000705 \tValidation Loss: 4.439662\n",
      "Validation loss decreased (4.81057 --> 4.43966).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.297391 \tValidation Loss: 3.990662\n",
      "Validation loss decreased (4.43966 --> 3.99066).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.502433 \tValidation Loss: 3.550484\n",
      "Validation loss decreased (3.99066 --> 3.55048).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.743434 \tValidation Loss: 3.170372\n",
      "Validation loss decreased (3.55048 --> 3.17037).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.105615 \tValidation Loss: 2.871354\n",
      "Validation loss decreased (3.17037 --> 2.87135).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.611764 \tValidation Loss: 2.650765\n",
      "Validation loss decreased (2.87135 --> 2.65076).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.242511 \tValidation Loss: 2.491992\n",
      "Validation loss decreased (2.65076 --> 2.49199).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.973751 \tValidation Loss: 2.377322\n",
      "Validation loss decreased (2.49199 --> 2.37732).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.772189 \tValidation Loss: 2.293546\n",
      "Validation loss decreased (2.37732 --> 2.29355).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.617276 \tValidation Loss: 2.232753\n",
      "Validation loss decreased (2.29355 --> 2.23275).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.504560 \tValidation Loss: 2.191172\n",
      "Validation loss decreased (2.23275 --> 2.19117).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.414645 \tValidation Loss: 2.165397\n",
      "Validation loss decreased (2.19117 --> 2.16540).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.345883 \tValidation Loss: 2.150100\n",
      "Validation loss decreased (2.16540 --> 2.15010).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.293407 \tValidation Loss: 2.142305\n",
      "Validation loss decreased (2.15010 --> 2.14230).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.251720 \tValidation Loss: 2.141553\n",
      "Validation loss decreased (2.14230 --> 2.14155).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.220506 \tValidation Loss: 2.145718\n",
      "Epoch: 19 \tTraining Loss: 0.196534 \tValidation Loss: 2.151760\n",
      "Epoch: 20 \tTraining Loss: 0.176426 \tValidation Loss: 2.160225\n",
      "Epoch: 1 \tTraining Loss: 6.336743 \tValidation Loss: 5.074945\n",
      "Validation loss decreased (inf --> 5.07495).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.514812 \tValidation Loss: 4.808809\n",
      "Validation loss decreased (5.07495 --> 4.80881).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.997097 \tValidation Loss: 4.436477\n",
      "Validation loss decreased (4.80881 --> 4.43648).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.298615 \tValidation Loss: 3.989909\n",
      "Validation loss decreased (4.43648 --> 3.98991).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.505637 \tValidation Loss: 3.543223\n",
      "Validation loss decreased (3.98991 --> 3.54322).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.744782 \tValidation Loss: 3.159392\n",
      "Validation loss decreased (3.54322 --> 3.15939).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.105514 \tValidation Loss: 2.860290\n",
      "Validation loss decreased (3.15939 --> 2.86029).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.613710 \tValidation Loss: 2.639851\n",
      "Validation loss decreased (2.86029 --> 2.63985).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.252802 \tValidation Loss: 2.478685\n",
      "Validation loss decreased (2.63985 --> 2.47869).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.987844 \tValidation Loss: 2.357770\n",
      "Validation loss decreased (2.47869 --> 2.35777).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.784640 \tValidation Loss: 2.267817\n",
      "Validation loss decreased (2.35777 --> 2.26782).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.630572 \tValidation Loss: 2.199758\n",
      "Validation loss decreased (2.26782 --> 2.19976).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.512055 \tValidation Loss: 2.151051\n",
      "Validation loss decreased (2.19976 --> 2.15105).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.421989 \tValidation Loss: 2.115560\n",
      "Validation loss decreased (2.15105 --> 2.11556).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.352231 \tValidation Loss: 2.097752\n",
      "Validation loss decreased (2.11556 --> 2.09775).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.299291 \tValidation Loss: 2.087246\n",
      "Validation loss decreased (2.09775 --> 2.08725).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.256053 \tValidation Loss: 2.082859\n",
      "Validation loss decreased (2.08725 --> 2.08286).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.226965 \tValidation Loss: 2.082050\n",
      "Validation loss decreased (2.08286 --> 2.08205).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.200337 \tValidation Loss: 2.085924\n",
      "Epoch: 20 \tTraining Loss: 0.180841 \tValidation Loss: 2.094240\n",
      "Epoch: 1 \tTraining Loss: 6.341162 \tValidation Loss: 5.061625\n",
      "Validation loss decreased (inf --> 5.06162).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.520040 \tValidation Loss: 4.785532\n",
      "Validation loss decreased (5.06162 --> 4.78553).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.992095 \tValidation Loss: 4.412107\n",
      "Validation loss decreased (4.78553 --> 4.41211).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.287152 \tValidation Loss: 3.965763\n",
      "Validation loss decreased (4.41211 --> 3.96576).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.489997 \tValidation Loss: 3.521537\n",
      "Validation loss decreased (3.96576 --> 3.52154).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.732177 \tValidation Loss: 3.133777\n",
      "Validation loss decreased (3.52154 --> 3.13378).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.100448 \tValidation Loss: 2.821446\n",
      "Validation loss decreased (3.13378 --> 2.82145).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.611370 \tValidation Loss: 2.582614\n",
      "Validation loss decreased (2.82145 --> 2.58261).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.248972 \tValidation Loss: 2.403333\n",
      "Validation loss decreased (2.58261 --> 2.40333).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.980069 \tValidation Loss: 2.271016\n",
      "Validation loss decreased (2.40333 --> 2.27102).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.778265 \tValidation Loss: 2.173041\n",
      "Validation loss decreased (2.27102 --> 2.17304).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.622693 \tValidation Loss: 2.100193\n",
      "Validation loss decreased (2.17304 --> 2.10019).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.504382 \tValidation Loss: 2.046422\n",
      "Validation loss decreased (2.10019 --> 2.04642).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.416285 \tValidation Loss: 2.011177\n",
      "Validation loss decreased (2.04642 --> 2.01118).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.346313 \tValidation Loss: 1.986163\n",
      "Validation loss decreased (2.01118 --> 1.98616).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 \tTraining Loss: 0.293526 \tValidation Loss: 1.974082\n",
      "Validation loss decreased (1.98616 --> 1.97408).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.254405 \tValidation Loss: 1.966805\n",
      "Validation loss decreased (1.97408 --> 1.96680).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.221139 \tValidation Loss: 1.965582\n",
      "Validation loss decreased (1.96680 --> 1.96558).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.197996 \tValidation Loss: 1.967181\n",
      "Epoch: 20 \tTraining Loss: 0.177436 \tValidation Loss: 1.973358\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 8 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.332326 \tValidation Loss: 4.418834\n",
      "Validation loss decreased (inf --> 4.41883).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.445841 \tValidation Loss: 4.134397\n",
      "Validation loss decreased (4.41883 --> 4.13440).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.928945 \tValidation Loss: 3.815652\n",
      "Validation loss decreased (4.13440 --> 3.81565).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.246859 \tValidation Loss: 3.432343\n",
      "Validation loss decreased (3.81565 --> 3.43234).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.463558 \tValidation Loss: 3.049634\n",
      "Validation loss decreased (3.43234 --> 3.04963).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.712654 \tValidation Loss: 2.718654\n",
      "Validation loss decreased (3.04963 --> 2.71865).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.089521 \tValidation Loss: 2.458802\n",
      "Validation loss decreased (2.71865 --> 2.45880).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.606828 \tValidation Loss: 2.264525\n",
      "Validation loss decreased (2.45880 --> 2.26453).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.241420 \tValidation Loss: 2.123037\n",
      "Validation loss decreased (2.26453 --> 2.12304).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.972630 \tValidation Loss: 2.018121\n",
      "Validation loss decreased (2.12304 --> 2.01812).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.765309 \tValidation Loss: 1.939110\n",
      "Validation loss decreased (2.01812 --> 1.93911).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.606943 \tValidation Loss: 1.879888\n",
      "Validation loss decreased (1.93911 --> 1.87989).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.487659 \tValidation Loss: 1.838891\n",
      "Validation loss decreased (1.87989 --> 1.83889).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.395815 \tValidation Loss: 1.811496\n",
      "Validation loss decreased (1.83889 --> 1.81150).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.325982 \tValidation Loss: 1.796515\n",
      "Validation loss decreased (1.81150 --> 1.79651).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.272609 \tValidation Loss: 1.786210\n",
      "Validation loss decreased (1.79651 --> 1.78621).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.233013 \tValidation Loss: 1.781270\n",
      "Validation loss decreased (1.78621 --> 1.78127).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.201238 \tValidation Loss: 1.782016\n",
      "Epoch: 19 \tTraining Loss: 0.177702 \tValidation Loss: 1.784109\n",
      "Epoch: 20 \tTraining Loss: 0.157783 \tValidation Loss: 1.791058\n",
      "Epoch: 1 \tTraining Loss: 6.342025 \tValidation Loss: 4.481152\n",
      "Validation loss decreased (inf --> 4.48115).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.447509 \tValidation Loss: 4.210923\n",
      "Validation loss decreased (4.48115 --> 4.21092).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.930736 \tValidation Loss: 3.893093\n",
      "Validation loss decreased (4.21092 --> 3.89309).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.255843 \tValidation Loss: 3.508612\n",
      "Validation loss decreased (3.89309 --> 3.50861).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.478726 \tValidation Loss: 3.123971\n",
      "Validation loss decreased (3.50861 --> 3.12397).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.733429 \tValidation Loss: 2.788782\n",
      "Validation loss decreased (3.12397 --> 2.78878).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.111563 \tValidation Loss: 2.518089\n",
      "Validation loss decreased (2.78878 --> 2.51809).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.629498 \tValidation Loss: 2.308835\n",
      "Validation loss decreased (2.51809 --> 2.30884).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.263779 \tValidation Loss: 2.152227\n",
      "Validation loss decreased (2.30884 --> 2.15223).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.990642 \tValidation Loss: 2.033539\n",
      "Validation loss decreased (2.15223 --> 2.03354).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.782823 \tValidation Loss: 1.944919\n",
      "Validation loss decreased (2.03354 --> 1.94492).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.619488 \tValidation Loss: 1.877977\n",
      "Validation loss decreased (1.94492 --> 1.87798).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.498840 \tValidation Loss: 1.831481\n",
      "Validation loss decreased (1.87798 --> 1.83148).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.402221 \tValidation Loss: 1.800478\n",
      "Validation loss decreased (1.83148 --> 1.80048).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.331562 \tValidation Loss: 1.778027\n",
      "Validation loss decreased (1.80048 --> 1.77803).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.276531 \tValidation Loss: 1.765329\n",
      "Validation loss decreased (1.77803 --> 1.76533).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.234225 \tValidation Loss: 1.759096\n",
      "Validation loss decreased (1.76533 --> 1.75910).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.201646 \tValidation Loss: 1.759930\n",
      "Epoch: 19 \tTraining Loss: 0.178643 \tValidation Loss: 1.762179\n",
      "Epoch: 20 \tTraining Loss: 0.157966 \tValidation Loss: 1.765210\n",
      "Epoch: 1 \tTraining Loss: 6.352130 \tValidation Loss: 4.417737\n",
      "Validation loss decreased (inf --> 4.41774).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.455788 \tValidation Loss: 4.099519\n",
      "Validation loss decreased (4.41774 --> 4.09952).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.926239 \tValidation Loss: 3.766756\n",
      "Validation loss decreased (4.09952 --> 3.76676).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.240629 \tValidation Loss: 3.375225\n",
      "Validation loss decreased (3.76676 --> 3.37523).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.457702 \tValidation Loss: 2.985128\n",
      "Validation loss decreased (3.37523 --> 2.98513).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.714288 \tValidation Loss: 2.649456\n",
      "Validation loss decreased (2.98513 --> 2.64946).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.091633 \tValidation Loss: 2.387628\n",
      "Validation loss decreased (2.64946 --> 2.38763).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.618387 \tValidation Loss: 2.190306\n",
      "Validation loss decreased (2.38763 --> 2.19031).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.257272 \tValidation Loss: 2.042171\n",
      "Validation loss decreased (2.19031 --> 2.04217).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.984509 \tValidation Loss: 1.932017\n",
      "Validation loss decreased (2.04217 --> 1.93202).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.779439 \tValidation Loss: 1.850095\n",
      "Validation loss decreased (1.93202 --> 1.85010).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.618747 \tValidation Loss: 1.789440\n",
      "Validation loss decreased (1.85010 --> 1.78944).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.499684 \tValidation Loss: 1.745966\n",
      "Validation loss decreased (1.78944 --> 1.74597).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.404623 \tValidation Loss: 1.715811\n",
      "Validation loss decreased (1.74597 --> 1.71581).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.337615 \tValidation Loss: 1.697804\n",
      "Validation loss decreased (1.71581 --> 1.69780).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.280923 \tValidation Loss: 1.685435\n",
      "Validation loss decreased (1.69780 --> 1.68544).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.240219 \tValidation Loss: 1.680475\n",
      "Validation loss decreased (1.68544 --> 1.68047).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.207561 \tValidation Loss: 1.678583\n",
      "Validation loss decreased (1.68047 --> 1.67858).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.184185 \tValidation Loss: 1.675978\n",
      "Validation loss decreased (1.67858 --> 1.67598).  Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 0.161481 \tValidation Loss: 1.680830\n",
      "Epoch: 1 \tTraining Loss: 6.328304 \tValidation Loss: 4.463818\n",
      "Validation loss decreased (inf --> 4.46382).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.439841 \tValidation Loss: 4.208164\n",
      "Validation loss decreased (4.46382 --> 4.20816).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.915542 \tValidation Loss: 3.898338\n",
      "Validation loss decreased (4.20816 --> 3.89834).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.232078 \tValidation Loss: 3.530424\n",
      "Validation loss decreased (3.89834 --> 3.53042).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \tTraining Loss: 3.458638 \tValidation Loss: 3.162922\n",
      "Validation loss decreased (3.53042 --> 3.16292).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.724407 \tValidation Loss: 2.836613\n",
      "Validation loss decreased (3.16292 --> 2.83661).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.103475 \tValidation Loss: 2.572085\n",
      "Validation loss decreased (2.83661 --> 2.57209).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.619487 \tValidation Loss: 2.372530\n",
      "Validation loss decreased (2.57209 --> 2.37253).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.252866 \tValidation Loss: 2.227066\n",
      "Validation loss decreased (2.37253 --> 2.22707).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.979502 \tValidation Loss: 2.121152\n",
      "Validation loss decreased (2.22707 --> 2.12115).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.770881 \tValidation Loss: 2.042226\n",
      "Validation loss decreased (2.12115 --> 2.04223).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.612188 \tValidation Loss: 1.983436\n",
      "Validation loss decreased (2.04223 --> 1.98344).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.492249 \tValidation Loss: 1.941071\n",
      "Validation loss decreased (1.98344 --> 1.94107).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.398115 \tValidation Loss: 1.911771\n",
      "Validation loss decreased (1.94107 --> 1.91177).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.328963 \tValidation Loss: 1.894630\n",
      "Validation loss decreased (1.91177 --> 1.89463).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.275750 \tValidation Loss: 1.881567\n",
      "Validation loss decreased (1.89463 --> 1.88157).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.234391 \tValidation Loss: 1.873783\n",
      "Validation loss decreased (1.88157 --> 1.87378).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.200723 \tValidation Loss: 1.871657\n",
      "Validation loss decreased (1.87378 --> 1.87166).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.175947 \tValidation Loss: 1.873168\n",
      "Epoch: 20 \tTraining Loss: 0.154955 \tValidation Loss: 1.877554\n",
      "Epoch: 1 \tTraining Loss: 6.332692 \tValidation Loss: 4.417062\n",
      "Validation loss decreased (inf --> 4.41706).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.454258 \tValidation Loss: 4.139246\n",
      "Validation loss decreased (4.41706 --> 4.13925).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.936441 \tValidation Loss: 3.818372\n",
      "Validation loss decreased (4.13925 --> 3.81837).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.252940 \tValidation Loss: 3.446241\n",
      "Validation loss decreased (3.81837 --> 3.44624).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.468538 \tValidation Loss: 3.082068\n",
      "Validation loss decreased (3.44624 --> 3.08207).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.722422 \tValidation Loss: 2.768296\n",
      "Validation loss decreased (3.08207 --> 2.76830).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.092401 \tValidation Loss: 2.524735\n",
      "Validation loss decreased (2.76830 --> 2.52473).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.608931 \tValidation Loss: 2.345783\n",
      "Validation loss decreased (2.52473 --> 2.34578).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.246817 \tValidation Loss: 2.215197\n",
      "Validation loss decreased (2.34578 --> 2.21520).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.971976 \tValidation Loss: 2.119748\n",
      "Validation loss decreased (2.21520 --> 2.11975).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.766742 \tValidation Loss: 2.050370\n",
      "Validation loss decreased (2.11975 --> 2.05037).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.606643 \tValidation Loss: 1.998607\n",
      "Validation loss decreased (2.05037 --> 1.99861).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.488367 \tValidation Loss: 1.962940\n",
      "Validation loss decreased (1.99861 --> 1.96294).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.396358 \tValidation Loss: 1.939928\n",
      "Validation loss decreased (1.96294 --> 1.93993).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.328923 \tValidation Loss: 1.926659\n",
      "Validation loss decreased (1.93993 --> 1.92666).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.273662 \tValidation Loss: 1.919070\n",
      "Validation loss decreased (1.92666 --> 1.91907).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.232906 \tValidation Loss: 1.914685\n",
      "Validation loss decreased (1.91907 --> 1.91468).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.203015 \tValidation Loss: 1.915548\n",
      "Epoch: 19 \tTraining Loss: 0.178966 \tValidation Loss: 1.918811\n",
      "Epoch: 20 \tTraining Loss: 0.157915 \tValidation Loss: 1.921729\n",
      "Epoch: 1 \tTraining Loss: 6.334746 \tValidation Loss: 4.417893\n",
      "Validation loss decreased (inf --> 4.41789).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.449656 \tValidation Loss: 4.127821\n",
      "Validation loss decreased (4.41789 --> 4.12782).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.927718 \tValidation Loss: 3.812571\n",
      "Validation loss decreased (4.12782 --> 3.81257).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.254312 \tValidation Loss: 3.425465\n",
      "Validation loss decreased (3.81257 --> 3.42547).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.483158 \tValidation Loss: 3.035223\n",
      "Validation loss decreased (3.42547 --> 3.03522).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.734373 \tValidation Loss: 2.705417\n",
      "Validation loss decreased (3.03522 --> 2.70542).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.106881 \tValidation Loss: 2.451543\n",
      "Validation loss decreased (2.70542 --> 2.45154).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.615354 \tValidation Loss: 2.262045\n",
      "Validation loss decreased (2.45154 --> 2.26204).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.250900 \tValidation Loss: 2.121566\n",
      "Validation loss decreased (2.26204 --> 2.12157).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.975091 \tValidation Loss: 2.016749\n",
      "Validation loss decreased (2.12157 --> 2.01675).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.765473 \tValidation Loss: 1.940565\n",
      "Validation loss decreased (2.01675 --> 1.94057).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.611229 \tValidation Loss: 1.884775\n",
      "Validation loss decreased (1.94057 --> 1.88478).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.488510 \tValidation Loss: 1.842693\n",
      "Validation loss decreased (1.88478 --> 1.84269).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.397566 \tValidation Loss: 1.815573\n",
      "Validation loss decreased (1.84269 --> 1.81557).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.328769 \tValidation Loss: 1.799195\n",
      "Validation loss decreased (1.81557 --> 1.79920).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.274980 \tValidation Loss: 1.791373\n",
      "Validation loss decreased (1.79920 --> 1.79137).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.233633 \tValidation Loss: 1.786668\n",
      "Validation loss decreased (1.79137 --> 1.78667).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.203451 \tValidation Loss: 1.785107\n",
      "Validation loss decreased (1.78667 --> 1.78511).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.177850 \tValidation Loss: 1.787016\n",
      "Epoch: 20 \tTraining Loss: 0.160324 \tValidation Loss: 1.791285\n",
      "Epoch: 1 \tTraining Loss: 6.334592 \tValidation Loss: 4.448206\n",
      "Validation loss decreased (inf --> 4.44821).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.442747 \tValidation Loss: 4.180260\n",
      "Validation loss decreased (4.44821 --> 4.18026).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.912782 \tValidation Loss: 3.877898\n",
      "Validation loss decreased (4.18026 --> 3.87790).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.232658 \tValidation Loss: 3.509667\n",
      "Validation loss decreased (3.87790 --> 3.50967).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.463403 \tValidation Loss: 3.133283\n",
      "Validation loss decreased (3.50967 --> 3.13328).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.725618 \tValidation Loss: 2.798262\n",
      "Validation loss decreased (3.13328 --> 2.79826).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.100099 \tValidation Loss: 2.530596\n",
      "Validation loss decreased (2.79826 --> 2.53060).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.615278 \tValidation Loss: 2.327688\n",
      "Validation loss decreased (2.53060 --> 2.32769).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.253687 \tValidation Loss: 2.174885\n",
      "Validation loss decreased (2.32769 --> 2.17489).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.981167 \tValidation Loss: 2.062112\n",
      "Validation loss decreased (2.17489 --> 2.06211).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.775055 \tValidation Loss: 1.978582\n",
      "Validation loss decreased (2.06211 --> 1.97858).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.614445 \tValidation Loss: 1.917625\n",
      "Validation loss decreased (1.97858 --> 1.91763).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 \tTraining Loss: 0.494901 \tValidation Loss: 1.875758\n",
      "Validation loss decreased (1.91763 --> 1.87576).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.401384 \tValidation Loss: 1.847353\n",
      "Validation loss decreased (1.87576 --> 1.84735).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.331938 \tValidation Loss: 1.829139\n",
      "Validation loss decreased (1.84735 --> 1.82914).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.275564 \tValidation Loss: 1.817016\n",
      "Validation loss decreased (1.82914 --> 1.81702).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.235744 \tValidation Loss: 1.811722\n",
      "Validation loss decreased (1.81702 --> 1.81172).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.204908 \tValidation Loss: 1.811220\n",
      "Validation loss decreased (1.81172 --> 1.81122).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.179091 \tValidation Loss: 1.813298\n",
      "Epoch: 20 \tTraining Loss: 0.159104 \tValidation Loss: 1.815541\n",
      "Epoch: 1 \tTraining Loss: 6.338475 \tValidation Loss: 4.405892\n",
      "Validation loss decreased (inf --> 4.40589).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.450916 \tValidation Loss: 4.108884\n",
      "Validation loss decreased (4.40589 --> 4.10888).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.930319 \tValidation Loss: 3.779067\n",
      "Validation loss decreased (4.10888 --> 3.77907).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.253505 \tValidation Loss: 3.388772\n",
      "Validation loss decreased (3.77907 --> 3.38877).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.478955 \tValidation Loss: 3.007711\n",
      "Validation loss decreased (3.38877 --> 3.00771).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.738891 \tValidation Loss: 2.679567\n",
      "Validation loss decreased (3.00771 --> 2.67957).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.113962 \tValidation Loss: 2.415604\n",
      "Validation loss decreased (2.67957 --> 2.41560).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.628569 \tValidation Loss: 2.207441\n",
      "Validation loss decreased (2.41560 --> 2.20744).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.261663 \tValidation Loss: 2.047329\n",
      "Validation loss decreased (2.20744 --> 2.04733).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.983945 \tValidation Loss: 1.926329\n",
      "Validation loss decreased (2.04733 --> 1.92633).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.777724 \tValidation Loss: 1.837252\n",
      "Validation loss decreased (1.92633 --> 1.83725).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.619061 \tValidation Loss: 1.773287\n",
      "Validation loss decreased (1.83725 --> 1.77329).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.494310 \tValidation Loss: 1.729473\n",
      "Validation loss decreased (1.77329 --> 1.72947).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.403016 \tValidation Loss: 1.698262\n",
      "Validation loss decreased (1.72947 --> 1.69826).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.330415 \tValidation Loss: 1.677511\n",
      "Validation loss decreased (1.69826 --> 1.67751).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.277556 \tValidation Loss: 1.666672\n",
      "Validation loss decreased (1.67751 --> 1.66667).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.234886 \tValidation Loss: 1.660224\n",
      "Validation loss decreased (1.66667 --> 1.66022).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.203961 \tValidation Loss: 1.658294\n",
      "Validation loss decreased (1.66022 --> 1.65829).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.178379 \tValidation Loss: 1.660502\n",
      "Epoch: 20 \tTraining Loss: 0.159858 \tValidation Loss: 1.662292\n",
      "Epoch: 1 \tTraining Loss: 6.329466 \tValidation Loss: 4.402199\n",
      "Validation loss decreased (inf --> 4.40220).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.443648 \tValidation Loss: 4.122582\n",
      "Validation loss decreased (4.40220 --> 4.12258).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.923665 \tValidation Loss: 3.800143\n",
      "Validation loss decreased (4.12258 --> 3.80014).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.243617 \tValidation Loss: 3.417668\n",
      "Validation loss decreased (3.80014 --> 3.41767).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.467846 \tValidation Loss: 3.033304\n",
      "Validation loss decreased (3.41767 --> 3.03330).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.719739 \tValidation Loss: 2.701319\n",
      "Validation loss decreased (3.03330 --> 2.70132).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.099790 \tValidation Loss: 2.444221\n",
      "Validation loss decreased (2.70132 --> 2.44422).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.617234 \tValidation Loss: 2.249954\n",
      "Validation loss decreased (2.44422 --> 2.24995).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.253346 \tValidation Loss: 2.105437\n",
      "Validation loss decreased (2.24995 --> 2.10544).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.980309 \tValidation Loss: 1.997648\n",
      "Validation loss decreased (2.10544 --> 1.99765).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.772618 \tValidation Loss: 1.920640\n",
      "Validation loss decreased (1.99765 --> 1.92064).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.613341 \tValidation Loss: 1.865507\n",
      "Validation loss decreased (1.92064 --> 1.86551).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.490866 \tValidation Loss: 1.829998\n",
      "Validation loss decreased (1.86551 --> 1.83000).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.400806 \tValidation Loss: 1.806300\n",
      "Validation loss decreased (1.83000 --> 1.80630).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.329728 \tValidation Loss: 1.791178\n",
      "Validation loss decreased (1.80630 --> 1.79118).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.274886 \tValidation Loss: 1.783915\n",
      "Validation loss decreased (1.79118 --> 1.78391).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.234580 \tValidation Loss: 1.782029\n",
      "Validation loss decreased (1.78391 --> 1.78203).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.201938 \tValidation Loss: 1.784436\n",
      "Epoch: 19 \tTraining Loss: 0.177300 \tValidation Loss: 1.786272\n",
      "Epoch: 20 \tTraining Loss: 0.156818 \tValidation Loss: 1.790578\n",
      "Epoch: 1 \tTraining Loss: 6.328209 \tValidation Loss: 4.443408\n",
      "Validation loss decreased (inf --> 4.44341).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.443141 \tValidation Loss: 4.175140\n",
      "Validation loss decreased (4.44341 --> 4.17514).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.918884 \tValidation Loss: 3.869456\n",
      "Validation loss decreased (4.17514 --> 3.86946).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.230221 \tValidation Loss: 3.498787\n",
      "Validation loss decreased (3.86946 --> 3.49879).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.447075 \tValidation Loss: 3.124534\n",
      "Validation loss decreased (3.49879 --> 3.12453).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.705981 \tValidation Loss: 2.800374\n",
      "Validation loss decreased (3.12453 --> 2.80037).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.084892 \tValidation Loss: 2.543239\n",
      "Validation loss decreased (2.80037 --> 2.54324).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.605506 \tValidation Loss: 2.349899\n",
      "Validation loss decreased (2.54324 --> 2.34990).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.243608 \tValidation Loss: 2.201397\n",
      "Validation loss decreased (2.34990 --> 2.20140).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.976055 \tValidation Loss: 2.088282\n",
      "Validation loss decreased (2.20140 --> 2.08828).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.768561 \tValidation Loss: 2.001158\n",
      "Validation loss decreased (2.08828 --> 2.00116).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.611639 \tValidation Loss: 1.937648\n",
      "Validation loss decreased (2.00116 --> 1.93765).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.491237 \tValidation Loss: 1.891328\n",
      "Validation loss decreased (1.93765 --> 1.89133).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.396835 \tValidation Loss: 1.859686\n",
      "Validation loss decreased (1.89133 --> 1.85969).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.326516 \tValidation Loss: 1.838655\n",
      "Validation loss decreased (1.85969 --> 1.83865).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.273187 \tValidation Loss: 1.826422\n",
      "Validation loss decreased (1.83865 --> 1.82642).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.232474 \tValidation Loss: 1.819051\n",
      "Validation loss decreased (1.82642 --> 1.81905).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.200830 \tValidation Loss: 1.818821\n",
      "Validation loss decreased (1.81905 --> 1.81882).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.177376 \tValidation Loss: 1.819971\n",
      "Epoch: 20 \tTraining Loss: 0.156677 \tValidation Loss: 1.823889\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 9 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.349231 \tValidation Loss: 5.429209\n",
      "Validation loss decreased (inf --> 5.42921).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 5.435211 \tValidation Loss: 5.018038\n",
      "Validation loss decreased (5.42921 --> 5.01804).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.929756 \tValidation Loss: 4.664087\n",
      "Validation loss decreased (5.01804 --> 4.66409).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.296098 \tValidation Loss: 4.235284\n",
      "Validation loss decreased (4.66409 --> 4.23528).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.559539 \tValidation Loss: 3.809832\n",
      "Validation loss decreased (4.23528 --> 3.80983).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.839672 \tValidation Loss: 3.447521\n",
      "Validation loss decreased (3.80983 --> 3.44752).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.224178 \tValidation Loss: 3.157452\n",
      "Validation loss decreased (3.44752 --> 3.15745).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.732609 \tValidation Loss: 2.929064\n",
      "Validation loss decreased (3.15745 --> 2.92906).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.352404 \tValidation Loss: 2.753103\n",
      "Validation loss decreased (2.92906 --> 2.75310).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.060842 \tValidation Loss: 2.620366\n",
      "Validation loss decreased (2.75310 --> 2.62037).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.840870 \tValidation Loss: 2.518409\n",
      "Validation loss decreased (2.62037 --> 2.51841).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.671494 \tValidation Loss: 2.444825\n",
      "Validation loss decreased (2.51841 --> 2.44482).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.537465 \tValidation Loss: 2.388750\n",
      "Validation loss decreased (2.44482 --> 2.38875).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.434585 \tValidation Loss: 2.350439\n",
      "Validation loss decreased (2.38875 --> 2.35044).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.354925 \tValidation Loss: 2.324047\n",
      "Validation loss decreased (2.35044 --> 2.32405).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.294485 \tValidation Loss: 2.308856\n",
      "Validation loss decreased (2.32405 --> 2.30886).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.248760 \tValidation Loss: 2.299496\n",
      "Validation loss decreased (2.30886 --> 2.29950).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.212557 \tValidation Loss: 2.295930\n",
      "Validation loss decreased (2.29950 --> 2.29593).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.184803 \tValidation Loss: 2.298529\n",
      "Epoch: 20 \tTraining Loss: 0.161986 \tValidation Loss: 2.300969\n",
      "Epoch: 1 \tTraining Loss: 6.357695 \tValidation Loss: 5.435732\n",
      "Validation loss decreased (inf --> 5.43573).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.422448 \tValidation Loss: 5.000334\n",
      "Validation loss decreased (5.43573 --> 5.00033).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.898563 \tValidation Loss: 4.643016\n",
      "Validation loss decreased (5.00033 --> 4.64302).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.269148 \tValidation Loss: 4.214150\n",
      "Validation loss decreased (4.64302 --> 4.21415).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.541783 \tValidation Loss: 3.789168\n",
      "Validation loss decreased (4.21415 --> 3.78917).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.827292 \tValidation Loss: 3.411447\n",
      "Validation loss decreased (3.78917 --> 3.41145).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.209171 \tValidation Loss: 3.107748\n",
      "Validation loss decreased (3.41145 --> 3.10775).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.717677 \tValidation Loss: 2.875312\n",
      "Validation loss decreased (3.10775 --> 2.87531).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.339365 \tValidation Loss: 2.697252\n",
      "Validation loss decreased (2.87531 --> 2.69725).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.050637 \tValidation Loss: 2.560645\n",
      "Validation loss decreased (2.69725 --> 2.56065).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.831023 \tValidation Loss: 2.456022\n",
      "Validation loss decreased (2.56065 --> 2.45602).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.663618 \tValidation Loss: 2.376300\n",
      "Validation loss decreased (2.45602 --> 2.37630).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.528455 \tValidation Loss: 2.320299\n",
      "Validation loss decreased (2.37630 --> 2.32030).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.427385 \tValidation Loss: 2.280977\n",
      "Validation loss decreased (2.32030 --> 2.28098).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.351836 \tValidation Loss: 2.254522\n",
      "Validation loss decreased (2.28098 --> 2.25452).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.289124 \tValidation Loss: 2.236803\n",
      "Validation loss decreased (2.25452 --> 2.23680).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.244637 \tValidation Loss: 2.226296\n",
      "Validation loss decreased (2.23680 --> 2.22630).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.209183 \tValidation Loss: 2.219920\n",
      "Validation loss decreased (2.22630 --> 2.21992).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.182807 \tValidation Loss: 2.217233\n",
      "Validation loss decreased (2.21992 --> 2.21723).  Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 0.160508 \tValidation Loss: 2.217795\n",
      "Epoch: 1 \tTraining Loss: 6.364292 \tValidation Loss: 5.429557\n",
      "Validation loss decreased (inf --> 5.42956).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.444180 \tValidation Loss: 4.994381\n",
      "Validation loss decreased (5.42956 --> 4.99438).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.936989 \tValidation Loss: 4.658745\n",
      "Validation loss decreased (4.99438 --> 4.65874).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.315027 \tValidation Loss: 4.248502\n",
      "Validation loss decreased (4.65874 --> 4.24850).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.591223 \tValidation Loss: 3.829092\n",
      "Validation loss decreased (4.24850 --> 3.82909).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.872111 \tValidation Loss: 3.458834\n",
      "Validation loss decreased (3.82909 --> 3.45883).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.250073 \tValidation Loss: 3.158369\n",
      "Validation loss decreased (3.45883 --> 3.15837).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.755692 \tValidation Loss: 2.924387\n",
      "Validation loss decreased (3.15837 --> 2.92439).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.374702 \tValidation Loss: 2.745208\n",
      "Validation loss decreased (2.92439 --> 2.74521).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.083237 \tValidation Loss: 2.610473\n",
      "Validation loss decreased (2.74521 --> 2.61047).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.859034 \tValidation Loss: 2.507662\n",
      "Validation loss decreased (2.61047 --> 2.50766).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.684068 \tValidation Loss: 2.433397\n",
      "Validation loss decreased (2.50766 --> 2.43340).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.546767 \tValidation Loss: 2.377679\n",
      "Validation loss decreased (2.43340 --> 2.37768).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.441536 \tValidation Loss: 2.338355\n",
      "Validation loss decreased (2.37768 --> 2.33836).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.361506 \tValidation Loss: 2.313756\n",
      "Validation loss decreased (2.33836 --> 2.31376).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.299330 \tValidation Loss: 2.299074\n",
      "Validation loss decreased (2.31376 --> 2.29907).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.253725 \tValidation Loss: 2.292727\n",
      "Validation loss decreased (2.29907 --> 2.29273).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.213975 \tValidation Loss: 2.292589\n",
      "Validation loss decreased (2.29273 --> 2.29259).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.188530 \tValidation Loss: 2.295140\n",
      "Epoch: 20 \tTraining Loss: 0.166213 \tValidation Loss: 2.301722\n",
      "Epoch: 1 \tTraining Loss: 6.354287 \tValidation Loss: 5.414351\n",
      "Validation loss decreased (inf --> 5.41435).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.442555 \tValidation Loss: 4.983238\n",
      "Validation loss decreased (5.41435 --> 4.98324).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.936384 \tValidation Loss: 4.647144\n",
      "Validation loss decreased (4.98324 --> 4.64714).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.313392 \tValidation Loss: 4.231796\n",
      "Validation loss decreased (4.64714 --> 4.23180).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.584034 \tValidation Loss: 3.803971\n",
      "Validation loss decreased (4.23180 --> 3.80397).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.862238 \tValidation Loss: 3.425868\n",
      "Validation loss decreased (3.80397 --> 3.42587).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.239493 \tValidation Loss: 3.127130\n",
      "Validation loss decreased (3.42587 --> 3.12713).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.741042 \tValidation Loss: 2.901855\n",
      "Validation loss decreased (3.12713 --> 2.90186).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 \tTraining Loss: 1.360893 \tValidation Loss: 2.729418\n",
      "Validation loss decreased (2.90186 --> 2.72942).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.067722 \tValidation Loss: 2.596637\n",
      "Validation loss decreased (2.72942 --> 2.59664).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.843286 \tValidation Loss: 2.496983\n",
      "Validation loss decreased (2.59664 --> 2.49698).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.670904 \tValidation Loss: 2.425306\n",
      "Validation loss decreased (2.49698 --> 2.42531).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.533855 \tValidation Loss: 2.375006\n",
      "Validation loss decreased (2.42531 --> 2.37501).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.431035 \tValidation Loss: 2.341094\n",
      "Validation loss decreased (2.37501 --> 2.34109).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.351183 \tValidation Loss: 2.319606\n",
      "Validation loss decreased (2.34109 --> 2.31961).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.292916 \tValidation Loss: 2.308320\n",
      "Validation loss decreased (2.31961 --> 2.30832).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.245205 \tValidation Loss: 2.300444\n",
      "Validation loss decreased (2.30832 --> 2.30044).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.210415 \tValidation Loss: 2.298468\n",
      "Validation loss decreased (2.30044 --> 2.29847).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.182830 \tValidation Loss: 2.301011\n",
      "Epoch: 20 \tTraining Loss: 0.160837 \tValidation Loss: 2.308455\n",
      "Epoch: 1 \tTraining Loss: 6.362218 \tValidation Loss: 5.421624\n",
      "Validation loss decreased (inf --> 5.42162).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.436765 \tValidation Loss: 4.970924\n",
      "Validation loss decreased (5.42162 --> 4.97092).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.922791 \tValidation Loss: 4.635238\n",
      "Validation loss decreased (4.97092 --> 4.63524).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.292826 \tValidation Loss: 4.219273\n",
      "Validation loss decreased (4.63524 --> 4.21927).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.558501 \tValidation Loss: 3.791907\n",
      "Validation loss decreased (4.21927 --> 3.79191).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.835732 \tValidation Loss: 3.422631\n",
      "Validation loss decreased (3.79191 --> 3.42263).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.215143 \tValidation Loss: 3.132903\n",
      "Validation loss decreased (3.42263 --> 3.13290).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.723292 \tValidation Loss: 2.910532\n",
      "Validation loss decreased (3.13290 --> 2.91053).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.346660 \tValidation Loss: 2.737234\n",
      "Validation loss decreased (2.91053 --> 2.73723).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.059257 \tValidation Loss: 2.604028\n",
      "Validation loss decreased (2.73723 --> 2.60403).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.839461 \tValidation Loss: 2.502037\n",
      "Validation loss decreased (2.60403 --> 2.50204).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.666741 \tValidation Loss: 2.425150\n",
      "Validation loss decreased (2.50204 --> 2.42515).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.533319 \tValidation Loss: 2.368723\n",
      "Validation loss decreased (2.42515 --> 2.36872).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.430188 \tValidation Loss: 2.329962\n",
      "Validation loss decreased (2.36872 --> 2.32996).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.351881 \tValidation Loss: 2.304826\n",
      "Validation loss decreased (2.32996 --> 2.30483).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.293208 \tValidation Loss: 2.290958\n",
      "Validation loss decreased (2.30483 --> 2.29096).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.246129 \tValidation Loss: 2.282181\n",
      "Validation loss decreased (2.29096 --> 2.28218).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.210656 \tValidation Loss: 2.281224\n",
      "Validation loss decreased (2.28218 --> 2.28122).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.183667 \tValidation Loss: 2.280277\n",
      "Validation loss decreased (2.28122 --> 2.28028).  Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 0.161446 \tValidation Loss: 2.283626\n",
      "Epoch: 1 \tTraining Loss: 6.358425 \tValidation Loss: 5.418833\n",
      "Validation loss decreased (inf --> 5.41883).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.442333 \tValidation Loss: 4.997403\n",
      "Validation loss decreased (5.41883 --> 4.99740).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.936551 \tValidation Loss: 4.666660\n",
      "Validation loss decreased (4.99740 --> 4.66666).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.310638 \tValidation Loss: 4.259777\n",
      "Validation loss decreased (4.66666 --> 4.25978).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.583678 \tValidation Loss: 3.839195\n",
      "Validation loss decreased (4.25978 --> 3.83919).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.862360 \tValidation Loss: 3.467248\n",
      "Validation loss decreased (3.83919 --> 3.46725).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.237616 \tValidation Loss: 3.172173\n",
      "Validation loss decreased (3.46725 --> 3.17217).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.742237 \tValidation Loss: 2.947234\n",
      "Validation loss decreased (3.17217 --> 2.94723).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.365416 \tValidation Loss: 2.773550\n",
      "Validation loss decreased (2.94723 --> 2.77355).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.072543 \tValidation Loss: 2.638715\n",
      "Validation loss decreased (2.77355 --> 2.63872).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.850673 \tValidation Loss: 2.534244\n",
      "Validation loss decreased (2.63872 --> 2.53424).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.673557 \tValidation Loss: 2.456685\n",
      "Validation loss decreased (2.53424 --> 2.45668).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.537428 \tValidation Loss: 2.401325\n",
      "Validation loss decreased (2.45668 --> 2.40132).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.435349 \tValidation Loss: 2.363668\n",
      "Validation loss decreased (2.40132 --> 2.36367).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.353881 \tValidation Loss: 2.336140\n",
      "Validation loss decreased (2.36367 --> 2.33614).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.291490 \tValidation Loss: 2.319564\n",
      "Validation loss decreased (2.33614 --> 2.31956).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.245735 \tValidation Loss: 2.313486\n",
      "Validation loss decreased (2.31956 --> 2.31349).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.210996 \tValidation Loss: 2.313278\n",
      "Validation loss decreased (2.31349 --> 2.31328).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.181319 \tValidation Loss: 2.316305\n",
      "Epoch: 20 \tTraining Loss: 0.163142 \tValidation Loss: 2.321600\n",
      "Epoch: 1 \tTraining Loss: 6.354640 \tValidation Loss: 5.443220\n",
      "Validation loss decreased (inf --> 5.44322).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.425226 \tValidation Loss: 5.028923\n",
      "Validation loss decreased (5.44322 --> 5.02892).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.919035 \tValidation Loss: 4.680104\n",
      "Validation loss decreased (5.02892 --> 4.68010).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.297207 \tValidation Loss: 4.265527\n",
      "Validation loss decreased (4.68010 --> 4.26553).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.573903 \tValidation Loss: 3.839062\n",
      "Validation loss decreased (4.26553 --> 3.83906).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.860892 \tValidation Loss: 3.462009\n",
      "Validation loss decreased (3.83906 --> 3.46201).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.241868 \tValidation Loss: 3.156541\n",
      "Validation loss decreased (3.46201 --> 3.15654).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.749574 \tValidation Loss: 2.917675\n",
      "Validation loss decreased (3.15654 --> 2.91767).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.366812 \tValidation Loss: 2.731980\n",
      "Validation loss decreased (2.91767 --> 2.73198).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.075680 \tValidation Loss: 2.588014\n",
      "Validation loss decreased (2.73198 --> 2.58801).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.849211 \tValidation Loss: 2.475473\n",
      "Validation loss decreased (2.58801 --> 2.47547).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.677389 \tValidation Loss: 2.391426\n",
      "Validation loss decreased (2.47547 --> 2.39143).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.542783 \tValidation Loss: 2.328670\n",
      "Validation loss decreased (2.39143 --> 2.32867).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.437875 \tValidation Loss: 2.285570\n",
      "Validation loss decreased (2.32867 --> 2.28557).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.358346 \tValidation Loss: 2.255751\n",
      "Validation loss decreased (2.28557 --> 2.25575).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 \tTraining Loss: 0.297306 \tValidation Loss: 2.236452\n",
      "Validation loss decreased (2.25575 --> 2.23645).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.251651 \tValidation Loss: 2.226609\n",
      "Validation loss decreased (2.23645 --> 2.22661).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.215507 \tValidation Loss: 2.221772\n",
      "Validation loss decreased (2.22661 --> 2.22177).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.186437 \tValidation Loss: 2.219583\n",
      "Validation loss decreased (2.22177 --> 2.21958).  Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 0.164533 \tValidation Loss: 2.221198\n",
      "Epoch: 1 \tTraining Loss: 6.351537 \tValidation Loss: 5.451334\n",
      "Validation loss decreased (inf --> 5.45133).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.433097 \tValidation Loss: 5.073117\n",
      "Validation loss decreased (5.45133 --> 5.07312).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.931895 \tValidation Loss: 4.728418\n",
      "Validation loss decreased (5.07312 --> 4.72842).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.305429 \tValidation Loss: 4.303700\n",
      "Validation loss decreased (4.72842 --> 4.30370).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.576307 \tValidation Loss: 3.861685\n",
      "Validation loss decreased (4.30370 --> 3.86168).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.856819 \tValidation Loss: 3.469756\n",
      "Validation loss decreased (3.86168 --> 3.46976).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.232786 \tValidation Loss: 3.156200\n",
      "Validation loss decreased (3.46976 --> 3.15620).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.738009 \tValidation Loss: 2.914006\n",
      "Validation loss decreased (3.15620 --> 2.91401).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.356833 \tValidation Loss: 2.728969\n",
      "Validation loss decreased (2.91401 --> 2.72897).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.068767 \tValidation Loss: 2.589259\n",
      "Validation loss decreased (2.72897 --> 2.58926).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.847575 \tValidation Loss: 2.484710\n",
      "Validation loss decreased (2.58926 --> 2.48471).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.673660 \tValidation Loss: 2.409090\n",
      "Validation loss decreased (2.48471 --> 2.40909).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.540374 \tValidation Loss: 2.352525\n",
      "Validation loss decreased (2.40909 --> 2.35253).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.434655 \tValidation Loss: 2.314268\n",
      "Validation loss decreased (2.35253 --> 2.31427).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.353980 \tValidation Loss: 2.287224\n",
      "Validation loss decreased (2.31427 --> 2.28722).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.295333 \tValidation Loss: 2.273802\n",
      "Validation loss decreased (2.28722 --> 2.27380).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.247499 \tValidation Loss: 2.266788\n",
      "Validation loss decreased (2.27380 --> 2.26679).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.212754 \tValidation Loss: 2.264759\n",
      "Validation loss decreased (2.26679 --> 2.26476).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.183224 \tValidation Loss: 2.264165\n",
      "Validation loss decreased (2.26476 --> 2.26416).  Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 0.161597 \tValidation Loss: 2.269552\n",
      "Epoch: 1 \tTraining Loss: 6.358166 \tValidation Loss: 5.432715\n",
      "Validation loss decreased (inf --> 5.43272).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.436422 \tValidation Loss: 4.999199\n",
      "Validation loss decreased (5.43272 --> 4.99920).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.925107 \tValidation Loss: 4.649103\n",
      "Validation loss decreased (4.99920 --> 4.64910).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.299440 \tValidation Loss: 4.221195\n",
      "Validation loss decreased (4.64910 --> 4.22120).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.577810 \tValidation Loss: 3.782740\n",
      "Validation loss decreased (4.22120 --> 3.78274).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.862528 \tValidation Loss: 3.393261\n",
      "Validation loss decreased (3.78274 --> 3.39326).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.242930 \tValidation Loss: 3.076773\n",
      "Validation loss decreased (3.39326 --> 3.07677).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.753096 \tValidation Loss: 2.826350\n",
      "Validation loss decreased (3.07677 --> 2.82635).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.369843 \tValidation Loss: 2.630252\n",
      "Validation loss decreased (2.82635 --> 2.63025).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.079220 \tValidation Loss: 2.479446\n",
      "Validation loss decreased (2.63025 --> 2.47945).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.854020 \tValidation Loss: 2.365048\n",
      "Validation loss decreased (2.47945 --> 2.36505).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.678719 \tValidation Loss: 2.280664\n",
      "Validation loss decreased (2.36505 --> 2.28066).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.544348 \tValidation Loss: 2.217722\n",
      "Validation loss decreased (2.28066 --> 2.21772).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.440149 \tValidation Loss: 2.174172\n",
      "Validation loss decreased (2.21772 --> 2.17417).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.355555 \tValidation Loss: 2.142786\n",
      "Validation loss decreased (2.17417 --> 2.14279).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.295003 \tValidation Loss: 2.125434\n",
      "Validation loss decreased (2.14279 --> 2.12543).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.249141 \tValidation Loss: 2.113138\n",
      "Validation loss decreased (2.12543 --> 2.11314).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.214096 \tValidation Loss: 2.108203\n",
      "Validation loss decreased (2.11314 --> 2.10820).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.186706 \tValidation Loss: 2.104378\n",
      "Validation loss decreased (2.10820 --> 2.10438).  Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 0.164772 \tValidation Loss: 2.105121\n",
      "Epoch: 1 \tTraining Loss: 6.360236 \tValidation Loss: 5.429350\n",
      "Validation loss decreased (inf --> 5.42935).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.429565 \tValidation Loss: 4.996908\n",
      "Validation loss decreased (5.42935 --> 4.99691).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.927999 \tValidation Loss: 4.647902\n",
      "Validation loss decreased (4.99691 --> 4.64790).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.304879 \tValidation Loss: 4.224160\n",
      "Validation loss decreased (4.64790 --> 4.22416).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.580383 \tValidation Loss: 3.787543\n",
      "Validation loss decreased (4.22416 --> 3.78754).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.860163 \tValidation Loss: 3.406073\n",
      "Validation loss decreased (3.78754 --> 3.40607).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.233723 \tValidation Loss: 3.105843\n",
      "Validation loss decreased (3.40607 --> 3.10584).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.738008 \tValidation Loss: 2.877983\n",
      "Validation loss decreased (3.10584 --> 2.87798).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.356223 \tValidation Loss: 2.706096\n",
      "Validation loss decreased (2.87798 --> 2.70610).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.063780 \tValidation Loss: 2.573392\n",
      "Validation loss decreased (2.70610 --> 2.57339).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.837656 \tValidation Loss: 2.469539\n",
      "Validation loss decreased (2.57339 --> 2.46954).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.666678 \tValidation Loss: 2.390696\n",
      "Validation loss decreased (2.46954 --> 2.39070).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.532871 \tValidation Loss: 2.333412\n",
      "Validation loss decreased (2.39070 --> 2.33341).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.429754 \tValidation Loss: 2.291108\n",
      "Validation loss decreased (2.33341 --> 2.29111).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.349309 \tValidation Loss: 2.264312\n",
      "Validation loss decreased (2.29111 --> 2.26431).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.290988 \tValidation Loss: 2.246786\n",
      "Validation loss decreased (2.26431 --> 2.24679).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.242035 \tValidation Loss: 2.238788\n",
      "Validation loss decreased (2.24679 --> 2.23879).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.207978 \tValidation Loss: 2.235187\n",
      "Validation loss decreased (2.23879 --> 2.23519).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.179654 \tValidation Loss: 2.238485\n",
      "Epoch: 20 \tTraining Loss: 0.158283 \tValidation Loss: 2.244374\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 10 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.543226 \tValidation Loss: 4.576860\n",
      "Validation loss decreased (inf --> 4.57686).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.600136 \tValidation Loss: 4.136914\n",
      "Validation loss decreased (4.57686 --> 4.13691).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \tTraining Loss: 5.056239 \tValidation Loss: 3.867142\n",
      "Validation loss decreased (4.13691 --> 3.86714).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.464192 \tValidation Loss: 3.556947\n",
      "Validation loss decreased (3.86714 --> 3.55695).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.773094 \tValidation Loss: 3.225582\n",
      "Validation loss decreased (3.55695 --> 3.22558).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.066230 \tValidation Loss: 2.914014\n",
      "Validation loss decreased (3.22558 --> 2.91401).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.433720 \tValidation Loss: 2.656347\n",
      "Validation loss decreased (2.91401 --> 2.65635).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.918090 \tValidation Loss: 2.454940\n",
      "Validation loss decreased (2.65635 --> 2.45494).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.513724 \tValidation Loss: 2.296554\n",
      "Validation loss decreased (2.45494 --> 2.29655).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.200038 \tValidation Loss: 2.174694\n",
      "Validation loss decreased (2.29655 --> 2.17469).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.955122 \tValidation Loss: 2.082178\n",
      "Validation loss decreased (2.17469 --> 2.08218).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.760579 \tValidation Loss: 2.011544\n",
      "Validation loss decreased (2.08218 --> 2.01154).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.611444 \tValidation Loss: 1.961836\n",
      "Validation loss decreased (2.01154 --> 1.96184).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.495002 \tValidation Loss: 1.926552\n",
      "Validation loss decreased (1.96184 --> 1.92655).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.404705 \tValidation Loss: 1.902190\n",
      "Validation loss decreased (1.92655 --> 1.90219).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.332932 \tValidation Loss: 1.886267\n",
      "Validation loss decreased (1.90219 --> 1.88627).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.279388 \tValidation Loss: 1.876964\n",
      "Validation loss decreased (1.88627 --> 1.87696).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.237447 \tValidation Loss: 1.872355\n",
      "Validation loss decreased (1.87696 --> 1.87236).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.203537 \tValidation Loss: 1.870764\n",
      "Validation loss decreased (1.87236 --> 1.87076).  Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 0.177517 \tValidation Loss: 1.871935\n",
      "Epoch: 1 \tTraining Loss: 6.541013 \tValidation Loss: 4.584796\n",
      "Validation loss decreased (inf --> 4.58480).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.590013 \tValidation Loss: 4.147428\n",
      "Validation loss decreased (4.58480 --> 4.14743).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.046432 \tValidation Loss: 3.860462\n",
      "Validation loss decreased (4.14743 --> 3.86046).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.453513 \tValidation Loss: 3.532264\n",
      "Validation loss decreased (3.86046 --> 3.53226).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.762454 \tValidation Loss: 3.193952\n",
      "Validation loss decreased (3.53226 --> 3.19395).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.054509 \tValidation Loss: 2.895561\n",
      "Validation loss decreased (3.19395 --> 2.89556).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.428032 \tValidation Loss: 2.653726\n",
      "Validation loss decreased (2.89556 --> 2.65373).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.918205 \tValidation Loss: 2.461997\n",
      "Validation loss decreased (2.65373 --> 2.46200).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.515054 \tValidation Loss: 2.311081\n",
      "Validation loss decreased (2.46200 --> 2.31108).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.205120 \tValidation Loss: 2.195772\n",
      "Validation loss decreased (2.31108 --> 2.19577).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.963965 \tValidation Loss: 2.106812\n",
      "Validation loss decreased (2.19577 --> 2.10681).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.771105 \tValidation Loss: 2.037906\n",
      "Validation loss decreased (2.10681 --> 2.03791).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.621996 \tValidation Loss: 1.987382\n",
      "Validation loss decreased (2.03791 --> 1.98738).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.501764 \tValidation Loss: 1.950612\n",
      "Validation loss decreased (1.98738 --> 1.95061).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.406131 \tValidation Loss: 1.924272\n",
      "Validation loss decreased (1.95061 --> 1.92427).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.336120 \tValidation Loss: 1.906293\n",
      "Validation loss decreased (1.92427 --> 1.90629).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.279602 \tValidation Loss: 1.894981\n",
      "Validation loss decreased (1.90629 --> 1.89498).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.238439 \tValidation Loss: 1.890210\n",
      "Validation loss decreased (1.89498 --> 1.89021).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.205088 \tValidation Loss: 1.888925\n",
      "Validation loss decreased (1.89021 --> 1.88893).  Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 0.180419 \tValidation Loss: 1.891656\n",
      "Epoch: 1 \tTraining Loss: 6.541277 \tValidation Loss: 4.597255\n",
      "Validation loss decreased (inf --> 4.59726).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.589628 \tValidation Loss: 4.195481\n",
      "Validation loss decreased (4.59726 --> 4.19548).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.058623 \tValidation Loss: 3.906834\n",
      "Validation loss decreased (4.19548 --> 3.90683).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.462288 \tValidation Loss: 3.594241\n",
      "Validation loss decreased (3.90683 --> 3.59424).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.766857 \tValidation Loss: 3.267837\n",
      "Validation loss decreased (3.59424 --> 3.26784).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.058102 \tValidation Loss: 2.963336\n",
      "Validation loss decreased (3.26784 --> 2.96334).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.426911 \tValidation Loss: 2.701523\n",
      "Validation loss decreased (2.96334 --> 2.70152).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.914426 \tValidation Loss: 2.494386\n",
      "Validation loss decreased (2.70152 --> 2.49439).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.512122 \tValidation Loss: 2.336760\n",
      "Validation loss decreased (2.49439 --> 2.33676).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.198213 \tValidation Loss: 2.215667\n",
      "Validation loss decreased (2.33676 --> 2.21567).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.955748 \tValidation Loss: 2.125520\n",
      "Validation loss decreased (2.21567 --> 2.12552).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.764244 \tValidation Loss: 2.059004\n",
      "Validation loss decreased (2.12552 --> 2.05900).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.610733 \tValidation Loss: 2.009900\n",
      "Validation loss decreased (2.05900 --> 2.00990).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.493787 \tValidation Loss: 1.974628\n",
      "Validation loss decreased (2.00990 --> 1.97463).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.403527 \tValidation Loss: 1.949927\n",
      "Validation loss decreased (1.97463 --> 1.94993).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.332359 \tValidation Loss: 1.936448\n",
      "Validation loss decreased (1.94993 --> 1.93645).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.279099 \tValidation Loss: 1.927544\n",
      "Validation loss decreased (1.93645 --> 1.92754).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.235055 \tValidation Loss: 1.923310\n",
      "Validation loss decreased (1.92754 --> 1.92331).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.202980 \tValidation Loss: 1.922975\n",
      "Validation loss decreased (1.92331 --> 1.92298).  Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 0.179463 \tValidation Loss: 1.923699\n",
      "Epoch: 1 \tTraining Loss: 6.535412 \tValidation Loss: 4.562885\n",
      "Validation loss decreased (inf --> 4.56288).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.585828 \tValidation Loss: 4.121834\n",
      "Validation loss decreased (4.56288 --> 4.12183).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.059354 \tValidation Loss: 3.837731\n",
      "Validation loss decreased (4.12183 --> 3.83773).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.463086 \tValidation Loss: 3.518536\n",
      "Validation loss decreased (3.83773 --> 3.51854).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.766509 \tValidation Loss: 3.178916\n",
      "Validation loss decreased (3.51854 --> 3.17892).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.052277 \tValidation Loss: 2.867716\n",
      "Validation loss decreased (3.17892 --> 2.86772).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.415598 \tValidation Loss: 2.614192\n",
      "Validation loss decreased (2.86772 --> 2.61419).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.902726 \tValidation Loss: 2.419706\n",
      "Validation loss decreased (2.61419 --> 2.41971).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 \tTraining Loss: 1.501489 \tValidation Loss: 2.271624\n",
      "Validation loss decreased (2.41971 --> 2.27162).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.194722 \tValidation Loss: 2.157637\n",
      "Validation loss decreased (2.27162 --> 2.15764).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.949506 \tValidation Loss: 2.068870\n",
      "Validation loss decreased (2.15764 --> 2.06887).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.757153 \tValidation Loss: 2.002945\n",
      "Validation loss decreased (2.06887 --> 2.00294).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.609825 \tValidation Loss: 1.952936\n",
      "Validation loss decreased (2.00294 --> 1.95294).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.491449 \tValidation Loss: 1.918873\n",
      "Validation loss decreased (1.95294 --> 1.91887).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.397980 \tValidation Loss: 1.897830\n",
      "Validation loss decreased (1.91887 --> 1.89783).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.328626 \tValidation Loss: 1.881329\n",
      "Validation loss decreased (1.89783 --> 1.88133).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.273805 \tValidation Loss: 1.873451\n",
      "Validation loss decreased (1.88133 --> 1.87345).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.232673 \tValidation Loss: 1.871988\n",
      "Validation loss decreased (1.87345 --> 1.87199).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.200814 \tValidation Loss: 1.873051\n",
      "Epoch: 20 \tTraining Loss: 0.173729 \tValidation Loss: 1.877012\n",
      "Epoch: 1 \tTraining Loss: 6.536013 \tValidation Loss: 4.580130\n",
      "Validation loss decreased (inf --> 4.58013).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.583273 \tValidation Loss: 4.165449\n",
      "Validation loss decreased (4.58013 --> 4.16545).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.058501 \tValidation Loss: 3.896149\n",
      "Validation loss decreased (4.16545 --> 3.89615).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.456008 \tValidation Loss: 3.595193\n",
      "Validation loss decreased (3.89615 --> 3.59519).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.759706 \tValidation Loss: 3.275608\n",
      "Validation loss decreased (3.59519 --> 3.27561).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.047242 \tValidation Loss: 2.982771\n",
      "Validation loss decreased (3.27561 --> 2.98277).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.411978 \tValidation Loss: 2.745305\n",
      "Validation loss decreased (2.98277 --> 2.74531).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.900030 \tValidation Loss: 2.563521\n",
      "Validation loss decreased (2.74531 --> 2.56352).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.500604 \tValidation Loss: 2.424701\n",
      "Validation loss decreased (2.56352 --> 2.42470).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.190821 \tValidation Loss: 2.314743\n",
      "Validation loss decreased (2.42470 --> 2.31474).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.951370 \tValidation Loss: 2.226949\n",
      "Validation loss decreased (2.31474 --> 2.22695).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.759550 \tValidation Loss: 2.157382\n",
      "Validation loss decreased (2.22695 --> 2.15738).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.610671 \tValidation Loss: 2.102662\n",
      "Validation loss decreased (2.15738 --> 2.10266).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.492017 \tValidation Loss: 2.063436\n",
      "Validation loss decreased (2.10266 --> 2.06344).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.404166 \tValidation Loss: 2.033979\n",
      "Validation loss decreased (2.06344 --> 2.03398).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.332583 \tValidation Loss: 2.014518\n",
      "Validation loss decreased (2.03398 --> 2.01452).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.276129 \tValidation Loss: 2.003089\n",
      "Validation loss decreased (2.01452 --> 2.00309).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.235689 \tValidation Loss: 1.996675\n",
      "Validation loss decreased (2.00309 --> 1.99668).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.202888 \tValidation Loss: 1.994262\n",
      "Validation loss decreased (1.99668 --> 1.99426).  Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 0.177671 \tValidation Loss: 1.995256\n",
      "Epoch: 1 \tTraining Loss: 6.551954 \tValidation Loss: 4.618321\n",
      "Validation loss decreased (inf --> 4.61832).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.599701 \tValidation Loss: 4.199219\n",
      "Validation loss decreased (4.61832 --> 4.19922).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.053368 \tValidation Loss: 3.917885\n",
      "Validation loss decreased (4.19922 --> 3.91789).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.449322 \tValidation Loss: 3.597796\n",
      "Validation loss decreased (3.91789 --> 3.59780).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.749796 \tValidation Loss: 3.254599\n",
      "Validation loss decreased (3.59780 --> 3.25460).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.045871 \tValidation Loss: 2.942216\n",
      "Validation loss decreased (3.25460 --> 2.94222).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.416619 \tValidation Loss: 2.689307\n",
      "Validation loss decreased (2.94222 --> 2.68931).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.907247 \tValidation Loss: 2.494524\n",
      "Validation loss decreased (2.68931 --> 2.49452).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.507735 \tValidation Loss: 2.344797\n",
      "Validation loss decreased (2.49452 --> 2.34480).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.197386 \tValidation Loss: 2.227526\n",
      "Validation loss decreased (2.34480 --> 2.22753).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.954008 \tValidation Loss: 2.137705\n",
      "Validation loss decreased (2.22753 --> 2.13771).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.764164 \tValidation Loss: 2.070646\n",
      "Validation loss decreased (2.13771 --> 2.07065).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.614205 \tValidation Loss: 2.018930\n",
      "Validation loss decreased (2.07065 --> 2.01893).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.499046 \tValidation Loss: 1.983148\n",
      "Validation loss decreased (2.01893 --> 1.98315).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.405250 \tValidation Loss: 1.958578\n",
      "Validation loss decreased (1.98315 --> 1.95858).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.335661 \tValidation Loss: 1.940509\n",
      "Validation loss decreased (1.95858 --> 1.94051).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.281375 \tValidation Loss: 1.930396\n",
      "Validation loss decreased (1.94051 --> 1.93040).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.236878 \tValidation Loss: 1.924281\n",
      "Validation loss decreased (1.93040 --> 1.92428).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.206367 \tValidation Loss: 1.923170\n",
      "Validation loss decreased (1.92428 --> 1.92317).  Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 0.181026 \tValidation Loss: 1.924580\n",
      "Epoch: 1 \tTraining Loss: 6.546619 \tValidation Loss: 4.572978\n",
      "Validation loss decreased (inf --> 4.57298).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.599984 \tValidation Loss: 4.099714\n",
      "Validation loss decreased (4.57298 --> 4.09971).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.056204 \tValidation Loss: 3.809971\n",
      "Validation loss decreased (4.09971 --> 3.80997).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.469997 \tValidation Loss: 3.479959\n",
      "Validation loss decreased (3.80997 --> 3.47996).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.783968 \tValidation Loss: 3.130961\n",
      "Validation loss decreased (3.47996 --> 3.13096).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.081424 \tValidation Loss: 2.809358\n",
      "Validation loss decreased (3.13096 --> 2.80936).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.450013 \tValidation Loss: 2.547257\n",
      "Validation loss decreased (2.80936 --> 2.54726).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.935450 \tValidation Loss: 2.346752\n",
      "Validation loss decreased (2.54726 --> 2.34675).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.527001 \tValidation Loss: 2.192059\n",
      "Validation loss decreased (2.34675 --> 2.19206).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.214019 \tValidation Loss: 2.076267\n",
      "Validation loss decreased (2.19206 --> 2.07627).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.965704 \tValidation Loss: 1.986757\n",
      "Validation loss decreased (2.07627 --> 1.98676).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.773763 \tValidation Loss: 1.919723\n",
      "Validation loss decreased (1.98676 --> 1.91972).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.623029 \tValidation Loss: 1.868992\n",
      "Validation loss decreased (1.91972 --> 1.86899).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.500159 \tValidation Loss: 1.833844\n",
      "Validation loss decreased (1.86899 --> 1.83384).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 \tTraining Loss: 0.408344 \tValidation Loss: 1.810099\n",
      "Validation loss decreased (1.83384 --> 1.81010).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.337762 \tValidation Loss: 1.792616\n",
      "Validation loss decreased (1.81010 --> 1.79262).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.281201 \tValidation Loss: 1.780438\n",
      "Validation loss decreased (1.79262 --> 1.78044).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.240035 \tValidation Loss: 1.773868\n",
      "Validation loss decreased (1.78044 --> 1.77387).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.205990 \tValidation Loss: 1.770171\n",
      "Validation loss decreased (1.77387 --> 1.77017).  Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 0.180914 \tValidation Loss: 1.767144\n",
      "Validation loss decreased (1.77017 --> 1.76714).  Saving model ...\n",
      "Epoch: 1 \tTraining Loss: 6.545631 \tValidation Loss: 4.582066\n",
      "Validation loss decreased (inf --> 4.58207).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.593050 \tValidation Loss: 4.125456\n",
      "Validation loss decreased (4.58207 --> 4.12546).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.049130 \tValidation Loss: 3.843186\n",
      "Validation loss decreased (4.12546 --> 3.84319).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.453291 \tValidation Loss: 3.513685\n",
      "Validation loss decreased (3.84319 --> 3.51369).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.760326 \tValidation Loss: 3.175459\n",
      "Validation loss decreased (3.51369 --> 3.17546).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.052787 \tValidation Loss: 2.867041\n",
      "Validation loss decreased (3.17546 --> 2.86704).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.420749 \tValidation Loss: 2.617394\n",
      "Validation loss decreased (2.86704 --> 2.61739).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.909248 \tValidation Loss: 2.428527\n",
      "Validation loss decreased (2.61739 --> 2.42853).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.510817 \tValidation Loss: 2.286621\n",
      "Validation loss decreased (2.42853 --> 2.28662).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.200416 \tValidation Loss: 2.178012\n",
      "Validation loss decreased (2.28662 --> 2.17801).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.961204 \tValidation Loss: 2.095891\n",
      "Validation loss decreased (2.17801 --> 2.09589).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.767042 \tValidation Loss: 2.033382\n",
      "Validation loss decreased (2.09589 --> 2.03338).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.615046 \tValidation Loss: 1.987318\n",
      "Validation loss decreased (2.03338 --> 1.98732).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.497971 \tValidation Loss: 1.955487\n",
      "Validation loss decreased (1.98732 --> 1.95549).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.406201 \tValidation Loss: 1.935659\n",
      "Validation loss decreased (1.95549 --> 1.93566).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.332086 \tValidation Loss: 1.923547\n",
      "Validation loss decreased (1.93566 --> 1.92355).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.277463 \tValidation Loss: 1.915611\n",
      "Validation loss decreased (1.92355 --> 1.91561).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.236807 \tValidation Loss: 1.913943\n",
      "Validation loss decreased (1.91561 --> 1.91394).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.202833 \tValidation Loss: 1.916536\n",
      "Epoch: 20 \tTraining Loss: 0.175859 \tValidation Loss: 1.920829\n",
      "Epoch: 1 \tTraining Loss: 6.541257 \tValidation Loss: 4.554733\n",
      "Validation loss decreased (inf --> 4.55473).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.604568 \tValidation Loss: 4.064902\n",
      "Validation loss decreased (4.55473 --> 4.06490).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.065969 \tValidation Loss: 3.780525\n",
      "Validation loss decreased (4.06490 --> 3.78053).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.471998 \tValidation Loss: 3.442199\n",
      "Validation loss decreased (3.78053 --> 3.44220).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.774175 \tValidation Loss: 3.094532\n",
      "Validation loss decreased (3.44220 --> 3.09453).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.061046 \tValidation Loss: 2.779111\n",
      "Validation loss decreased (3.09453 --> 2.77911).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.423258 \tValidation Loss: 2.523925\n",
      "Validation loss decreased (2.77911 --> 2.52393).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.903960 \tValidation Loss: 2.328237\n",
      "Validation loss decreased (2.52393 --> 2.32824).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.501956 \tValidation Loss: 2.179749\n",
      "Validation loss decreased (2.32824 --> 2.17975).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.190461 \tValidation Loss: 2.066233\n",
      "Validation loss decreased (2.17975 --> 2.06623).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.949163 \tValidation Loss: 1.979175\n",
      "Validation loss decreased (2.06623 --> 1.97917).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.757008 \tValidation Loss: 1.913738\n",
      "Validation loss decreased (1.97917 --> 1.91374).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.608327 \tValidation Loss: 1.864288\n",
      "Validation loss decreased (1.91374 --> 1.86429).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.491138 \tValidation Loss: 1.831741\n",
      "Validation loss decreased (1.86429 --> 1.83174).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.402659 \tValidation Loss: 1.809015\n",
      "Validation loss decreased (1.83174 --> 1.80902).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.331659 \tValidation Loss: 1.794660\n",
      "Validation loss decreased (1.80902 --> 1.79466).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.278311 \tValidation Loss: 1.782504\n",
      "Validation loss decreased (1.79466 --> 1.78250).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.236961 \tValidation Loss: 1.779020\n",
      "Validation loss decreased (1.78250 --> 1.77902).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.202469 \tValidation Loss: 1.778114\n",
      "Validation loss decreased (1.77902 --> 1.77811).  Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 0.179683 \tValidation Loss: 1.779772\n",
      "Epoch: 1 \tTraining Loss: 6.534746 \tValidation Loss: 4.569411\n",
      "Validation loss decreased (inf --> 4.56941).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.595081 \tValidation Loss: 4.162389\n",
      "Validation loss decreased (4.56941 --> 4.16239).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.063931 \tValidation Loss: 3.884364\n",
      "Validation loss decreased (4.16239 --> 3.88436).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.473447 \tValidation Loss: 3.568375\n",
      "Validation loss decreased (3.88436 --> 3.56838).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.779904 \tValidation Loss: 3.238486\n",
      "Validation loss decreased (3.56838 --> 3.23849).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.071888 \tValidation Loss: 2.944096\n",
      "Validation loss decreased (3.23849 --> 2.94410).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.439696 \tValidation Loss: 2.704205\n",
      "Validation loss decreased (2.94410 --> 2.70421).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.926407 \tValidation Loss: 2.513819\n",
      "Validation loss decreased (2.70421 --> 2.51382).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.527216 \tValidation Loss: 2.362966\n",
      "Validation loss decreased (2.51382 --> 2.36297).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.213154 \tValidation Loss: 2.244117\n",
      "Validation loss decreased (2.36297 --> 2.24412).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.967229 \tValidation Loss: 2.151812\n",
      "Validation loss decreased (2.24412 --> 2.15181).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.776808 \tValidation Loss: 2.079047\n",
      "Validation loss decreased (2.15181 --> 2.07905).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.626347 \tValidation Loss: 2.023030\n",
      "Validation loss decreased (2.07905 --> 2.02303).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.506434 \tValidation Loss: 1.982651\n",
      "Validation loss decreased (2.02303 --> 1.98265).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.412496 \tValidation Loss: 1.954543\n",
      "Validation loss decreased (1.98265 --> 1.95454).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.342529 \tValidation Loss: 1.937979\n",
      "Validation loss decreased (1.95454 --> 1.93798).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.286524 \tValidation Loss: 1.928434\n",
      "Validation loss decreased (1.93798 --> 1.92843).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.244220 \tValidation Loss: 1.919802\n",
      "Validation loss decreased (1.92843 --> 1.91980).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.211514 \tValidation Loss: 1.916719\n",
      "Validation loss decreased (1.91980 --> 1.91672).  Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 0.182496 \tValidation Loss: 1.918578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting:...-> Lemmatize = True , window = 3 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 5.876977 \tValidation Loss: 4.860609\n",
      "Validation loss decreased (inf --> 4.86061).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.295933 \tValidation Loss: 4.757221\n",
      "Validation loss decreased (4.86061 --> 4.75722).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.091509 \tValidation Loss: 4.619859\n",
      "Validation loss decreased (4.75722 --> 4.61986).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.811563 \tValidation Loss: 4.459714\n",
      "Validation loss decreased (4.61986 --> 4.45971).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.474874 \tValidation Loss: 4.305955\n",
      "Validation loss decreased (4.45971 --> 4.30596).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.111210 \tValidation Loss: 4.172909\n",
      "Validation loss decreased (4.30596 --> 4.17291).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.745110 \tValidation Loss: 4.066892\n",
      "Validation loss decreased (4.17291 --> 4.06689).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.398300 \tValidation Loss: 3.988497\n",
      "Validation loss decreased (4.06689 --> 3.98850).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.087665 \tValidation Loss: 3.935893\n",
      "Validation loss decreased (3.98850 --> 3.93589).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.814727 \tValidation Loss: 3.903489\n",
      "Validation loss decreased (3.93589 --> 3.90349).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.579586 \tValidation Loss: 3.886753\n",
      "Validation loss decreased (3.90349 --> 3.88675).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.387500 \tValidation Loss: 3.882733\n",
      "Validation loss decreased (3.88675 --> 3.88273).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.223422 \tValidation Loss: 3.887599\n",
      "Epoch: 14 \tTraining Loss: 2.085507 \tValidation Loss: 3.900592\n",
      "Epoch: 15 \tTraining Loss: 1.972144 \tValidation Loss: 3.921047\n",
      "Epoch: 16 \tTraining Loss: 1.878998 \tValidation Loss: 3.945587\n",
      "Epoch: 17 \tTraining Loss: 1.801906 \tValidation Loss: 3.971382\n",
      "Epoch: 18 \tTraining Loss: 1.730591 \tValidation Loss: 4.001847\n",
      "Epoch: 19 \tTraining Loss: 1.676366 \tValidation Loss: 4.034325\n",
      "Epoch: 20 \tTraining Loss: 1.626939 \tValidation Loss: 4.069069\n",
      "Epoch: 1 \tTraining Loss: 5.873136 \tValidation Loss: 4.848428\n",
      "Validation loss decreased (inf --> 4.84843).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.292081 \tValidation Loss: 4.729958\n",
      "Validation loss decreased (4.84843 --> 4.72996).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.084291 \tValidation Loss: 4.584103\n",
      "Validation loss decreased (4.72996 --> 4.58410).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.800320 \tValidation Loss: 4.426524\n",
      "Validation loss decreased (4.58410 --> 4.42652).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.459833 \tValidation Loss: 4.279921\n",
      "Validation loss decreased (4.42652 --> 4.27992).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.095620 \tValidation Loss: 4.156584\n",
      "Validation loss decreased (4.27992 --> 4.15658).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.732494 \tValidation Loss: 4.056552\n",
      "Validation loss decreased (4.15658 --> 4.05655).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.388545 \tValidation Loss: 3.977514\n",
      "Validation loss decreased (4.05655 --> 3.97751).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.080617 \tValidation Loss: 3.918813\n",
      "Validation loss decreased (3.97751 --> 3.91881).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.805384 \tValidation Loss: 3.878884\n",
      "Validation loss decreased (3.91881 --> 3.87888).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.573255 \tValidation Loss: 3.854627\n",
      "Validation loss decreased (3.87888 --> 3.85463).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.373154 \tValidation Loss: 3.844357\n",
      "Validation loss decreased (3.85463 --> 3.84436).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.209565 \tValidation Loss: 3.845037\n",
      "Epoch: 14 \tTraining Loss: 2.073626 \tValidation Loss: 3.852892\n",
      "Epoch: 15 \tTraining Loss: 1.958622 \tValidation Loss: 3.869219\n",
      "Epoch: 16 \tTraining Loss: 1.865115 \tValidation Loss: 3.890408\n",
      "Epoch: 17 \tTraining Loss: 1.783452 \tValidation Loss: 3.914803\n",
      "Epoch: 18 \tTraining Loss: 1.715794 \tValidation Loss: 3.943485\n",
      "Epoch: 19 \tTraining Loss: 1.661029 \tValidation Loss: 3.973603\n",
      "Epoch: 20 \tTraining Loss: 1.608397 \tValidation Loss: 4.004111\n",
      "Epoch: 1 \tTraining Loss: 5.880691 \tValidation Loss: 4.859480\n",
      "Validation loss decreased (inf --> 4.85948).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.296941 \tValidation Loss: 4.750636\n",
      "Validation loss decreased (4.85948 --> 4.75064).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.091078 \tValidation Loss: 4.613630\n",
      "Validation loss decreased (4.75064 --> 4.61363).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.810761 \tValidation Loss: 4.454382\n",
      "Validation loss decreased (4.61363 --> 4.45438).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.475439 \tValidation Loss: 4.299361\n",
      "Validation loss decreased (4.45438 --> 4.29936).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.114956 \tValidation Loss: 4.161963\n",
      "Validation loss decreased (4.29936 --> 4.16196).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.752465 \tValidation Loss: 4.048753\n",
      "Validation loss decreased (4.16196 --> 4.04875).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.410525 \tValidation Loss: 3.960681\n",
      "Validation loss decreased (4.04875 --> 3.96068).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.100590 \tValidation Loss: 3.894212\n",
      "Validation loss decreased (3.96068 --> 3.89421).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.826473 \tValidation Loss: 3.848412\n",
      "Validation loss decreased (3.89421 --> 3.84841).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.591507 \tValidation Loss: 3.819026\n",
      "Validation loss decreased (3.84841 --> 3.81903).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.390342 \tValidation Loss: 3.805292\n",
      "Validation loss decreased (3.81903 --> 3.80529).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.227984 \tValidation Loss: 3.802931\n",
      "Validation loss decreased (3.80529 --> 3.80293).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 2.091525 \tValidation Loss: 3.810925\n",
      "Epoch: 15 \tTraining Loss: 1.978327 \tValidation Loss: 3.824009\n",
      "Epoch: 16 \tTraining Loss: 1.881027 \tValidation Loss: 3.844368\n",
      "Epoch: 17 \tTraining Loss: 1.803519 \tValidation Loss: 3.866510\n",
      "Epoch: 18 \tTraining Loss: 1.736657 \tValidation Loss: 3.893145\n",
      "Epoch: 19 \tTraining Loss: 1.678571 \tValidation Loss: 3.921362\n",
      "Epoch: 20 \tTraining Loss: 1.625296 \tValidation Loss: 3.951916\n",
      "Epoch: 1 \tTraining Loss: 5.875987 \tValidation Loss: 4.846593\n",
      "Validation loss decreased (inf --> 4.84659).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.287145 \tValidation Loss: 4.735320\n",
      "Validation loss decreased (4.84659 --> 4.73532).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.077539 \tValidation Loss: 4.596885\n",
      "Validation loss decreased (4.73532 --> 4.59688).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.799598 \tValidation Loss: 4.439749\n",
      "Validation loss decreased (4.59688 --> 4.43975).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.472238 \tValidation Loss: 4.287712\n",
      "Validation loss decreased (4.43975 --> 4.28771).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.118594 \tValidation Loss: 4.150154\n",
      "Validation loss decreased (4.28771 --> 4.15015).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.759948 \tValidation Loss: 4.032911\n",
      "Validation loss decreased (4.15015 --> 4.03291).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.420099 \tValidation Loss: 3.938464\n",
      "Validation loss decreased (4.03291 --> 3.93846).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.107866 \tValidation Loss: 3.868251\n",
      "Validation loss decreased (3.93846 --> 3.86825).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.836274 \tValidation Loss: 3.821048\n",
      "Validation loss decreased (3.86825 --> 3.82105).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.597616 \tValidation Loss: 3.793002\n",
      "Validation loss decreased (3.82105 --> 3.79300).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.397527 \tValidation Loss: 3.778776\n",
      "Validation loss decreased (3.79300 --> 3.77878).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.233476 \tValidation Loss: 3.775766\n",
      "Validation loss decreased (3.77878 --> 3.77577).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 2.092461 \tValidation Loss: 3.782901\n",
      "Epoch: 15 \tTraining Loss: 1.974023 \tValidation Loss: 3.795273\n",
      "Epoch: 16 \tTraining Loss: 1.881447 \tValidation Loss: 3.813937\n",
      "Epoch: 17 \tTraining Loss: 1.802219 \tValidation Loss: 3.837478\n",
      "Epoch: 18 \tTraining Loss: 1.730771 \tValidation Loss: 3.863782\n",
      "Epoch: 19 \tTraining Loss: 1.675863 \tValidation Loss: 3.892069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 \tTraining Loss: 1.624211 \tValidation Loss: 3.923831\n",
      "Epoch: 1 \tTraining Loss: 5.876944 \tValidation Loss: 4.887624\n",
      "Validation loss decreased (inf --> 4.88762).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.285149 \tValidation Loss: 4.778390\n",
      "Validation loss decreased (4.88762 --> 4.77839).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.080483 \tValidation Loss: 4.642167\n",
      "Validation loss decreased (4.77839 --> 4.64217).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.803781 \tValidation Loss: 4.480305\n",
      "Validation loss decreased (4.64217 --> 4.48030).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.468730 \tValidation Loss: 4.324137\n",
      "Validation loss decreased (4.48030 --> 4.32414).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.110106 \tValidation Loss: 4.187130\n",
      "Validation loss decreased (4.32414 --> 4.18713).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.751944 \tValidation Loss: 4.073313\n",
      "Validation loss decreased (4.18713 --> 4.07331).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.410001 \tValidation Loss: 3.986922\n",
      "Validation loss decreased (4.07331 --> 3.98692).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.102852 \tValidation Loss: 3.924983\n",
      "Validation loss decreased (3.98692 --> 3.92498).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.834415 \tValidation Loss: 3.884539\n",
      "Validation loss decreased (3.92498 --> 3.88454).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.599977 \tValidation Loss: 3.859879\n",
      "Validation loss decreased (3.88454 --> 3.85988).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.402910 \tValidation Loss: 3.847679\n",
      "Validation loss decreased (3.85988 --> 3.84768).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.237625 \tValidation Loss: 3.847174\n",
      "Validation loss decreased (3.84768 --> 3.84717).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 2.102017 \tValidation Loss: 3.853081\n",
      "Epoch: 15 \tTraining Loss: 1.989832 \tValidation Loss: 3.865019\n",
      "Epoch: 16 \tTraining Loss: 1.895349 \tValidation Loss: 3.882570\n",
      "Epoch: 17 \tTraining Loss: 1.811506 \tValidation Loss: 3.903287\n",
      "Epoch: 18 \tTraining Loss: 1.743874 \tValidation Loss: 3.925971\n",
      "Epoch: 19 \tTraining Loss: 1.684449 \tValidation Loss: 3.953580\n",
      "Epoch: 20 \tTraining Loss: 1.639007 \tValidation Loss: 3.982328\n",
      "Epoch: 1 \tTraining Loss: 5.872437 \tValidation Loss: 4.856278\n",
      "Validation loss decreased (inf --> 4.85628).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.285266 \tValidation Loss: 4.747835\n",
      "Validation loss decreased (4.85628 --> 4.74783).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.076124 \tValidation Loss: 4.613686\n",
      "Validation loss decreased (4.74783 --> 4.61369).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.795470 \tValidation Loss: 4.459472\n",
      "Validation loss decreased (4.61369 --> 4.45947).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.460535 \tValidation Loss: 4.312568\n",
      "Validation loss decreased (4.45947 --> 4.31257).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.101987 \tValidation Loss: 4.182871\n",
      "Validation loss decreased (4.31257 --> 4.18287).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.745943 \tValidation Loss: 4.072765\n",
      "Validation loss decreased (4.18287 --> 4.07277).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.409405 \tValidation Loss: 3.983694\n",
      "Validation loss decreased (4.07277 --> 3.98369).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.100266 \tValidation Loss: 3.916734\n",
      "Validation loss decreased (3.98369 --> 3.91673).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.826811 \tValidation Loss: 3.870221\n",
      "Validation loss decreased (3.91673 --> 3.87022).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.594548 \tValidation Loss: 3.841520\n",
      "Validation loss decreased (3.87022 --> 3.84152).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.397077 \tValidation Loss: 3.829844\n",
      "Validation loss decreased (3.84152 --> 3.82984).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.230851 \tValidation Loss: 3.830521\n",
      "Epoch: 14 \tTraining Loss: 2.089393 \tValidation Loss: 3.839976\n",
      "Epoch: 15 \tTraining Loss: 1.976224 \tValidation Loss: 3.856977\n",
      "Epoch: 16 \tTraining Loss: 1.880503 \tValidation Loss: 3.879284\n",
      "Epoch: 17 \tTraining Loss: 1.798581 \tValidation Loss: 3.904027\n",
      "Epoch: 18 \tTraining Loss: 1.733607 \tValidation Loss: 3.932859\n",
      "Epoch: 19 \tTraining Loss: 1.674464 \tValidation Loss: 3.962959\n",
      "Epoch: 20 \tTraining Loss: 1.622287 \tValidation Loss: 3.994608\n",
      "Epoch: 1 \tTraining Loss: 5.874113 \tValidation Loss: 4.849950\n",
      "Validation loss decreased (inf --> 4.84995).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.289656 \tValidation Loss: 4.749022\n",
      "Validation loss decreased (4.84995 --> 4.74902).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.085950 \tValidation Loss: 4.610804\n",
      "Validation loss decreased (4.74902 --> 4.61080).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.811188 \tValidation Loss: 4.449556\n",
      "Validation loss decreased (4.61080 --> 4.44956).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.478875 \tValidation Loss: 4.293057\n",
      "Validation loss decreased (4.44956 --> 4.29306).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.119905 \tValidation Loss: 4.156269\n",
      "Validation loss decreased (4.29306 --> 4.15627).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.761608 \tValidation Loss: 4.042071\n",
      "Validation loss decreased (4.15627 --> 4.04207).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.418798 \tValidation Loss: 3.954358\n",
      "Validation loss decreased (4.04207 --> 3.95436).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.108791 \tValidation Loss: 3.892871\n",
      "Validation loss decreased (3.95436 --> 3.89287).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.836264 \tValidation Loss: 3.854030\n",
      "Validation loss decreased (3.89287 --> 3.85403).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.602199 \tValidation Loss: 3.830773\n",
      "Validation loss decreased (3.85403 --> 3.83077).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.406045 \tValidation Loss: 3.821805\n",
      "Validation loss decreased (3.83077 --> 3.82180).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.240499 \tValidation Loss: 3.820868\n",
      "Validation loss decreased (3.82180 --> 3.82087).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 2.101162 \tValidation Loss: 3.829715\n",
      "Epoch: 15 \tTraining Loss: 1.986374 \tValidation Loss: 3.845220\n",
      "Epoch: 16 \tTraining Loss: 1.888229 \tValidation Loss: 3.864908\n",
      "Epoch: 17 \tTraining Loss: 1.808595 \tValidation Loss: 3.889267\n",
      "Epoch: 18 \tTraining Loss: 1.743154 \tValidation Loss: 3.913495\n",
      "Epoch: 19 \tTraining Loss: 1.685934 \tValidation Loss: 3.943761\n",
      "Epoch: 20 \tTraining Loss: 1.638439 \tValidation Loss: 3.972932\n",
      "Epoch: 1 \tTraining Loss: 5.875737 \tValidation Loss: 4.902112\n",
      "Validation loss decreased (inf --> 4.90211).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.288572 \tValidation Loss: 4.796557\n",
      "Validation loss decreased (4.90211 --> 4.79656).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.085525 \tValidation Loss: 4.661886\n",
      "Validation loss decreased (4.79656 --> 4.66189).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.809079 \tValidation Loss: 4.496699\n",
      "Validation loss decreased (4.66189 --> 4.49670).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.474916 \tValidation Loss: 4.332297\n",
      "Validation loss decreased (4.49670 --> 4.33230).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.115459 \tValidation Loss: 4.186554\n",
      "Validation loss decreased (4.33230 --> 4.18655).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.752885 \tValidation Loss: 4.067633\n",
      "Validation loss decreased (4.18655 --> 4.06763).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.412213 \tValidation Loss: 3.975772\n",
      "Validation loss decreased (4.06763 --> 3.97577).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.099338 \tValidation Loss: 3.909746\n",
      "Validation loss decreased (3.97577 --> 3.90975).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.826351 \tValidation Loss: 3.863933\n",
      "Validation loss decreased (3.90975 --> 3.86393).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.593579 \tValidation Loss: 3.835916\n",
      "Validation loss decreased (3.86393 --> 3.83592).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.395839 \tValidation Loss: 3.822377\n",
      "Validation loss decreased (3.83592 --> 3.82238).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.230997 \tValidation Loss: 3.821627\n",
      "Validation loss decreased (3.82238 --> 3.82163).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 2.092174 \tValidation Loss: 3.829854\n",
      "Epoch: 15 \tTraining Loss: 1.976893 \tValidation Loss: 3.844657\n",
      "Epoch: 16 \tTraining Loss: 1.882041 \tValidation Loss: 3.865710\n",
      "Epoch: 17 \tTraining Loss: 1.802092 \tValidation Loss: 3.889579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 \tTraining Loss: 1.732453 \tValidation Loss: 3.918380\n",
      "Epoch: 19 \tTraining Loss: 1.679888 \tValidation Loss: 3.948537\n",
      "Epoch: 20 \tTraining Loss: 1.628011 \tValidation Loss: 3.980945\n",
      "Epoch: 1 \tTraining Loss: 5.882134 \tValidation Loss: 4.836437\n",
      "Validation loss decreased (inf --> 4.83644).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.292649 \tValidation Loss: 4.724861\n",
      "Validation loss decreased (4.83644 --> 4.72486).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.084102 \tValidation Loss: 4.586519\n",
      "Validation loss decreased (4.72486 --> 4.58652).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.804768 \tValidation Loss: 4.429985\n",
      "Validation loss decreased (4.58652 --> 4.42998).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.468629 \tValidation Loss: 4.279337\n",
      "Validation loss decreased (4.42998 --> 4.27934).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.106392 \tValidation Loss: 4.150485\n",
      "Validation loss decreased (4.27934 --> 4.15048).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.741880 \tValidation Loss: 4.046888\n",
      "Validation loss decreased (4.15048 --> 4.04689).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.398133 \tValidation Loss: 3.970081\n",
      "Validation loss decreased (4.04689 --> 3.97008).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.090265 \tValidation Loss: 3.916533\n",
      "Validation loss decreased (3.97008 --> 3.91653).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.815730 \tValidation Loss: 3.884607\n",
      "Validation loss decreased (3.91653 --> 3.88461).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.581409 \tValidation Loss: 3.867591\n",
      "Validation loss decreased (3.88461 --> 3.86759).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.384033 \tValidation Loss: 3.863089\n",
      "Validation loss decreased (3.86759 --> 3.86309).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.218046 \tValidation Loss: 3.868401\n",
      "Epoch: 14 \tTraining Loss: 2.085003 \tValidation Loss: 3.883195\n",
      "Epoch: 15 \tTraining Loss: 1.967602 \tValidation Loss: 3.902883\n",
      "Epoch: 16 \tTraining Loss: 1.875795 \tValidation Loss: 3.927805\n",
      "Epoch: 17 \tTraining Loss: 1.796363 \tValidation Loss: 3.956536\n",
      "Epoch: 18 \tTraining Loss: 1.731875 \tValidation Loss: 3.987301\n",
      "Epoch: 19 \tTraining Loss: 1.673685 \tValidation Loss: 4.018140\n",
      "Epoch: 20 \tTraining Loss: 1.628054 \tValidation Loss: 4.053196\n",
      "Epoch: 1 \tTraining Loss: 5.872767 \tValidation Loss: 4.876391\n",
      "Validation loss decreased (inf --> 4.87639).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.285282 \tValidation Loss: 4.771926\n",
      "Validation loss decreased (4.87639 --> 4.77193).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.079497 \tValidation Loss: 4.641058\n",
      "Validation loss decreased (4.77193 --> 4.64106).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.799438 \tValidation Loss: 4.487183\n",
      "Validation loss decreased (4.64106 --> 4.48718).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.463451 \tValidation Loss: 4.336062\n",
      "Validation loss decreased (4.48718 --> 4.33606).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.098520 \tValidation Loss: 4.206143\n",
      "Validation loss decreased (4.33606 --> 4.20614).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.734685 \tValidation Loss: 4.101784\n",
      "Validation loss decreased (4.20614 --> 4.10178).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.392629 \tValidation Loss: 4.024054\n",
      "Validation loss decreased (4.10178 --> 4.02405).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.083048 \tValidation Loss: 3.969028\n",
      "Validation loss decreased (4.02405 --> 3.96903).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.813389 \tValidation Loss: 3.934037\n",
      "Validation loss decreased (3.96903 --> 3.93404).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.581425 \tValidation Loss: 3.914610\n",
      "Validation loss decreased (3.93404 --> 3.91461).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.383720 \tValidation Loss: 3.907200\n",
      "Validation loss decreased (3.91461 --> 3.90720).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.219380 \tValidation Loss: 3.909529\n",
      "Epoch: 14 \tTraining Loss: 2.081871 \tValidation Loss: 3.919859\n",
      "Epoch: 15 \tTraining Loss: 1.967716 \tValidation Loss: 3.938196\n",
      "Epoch: 16 \tTraining Loss: 1.871258 \tValidation Loss: 3.961949\n",
      "Epoch: 17 \tTraining Loss: 1.793592 \tValidation Loss: 3.990349\n",
      "Epoch: 18 \tTraining Loss: 1.725635 \tValidation Loss: 4.019924\n",
      "Epoch: 19 \tTraining Loss: 1.670361 \tValidation Loss: 4.050253\n",
      "Epoch: 20 \tTraining Loss: 1.620820 \tValidation Loss: 4.085367\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 4 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 5.898988 \tValidation Loss: 4.788157\n",
      "Validation loss decreased (inf --> 4.78816).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.272465 \tValidation Loss: 4.602868\n",
      "Validation loss decreased (4.78816 --> 4.60287).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.943067 \tValidation Loss: 4.361258\n",
      "Validation loss decreased (4.60287 --> 4.36126).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.509291 \tValidation Loss: 4.108721\n",
      "Validation loss decreased (4.36126 --> 4.10872).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.019985 \tValidation Loss: 3.873212\n",
      "Validation loss decreased (4.10872 --> 3.87321).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.525712 \tValidation Loss: 3.672675\n",
      "Validation loss decreased (3.87321 --> 3.67267).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.067493 \tValidation Loss: 3.509234\n",
      "Validation loss decreased (3.67267 --> 3.50923).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.668298 \tValidation Loss: 3.383882\n",
      "Validation loss decreased (3.50923 --> 3.38388).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.335418 \tValidation Loss: 3.291483\n",
      "Validation loss decreased (3.38388 --> 3.29148).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.063876 \tValidation Loss: 3.225075\n",
      "Validation loss decreased (3.29148 --> 3.22508).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.839809 \tValidation Loss: 3.178570\n",
      "Validation loss decreased (3.22508 --> 3.17857).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.657994 \tValidation Loss: 3.148438\n",
      "Validation loss decreased (3.17857 --> 3.14844).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.509609 \tValidation Loss: 3.130778\n",
      "Validation loss decreased (3.14844 --> 3.13078).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.390622 \tValidation Loss: 3.122660\n",
      "Validation loss decreased (3.13078 --> 3.12266).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.289966 \tValidation Loss: 3.126159\n",
      "Epoch: 16 \tTraining Loss: 1.205468 \tValidation Loss: 3.135669\n",
      "Epoch: 17 \tTraining Loss: 1.135398 \tValidation Loss: 3.149384\n",
      "Epoch: 18 \tTraining Loss: 1.075854 \tValidation Loss: 3.169387\n",
      "Epoch: 19 \tTraining Loss: 1.025113 \tValidation Loss: 3.192714\n",
      "Epoch: 20 \tTraining Loss: 0.982539 \tValidation Loss: 3.214610\n",
      "Epoch: 1 \tTraining Loss: 5.889007 \tValidation Loss: 4.837550\n",
      "Validation loss decreased (inf --> 4.83755).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.266549 \tValidation Loss: 4.660270\n",
      "Validation loss decreased (4.83755 --> 4.66027).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.934946 \tValidation Loss: 4.431099\n",
      "Validation loss decreased (4.66027 --> 4.43110).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.498300 \tValidation Loss: 4.181474\n",
      "Validation loss decreased (4.43110 --> 4.18147).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.008063 \tValidation Loss: 3.946783\n",
      "Validation loss decreased (4.18147 --> 3.94678).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.514248 \tValidation Loss: 3.741781\n",
      "Validation loss decreased (3.94678 --> 3.74178).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.060533 \tValidation Loss: 3.571880\n",
      "Validation loss decreased (3.74178 --> 3.57188).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.662784 \tValidation Loss: 3.437425\n",
      "Validation loss decreased (3.57188 --> 3.43743).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.328838 \tValidation Loss: 3.335382\n",
      "Validation loss decreased (3.43743 --> 3.33538).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.053735 \tValidation Loss: 3.258910\n",
      "Validation loss decreased (3.33538 --> 3.25891).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.831783 \tValidation Loss: 3.205475\n",
      "Validation loss decreased (3.25891 --> 3.20547).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.651745 \tValidation Loss: 3.169279\n",
      "Validation loss decreased (3.20547 --> 3.16928).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.506899 \tValidation Loss: 3.147961\n",
      "Validation loss decreased (3.16928 --> 3.14796).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.382354 \tValidation Loss: 3.138340\n",
      "Validation loss decreased (3.14796 --> 3.13834).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 \tTraining Loss: 1.285745 \tValidation Loss: 3.138174\n",
      "Validation loss decreased (3.13834 --> 3.13817).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 1.204440 \tValidation Loss: 3.142587\n",
      "Epoch: 17 \tTraining Loss: 1.130937 \tValidation Loss: 3.153233\n",
      "Epoch: 18 \tTraining Loss: 1.075320 \tValidation Loss: 3.170139\n",
      "Epoch: 19 \tTraining Loss: 1.024222 \tValidation Loss: 3.191228\n",
      "Epoch: 20 \tTraining Loss: 0.978435 \tValidation Loss: 3.214923\n",
      "Epoch: 1 \tTraining Loss: 5.907171 \tValidation Loss: 4.799096\n",
      "Validation loss decreased (inf --> 4.79910).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.272029 \tValidation Loss: 4.616558\n",
      "Validation loss decreased (4.79910 --> 4.61656).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.936938 \tValidation Loss: 4.375314\n",
      "Validation loss decreased (4.61656 --> 4.37531).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.497326 \tValidation Loss: 4.128078\n",
      "Validation loss decreased (4.37531 --> 4.12808).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.006941 \tValidation Loss: 3.899287\n",
      "Validation loss decreased (4.12808 --> 3.89929).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.511708 \tValidation Loss: 3.704791\n",
      "Validation loss decreased (3.89929 --> 3.70479).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.054540 \tValidation Loss: 3.547688\n",
      "Validation loss decreased (3.70479 --> 3.54769).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.658381 \tValidation Loss: 3.427032\n",
      "Validation loss decreased (3.54769 --> 3.42703).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.324494 \tValidation Loss: 3.336235\n",
      "Validation loss decreased (3.42703 --> 3.33624).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.053278 \tValidation Loss: 3.271968\n",
      "Validation loss decreased (3.33624 --> 3.27197).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.833847 \tValidation Loss: 3.227710\n",
      "Validation loss decreased (3.27197 --> 3.22771).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.652031 \tValidation Loss: 3.200297\n",
      "Validation loss decreased (3.22771 --> 3.20030).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.502862 \tValidation Loss: 3.185169\n",
      "Validation loss decreased (3.20030 --> 3.18517).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.385389 \tValidation Loss: 3.180098\n",
      "Validation loss decreased (3.18517 --> 3.18010).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.284740 \tValidation Loss: 3.185150\n",
      "Epoch: 16 \tTraining Loss: 1.203490 \tValidation Loss: 3.195962\n",
      "Epoch: 17 \tTraining Loss: 1.129604 \tValidation Loss: 3.213412\n",
      "Epoch: 18 \tTraining Loss: 1.072157 \tValidation Loss: 3.235526\n",
      "Epoch: 19 \tTraining Loss: 1.024447 \tValidation Loss: 3.259313\n",
      "Epoch: 20 \tTraining Loss: 0.977848 \tValidation Loss: 3.285870\n",
      "Epoch: 1 \tTraining Loss: 5.905952 \tValidation Loss: 4.773961\n",
      "Validation loss decreased (inf --> 4.77396).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.270624 \tValidation Loss: 4.598684\n",
      "Validation loss decreased (4.77396 --> 4.59868).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.929259 \tValidation Loss: 4.366617\n",
      "Validation loss decreased (4.59868 --> 4.36662).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.490523 \tValidation Loss: 4.118411\n",
      "Validation loss decreased (4.36662 --> 4.11841).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.995830 \tValidation Loss: 3.886868\n",
      "Validation loss decreased (4.11841 --> 3.88687).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.498604 \tValidation Loss: 3.691881\n",
      "Validation loss decreased (3.88687 --> 3.69188).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.041426 \tValidation Loss: 3.538197\n",
      "Validation loss decreased (3.69188 --> 3.53820).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.643129 \tValidation Loss: 3.420907\n",
      "Validation loss decreased (3.53820 --> 3.42091).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.311303 \tValidation Loss: 3.334975\n",
      "Validation loss decreased (3.42091 --> 3.33498).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.037178 \tValidation Loss: 3.275841\n",
      "Validation loss decreased (3.33498 --> 3.27584).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.817484 \tValidation Loss: 3.235860\n",
      "Validation loss decreased (3.27584 --> 3.23586).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.638274 \tValidation Loss: 3.213037\n",
      "Validation loss decreased (3.23586 --> 3.21304).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.490343 \tValidation Loss: 3.202247\n",
      "Validation loss decreased (3.21304 --> 3.20225).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.375354 \tValidation Loss: 3.201912\n",
      "Validation loss decreased (3.20225 --> 3.20191).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.275435 \tValidation Loss: 3.208856\n",
      "Epoch: 16 \tTraining Loss: 1.193073 \tValidation Loss: 3.222037\n",
      "Epoch: 17 \tTraining Loss: 1.126045 \tValidation Loss: 3.239992\n",
      "Epoch: 18 \tTraining Loss: 1.063390 \tValidation Loss: 3.262174\n",
      "Epoch: 19 \tTraining Loss: 1.013312 \tValidation Loss: 3.287820\n",
      "Epoch: 20 \tTraining Loss: 0.971972 \tValidation Loss: 3.318736\n",
      "Epoch: 1 \tTraining Loss: 5.895748 \tValidation Loss: 4.796798\n",
      "Validation loss decreased (inf --> 4.79680).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.263768 \tValidation Loss: 4.619672\n",
      "Validation loss decreased (4.79680 --> 4.61967).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.925656 \tValidation Loss: 4.388553\n",
      "Validation loss decreased (4.61967 --> 4.38855).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.484579 \tValidation Loss: 4.145361\n",
      "Validation loss decreased (4.38855 --> 4.14536).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.996700 \tValidation Loss: 3.914031\n",
      "Validation loss decreased (4.14536 --> 3.91403).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.504210 \tValidation Loss: 3.711198\n",
      "Validation loss decreased (3.91403 --> 3.71120).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.049039 \tValidation Loss: 3.548973\n",
      "Validation loss decreased (3.71120 --> 3.54897).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.651332 \tValidation Loss: 3.425989\n",
      "Validation loss decreased (3.54897 --> 3.42599).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.320659 \tValidation Loss: 3.331928\n",
      "Validation loss decreased (3.42599 --> 3.33193).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.049705 \tValidation Loss: 3.261879\n",
      "Validation loss decreased (3.33193 --> 3.26188).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.829334 \tValidation Loss: 3.213240\n",
      "Validation loss decreased (3.26188 --> 3.21324).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.650063 \tValidation Loss: 3.182718\n",
      "Validation loss decreased (3.21324 --> 3.18272).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.499760 \tValidation Loss: 3.163480\n",
      "Validation loss decreased (3.18272 --> 3.16348).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.383577 \tValidation Loss: 3.157428\n",
      "Validation loss decreased (3.16348 --> 3.15743).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.283406 \tValidation Loss: 3.159452\n",
      "Epoch: 16 \tTraining Loss: 1.200334 \tValidation Loss: 3.169642\n",
      "Epoch: 17 \tTraining Loss: 1.129679 \tValidation Loss: 3.183788\n",
      "Epoch: 18 \tTraining Loss: 1.072486 \tValidation Loss: 3.199482\n",
      "Epoch: 19 \tTraining Loss: 1.019565 \tValidation Loss: 3.221448\n",
      "Epoch: 20 \tTraining Loss: 0.973406 \tValidation Loss: 3.248063\n",
      "Epoch: 1 \tTraining Loss: 5.890512 \tValidation Loss: 4.821848\n",
      "Validation loss decreased (inf --> 4.82185).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.260784 \tValidation Loss: 4.648292\n",
      "Validation loss decreased (4.82185 --> 4.64829).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.920655 \tValidation Loss: 4.425130\n",
      "Validation loss decreased (4.64829 --> 4.42513).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.480849 \tValidation Loss: 4.193303\n",
      "Validation loss decreased (4.42513 --> 4.19330).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.991266 \tValidation Loss: 3.977886\n",
      "Validation loss decreased (4.19330 --> 3.97789).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.498243 \tValidation Loss: 3.791011\n",
      "Validation loss decreased (3.97789 --> 3.79101).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.044896 \tValidation Loss: 3.638272\n",
      "Validation loss decreased (3.79101 --> 3.63827).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.647383 \tValidation Loss: 3.521389\n",
      "Validation loss decreased (3.63827 --> 3.52139).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.317171 \tValidation Loss: 3.434730\n",
      "Validation loss decreased (3.52139 --> 3.43473).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.046486 \tValidation Loss: 3.372175\n",
      "Validation loss decreased (3.43473 --> 3.37218).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 \tTraining Loss: 1.829693 \tValidation Loss: 3.330900\n",
      "Validation loss decreased (3.37218 --> 3.33090).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.651371 \tValidation Loss: 3.303647\n",
      "Validation loss decreased (3.33090 --> 3.30365).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.506362 \tValidation Loss: 3.289765\n",
      "Validation loss decreased (3.30365 --> 3.28977).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.386472 \tValidation Loss: 3.286258\n",
      "Validation loss decreased (3.28977 --> 3.28626).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.285406 \tValidation Loss: 3.291962\n",
      "Epoch: 16 \tTraining Loss: 1.206599 \tValidation Loss: 3.304174\n",
      "Epoch: 17 \tTraining Loss: 1.136346 \tValidation Loss: 3.324114\n",
      "Epoch: 18 \tTraining Loss: 1.078775 \tValidation Loss: 3.342953\n",
      "Epoch: 19 \tTraining Loss: 1.028600 \tValidation Loss: 3.366116\n",
      "Epoch: 20 \tTraining Loss: 0.980730 \tValidation Loss: 3.395098\n",
      "Epoch: 1 \tTraining Loss: 5.907428 \tValidation Loss: 4.798589\n",
      "Validation loss decreased (inf --> 4.79859).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.267442 \tValidation Loss: 4.617573\n",
      "Validation loss decreased (4.79859 --> 4.61757).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.929330 \tValidation Loss: 4.389232\n",
      "Validation loss decreased (4.61757 --> 4.38923).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.491104 \tValidation Loss: 4.145812\n",
      "Validation loss decreased (4.38923 --> 4.14581).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.999407 \tValidation Loss: 3.916984\n",
      "Validation loss decreased (4.14581 --> 3.91698).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.507092 \tValidation Loss: 3.718579\n",
      "Validation loss decreased (3.91698 --> 3.71858).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.053407 \tValidation Loss: 3.557181\n",
      "Validation loss decreased (3.71858 --> 3.55718).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.655251 \tValidation Loss: 3.432705\n",
      "Validation loss decreased (3.55718 --> 3.43271).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.322843 \tValidation Loss: 3.340115\n",
      "Validation loss decreased (3.43271 --> 3.34012).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.051498 \tValidation Loss: 3.272298\n",
      "Validation loss decreased (3.34012 --> 3.27230).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.828592 \tValidation Loss: 3.224649\n",
      "Validation loss decreased (3.27230 --> 3.22465).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.650797 \tValidation Loss: 3.192388\n",
      "Validation loss decreased (3.22465 --> 3.19239).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.505749 \tValidation Loss: 3.172491\n",
      "Validation loss decreased (3.19239 --> 3.17249).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.390612 \tValidation Loss: 3.163593\n",
      "Validation loss decreased (3.17249 --> 3.16359).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.289717 \tValidation Loss: 3.164625\n",
      "Epoch: 16 \tTraining Loss: 1.201477 \tValidation Loss: 3.173056\n",
      "Epoch: 17 \tTraining Loss: 1.134742 \tValidation Loss: 3.187045\n",
      "Epoch: 18 \tTraining Loss: 1.076285 \tValidation Loss: 3.204022\n",
      "Epoch: 19 \tTraining Loss: 1.025650 \tValidation Loss: 3.223498\n",
      "Epoch: 20 \tTraining Loss: 0.980157 \tValidation Loss: 3.243724\n",
      "Epoch: 1 \tTraining Loss: 5.899444 \tValidation Loss: 4.820064\n",
      "Validation loss decreased (inf --> 4.82006).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.274893 \tValidation Loss: 4.656630\n",
      "Validation loss decreased (4.82006 --> 4.65663).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.945263 \tValidation Loss: 4.429164\n",
      "Validation loss decreased (4.65663 --> 4.42916).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.507488 \tValidation Loss: 4.179782\n",
      "Validation loss decreased (4.42916 --> 4.17978).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.011954 \tValidation Loss: 3.942935\n",
      "Validation loss decreased (4.17978 --> 3.94293).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.515351 \tValidation Loss: 3.737948\n",
      "Validation loss decreased (3.94293 --> 3.73795).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.057086 \tValidation Loss: 3.571853\n",
      "Validation loss decreased (3.73795 --> 3.57185).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.657911 \tValidation Loss: 3.441695\n",
      "Validation loss decreased (3.57185 --> 3.44170).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.323610 \tValidation Loss: 3.341311\n",
      "Validation loss decreased (3.44170 --> 3.34131).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.049587 \tValidation Loss: 3.268076\n",
      "Validation loss decreased (3.34131 --> 3.26808).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.823688 \tValidation Loss: 3.218695\n",
      "Validation loss decreased (3.26808 --> 3.21869).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.642512 \tValidation Loss: 3.187184\n",
      "Validation loss decreased (3.21869 --> 3.18718).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.497462 \tValidation Loss: 3.169541\n",
      "Validation loss decreased (3.18718 --> 3.16954).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.377735 \tValidation Loss: 3.166818\n",
      "Validation loss decreased (3.16954 --> 3.16682).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.279326 \tValidation Loss: 3.171899\n",
      "Epoch: 16 \tTraining Loss: 1.197071 \tValidation Loss: 3.185233\n",
      "Epoch: 17 \tTraining Loss: 1.126176 \tValidation Loss: 3.202975\n",
      "Epoch: 18 \tTraining Loss: 1.069103 \tValidation Loss: 3.226100\n",
      "Epoch: 19 \tTraining Loss: 1.018756 \tValidation Loss: 3.251974\n",
      "Epoch: 20 \tTraining Loss: 0.972297 \tValidation Loss: 3.280353\n",
      "Epoch: 1 \tTraining Loss: 5.904713 \tValidation Loss: 4.773594\n",
      "Validation loss decreased (inf --> 4.77359).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.267966 \tValidation Loss: 4.603294\n",
      "Validation loss decreased (4.77359 --> 4.60329).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.935337 \tValidation Loss: 4.369354\n",
      "Validation loss decreased (4.60329 --> 4.36935).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.497779 \tValidation Loss: 4.115523\n",
      "Validation loss decreased (4.36935 --> 4.11552).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.003685 \tValidation Loss: 3.879936\n",
      "Validation loss decreased (4.11552 --> 3.87994).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.508524 \tValidation Loss: 3.682838\n",
      "Validation loss decreased (3.87994 --> 3.68284).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.051565 \tValidation Loss: 3.526733\n",
      "Validation loss decreased (3.68284 --> 3.52673).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.651617 \tValidation Loss: 3.408419\n",
      "Validation loss decreased (3.52673 --> 3.40842).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.318243 \tValidation Loss: 3.323014\n",
      "Validation loss decreased (3.40842 --> 3.32301).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.045628 \tValidation Loss: 3.262800\n",
      "Validation loss decreased (3.32301 --> 3.26280).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.823002 \tValidation Loss: 3.223472\n",
      "Validation loss decreased (3.26280 --> 3.22347).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.644626 \tValidation Loss: 3.199888\n",
      "Validation loss decreased (3.22347 --> 3.19989).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.498072 \tValidation Loss: 3.190534\n",
      "Validation loss decreased (3.19989 --> 3.19053).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.379349 \tValidation Loss: 3.191285\n",
      "Epoch: 15 \tTraining Loss: 1.280040 \tValidation Loss: 3.199135\n",
      "Epoch: 16 \tTraining Loss: 1.196490 \tValidation Loss: 3.215639\n",
      "Epoch: 17 \tTraining Loss: 1.128542 \tValidation Loss: 3.233052\n",
      "Epoch: 18 \tTraining Loss: 1.068698 \tValidation Loss: 3.257876\n",
      "Epoch: 19 \tTraining Loss: 1.019530 \tValidation Loss: 3.284460\n",
      "Epoch: 20 \tTraining Loss: 0.975661 \tValidation Loss: 3.311797\n",
      "Epoch: 1 \tTraining Loss: 5.900827 \tValidation Loss: 4.805196\n",
      "Validation loss decreased (inf --> 4.80520).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.264930 \tValidation Loss: 4.623563\n",
      "Validation loss decreased (4.80520 --> 4.62356).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.929919 \tValidation Loss: 4.386421\n",
      "Validation loss decreased (4.62356 --> 4.38642).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.490059 \tValidation Loss: 4.137638\n",
      "Validation loss decreased (4.38642 --> 4.13764).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.999737 \tValidation Loss: 3.903945\n",
      "Validation loss decreased (4.13764 --> 3.90395).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.507287 \tValidation Loss: 3.702490\n",
      "Validation loss decreased (3.90395 --> 3.70249).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.056378 \tValidation Loss: 3.539208\n",
      "Validation loss decreased (3.70249 --> 3.53921).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 \tTraining Loss: 2.660823 \tValidation Loss: 3.408687\n",
      "Validation loss decreased (3.53921 --> 3.40869).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.330130 \tValidation Loss: 3.309659\n",
      "Validation loss decreased (3.40869 --> 3.30966).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.051989 \tValidation Loss: 3.236528\n",
      "Validation loss decreased (3.30966 --> 3.23653).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.829952 \tValidation Loss: 3.185787\n",
      "Validation loss decreased (3.23653 --> 3.18579).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.650855 \tValidation Loss: 3.154455\n",
      "Validation loss decreased (3.18579 --> 3.15445).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.504512 \tValidation Loss: 3.138395\n",
      "Validation loss decreased (3.15445 --> 3.13839).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.387785 \tValidation Loss: 3.133948\n",
      "Validation loss decreased (3.13839 --> 3.13395).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.285931 \tValidation Loss: 3.137621\n",
      "Epoch: 16 \tTraining Loss: 1.204369 \tValidation Loss: 3.150046\n",
      "Epoch: 17 \tTraining Loss: 1.134852 \tValidation Loss: 3.166621\n",
      "Epoch: 18 \tTraining Loss: 1.075376 \tValidation Loss: 3.184030\n",
      "Epoch: 19 \tTraining Loss: 1.023192 \tValidation Loss: 3.210002\n",
      "Epoch: 20 \tTraining Loss: 0.981160 \tValidation Loss: 3.236979\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 5 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 5.853503 \tValidation Loss: 5.091697\n",
      "Validation loss decreased (inf --> 5.09170).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.156987 \tValidation Loss: 4.841558\n",
      "Validation loss decreased (5.09170 --> 4.84156).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.735667 \tValidation Loss: 4.531018\n",
      "Validation loss decreased (4.84156 --> 4.53102).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.205437 \tValidation Loss: 4.204126\n",
      "Validation loss decreased (4.53102 --> 4.20413).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.631793 \tValidation Loss: 3.895672\n",
      "Validation loss decreased (4.20413 --> 3.89567).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.080005 \tValidation Loss: 3.628780\n",
      "Validation loss decreased (3.89567 --> 3.62878).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.589997 \tValidation Loss: 3.413874\n",
      "Validation loss decreased (3.62878 --> 3.41387).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.184528 \tValidation Loss: 3.249801\n",
      "Validation loss decreased (3.41387 --> 3.24980).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.860083 \tValidation Loss: 3.129404\n",
      "Validation loss decreased (3.24980 --> 3.12940).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.595414 \tValidation Loss: 3.042740\n",
      "Validation loss decreased (3.12940 --> 3.04274).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.387638 \tValidation Loss: 2.983556\n",
      "Validation loss decreased (3.04274 --> 2.98356).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.223826 \tValidation Loss: 2.943830\n",
      "Validation loss decreased (2.98356 --> 2.94383).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.086624 \tValidation Loss: 2.920508\n",
      "Validation loss decreased (2.94383 --> 2.92051).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.977595 \tValidation Loss: 2.908993\n",
      "Validation loss decreased (2.92051 --> 2.90899).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.884706 \tValidation Loss: 2.908178\n",
      "Validation loss decreased (2.90899 --> 2.90818).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.816308 \tValidation Loss: 2.914249\n",
      "Epoch: 17 \tTraining Loss: 0.749835 \tValidation Loss: 2.928092\n",
      "Epoch: 18 \tTraining Loss: 0.696409 \tValidation Loss: 2.943898\n",
      "Epoch: 19 \tTraining Loss: 0.650565 \tValidation Loss: 2.966375\n",
      "Epoch: 20 \tTraining Loss: 0.611394 \tValidation Loss: 2.990137\n",
      "Epoch: 1 \tTraining Loss: 5.841396 \tValidation Loss: 5.109734\n",
      "Validation loss decreased (inf --> 5.10973).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.163211 \tValidation Loss: 4.871331\n",
      "Validation loss decreased (5.10973 --> 4.87133).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.747534 \tValidation Loss: 4.572668\n",
      "Validation loss decreased (4.87133 --> 4.57267).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.215780 \tValidation Loss: 4.263105\n",
      "Validation loss decreased (4.57267 --> 4.26310).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.637451 \tValidation Loss: 3.971835\n",
      "Validation loss decreased (4.26310 --> 3.97184).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.077378 \tValidation Loss: 3.719789\n",
      "Validation loss decreased (3.97184 --> 3.71979).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.584239 \tValidation Loss: 3.516016\n",
      "Validation loss decreased (3.71979 --> 3.51602).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.178422 \tValidation Loss: 3.357235\n",
      "Validation loss decreased (3.51602 --> 3.35724).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.850795 \tValidation Loss: 3.236894\n",
      "Validation loss decreased (3.35724 --> 3.23689).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.593375 \tValidation Loss: 3.146600\n",
      "Validation loss decreased (3.23689 --> 3.14660).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.381791 \tValidation Loss: 3.082855\n",
      "Validation loss decreased (3.14660 --> 3.08285).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.218369 \tValidation Loss: 3.038350\n",
      "Validation loss decreased (3.08285 --> 3.03835).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.082369 \tValidation Loss: 3.009917\n",
      "Validation loss decreased (3.03835 --> 3.00992).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.978212 \tValidation Loss: 2.996772\n",
      "Validation loss decreased (3.00992 --> 2.99677).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.886531 \tValidation Loss: 2.991752\n",
      "Validation loss decreased (2.99677 --> 2.99175).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.814219 \tValidation Loss: 2.998065\n",
      "Epoch: 17 \tTraining Loss: 0.748611 \tValidation Loss: 3.005235\n",
      "Epoch: 18 \tTraining Loss: 0.694806 \tValidation Loss: 3.023559\n",
      "Epoch: 19 \tTraining Loss: 0.653674 \tValidation Loss: 3.044072\n",
      "Epoch: 20 \tTraining Loss: 0.615814 \tValidation Loss: 3.064571\n",
      "Epoch: 1 \tTraining Loss: 5.839162 \tValidation Loss: 5.112787\n",
      "Validation loss decreased (inf --> 5.11279).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.163653 \tValidation Loss: 4.872850\n",
      "Validation loss decreased (5.11279 --> 4.87285).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.755645 \tValidation Loss: 4.568218\n",
      "Validation loss decreased (4.87285 --> 4.56822).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.228864 \tValidation Loss: 4.250289\n",
      "Validation loss decreased (4.56822 --> 4.25029).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.649436 \tValidation Loss: 3.948526\n",
      "Validation loss decreased (4.25029 --> 3.94853).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.092846 \tValidation Loss: 3.687674\n",
      "Validation loss decreased (3.94853 --> 3.68767).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.603079 \tValidation Loss: 3.474177\n",
      "Validation loss decreased (3.68767 --> 3.47418).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.197156 \tValidation Loss: 3.308363\n",
      "Validation loss decreased (3.47418 --> 3.30836).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.867616 \tValidation Loss: 3.180542\n",
      "Validation loss decreased (3.30836 --> 3.18054).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.606683 \tValidation Loss: 3.087753\n",
      "Validation loss decreased (3.18054 --> 3.08775).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.394570 \tValidation Loss: 3.018983\n",
      "Validation loss decreased (3.08775 --> 3.01898).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.228017 \tValidation Loss: 2.971467\n",
      "Validation loss decreased (3.01898 --> 2.97147).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.093421 \tValidation Loss: 2.942301\n",
      "Validation loss decreased (2.97147 --> 2.94230).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.983789 \tValidation Loss: 2.924553\n",
      "Validation loss decreased (2.94230 --> 2.92455).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.894254 \tValidation Loss: 2.919010\n",
      "Validation loss decreased (2.92455 --> 2.91901).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.817447 \tValidation Loss: 2.920559\n",
      "Epoch: 17 \tTraining Loss: 0.753633 \tValidation Loss: 2.931606\n",
      "Epoch: 18 \tTraining Loss: 0.702854 \tValidation Loss: 2.947722\n",
      "Epoch: 19 \tTraining Loss: 0.657143 \tValidation Loss: 2.966876\n",
      "Epoch: 20 \tTraining Loss: 0.618197 \tValidation Loss: 2.990654\n",
      "Epoch: 1 \tTraining Loss: 5.844738 \tValidation Loss: 5.068586\n",
      "Validation loss decreased (inf --> 5.06859).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.168139 \tValidation Loss: 4.828027\n",
      "Validation loss decreased (5.06859 --> 4.82803).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \tTraining Loss: 4.759627 \tValidation Loss: 4.516434\n",
      "Validation loss decreased (4.82803 --> 4.51643).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.233566 \tValidation Loss: 4.182496\n",
      "Validation loss decreased (4.51643 --> 4.18250).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.653701 \tValidation Loss: 3.866149\n",
      "Validation loss decreased (4.18250 --> 3.86615).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.089444 \tValidation Loss: 3.601761\n",
      "Validation loss decreased (3.86615 --> 3.60176).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.593557 \tValidation Loss: 3.391595\n",
      "Validation loss decreased (3.60176 --> 3.39159).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.184239 \tValidation Loss: 3.231688\n",
      "Validation loss decreased (3.39159 --> 3.23169).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.850563 \tValidation Loss: 3.113723\n",
      "Validation loss decreased (3.23169 --> 3.11372).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.588671 \tValidation Loss: 3.024626\n",
      "Validation loss decreased (3.11372 --> 3.02463).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.381807 \tValidation Loss: 2.959584\n",
      "Validation loss decreased (3.02463 --> 2.95958).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.218128 \tValidation Loss: 2.915118\n",
      "Validation loss decreased (2.95958 --> 2.91512).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.085428 \tValidation Loss: 2.888243\n",
      "Validation loss decreased (2.91512 --> 2.88824).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.974327 \tValidation Loss: 2.874526\n",
      "Validation loss decreased (2.88824 --> 2.87453).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.886983 \tValidation Loss: 2.873912\n",
      "Validation loss decreased (2.87453 --> 2.87391).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.809804 \tValidation Loss: 2.882384\n",
      "Epoch: 17 \tTraining Loss: 0.747146 \tValidation Loss: 2.895690\n",
      "Epoch: 18 \tTraining Loss: 0.696493 \tValidation Loss: 2.910711\n",
      "Epoch: 19 \tTraining Loss: 0.652423 \tValidation Loss: 2.933925\n",
      "Epoch: 20 \tTraining Loss: 0.615682 \tValidation Loss: 2.962679\n",
      "Epoch: 1 \tTraining Loss: 5.839369 \tValidation Loss: 5.108761\n",
      "Validation loss decreased (inf --> 5.10876).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.156676 \tValidation Loss: 4.870987\n",
      "Validation loss decreased (5.10876 --> 4.87099).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.747050 \tValidation Loss: 4.576281\n",
      "Validation loss decreased (4.87099 --> 4.57628).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.220576 \tValidation Loss: 4.268309\n",
      "Validation loss decreased (4.57628 --> 4.26831).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.645351 \tValidation Loss: 3.975786\n",
      "Validation loss decreased (4.26831 --> 3.97579).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.091853 \tValidation Loss: 3.722126\n",
      "Validation loss decreased (3.97579 --> 3.72213).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.604908 \tValidation Loss: 3.515375\n",
      "Validation loss decreased (3.72213 --> 3.51538).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.197247 \tValidation Loss: 3.353633\n",
      "Validation loss decreased (3.51538 --> 3.35363).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.870572 \tValidation Loss: 3.230388\n",
      "Validation loss decreased (3.35363 --> 3.23039).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.606978 \tValidation Loss: 3.139054\n",
      "Validation loss decreased (3.23039 --> 3.13905).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.395580 \tValidation Loss: 3.073923\n",
      "Validation loss decreased (3.13905 --> 3.07392).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.229326 \tValidation Loss: 3.029981\n",
      "Validation loss decreased (3.07392 --> 3.02998).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.089333 \tValidation Loss: 3.001906\n",
      "Validation loss decreased (3.02998 --> 3.00191).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.983616 \tValidation Loss: 2.987692\n",
      "Validation loss decreased (3.00191 --> 2.98769).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.891968 \tValidation Loss: 2.986564\n",
      "Validation loss decreased (2.98769 --> 2.98656).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.817138 \tValidation Loss: 2.990233\n",
      "Epoch: 17 \tTraining Loss: 0.752785 \tValidation Loss: 3.001552\n",
      "Epoch: 18 \tTraining Loss: 0.703920 \tValidation Loss: 3.017315\n",
      "Epoch: 19 \tTraining Loss: 0.658759 \tValidation Loss: 3.042114\n",
      "Epoch: 20 \tTraining Loss: 0.616100 \tValidation Loss: 3.065308\n",
      "Epoch: 1 \tTraining Loss: 5.842729 \tValidation Loss: 5.052851\n",
      "Validation loss decreased (inf --> 5.05285).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.163637 \tValidation Loss: 4.808791\n",
      "Validation loss decreased (5.05285 --> 4.80879).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.754721 \tValidation Loss: 4.487215\n",
      "Validation loss decreased (4.80879 --> 4.48722).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.230669 \tValidation Loss: 4.155795\n",
      "Validation loss decreased (4.48722 --> 4.15579).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.660902 \tValidation Loss: 3.847234\n",
      "Validation loss decreased (4.15579 --> 3.84723).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.107729 \tValidation Loss: 3.585701\n",
      "Validation loss decreased (3.84723 --> 3.58570).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.616831 \tValidation Loss: 3.378823\n",
      "Validation loss decreased (3.58570 --> 3.37882).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.209273 \tValidation Loss: 3.221130\n",
      "Validation loss decreased (3.37882 --> 3.22113).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.879528 \tValidation Loss: 3.100577\n",
      "Validation loss decreased (3.22113 --> 3.10058).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.613794 \tValidation Loss: 3.012213\n",
      "Validation loss decreased (3.10058 --> 3.01221).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.402323 \tValidation Loss: 2.949245\n",
      "Validation loss decreased (3.01221 --> 2.94924).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.234377 \tValidation Loss: 2.905951\n",
      "Validation loss decreased (2.94924 --> 2.90595).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.096395 \tValidation Loss: 2.879268\n",
      "Validation loss decreased (2.90595 --> 2.87927).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.986820 \tValidation Loss: 2.867281\n",
      "Validation loss decreased (2.87927 --> 2.86728).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.892926 \tValidation Loss: 2.865416\n",
      "Validation loss decreased (2.86728 --> 2.86542).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.820344 \tValidation Loss: 2.872037\n",
      "Epoch: 17 \tTraining Loss: 0.754884 \tValidation Loss: 2.882208\n",
      "Epoch: 18 \tTraining Loss: 0.701836 \tValidation Loss: 2.898770\n",
      "Epoch: 19 \tTraining Loss: 0.657234 \tValidation Loss: 2.916334\n",
      "Epoch: 20 \tTraining Loss: 0.621484 \tValidation Loss: 2.943391\n",
      "Epoch: 1 \tTraining Loss: 5.845721 \tValidation Loss: 5.054980\n",
      "Validation loss decreased (inf --> 5.05498).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.159410 \tValidation Loss: 4.810531\n",
      "Validation loss decreased (5.05498 --> 4.81053).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.744658 \tValidation Loss: 4.493455\n",
      "Validation loss decreased (4.81053 --> 4.49345).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.210380 \tValidation Loss: 4.167757\n",
      "Validation loss decreased (4.49345 --> 4.16776).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.628701 \tValidation Loss: 3.871951\n",
      "Validation loss decreased (4.16776 --> 3.87195).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.071630 \tValidation Loss: 3.622419\n",
      "Validation loss decreased (3.87195 --> 3.62242).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.582295 \tValidation Loss: 3.424179\n",
      "Validation loss decreased (3.62242 --> 3.42418).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.174390 \tValidation Loss: 3.276222\n",
      "Validation loss decreased (3.42418 --> 3.27622).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.845090 \tValidation Loss: 3.168074\n",
      "Validation loss decreased (3.27622 --> 3.16807).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.584924 \tValidation Loss: 3.092431\n",
      "Validation loss decreased (3.16807 --> 3.09243).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.379828 \tValidation Loss: 3.039864\n",
      "Validation loss decreased (3.09243 --> 3.03986).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.213887 \tValidation Loss: 3.007019\n",
      "Validation loss decreased (3.03986 --> 3.00702).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.079268 \tValidation Loss: 2.988172\n",
      "Validation loss decreased (3.00702 --> 2.98817).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.974308 \tValidation Loss: 2.981713\n",
      "Validation loss decreased (2.98817 --> 2.98171).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 \tTraining Loss: 0.883679 \tValidation Loss: 2.984524\n",
      "Epoch: 16 \tTraining Loss: 0.808677 \tValidation Loss: 2.993902\n",
      "Epoch: 17 \tTraining Loss: 0.749738 \tValidation Loss: 3.006175\n",
      "Epoch: 18 \tTraining Loss: 0.698468 \tValidation Loss: 3.026187\n",
      "Epoch: 19 \tTraining Loss: 0.652095 \tValidation Loss: 3.050079\n",
      "Epoch: 20 \tTraining Loss: 0.615368 \tValidation Loss: 3.075581\n",
      "Epoch: 1 \tTraining Loss: 5.839726 \tValidation Loss: 5.084419\n",
      "Validation loss decreased (inf --> 5.08442).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.156790 \tValidation Loss: 4.838811\n",
      "Validation loss decreased (5.08442 --> 4.83881).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.745219 \tValidation Loss: 4.523976\n",
      "Validation loss decreased (4.83881 --> 4.52398).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.212852 \tValidation Loss: 4.202882\n",
      "Validation loss decreased (4.52398 --> 4.20288).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.636297 \tValidation Loss: 3.903903\n",
      "Validation loss decreased (4.20288 --> 3.90390).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.079266 \tValidation Loss: 3.646686\n",
      "Validation loss decreased (3.90390 --> 3.64669).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.591362 \tValidation Loss: 3.444934\n",
      "Validation loss decreased (3.64669 --> 3.44493).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.180422 \tValidation Loss: 3.291050\n",
      "Validation loss decreased (3.44493 --> 3.29105).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.854907 \tValidation Loss: 3.176309\n",
      "Validation loss decreased (3.29105 --> 3.17631).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.595035 \tValidation Loss: 3.090136\n",
      "Validation loss decreased (3.17631 --> 3.09014).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.387677 \tValidation Loss: 3.031154\n",
      "Validation loss decreased (3.09014 --> 3.03115).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.222099 \tValidation Loss: 2.990471\n",
      "Validation loss decreased (3.03115 --> 2.99047).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.086926 \tValidation Loss: 2.966029\n",
      "Validation loss decreased (2.99047 --> 2.96603).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.980392 \tValidation Loss: 2.954808\n",
      "Validation loss decreased (2.96603 --> 2.95481).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.890997 \tValidation Loss: 2.954395\n",
      "Validation loss decreased (2.95481 --> 2.95440).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.815475 \tValidation Loss: 2.963468\n",
      "Epoch: 17 \tTraining Loss: 0.752373 \tValidation Loss: 2.974620\n",
      "Epoch: 18 \tTraining Loss: 0.699159 \tValidation Loss: 2.993857\n",
      "Epoch: 19 \tTraining Loss: 0.655926 \tValidation Loss: 3.013318\n",
      "Epoch: 20 \tTraining Loss: 0.617941 \tValidation Loss: 3.036465\n",
      "Epoch: 1 \tTraining Loss: 5.846039 \tValidation Loss: 5.034232\n",
      "Validation loss decreased (inf --> 5.03423).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.167152 \tValidation Loss: 4.796472\n",
      "Validation loss decreased (5.03423 --> 4.79647).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.762379 \tValidation Loss: 4.475903\n",
      "Validation loss decreased (4.79647 --> 4.47590).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.234994 \tValidation Loss: 4.144264\n",
      "Validation loss decreased (4.47590 --> 4.14426).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.653789 \tValidation Loss: 3.843223\n",
      "Validation loss decreased (4.14426 --> 3.84322).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.092180 \tValidation Loss: 3.591886\n",
      "Validation loss decreased (3.84322 --> 3.59189).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.599216 \tValidation Loss: 3.395889\n",
      "Validation loss decreased (3.59189 --> 3.39589).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.188548 \tValidation Loss: 3.248552\n",
      "Validation loss decreased (3.39589 --> 3.24855).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.858343 \tValidation Loss: 3.140523\n",
      "Validation loss decreased (3.24855 --> 3.14052).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.595727 \tValidation Loss: 3.063036\n",
      "Validation loss decreased (3.14052 --> 3.06304).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.385644 \tValidation Loss: 3.006578\n",
      "Validation loss decreased (3.06304 --> 3.00658).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.218652 \tValidation Loss: 2.969110\n",
      "Validation loss decreased (3.00658 --> 2.96911).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.087395 \tValidation Loss: 2.945712\n",
      "Validation loss decreased (2.96911 --> 2.94571).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.977259 \tValidation Loss: 2.935433\n",
      "Validation loss decreased (2.94571 --> 2.93543).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.890454 \tValidation Loss: 2.933639\n",
      "Validation loss decreased (2.93543 --> 2.93364).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.815715 \tValidation Loss: 2.938433\n",
      "Epoch: 17 \tTraining Loss: 0.753037 \tValidation Loss: 2.951096\n",
      "Epoch: 18 \tTraining Loss: 0.702518 \tValidation Loss: 2.965468\n",
      "Epoch: 19 \tTraining Loss: 0.654221 \tValidation Loss: 2.986915\n",
      "Epoch: 20 \tTraining Loss: 0.617694 \tValidation Loss: 3.010556\n",
      "Epoch: 1 \tTraining Loss: 5.835407 \tValidation Loss: 5.114596\n",
      "Validation loss decreased (inf --> 5.11460).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.153758 \tValidation Loss: 4.859868\n",
      "Validation loss decreased (5.11460 --> 4.85987).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.745284 \tValidation Loss: 4.541716\n",
      "Validation loss decreased (4.85987 --> 4.54172).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.221782 \tValidation Loss: 4.221912\n",
      "Validation loss decreased (4.54172 --> 4.22191).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.653324 \tValidation Loss: 3.922804\n",
      "Validation loss decreased (4.22191 --> 3.92280).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.103284 \tValidation Loss: 3.663891\n",
      "Validation loss decreased (3.92280 --> 3.66389).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.612870 \tValidation Loss: 3.457024\n",
      "Validation loss decreased (3.66389 --> 3.45702).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.204489 \tValidation Loss: 3.297776\n",
      "Validation loss decreased (3.45702 --> 3.29778).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.873310 \tValidation Loss: 3.178505\n",
      "Validation loss decreased (3.29778 --> 3.17850).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.607725 \tValidation Loss: 3.092014\n",
      "Validation loss decreased (3.17850 --> 3.09201).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.396504 \tValidation Loss: 3.031540\n",
      "Validation loss decreased (3.09201 --> 3.03154).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.228305 \tValidation Loss: 2.993720\n",
      "Validation loss decreased (3.03154 --> 2.99372).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.093255 \tValidation Loss: 2.970861\n",
      "Validation loss decreased (2.99372 --> 2.97086).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.983663 \tValidation Loss: 2.959608\n",
      "Validation loss decreased (2.97086 --> 2.95961).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.893599 \tValidation Loss: 2.958255\n",
      "Validation loss decreased (2.95961 --> 2.95825).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.817462 \tValidation Loss: 2.966832\n",
      "Epoch: 17 \tTraining Loss: 0.755159 \tValidation Loss: 2.982352\n",
      "Epoch: 18 \tTraining Loss: 0.704239 \tValidation Loss: 2.998783\n",
      "Epoch: 19 \tTraining Loss: 0.663680 \tValidation Loss: 3.019205\n",
      "Epoch: 20 \tTraining Loss: 0.624400 \tValidation Loss: 3.045167\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 6 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 5.896881 \tValidation Loss: 4.573339\n",
      "Validation loss decreased (inf --> 4.57334).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.160042 \tValidation Loss: 4.322739\n",
      "Validation loss decreased (4.57334 --> 4.32274).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.694636 \tValidation Loss: 3.989652\n",
      "Validation loss decreased (4.32274 --> 3.98965).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.097727 \tValidation Loss: 3.636114\n",
      "Validation loss decreased (3.98965 --> 3.63611).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.454176 \tValidation Loss: 3.321955\n",
      "Validation loss decreased (3.63611 --> 3.32195).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.855141 \tValidation Loss: 3.072643\n",
      "Validation loss decreased (3.32195 --> 3.07264).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.345479 \tValidation Loss: 2.881067\n",
      "Validation loss decreased (3.07264 --> 2.88107).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.933965 \tValidation Loss: 2.738721\n",
      "Validation loss decreased (2.88107 --> 2.73872).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.614017 \tValidation Loss: 2.632801\n",
      "Validation loss decreased (2.73872 --> 2.63280).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 \tTraining Loss: 1.362007 \tValidation Loss: 2.555196\n",
      "Validation loss decreased (2.63280 --> 2.55520).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.159637 \tValidation Loss: 2.499467\n",
      "Validation loss decreased (2.55520 --> 2.49947).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.003079 \tValidation Loss: 2.459798\n",
      "Validation loss decreased (2.49947 --> 2.45980).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.871003 \tValidation Loss: 2.430322\n",
      "Validation loss decreased (2.45980 --> 2.43032).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.765579 \tValidation Loss: 2.416076\n",
      "Validation loss decreased (2.43032 --> 2.41608).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.679093 \tValidation Loss: 2.410096\n",
      "Validation loss decreased (2.41608 --> 2.41010).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.612526 \tValidation Loss: 2.411595\n",
      "Epoch: 17 \tTraining Loss: 0.552953 \tValidation Loss: 2.415822\n",
      "Epoch: 18 \tTraining Loss: 0.501518 \tValidation Loss: 2.430203\n",
      "Epoch: 19 \tTraining Loss: 0.462564 \tValidation Loss: 2.446667\n",
      "Epoch: 20 \tTraining Loss: 0.425679 \tValidation Loss: 2.464680\n",
      "Epoch: 1 \tTraining Loss: 5.896751 \tValidation Loss: 4.656968\n",
      "Validation loss decreased (inf --> 4.65697).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.147057 \tValidation Loss: 4.391884\n",
      "Validation loss decreased (4.65697 --> 4.39188).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.676424 \tValidation Loss: 4.067831\n",
      "Validation loss decreased (4.39188 --> 4.06783).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.087346 \tValidation Loss: 3.738387\n",
      "Validation loss decreased (4.06783 --> 3.73839).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.459413 \tValidation Loss: 3.436203\n",
      "Validation loss decreased (3.73839 --> 3.43620).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.865993 \tValidation Loss: 3.176991\n",
      "Validation loss decreased (3.43620 --> 3.17699).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.358871 \tValidation Loss: 2.965918\n",
      "Validation loss decreased (3.17699 --> 2.96592).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.948002 \tValidation Loss: 2.798800\n",
      "Validation loss decreased (2.96592 --> 2.79880).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.621098 \tValidation Loss: 2.670206\n",
      "Validation loss decreased (2.79880 --> 2.67021).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.362038 \tValidation Loss: 2.573820\n",
      "Validation loss decreased (2.67021 --> 2.57382).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.162840 \tValidation Loss: 2.505436\n",
      "Validation loss decreased (2.57382 --> 2.50544).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.002555 \tValidation Loss: 2.460182\n",
      "Validation loss decreased (2.50544 --> 2.46018).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.872625 \tValidation Loss: 2.429771\n",
      "Validation loss decreased (2.46018 --> 2.42977).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.765913 \tValidation Loss: 2.413393\n",
      "Validation loss decreased (2.42977 --> 2.41339).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.680065 \tValidation Loss: 2.407477\n",
      "Validation loss decreased (2.41339 --> 2.40748).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.609412 \tValidation Loss: 2.408737\n",
      "Epoch: 17 \tTraining Loss: 0.551316 \tValidation Loss: 2.412727\n",
      "Epoch: 18 \tTraining Loss: 0.504190 \tValidation Loss: 2.424756\n",
      "Epoch: 19 \tTraining Loss: 0.462595 \tValidation Loss: 2.438093\n",
      "Epoch: 20 \tTraining Loss: 0.427107 \tValidation Loss: 2.456750\n",
      "Epoch: 1 \tTraining Loss: 5.887171 \tValidation Loss: 4.672444\n",
      "Validation loss decreased (inf --> 4.67244).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.150229 \tValidation Loss: 4.410449\n",
      "Validation loss decreased (4.67244 --> 4.41045).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.678873 \tValidation Loss: 4.085920\n",
      "Validation loss decreased (4.41045 --> 4.08592).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.087115 \tValidation Loss: 3.743314\n",
      "Validation loss decreased (4.08592 --> 3.74331).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.453796 \tValidation Loss: 3.424969\n",
      "Validation loss decreased (3.74331 --> 3.42497).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.861523 \tValidation Loss: 3.154105\n",
      "Validation loss decreased (3.42497 --> 3.15411).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.354379 \tValidation Loss: 2.936502\n",
      "Validation loss decreased (3.15411 --> 2.93650).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.947556 \tValidation Loss: 2.771227\n",
      "Validation loss decreased (2.93650 --> 2.77123).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.621249 \tValidation Loss: 2.648220\n",
      "Validation loss decreased (2.77123 --> 2.64822).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.367299 \tValidation Loss: 2.560044\n",
      "Validation loss decreased (2.64822 --> 2.56004).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.166311 \tValidation Loss: 2.495656\n",
      "Validation loss decreased (2.56004 --> 2.49566).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.005377 \tValidation Loss: 2.451677\n",
      "Validation loss decreased (2.49566 --> 2.45168).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.877904 \tValidation Loss: 2.423479\n",
      "Validation loss decreased (2.45168 --> 2.42348).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.770780 \tValidation Loss: 2.407503\n",
      "Validation loss decreased (2.42348 --> 2.40750).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.684582 \tValidation Loss: 2.400060\n",
      "Validation loss decreased (2.40750 --> 2.40006).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.615743 \tValidation Loss: 2.400271\n",
      "Epoch: 17 \tTraining Loss: 0.555579 \tValidation Loss: 2.404802\n",
      "Epoch: 18 \tTraining Loss: 0.505987 \tValidation Loss: 2.415472\n",
      "Epoch: 19 \tTraining Loss: 0.466128 \tValidation Loss: 2.431947\n",
      "Epoch: 20 \tTraining Loss: 0.430268 \tValidation Loss: 2.451581\n",
      "Epoch: 1 \tTraining Loss: 5.893910 \tValidation Loss: 4.596434\n",
      "Validation loss decreased (inf --> 4.59643).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.154621 \tValidation Loss: 4.344221\n",
      "Validation loss decreased (4.59643 --> 4.34422).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.689828 \tValidation Loss: 4.026117\n",
      "Validation loss decreased (4.34422 --> 4.02612).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.096987 \tValidation Loss: 3.697301\n",
      "Validation loss decreased (4.02612 --> 3.69730).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.454726 \tValidation Loss: 3.395849\n",
      "Validation loss decreased (3.69730 --> 3.39585).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.855355 \tValidation Loss: 3.144521\n",
      "Validation loss decreased (3.39585 --> 3.14452).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.349890 \tValidation Loss: 2.949244\n",
      "Validation loss decreased (3.14452 --> 2.94924).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.939536 \tValidation Loss: 2.803126\n",
      "Validation loss decreased (2.94924 --> 2.80313).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.618098 \tValidation Loss: 2.694307\n",
      "Validation loss decreased (2.80313 --> 2.69431).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.365378 \tValidation Loss: 2.616400\n",
      "Validation loss decreased (2.69431 --> 2.61640).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.164697 \tValidation Loss: 2.560746\n",
      "Validation loss decreased (2.61640 --> 2.56075).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.005176 \tValidation Loss: 2.522108\n",
      "Validation loss decreased (2.56075 --> 2.52211).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.875304 \tValidation Loss: 2.498506\n",
      "Validation loss decreased (2.52211 --> 2.49851).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.769474 \tValidation Loss: 2.485734\n",
      "Validation loss decreased (2.49851 --> 2.48573).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.684934 \tValidation Loss: 2.483986\n",
      "Validation loss decreased (2.48573 --> 2.48399).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.613221 \tValidation Loss: 2.488039\n",
      "Epoch: 17 \tTraining Loss: 0.555402 \tValidation Loss: 2.498806\n",
      "Epoch: 18 \tTraining Loss: 0.504559 \tValidation Loss: 2.514964\n",
      "Epoch: 19 \tTraining Loss: 0.467339 \tValidation Loss: 2.533853\n",
      "Epoch: 20 \tTraining Loss: 0.431888 \tValidation Loss: 2.557095\n",
      "Epoch: 1 \tTraining Loss: 5.887372 \tValidation Loss: 4.621545\n",
      "Validation loss decreased (inf --> 4.62154).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.153173 \tValidation Loss: 4.371297\n",
      "Validation loss decreased (4.62154 --> 4.37130).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.685524 \tValidation Loss: 4.050898\n",
      "Validation loss decreased (4.37130 --> 4.05090).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.090211 \tValidation Loss: 3.714963\n",
      "Validation loss decreased (4.05090 --> 3.71496).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \tTraining Loss: 3.452908 \tValidation Loss: 3.409971\n",
      "Validation loss decreased (3.71496 --> 3.40997).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.859257 \tValidation Loss: 3.156001\n",
      "Validation loss decreased (3.40997 --> 3.15600).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.352311 \tValidation Loss: 2.951953\n",
      "Validation loss decreased (3.15600 --> 2.95195).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.945229 \tValidation Loss: 2.793491\n",
      "Validation loss decreased (2.95195 --> 2.79349).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.622922 \tValidation Loss: 2.671616\n",
      "Validation loss decreased (2.79349 --> 2.67162).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.366642 \tValidation Loss: 2.581996\n",
      "Validation loss decreased (2.67162 --> 2.58200).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.164085 \tValidation Loss: 2.519013\n",
      "Validation loss decreased (2.58200 --> 2.51901).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.003977 \tValidation Loss: 2.474740\n",
      "Validation loss decreased (2.51901 --> 2.47474).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.873130 \tValidation Loss: 2.447851\n",
      "Validation loss decreased (2.47474 --> 2.44785).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.769083 \tValidation Loss: 2.432804\n",
      "Validation loss decreased (2.44785 --> 2.43280).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.678966 \tValidation Loss: 2.426982\n",
      "Validation loss decreased (2.43280 --> 2.42698).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.613738 \tValidation Loss: 2.431085\n",
      "Epoch: 17 \tTraining Loss: 0.552800 \tValidation Loss: 2.439261\n",
      "Epoch: 18 \tTraining Loss: 0.502511 \tValidation Loss: 2.452979\n",
      "Epoch: 19 \tTraining Loss: 0.462612 \tValidation Loss: 2.469762\n",
      "Epoch: 20 \tTraining Loss: 0.429351 \tValidation Loss: 2.490016\n",
      "Epoch: 1 \tTraining Loss: 5.900319 \tValidation Loss: 4.690155\n",
      "Validation loss decreased (inf --> 4.69016).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.145951 \tValidation Loss: 4.427920\n",
      "Validation loss decreased (4.69016 --> 4.42792).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.670026 \tValidation Loss: 4.104530\n",
      "Validation loss decreased (4.42792 --> 4.10453).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.079765 \tValidation Loss: 3.769006\n",
      "Validation loss decreased (4.10453 --> 3.76901).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.450435 \tValidation Loss: 3.459649\n",
      "Validation loss decreased (3.76901 --> 3.45965).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.859592 \tValidation Loss: 3.199604\n",
      "Validation loss decreased (3.45965 --> 3.19960).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.355188 \tValidation Loss: 2.992128\n",
      "Validation loss decreased (3.19960 --> 2.99213).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.948131 \tValidation Loss: 2.833487\n",
      "Validation loss decreased (2.99213 --> 2.83349).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.620133 \tValidation Loss: 2.715272\n",
      "Validation loss decreased (2.83349 --> 2.71527).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.365190 \tValidation Loss: 2.630606\n",
      "Validation loss decreased (2.71527 --> 2.63061).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.164917 \tValidation Loss: 2.569957\n",
      "Validation loss decreased (2.63061 --> 2.56996).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.005144 \tValidation Loss: 2.529376\n",
      "Validation loss decreased (2.56996 --> 2.52938).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.874317 \tValidation Loss: 2.503318\n",
      "Validation loss decreased (2.52938 --> 2.50332).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.767831 \tValidation Loss: 2.490607\n",
      "Validation loss decreased (2.50332 --> 2.49061).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.684996 \tValidation Loss: 2.484879\n",
      "Validation loss decreased (2.49061 --> 2.48488).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.614544 \tValidation Loss: 2.487687\n",
      "Epoch: 17 \tTraining Loss: 0.553427 \tValidation Loss: 2.499504\n",
      "Epoch: 18 \tTraining Loss: 0.506947 \tValidation Loss: 2.515152\n",
      "Epoch: 19 \tTraining Loss: 0.463066 \tValidation Loss: 2.533222\n",
      "Epoch: 20 \tTraining Loss: 0.427776 \tValidation Loss: 2.552258\n",
      "Epoch: 1 \tTraining Loss: 5.890482 \tValidation Loss: 4.650037\n",
      "Validation loss decreased (inf --> 4.65004).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.154907 \tValidation Loss: 4.386380\n",
      "Validation loss decreased (4.65004 --> 4.38638).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.686000 \tValidation Loss: 4.054550\n",
      "Validation loss decreased (4.38638 --> 4.05455).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.091107 \tValidation Loss: 3.715683\n",
      "Validation loss decreased (4.05455 --> 3.71568).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.453211 \tValidation Loss: 3.411327\n",
      "Validation loss decreased (3.71568 --> 3.41133).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.858782 \tValidation Loss: 3.159107\n",
      "Validation loss decreased (3.41133 --> 3.15911).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.354272 \tValidation Loss: 2.959337\n",
      "Validation loss decreased (3.15911 --> 2.95934).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.945330 \tValidation Loss: 2.803622\n",
      "Validation loss decreased (2.95934 --> 2.80362).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.622338 \tValidation Loss: 2.685710\n",
      "Validation loss decreased (2.80362 --> 2.68571).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.367493 \tValidation Loss: 2.596118\n",
      "Validation loss decreased (2.68571 --> 2.59612).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.166172 \tValidation Loss: 2.531961\n",
      "Validation loss decreased (2.59612 --> 2.53196).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.004811 \tValidation Loss: 2.487319\n",
      "Validation loss decreased (2.53196 --> 2.48732).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.877232 \tValidation Loss: 2.457954\n",
      "Validation loss decreased (2.48732 --> 2.45795).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.770581 \tValidation Loss: 2.440095\n",
      "Validation loss decreased (2.45795 --> 2.44009).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.683959 \tValidation Loss: 2.429981\n",
      "Validation loss decreased (2.44009 --> 2.42998).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.612656 \tValidation Loss: 2.430166\n",
      "Epoch: 17 \tTraining Loss: 0.554374 \tValidation Loss: 2.432806\n",
      "Epoch: 18 \tTraining Loss: 0.505291 \tValidation Loss: 2.444079\n",
      "Epoch: 19 \tTraining Loss: 0.465953 \tValidation Loss: 2.457755\n",
      "Epoch: 20 \tTraining Loss: 0.430733 \tValidation Loss: 2.475877\n",
      "Epoch: 1 \tTraining Loss: 5.884560 \tValidation Loss: 4.601199\n",
      "Validation loss decreased (inf --> 4.60120).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.150485 \tValidation Loss: 4.341607\n",
      "Validation loss decreased (4.60120 --> 4.34161).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.685251 \tValidation Loss: 4.019921\n",
      "Validation loss decreased (4.34161 --> 4.01992).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.097387 \tValidation Loss: 3.684419\n",
      "Validation loss decreased (4.01992 --> 3.68442).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.460090 \tValidation Loss: 3.379070\n",
      "Validation loss decreased (3.68442 --> 3.37907).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.859660 \tValidation Loss: 3.127695\n",
      "Validation loss decreased (3.37907 --> 3.12769).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.348149 \tValidation Loss: 2.930934\n",
      "Validation loss decreased (3.12769 --> 2.93093).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.937682 \tValidation Loss: 2.776374\n",
      "Validation loss decreased (2.93093 --> 2.77637).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.615338 \tValidation Loss: 2.654418\n",
      "Validation loss decreased (2.77637 --> 2.65442).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.364149 \tValidation Loss: 2.562244\n",
      "Validation loss decreased (2.65442 --> 2.56224).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.160993 \tValidation Loss: 2.492073\n",
      "Validation loss decreased (2.56224 --> 2.49207).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.002972 \tValidation Loss: 2.443677\n",
      "Validation loss decreased (2.49207 --> 2.44368).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.873007 \tValidation Loss: 2.411596\n",
      "Validation loss decreased (2.44368 --> 2.41160).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.768124 \tValidation Loss: 2.389376\n",
      "Validation loss decreased (2.41160 --> 2.38938).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.684014 \tValidation Loss: 2.379090\n",
      "Validation loss decreased (2.38938 --> 2.37909).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.610950 \tValidation Loss: 2.375988\n",
      "Validation loss decreased (2.37909 --> 2.37599).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 \tTraining Loss: 0.552819 \tValidation Loss: 2.383462\n",
      "Epoch: 18 \tTraining Loss: 0.503733 \tValidation Loss: 2.392771\n",
      "Epoch: 19 \tTraining Loss: 0.465611 \tValidation Loss: 2.405043\n",
      "Epoch: 20 \tTraining Loss: 0.427940 \tValidation Loss: 2.421881\n",
      "Epoch: 1 \tTraining Loss: 5.889926 \tValidation Loss: 4.636245\n",
      "Validation loss decreased (inf --> 4.63625).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.153514 \tValidation Loss: 4.382750\n",
      "Validation loss decreased (4.63625 --> 4.38275).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.685591 \tValidation Loss: 4.068898\n",
      "Validation loss decreased (4.38275 --> 4.06890).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.094089 \tValidation Loss: 3.738869\n",
      "Validation loss decreased (4.06890 --> 3.73887).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.456750 \tValidation Loss: 3.430991\n",
      "Validation loss decreased (3.73887 --> 3.43099).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.859140 \tValidation Loss: 3.170482\n",
      "Validation loss decreased (3.43099 --> 3.17048).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.346131 \tValidation Loss: 2.962360\n",
      "Validation loss decreased (3.17048 --> 2.96236).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.933964 \tValidation Loss: 2.801634\n",
      "Validation loss decreased (2.96236 --> 2.80163).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.608845 \tValidation Loss: 2.680276\n",
      "Validation loss decreased (2.80163 --> 2.68028).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.354088 \tValidation Loss: 2.590380\n",
      "Validation loss decreased (2.68028 --> 2.59038).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.155711 \tValidation Loss: 2.525591\n",
      "Validation loss decreased (2.59038 --> 2.52559).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.992361 \tValidation Loss: 2.480952\n",
      "Validation loss decreased (2.52559 --> 2.48095).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.864388 \tValidation Loss: 2.451465\n",
      "Validation loss decreased (2.48095 --> 2.45147).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.762433 \tValidation Loss: 2.434165\n",
      "Validation loss decreased (2.45147 --> 2.43416).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.673883 \tValidation Loss: 2.430773\n",
      "Validation loss decreased (2.43416 --> 2.43077).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.605827 \tValidation Loss: 2.429200\n",
      "Validation loss decreased (2.43077 --> 2.42920).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.546297 \tValidation Loss: 2.434405\n",
      "Epoch: 18 \tTraining Loss: 0.500010 \tValidation Loss: 2.444399\n",
      "Epoch: 19 \tTraining Loss: 0.457594 \tValidation Loss: 2.462374\n",
      "Epoch: 20 \tTraining Loss: 0.424863 \tValidation Loss: 2.482077\n",
      "Epoch: 1 \tTraining Loss: 5.901129 \tValidation Loss: 4.617365\n",
      "Validation loss decreased (inf --> 4.61736).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.161574 \tValidation Loss: 4.365038\n",
      "Validation loss decreased (4.61736 --> 4.36504).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.693361 \tValidation Loss: 4.038425\n",
      "Validation loss decreased (4.36504 --> 4.03843).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.097844 \tValidation Loss: 3.696488\n",
      "Validation loss decreased (4.03843 --> 3.69649).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.453619 \tValidation Loss: 3.384878\n",
      "Validation loss decreased (3.69649 --> 3.38488).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.852080 \tValidation Loss: 3.127139\n",
      "Validation loss decreased (3.38488 --> 3.12714).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.340009 \tValidation Loss: 2.923650\n",
      "Validation loss decreased (3.12714 --> 2.92365).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.931440 \tValidation Loss: 2.767946\n",
      "Validation loss decreased (2.92365 --> 2.76795).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.607021 \tValidation Loss: 2.653353\n",
      "Validation loss decreased (2.76795 --> 2.65335).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.351136 \tValidation Loss: 2.572310\n",
      "Validation loss decreased (2.65335 --> 2.57231).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.152406 \tValidation Loss: 2.513740\n",
      "Validation loss decreased (2.57231 --> 2.51374).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.991748 \tValidation Loss: 2.477136\n",
      "Validation loss decreased (2.51374 --> 2.47714).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.863718 \tValidation Loss: 2.451261\n",
      "Validation loss decreased (2.47714 --> 2.45126).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.758952 \tValidation Loss: 2.439479\n",
      "Validation loss decreased (2.45126 --> 2.43948).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.671851 \tValidation Loss: 2.439768\n",
      "Epoch: 16 \tTraining Loss: 0.602890 \tValidation Loss: 2.441076\n",
      "Epoch: 17 \tTraining Loss: 0.545029 \tValidation Loss: 2.451658\n",
      "Epoch: 18 \tTraining Loss: 0.497526 \tValidation Loss: 2.465797\n",
      "Epoch: 19 \tTraining Loss: 0.455722 \tValidation Loss: 2.483145\n",
      "Epoch: 20 \tTraining Loss: 0.423387 \tValidation Loss: 2.504242\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 7 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 5.839280 \tValidation Loss: 5.334803\n",
      "Validation loss decreased (inf --> 5.33480).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.052194 \tValidation Loss: 5.038180\n",
      "Validation loss decreased (5.33480 --> 5.03818).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.582652 \tValidation Loss: 4.687049\n",
      "Validation loss decreased (5.03818 --> 4.68705).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 3.998052 \tValidation Loss: 4.300881\n",
      "Validation loss decreased (4.68705 --> 4.30088).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.368880 \tValidation Loss: 3.925079\n",
      "Validation loss decreased (4.30088 --> 3.92508).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.774762 \tValidation Loss: 3.594490\n",
      "Validation loss decreased (3.92508 --> 3.59449).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.262290 \tValidation Loss: 3.325471\n",
      "Validation loss decreased (3.59449 --> 3.32547).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.847470 \tValidation Loss: 3.120705\n",
      "Validation loss decreased (3.32547 --> 3.12070).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.521862 \tValidation Loss: 2.967554\n",
      "Validation loss decreased (3.12070 --> 2.96755).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.266190 \tValidation Loss: 2.855988\n",
      "Validation loss decreased (2.96755 --> 2.85599).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.057274 \tValidation Loss: 2.776579\n",
      "Validation loss decreased (2.85599 --> 2.77658).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.895297 \tValidation Loss: 2.721588\n",
      "Validation loss decreased (2.77658 --> 2.72159).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.766040 \tValidation Loss: 2.683875\n",
      "Validation loss decreased (2.72159 --> 2.68387).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.657584 \tValidation Loss: 2.660717\n",
      "Validation loss decreased (2.68387 --> 2.66072).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.569260 \tValidation Loss: 2.646536\n",
      "Validation loss decreased (2.66072 --> 2.64654).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.500164 \tValidation Loss: 2.645520\n",
      "Validation loss decreased (2.64654 --> 2.64552).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.442872 \tValidation Loss: 2.650742\n",
      "Epoch: 18 \tTraining Loss: 0.396108 \tValidation Loss: 2.660315\n",
      "Epoch: 19 \tTraining Loss: 0.357833 \tValidation Loss: 2.675558\n",
      "Epoch: 20 \tTraining Loss: 0.324848 \tValidation Loss: 2.694555\n",
      "Epoch: 1 \tTraining Loss: 5.836897 \tValidation Loss: 5.277857\n",
      "Validation loss decreased (inf --> 5.27786).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.054469 \tValidation Loss: 4.993815\n",
      "Validation loss decreased (5.27786 --> 4.99382).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.583286 \tValidation Loss: 4.633121\n",
      "Validation loss decreased (4.99382 --> 4.63312).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 3.995410 \tValidation Loss: 4.240354\n",
      "Validation loss decreased (4.63312 --> 4.24035).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.359172 \tValidation Loss: 3.870125\n",
      "Validation loss decreased (4.24035 --> 3.87012).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.757283 \tValidation Loss: 3.562527\n",
      "Validation loss decreased (3.87012 --> 3.56253).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.245343 \tValidation Loss: 3.321026\n",
      "Validation loss decreased (3.56253 --> 3.32103).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.827672 \tValidation Loss: 3.139525\n",
      "Validation loss decreased (3.32103 --> 3.13953).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.505990 \tValidation Loss: 3.006479\n",
      "Validation loss decreased (3.13953 --> 3.00648).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 \tTraining Loss: 1.247000 \tValidation Loss: 2.907762\n",
      "Validation loss decreased (3.00648 --> 2.90776).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.043614 \tValidation Loss: 2.836704\n",
      "Validation loss decreased (2.90776 --> 2.83670).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.877929 \tValidation Loss: 2.787368\n",
      "Validation loss decreased (2.83670 --> 2.78737).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.747259 \tValidation Loss: 2.755178\n",
      "Validation loss decreased (2.78737 --> 2.75518).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.642640 \tValidation Loss: 2.736843\n",
      "Validation loss decreased (2.75518 --> 2.73684).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.557479 \tValidation Loss: 2.728382\n",
      "Validation loss decreased (2.73684 --> 2.72838).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.489692 \tValidation Loss: 2.727823\n",
      "Validation loss decreased (2.72838 --> 2.72782).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.434403 \tValidation Loss: 2.734457\n",
      "Epoch: 18 \tTraining Loss: 0.387338 \tValidation Loss: 2.745527\n",
      "Epoch: 19 \tTraining Loss: 0.346884 \tValidation Loss: 2.766916\n",
      "Epoch: 20 \tTraining Loss: 0.318105 \tValidation Loss: 2.782921\n",
      "Epoch: 1 \tTraining Loss: 5.827319 \tValidation Loss: 5.333132\n",
      "Validation loss decreased (inf --> 5.33313).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.056519 \tValidation Loss: 5.053408\n",
      "Validation loss decreased (5.33313 --> 5.05341).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.589262 \tValidation Loss: 4.695336\n",
      "Validation loss decreased (5.05341 --> 4.69534).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 3.994821 \tValidation Loss: 4.311293\n",
      "Validation loss decreased (4.69534 --> 4.31129).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.349584 \tValidation Loss: 3.953436\n",
      "Validation loss decreased (4.31129 --> 3.95344).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.744915 \tValidation Loss: 3.653556\n",
      "Validation loss decreased (3.95344 --> 3.65356).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.237187 \tValidation Loss: 3.415406\n",
      "Validation loss decreased (3.65356 --> 3.41541).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.827396 \tValidation Loss: 3.232403\n",
      "Validation loss decreased (3.41541 --> 3.23240).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.507358 \tValidation Loss: 3.095228\n",
      "Validation loss decreased (3.23240 --> 3.09523).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.251347 \tValidation Loss: 2.994312\n",
      "Validation loss decreased (3.09523 --> 2.99431).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.046652 \tValidation Loss: 2.921360\n",
      "Validation loss decreased (2.99431 --> 2.92136).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.882929 \tValidation Loss: 2.870645\n",
      "Validation loss decreased (2.92136 --> 2.87064).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.750957 \tValidation Loss: 2.836857\n",
      "Validation loss decreased (2.87064 --> 2.83686).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.648953 \tValidation Loss: 2.819090\n",
      "Validation loss decreased (2.83686 --> 2.81909).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.560636 \tValidation Loss: 2.813468\n",
      "Validation loss decreased (2.81909 --> 2.81347).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.491333 \tValidation Loss: 2.815448\n",
      "Epoch: 17 \tTraining Loss: 0.436340 \tValidation Loss: 2.820800\n",
      "Epoch: 18 \tTraining Loss: 0.389837 \tValidation Loss: 2.833992\n",
      "Epoch: 19 \tTraining Loss: 0.350845 \tValidation Loss: 2.857822\n",
      "Epoch: 20 \tTraining Loss: 0.318844 \tValidation Loss: 2.873567\n",
      "Epoch: 1 \tTraining Loss: 5.835583 \tValidation Loss: 5.268385\n",
      "Validation loss decreased (inf --> 5.26839).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.064665 \tValidation Loss: 4.993446\n",
      "Validation loss decreased (5.26839 --> 4.99345).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.597653 \tValidation Loss: 4.632164\n",
      "Validation loss decreased (4.99345 --> 4.63216).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 3.999705 \tValidation Loss: 4.251511\n",
      "Validation loss decreased (4.63216 --> 4.25151).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.355164 \tValidation Loss: 3.890895\n",
      "Validation loss decreased (4.25151 --> 3.89090).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.749045 \tValidation Loss: 3.584704\n",
      "Validation loss decreased (3.89090 --> 3.58470).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.233912 \tValidation Loss: 3.340724\n",
      "Validation loss decreased (3.58470 --> 3.34072).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.817021 \tValidation Loss: 3.155600\n",
      "Validation loss decreased (3.34072 --> 3.15560).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.494589 \tValidation Loss: 3.017601\n",
      "Validation loss decreased (3.15560 --> 3.01760).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.236828 \tValidation Loss: 2.917365\n",
      "Validation loss decreased (3.01760 --> 2.91736).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.034942 \tValidation Loss: 2.846146\n",
      "Validation loss decreased (2.91736 --> 2.84615).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.877528 \tValidation Loss: 2.796826\n",
      "Validation loss decreased (2.84615 --> 2.79683).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.747915 \tValidation Loss: 2.761625\n",
      "Validation loss decreased (2.79683 --> 2.76162).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.642005 \tValidation Loss: 2.740807\n",
      "Validation loss decreased (2.76162 --> 2.74081).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.557213 \tValidation Loss: 2.731322\n",
      "Validation loss decreased (2.74081 --> 2.73132).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.489079 \tValidation Loss: 2.732678\n",
      "Epoch: 17 \tTraining Loss: 0.434243 \tValidation Loss: 2.742132\n",
      "Epoch: 18 \tTraining Loss: 0.388906 \tValidation Loss: 2.756353\n",
      "Epoch: 19 \tTraining Loss: 0.351382 \tValidation Loss: 2.771199\n",
      "Epoch: 20 \tTraining Loss: 0.321404 \tValidation Loss: 2.789130\n",
      "Epoch: 1 \tTraining Loss: 5.842868 \tValidation Loss: 5.276764\n",
      "Validation loss decreased (inf --> 5.27676).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.053658 \tValidation Loss: 4.982380\n",
      "Validation loss decreased (5.27676 --> 4.98238).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.586416 \tValidation Loss: 4.616888\n",
      "Validation loss decreased (4.98238 --> 4.61689).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 3.999123 \tValidation Loss: 4.220619\n",
      "Validation loss decreased (4.61689 --> 4.22062).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.364677 \tValidation Loss: 3.848843\n",
      "Validation loss decreased (4.22062 --> 3.84884).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.766655 \tValidation Loss: 3.538149\n",
      "Validation loss decreased (3.84884 --> 3.53815).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.257109 \tValidation Loss: 3.289078\n",
      "Validation loss decreased (3.53815 --> 3.28908).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.841950 \tValidation Loss: 3.093356\n",
      "Validation loss decreased (3.28908 --> 3.09336).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.513957 \tValidation Loss: 2.943065\n",
      "Validation loss decreased (3.09336 --> 2.94307).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.256545 \tValidation Loss: 2.831803\n",
      "Validation loss decreased (2.94307 --> 2.83180).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.050092 \tValidation Loss: 2.751147\n",
      "Validation loss decreased (2.83180 --> 2.75115).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.888738 \tValidation Loss: 2.694079\n",
      "Validation loss decreased (2.75115 --> 2.69408).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.758137 \tValidation Loss: 2.652895\n",
      "Validation loss decreased (2.69408 --> 2.65290).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.652555 \tValidation Loss: 2.623082\n",
      "Validation loss decreased (2.65290 --> 2.62308).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.564841 \tValidation Loss: 2.606806\n",
      "Validation loss decreased (2.62308 --> 2.60681).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.497435 \tValidation Loss: 2.600829\n",
      "Validation loss decreased (2.60681 --> 2.60083).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.441667 \tValidation Loss: 2.601360\n",
      "Epoch: 18 \tTraining Loss: 0.393100 \tValidation Loss: 2.607761\n",
      "Epoch: 19 \tTraining Loss: 0.356163 \tValidation Loss: 2.619733\n",
      "Epoch: 20 \tTraining Loss: 0.324496 \tValidation Loss: 2.635080\n",
      "Epoch: 1 \tTraining Loss: 5.843960 \tValidation Loss: 5.330632\n",
      "Validation loss decreased (inf --> 5.33063).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.054122 \tValidation Loss: 5.046778\n",
      "Validation loss decreased (5.33063 --> 5.04678).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.585048 \tValidation Loss: 4.692387\n",
      "Validation loss decreased (5.04678 --> 4.69239).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 \tTraining Loss: 3.993866 \tValidation Loss: 4.306294\n",
      "Validation loss decreased (4.69239 --> 4.30629).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.352729 \tValidation Loss: 3.946433\n",
      "Validation loss decreased (4.30629 --> 3.94643).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.748938 \tValidation Loss: 3.642652\n",
      "Validation loss decreased (3.94643 --> 3.64265).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.234664 \tValidation Loss: 3.399675\n",
      "Validation loss decreased (3.64265 --> 3.39967).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.819398 \tValidation Loss: 3.213429\n",
      "Validation loss decreased (3.39967 --> 3.21343).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.493694 \tValidation Loss: 3.074023\n",
      "Validation loss decreased (3.21343 --> 3.07402).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.236650 \tValidation Loss: 2.974064\n",
      "Validation loss decreased (3.07402 --> 2.97406).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.035709 \tValidation Loss: 2.903771\n",
      "Validation loss decreased (2.97406 --> 2.90377).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.876221 \tValidation Loss: 2.854855\n",
      "Validation loss decreased (2.90377 --> 2.85485).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.749858 \tValidation Loss: 2.826370\n",
      "Validation loss decreased (2.85485 --> 2.82637).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.643390 \tValidation Loss: 2.811289\n",
      "Validation loss decreased (2.82637 --> 2.81129).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.559309 \tValidation Loss: 2.804462\n",
      "Validation loss decreased (2.81129 --> 2.80446).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.486676 \tValidation Loss: 2.804979\n",
      "Epoch: 17 \tTraining Loss: 0.434389 \tValidation Loss: 2.817228\n",
      "Epoch: 18 \tTraining Loss: 0.386946 \tValidation Loss: 2.835203\n",
      "Epoch: 19 \tTraining Loss: 0.350090 \tValidation Loss: 2.852940\n",
      "Epoch: 20 \tTraining Loss: 0.320126 \tValidation Loss: 2.872816\n",
      "Epoch: 1 \tTraining Loss: 5.836977 \tValidation Loss: 5.276725\n",
      "Validation loss decreased (inf --> 5.27673).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.054786 \tValidation Loss: 4.991109\n",
      "Validation loss decreased (5.27673 --> 4.99111).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.588706 \tValidation Loss: 4.630705\n",
      "Validation loss decreased (4.99111 --> 4.63071).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 3.999578 \tValidation Loss: 4.247204\n",
      "Validation loss decreased (4.63071 --> 4.24720).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.359615 \tValidation Loss: 3.894334\n",
      "Validation loss decreased (4.24720 --> 3.89433).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.757419 \tValidation Loss: 3.596937\n",
      "Validation loss decreased (3.89433 --> 3.59694).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.238551 \tValidation Loss: 3.361563\n",
      "Validation loss decreased (3.59694 --> 3.36156).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.822826 \tValidation Loss: 3.184085\n",
      "Validation loss decreased (3.36156 --> 3.18408).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.495808 \tValidation Loss: 3.048844\n",
      "Validation loss decreased (3.18408 --> 3.04884).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.243974 \tValidation Loss: 2.948585\n",
      "Validation loss decreased (3.04884 --> 2.94858).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.042784 \tValidation Loss: 2.877149\n",
      "Validation loss decreased (2.94858 --> 2.87715).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.880127 \tValidation Loss: 2.828019\n",
      "Validation loss decreased (2.87715 --> 2.82802).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.749795 \tValidation Loss: 2.792862\n",
      "Validation loss decreased (2.82802 --> 2.79286).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.647626 \tValidation Loss: 2.772972\n",
      "Validation loss decreased (2.79286 --> 2.77297).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.561846 \tValidation Loss: 2.764137\n",
      "Validation loss decreased (2.77297 --> 2.76414).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.487945 \tValidation Loss: 2.764037\n",
      "Validation loss decreased (2.76414 --> 2.76404).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.436058 \tValidation Loss: 2.771051\n",
      "Epoch: 18 \tTraining Loss: 0.388973 \tValidation Loss: 2.784228\n",
      "Epoch: 19 \tTraining Loss: 0.351577 \tValidation Loss: 2.799517\n",
      "Epoch: 20 \tTraining Loss: 0.319648 \tValidation Loss: 2.818105\n",
      "Epoch: 1 \tTraining Loss: 5.838328 \tValidation Loss: 5.262383\n",
      "Validation loss decreased (inf --> 5.26238).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.064429 \tValidation Loss: 4.971056\n",
      "Validation loss decreased (5.26238 --> 4.97106).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.604231 \tValidation Loss: 4.606308\n",
      "Validation loss decreased (4.97106 --> 4.60631).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.020270 \tValidation Loss: 4.213057\n",
      "Validation loss decreased (4.60631 --> 4.21306).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.384663 \tValidation Loss: 3.838523\n",
      "Validation loss decreased (4.21306 --> 3.83852).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.781455 \tValidation Loss: 3.521827\n",
      "Validation loss decreased (3.83852 --> 3.52183).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.261741 \tValidation Loss: 3.272486\n",
      "Validation loss decreased (3.52183 --> 3.27249).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.841305 \tValidation Loss: 3.084900\n",
      "Validation loss decreased (3.27249 --> 3.08490).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.513984 \tValidation Loss: 2.942426\n",
      "Validation loss decreased (3.08490 --> 2.94243).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.253561 \tValidation Loss: 2.838665\n",
      "Validation loss decreased (2.94243 --> 2.83867).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.050527 \tValidation Loss: 2.760987\n",
      "Validation loss decreased (2.83867 --> 2.76099).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.885620 \tValidation Loss: 2.706313\n",
      "Validation loss decreased (2.76099 --> 2.70631).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.757874 \tValidation Loss: 2.669969\n",
      "Validation loss decreased (2.70631 --> 2.66997).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.649769 \tValidation Loss: 2.649205\n",
      "Validation loss decreased (2.66997 --> 2.64920).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.562817 \tValidation Loss: 2.638686\n",
      "Validation loss decreased (2.64920 --> 2.63869).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.495678 \tValidation Loss: 2.635261\n",
      "Validation loss decreased (2.63869 --> 2.63526).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.438932 \tValidation Loss: 2.641618\n",
      "Epoch: 18 \tTraining Loss: 0.391333 \tValidation Loss: 2.651858\n",
      "Epoch: 19 \tTraining Loss: 0.353191 \tValidation Loss: 2.667434\n",
      "Epoch: 20 \tTraining Loss: 0.322330 \tValidation Loss: 2.687667\n",
      "Epoch: 1 \tTraining Loss: 5.849261 \tValidation Loss: 5.289232\n",
      "Validation loss decreased (inf --> 5.28923).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.061304 \tValidation Loss: 5.014908\n",
      "Validation loss decreased (5.28923 --> 5.01491).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.592422 \tValidation Loss: 4.662294\n",
      "Validation loss decreased (5.01491 --> 4.66229).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.000682 \tValidation Loss: 4.283792\n",
      "Validation loss decreased (4.66229 --> 4.28379).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.358973 \tValidation Loss: 3.923447\n",
      "Validation loss decreased (4.28379 --> 3.92345).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.751888 \tValidation Loss: 3.625024\n",
      "Validation loss decreased (3.92345 --> 3.62502).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.234343 \tValidation Loss: 3.392426\n",
      "Validation loss decreased (3.62502 --> 3.39243).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.814481 \tValidation Loss: 3.215628\n",
      "Validation loss decreased (3.39243 --> 3.21563).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.488385 \tValidation Loss: 3.085983\n",
      "Validation loss decreased (3.21563 --> 3.08598).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.232581 \tValidation Loss: 2.993783\n",
      "Validation loss decreased (3.08598 --> 2.99378).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.027784 \tValidation Loss: 2.928707\n",
      "Validation loss decreased (2.99378 --> 2.92871).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.866931 \tValidation Loss: 2.883841\n",
      "Validation loss decreased (2.92871 --> 2.88384).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.739165 \tValidation Loss: 2.856185\n",
      "Validation loss decreased (2.88384 --> 2.85619).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.638535 \tValidation Loss: 2.841690\n",
      "Validation loss decreased (2.85619 --> 2.84169).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 \tTraining Loss: 0.553117 \tValidation Loss: 2.840396\n",
      "Validation loss decreased (2.84169 --> 2.84040).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.483959 \tValidation Loss: 2.847516\n",
      "Epoch: 17 \tTraining Loss: 0.430761 \tValidation Loss: 2.861068\n",
      "Epoch: 18 \tTraining Loss: 0.382150 \tValidation Loss: 2.876744\n",
      "Epoch: 19 \tTraining Loss: 0.347196 \tValidation Loss: 2.897436\n",
      "Epoch: 20 \tTraining Loss: 0.316208 \tValidation Loss: 2.922285\n",
      "Epoch: 1 \tTraining Loss: 5.836364 \tValidation Loss: 5.328334\n",
      "Validation loss decreased (inf --> 5.32833).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.049459 \tValidation Loss: 5.039531\n",
      "Validation loss decreased (5.32833 --> 5.03953).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.582431 \tValidation Loss: 4.677492\n",
      "Validation loss decreased (5.03953 --> 4.67749).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 3.994744 \tValidation Loss: 4.283713\n",
      "Validation loss decreased (4.67749 --> 4.28371).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.355956 \tValidation Loss: 3.912507\n",
      "Validation loss decreased (4.28371 --> 3.91251).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.758385 \tValidation Loss: 3.597402\n",
      "Validation loss decreased (3.91251 --> 3.59740).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.247356 \tValidation Loss: 3.344888\n",
      "Validation loss decreased (3.59740 --> 3.34489).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.837732 \tValidation Loss: 3.149055\n",
      "Validation loss decreased (3.34489 --> 3.14906).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.509392 \tValidation Loss: 2.999913\n",
      "Validation loss decreased (3.14906 --> 2.99991).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.251317 \tValidation Loss: 2.887767\n",
      "Validation loss decreased (2.99991 --> 2.88777).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.051855 \tValidation Loss: 2.804388\n",
      "Validation loss decreased (2.88777 --> 2.80439).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.887011 \tValidation Loss: 2.746991\n",
      "Validation loss decreased (2.80439 --> 2.74699).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.756179 \tValidation Loss: 2.702399\n",
      "Validation loss decreased (2.74699 --> 2.70240).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.650186 \tValidation Loss: 2.678816\n",
      "Validation loss decreased (2.70240 --> 2.67882).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.565279 \tValidation Loss: 2.663361\n",
      "Validation loss decreased (2.67882 --> 2.66336).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.494698 \tValidation Loss: 2.659837\n",
      "Validation loss decreased (2.66336 --> 2.65984).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.439382 \tValidation Loss: 2.663269\n",
      "Epoch: 18 \tTraining Loss: 0.394622 \tValidation Loss: 2.668849\n",
      "Epoch: 19 \tTraining Loss: 0.354451 \tValidation Loss: 2.682008\n",
      "Epoch: 20 \tTraining Loss: 0.323381 \tValidation Loss: 2.700439\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 8 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 5.963741 \tValidation Loss: 4.885503\n",
      "Validation loss decreased (inf --> 4.88550).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.114038 \tValidation Loss: 4.641347\n",
      "Validation loss decreased (4.88550 --> 4.64135).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.653476 \tValidation Loss: 4.313916\n",
      "Validation loss decreased (4.64135 --> 4.31392).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.072778 \tValidation Loss: 3.953566\n",
      "Validation loss decreased (4.31392 --> 3.95357).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.433410 \tValidation Loss: 3.605408\n",
      "Validation loss decreased (3.95357 --> 3.60541).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.825772 \tValidation Loss: 3.304523\n",
      "Validation loss decreased (3.60541 --> 3.30452).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.298509 \tValidation Loss: 3.063842\n",
      "Validation loss decreased (3.30452 --> 3.06384).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.868205 \tValidation Loss: 2.878237\n",
      "Validation loss decreased (3.06384 --> 2.87824).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.524058 \tValidation Loss: 2.737938\n",
      "Validation loss decreased (2.87824 --> 2.73794).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.250617 \tValidation Loss: 2.631454\n",
      "Validation loss decreased (2.73794 --> 2.63145).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.034195 \tValidation Loss: 2.552101\n",
      "Validation loss decreased (2.63145 --> 2.55210).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.862419 \tValidation Loss: 2.493749\n",
      "Validation loss decreased (2.55210 --> 2.49375).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.722182 \tValidation Loss: 2.450802\n",
      "Validation loss decreased (2.49375 --> 2.45080).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.611367 \tValidation Loss: 2.423482\n",
      "Validation loss decreased (2.45080 --> 2.42348).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.519430 \tValidation Loss: 2.406472\n",
      "Validation loss decreased (2.42348 --> 2.40647).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.450809 \tValidation Loss: 2.399838\n",
      "Validation loss decreased (2.40647 --> 2.39984).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.393437 \tValidation Loss: 2.398786\n",
      "Validation loss decreased (2.39984 --> 2.39879).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.345276 \tValidation Loss: 2.403051\n",
      "Epoch: 19 \tTraining Loss: 0.308062 \tValidation Loss: 2.412071\n",
      "Epoch: 20 \tTraining Loss: 0.279279 \tValidation Loss: 2.426149\n",
      "Epoch: 1 \tTraining Loss: 5.950513 \tValidation Loss: 4.914003\n",
      "Validation loss decreased (inf --> 4.91400).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.114188 \tValidation Loss: 4.660334\n",
      "Validation loss decreased (4.91400 --> 4.66033).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.656115 \tValidation Loss: 4.326132\n",
      "Validation loss decreased (4.66033 --> 4.32613).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.072080 \tValidation Loss: 3.959618\n",
      "Validation loss decreased (4.32613 --> 3.95962).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.427168 \tValidation Loss: 3.614754\n",
      "Validation loss decreased (3.95962 --> 3.61475).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.811480 \tValidation Loss: 3.322196\n",
      "Validation loss decreased (3.61475 --> 3.32220).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.287125 \tValidation Loss: 3.087082\n",
      "Validation loss decreased (3.32220 --> 3.08708).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.863760 \tValidation Loss: 2.901262\n",
      "Validation loss decreased (3.08708 --> 2.90126).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.522836 \tValidation Loss: 2.755361\n",
      "Validation loss decreased (2.90126 --> 2.75536).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.251082 \tValidation Loss: 2.641388\n",
      "Validation loss decreased (2.75536 --> 2.64139).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.031445 \tValidation Loss: 2.555233\n",
      "Validation loss decreased (2.64139 --> 2.55523).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.859514 \tValidation Loss: 2.493610\n",
      "Validation loss decreased (2.55523 --> 2.49361).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.721316 \tValidation Loss: 2.448083\n",
      "Validation loss decreased (2.49361 --> 2.44808).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.611115 \tValidation Loss: 2.416220\n",
      "Validation loss decreased (2.44808 --> 2.41622).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.519964 \tValidation Loss: 2.396232\n",
      "Validation loss decreased (2.41622 --> 2.39623).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.446749 \tValidation Loss: 2.387846\n",
      "Validation loss decreased (2.39623 --> 2.38785).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.389154 \tValidation Loss: 2.387204\n",
      "Validation loss decreased (2.38785 --> 2.38720).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.341170 \tValidation Loss: 2.392122\n",
      "Epoch: 19 \tTraining Loss: 0.303643 \tValidation Loss: 2.402648\n",
      "Epoch: 20 \tTraining Loss: 0.271526 \tValidation Loss: 2.416151\n",
      "Epoch: 1 \tTraining Loss: 5.960335 \tValidation Loss: 4.907244\n",
      "Validation loss decreased (inf --> 4.90724).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.109949 \tValidation Loss: 4.658065\n",
      "Validation loss decreased (4.90724 --> 4.65807).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.639972 \tValidation Loss: 4.326456\n",
      "Validation loss decreased (4.65807 --> 4.32646).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.051745 \tValidation Loss: 3.965572\n",
      "Validation loss decreased (4.32646 --> 3.96557).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.412671 \tValidation Loss: 3.622889\n",
      "Validation loss decreased (3.96557 --> 3.62289).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.805049 \tValidation Loss: 3.329995\n",
      "Validation loss decreased (3.62289 --> 3.32999).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 \tTraining Loss: 2.282567 \tValidation Loss: 3.094659\n",
      "Validation loss decreased (3.32999 --> 3.09466).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.858371 \tValidation Loss: 2.912633\n",
      "Validation loss decreased (3.09466 --> 2.91263).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.520674 \tValidation Loss: 2.773558\n",
      "Validation loss decreased (2.91263 --> 2.77356).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.249070 \tValidation Loss: 2.670441\n",
      "Validation loss decreased (2.77356 --> 2.67044).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.035181 \tValidation Loss: 2.594078\n",
      "Validation loss decreased (2.67044 --> 2.59408).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.866428 \tValidation Loss: 2.539406\n",
      "Validation loss decreased (2.59408 --> 2.53941).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.727032 \tValidation Loss: 2.503797\n",
      "Validation loss decreased (2.53941 --> 2.50380).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.618365 \tValidation Loss: 2.482850\n",
      "Validation loss decreased (2.50380 --> 2.48285).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.529080 \tValidation Loss: 2.471800\n",
      "Validation loss decreased (2.48285 --> 2.47180).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.456581 \tValidation Loss: 2.467854\n",
      "Validation loss decreased (2.47180 --> 2.46785).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.398966 \tValidation Loss: 2.472083\n",
      "Epoch: 18 \tTraining Loss: 0.355439 \tValidation Loss: 2.483984\n",
      "Epoch: 19 \tTraining Loss: 0.313536 \tValidation Loss: 2.495531\n",
      "Epoch: 20 \tTraining Loss: 0.282152 \tValidation Loss: 2.512843\n",
      "Epoch: 1 \tTraining Loss: 5.959550 \tValidation Loss: 4.928706\n",
      "Validation loss decreased (inf --> 4.92871).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.105718 \tValidation Loss: 4.674028\n",
      "Validation loss decreased (4.92871 --> 4.67403).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.634202 \tValidation Loss: 4.351841\n",
      "Validation loss decreased (4.67403 --> 4.35184).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.044084 \tValidation Loss: 4.001529\n",
      "Validation loss decreased (4.35184 --> 4.00153).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.402667 \tValidation Loss: 3.667982\n",
      "Validation loss decreased (4.00153 --> 3.66798).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.793546 \tValidation Loss: 3.376065\n",
      "Validation loss decreased (3.66798 --> 3.37606).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.270363 \tValidation Loss: 3.139321\n",
      "Validation loss decreased (3.37606 --> 3.13932).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.846019 \tValidation Loss: 2.954020\n",
      "Validation loss decreased (3.13932 --> 2.95402).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.505942 \tValidation Loss: 2.812370\n",
      "Validation loss decreased (2.95402 --> 2.81237).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.236446 \tValidation Loss: 2.706297\n",
      "Validation loss decreased (2.81237 --> 2.70630).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.021852 \tValidation Loss: 2.625567\n",
      "Validation loss decreased (2.70630 --> 2.62557).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.852529 \tValidation Loss: 2.566636\n",
      "Validation loss decreased (2.62557 --> 2.56664).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.713525 \tValidation Loss: 2.525786\n",
      "Validation loss decreased (2.56664 --> 2.52579).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.605634 \tValidation Loss: 2.499984\n",
      "Validation loss decreased (2.52579 --> 2.49998).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.515420 \tValidation Loss: 2.485389\n",
      "Validation loss decreased (2.49998 --> 2.48539).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.448526 \tValidation Loss: 2.480108\n",
      "Validation loss decreased (2.48539 --> 2.48011).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.389528 \tValidation Loss: 2.481265\n",
      "Epoch: 18 \tTraining Loss: 0.343465 \tValidation Loss: 2.486719\n",
      "Epoch: 19 \tTraining Loss: 0.304299 \tValidation Loss: 2.497083\n",
      "Epoch: 20 \tTraining Loss: 0.275320 \tValidation Loss: 2.511223\n",
      "Epoch: 1 \tTraining Loss: 5.948264 \tValidation Loss: 4.931129\n",
      "Validation loss decreased (inf --> 4.93113).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.120993 \tValidation Loss: 4.671123\n",
      "Validation loss decreased (4.93113 --> 4.67112).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.667407 \tValidation Loss: 4.332103\n",
      "Validation loss decreased (4.67112 --> 4.33210).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.085601 \tValidation Loss: 3.961858\n",
      "Validation loss decreased (4.33210 --> 3.96186).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.439872 \tValidation Loss: 3.611466\n",
      "Validation loss decreased (3.96186 --> 3.61147).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.824613 \tValidation Loss: 3.313044\n",
      "Validation loss decreased (3.61147 --> 3.31304).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.295513 \tValidation Loss: 3.072817\n",
      "Validation loss decreased (3.31304 --> 3.07282).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.864895 \tValidation Loss: 2.885024\n",
      "Validation loss decreased (3.07282 --> 2.88502).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.524016 \tValidation Loss: 2.743306\n",
      "Validation loss decreased (2.88502 --> 2.74331).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.252836 \tValidation Loss: 2.637353\n",
      "Validation loss decreased (2.74331 --> 2.63735).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.035535 \tValidation Loss: 2.557570\n",
      "Validation loss decreased (2.63735 --> 2.55757).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.863920 \tValidation Loss: 2.499334\n",
      "Validation loss decreased (2.55757 --> 2.49933).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.723456 \tValidation Loss: 2.457873\n",
      "Validation loss decreased (2.49933 --> 2.45787).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.614683 \tValidation Loss: 2.430059\n",
      "Validation loss decreased (2.45787 --> 2.43006).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.525571 \tValidation Loss: 2.411168\n",
      "Validation loss decreased (2.43006 --> 2.41117).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.453724 \tValidation Loss: 2.402953\n",
      "Validation loss decreased (2.41117 --> 2.40295).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.393343 \tValidation Loss: 2.401050\n",
      "Validation loss decreased (2.40295 --> 2.40105).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.346487 \tValidation Loss: 2.406307\n",
      "Epoch: 19 \tTraining Loss: 0.307930 \tValidation Loss: 2.415684\n",
      "Epoch: 20 \tTraining Loss: 0.277051 \tValidation Loss: 2.426743\n",
      "Epoch: 1 \tTraining Loss: 5.961854 \tValidation Loss: 4.935452\n",
      "Validation loss decreased (inf --> 4.93545).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.106000 \tValidation Loss: 4.686502\n",
      "Validation loss decreased (4.93545 --> 4.68650).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.624688 \tValidation Loss: 4.362275\n",
      "Validation loss decreased (4.68650 --> 4.36228).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.031309 \tValidation Loss: 4.010787\n",
      "Validation loss decreased (4.36228 --> 4.01079).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.390269 \tValidation Loss: 3.676848\n",
      "Validation loss decreased (4.01079 --> 3.67685).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.782362 \tValidation Loss: 3.392019\n",
      "Validation loss decreased (3.67685 --> 3.39202).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.260066 \tValidation Loss: 3.161835\n",
      "Validation loss decreased (3.39202 --> 3.16184).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.836560 \tValidation Loss: 2.982615\n",
      "Validation loss decreased (3.16184 --> 2.98262).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.499026 \tValidation Loss: 2.846340\n",
      "Validation loss decreased (2.98262 --> 2.84634).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.230119 \tValidation Loss: 2.743821\n",
      "Validation loss decreased (2.84634 --> 2.74382).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.017550 \tValidation Loss: 2.668484\n",
      "Validation loss decreased (2.74382 --> 2.66848).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.850063 \tValidation Loss: 2.615346\n",
      "Validation loss decreased (2.66848 --> 2.61535).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.711856 \tValidation Loss: 2.580050\n",
      "Validation loss decreased (2.61535 --> 2.58005).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.604322 \tValidation Loss: 2.558197\n",
      "Validation loss decreased (2.58005 --> 2.55820).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.515990 \tValidation Loss: 2.545992\n",
      "Validation loss decreased (2.55820 --> 2.54599).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.447386 \tValidation Loss: 2.538868\n",
      "Validation loss decreased (2.54599 --> 2.53887).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 \tTraining Loss: 0.388821 \tValidation Loss: 2.539998\n",
      "Epoch: 18 \tTraining Loss: 0.342080 \tValidation Loss: 2.549228\n",
      "Epoch: 19 \tTraining Loss: 0.301846 \tValidation Loss: 2.561817\n",
      "Epoch: 20 \tTraining Loss: 0.274066 \tValidation Loss: 2.576525\n",
      "Epoch: 1 \tTraining Loss: 5.950619 \tValidation Loss: 4.910557\n",
      "Validation loss decreased (inf --> 4.91056).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.110302 \tValidation Loss: 4.657396\n",
      "Validation loss decreased (4.91056 --> 4.65740).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.642754 \tValidation Loss: 4.321752\n",
      "Validation loss decreased (4.65740 --> 4.32175).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.057950 \tValidation Loss: 3.957259\n",
      "Validation loss decreased (4.32175 --> 3.95726).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.416096 \tValidation Loss: 3.614209\n",
      "Validation loss decreased (3.95726 --> 3.61421).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.800390 \tValidation Loss: 3.324063\n",
      "Validation loss decreased (3.61421 --> 3.32406).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.274570 \tValidation Loss: 3.095127\n",
      "Validation loss decreased (3.32406 --> 3.09513).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.850052 \tValidation Loss: 2.918269\n",
      "Validation loss decreased (3.09513 --> 2.91827).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.508991 \tValidation Loss: 2.783677\n",
      "Validation loss decreased (2.91827 --> 2.78368).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.239570 \tValidation Loss: 2.683737\n",
      "Validation loss decreased (2.78368 --> 2.68374).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.023491 \tValidation Loss: 2.610555\n",
      "Validation loss decreased (2.68374 --> 2.61056).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.855623 \tValidation Loss: 2.558913\n",
      "Validation loss decreased (2.61056 --> 2.55891).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.714877 \tValidation Loss: 2.523144\n",
      "Validation loss decreased (2.55891 --> 2.52314).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.606521 \tValidation Loss: 2.497624\n",
      "Validation loss decreased (2.52314 --> 2.49762).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.516568 \tValidation Loss: 2.485027\n",
      "Validation loss decreased (2.49762 --> 2.48503).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.446662 \tValidation Loss: 2.479436\n",
      "Validation loss decreased (2.48503 --> 2.47944).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.388757 \tValidation Loss: 2.480898\n",
      "Epoch: 18 \tTraining Loss: 0.341308 \tValidation Loss: 2.487521\n",
      "Epoch: 19 \tTraining Loss: 0.302916 \tValidation Loss: 2.500437\n",
      "Epoch: 20 \tTraining Loss: 0.272839 \tValidation Loss: 2.515181\n",
      "Epoch: 1 \tTraining Loss: 5.957701 \tValidation Loss: 4.895084\n",
      "Validation loss decreased (inf --> 4.89508).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.117050 \tValidation Loss: 4.635894\n",
      "Validation loss decreased (4.89508 --> 4.63589).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.655913 \tValidation Loss: 4.299712\n",
      "Validation loss decreased (4.63589 --> 4.29971).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.072149 \tValidation Loss: 3.939003\n",
      "Validation loss decreased (4.29971 --> 3.93900).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.431838 \tValidation Loss: 3.603540\n",
      "Validation loss decreased (3.93900 --> 3.60354).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.821313 \tValidation Loss: 3.322511\n",
      "Validation loss decreased (3.60354 --> 3.32251).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.295010 \tValidation Loss: 3.100661\n",
      "Validation loss decreased (3.32251 --> 3.10066).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.865303 \tValidation Loss: 2.930360\n",
      "Validation loss decreased (3.10066 --> 2.93036).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.528811 \tValidation Loss: 2.801310\n",
      "Validation loss decreased (2.93036 --> 2.80131).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.255997 \tValidation Loss: 2.699416\n",
      "Validation loss decreased (2.80131 --> 2.69942).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.042347 \tValidation Loss: 2.619779\n",
      "Validation loss decreased (2.69942 --> 2.61978).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.868101 \tValidation Loss: 2.561939\n",
      "Validation loss decreased (2.61978 --> 2.56194).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.727994 \tValidation Loss: 2.519480\n",
      "Validation loss decreased (2.56194 --> 2.51948).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.619577 \tValidation Loss: 2.492735\n",
      "Validation loss decreased (2.51948 --> 2.49274).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.527785 \tValidation Loss: 2.476883\n",
      "Validation loss decreased (2.49274 --> 2.47688).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.450295 \tValidation Loss: 2.470998\n",
      "Validation loss decreased (2.47688 --> 2.47100).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.396851 \tValidation Loss: 2.472253\n",
      "Epoch: 18 \tTraining Loss: 0.344884 \tValidation Loss: 2.479508\n",
      "Epoch: 19 \tTraining Loss: 0.307997 \tValidation Loss: 2.489904\n",
      "Epoch: 20 \tTraining Loss: 0.277912 \tValidation Loss: 2.499352\n",
      "Epoch: 1 \tTraining Loss: 5.956493 \tValidation Loss: 4.916750\n",
      "Validation loss decreased (inf --> 4.91675).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.114493 \tValidation Loss: 4.662349\n",
      "Validation loss decreased (4.91675 --> 4.66235).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.653338 \tValidation Loss: 4.323434\n",
      "Validation loss decreased (4.66235 --> 4.32343).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.067242 \tValidation Loss: 3.966214\n",
      "Validation loss decreased (4.32343 --> 3.96621).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.427101 \tValidation Loss: 3.631458\n",
      "Validation loss decreased (3.96621 --> 3.63146).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.816784 \tValidation Loss: 3.350800\n",
      "Validation loss decreased (3.63146 --> 3.35080).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.289662 \tValidation Loss: 3.129213\n",
      "Validation loss decreased (3.35080 --> 3.12921).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.862342 \tValidation Loss: 2.956946\n",
      "Validation loss decreased (3.12921 --> 2.95695).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.522153 \tValidation Loss: 2.829028\n",
      "Validation loss decreased (2.95695 --> 2.82903).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.252865 \tValidation Loss: 2.734951\n",
      "Validation loss decreased (2.82903 --> 2.73495).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.033817 \tValidation Loss: 2.666431\n",
      "Validation loss decreased (2.73495 --> 2.66643).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.861917 \tValidation Loss: 2.617960\n",
      "Validation loss decreased (2.66643 --> 2.61796).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.721442 \tValidation Loss: 2.583017\n",
      "Validation loss decreased (2.61796 --> 2.58302).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.610377 \tValidation Loss: 2.562695\n",
      "Validation loss decreased (2.58302 --> 2.56270).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.520498 \tValidation Loss: 2.552656\n",
      "Validation loss decreased (2.56270 --> 2.55266).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.447053 \tValidation Loss: 2.551695\n",
      "Validation loss decreased (2.55266 --> 2.55169).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.390396 \tValidation Loss: 2.554170\n",
      "Epoch: 18 \tTraining Loss: 0.342227 \tValidation Loss: 2.562584\n",
      "Epoch: 19 \tTraining Loss: 0.303968 \tValidation Loss: 2.575855\n",
      "Epoch: 20 \tTraining Loss: 0.274910 \tValidation Loss: 2.591349\n",
      "Epoch: 1 \tTraining Loss: 5.959172 \tValidation Loss: 4.969690\n",
      "Validation loss decreased (inf --> 4.96969).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.104795 \tValidation Loss: 4.715316\n",
      "Validation loss decreased (4.96969 --> 4.71532).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.634856 \tValidation Loss: 4.387160\n",
      "Validation loss decreased (4.71532 --> 4.38716).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.046662 \tValidation Loss: 4.034345\n",
      "Validation loss decreased (4.38716 --> 4.03434).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.407013 \tValidation Loss: 3.703534\n",
      "Validation loss decreased (4.03434 --> 3.70353).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.795926 \tValidation Loss: 3.426037\n",
      "Validation loss decreased (3.70353 --> 3.42604).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.276325 \tValidation Loss: 3.203153\n",
      "Validation loss decreased (3.42604 --> 3.20315).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.850821 \tValidation Loss: 3.029353\n",
      "Validation loss decreased (3.20315 --> 3.02935).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.513632 \tValidation Loss: 2.894641\n",
      "Validation loss decreased (3.02935 --> 2.89464).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 \tTraining Loss: 1.244668 \tValidation Loss: 2.789605\n",
      "Validation loss decreased (2.89464 --> 2.78961).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.032025 \tValidation Loss: 2.710154\n",
      "Validation loss decreased (2.78961 --> 2.71015).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.856666 \tValidation Loss: 2.654401\n",
      "Validation loss decreased (2.71015 --> 2.65440).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.718243 \tValidation Loss: 2.616097\n",
      "Validation loss decreased (2.65440 --> 2.61610).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.607320 \tValidation Loss: 2.590213\n",
      "Validation loss decreased (2.61610 --> 2.59021).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.518860 \tValidation Loss: 2.574744\n",
      "Validation loss decreased (2.59021 --> 2.57474).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.445761 \tValidation Loss: 2.566659\n",
      "Validation loss decreased (2.57474 --> 2.56666).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.387605 \tValidation Loss: 2.568354\n",
      "Epoch: 18 \tTraining Loss: 0.340977 \tValidation Loss: 2.572616\n",
      "Epoch: 19 \tTraining Loss: 0.302097 \tValidation Loss: 2.585510\n",
      "Epoch: 20 \tTraining Loss: 0.272650 \tValidation Loss: 2.605032\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 9 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 5.961192 \tValidation Loss: 4.441458\n",
      "Validation loss decreased (inf --> 4.44146).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.077226 \tValidation Loss: 4.207898\n",
      "Validation loss decreased (4.44146 --> 4.20790).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.661203 \tValidation Loss: 3.937424\n",
      "Validation loss decreased (4.20790 --> 3.93742).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.133342 \tValidation Loss: 3.635470\n",
      "Validation loss decreased (3.93742 --> 3.63547).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.530386 \tValidation Loss: 3.337009\n",
      "Validation loss decreased (3.63547 --> 3.33701).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.933195 \tValidation Loss: 3.073854\n",
      "Validation loss decreased (3.33701 --> 3.07385).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.403827 \tValidation Loss: 2.860474\n",
      "Validation loss decreased (3.07385 --> 2.86047).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.964858 \tValidation Loss: 2.693406\n",
      "Validation loss decreased (2.86047 --> 2.69341).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.606327 \tValidation Loss: 2.564392\n",
      "Validation loss decreased (2.69341 --> 2.56439).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.318111 \tValidation Loss: 2.464038\n",
      "Validation loss decreased (2.56439 --> 2.46404).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.087508 \tValidation Loss: 2.388102\n",
      "Validation loss decreased (2.46404 --> 2.38810).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.895772 \tValidation Loss: 2.332593\n",
      "Validation loss decreased (2.38810 --> 2.33259).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.744119 \tValidation Loss: 2.294050\n",
      "Validation loss decreased (2.33259 --> 2.29405).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.623539 \tValidation Loss: 2.266400\n",
      "Validation loss decreased (2.29405 --> 2.26640).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.523108 \tValidation Loss: 2.252151\n",
      "Validation loss decreased (2.26640 --> 2.25215).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.442832 \tValidation Loss: 2.244582\n",
      "Validation loss decreased (2.25215 --> 2.24458).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.379419 \tValidation Loss: 2.244687\n",
      "Epoch: 18 \tTraining Loss: 0.326899 \tValidation Loss: 2.249991\n",
      "Epoch: 19 \tTraining Loss: 0.283572 \tValidation Loss: 2.256512\n",
      "Epoch: 20 \tTraining Loss: 0.249825 \tValidation Loss: 2.266865\n",
      "Epoch: 1 \tTraining Loss: 5.966067 \tValidation Loss: 4.482524\n",
      "Validation loss decreased (inf --> 4.48252).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.067692 \tValidation Loss: 4.246700\n",
      "Validation loss decreased (4.48252 --> 4.24670).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.641306 \tValidation Loss: 3.983032\n",
      "Validation loss decreased (4.24670 --> 3.98303).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.112963 \tValidation Loss: 3.690672\n",
      "Validation loss decreased (3.98303 --> 3.69067).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.513699 \tValidation Loss: 3.398192\n",
      "Validation loss decreased (3.69067 --> 3.39819).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.915536 \tValidation Loss: 3.139911\n",
      "Validation loss decreased (3.39819 --> 3.13991).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.392872 \tValidation Loss: 2.926877\n",
      "Validation loss decreased (3.13991 --> 2.92688).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.954307 \tValidation Loss: 2.758468\n",
      "Validation loss decreased (2.92688 --> 2.75847).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.599347 \tValidation Loss: 2.629632\n",
      "Validation loss decreased (2.75847 --> 2.62963).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.311287 \tValidation Loss: 2.532173\n",
      "Validation loss decreased (2.62963 --> 2.53217).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.076699 \tValidation Loss: 2.457296\n",
      "Validation loss decreased (2.53217 --> 2.45730).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.890641 \tValidation Loss: 2.405373\n",
      "Validation loss decreased (2.45730 --> 2.40537).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.742275 \tValidation Loss: 2.368543\n",
      "Validation loss decreased (2.40537 --> 2.36854).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.620364 \tValidation Loss: 2.347726\n",
      "Validation loss decreased (2.36854 --> 2.34773).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.518759 \tValidation Loss: 2.337403\n",
      "Validation loss decreased (2.34773 --> 2.33740).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.441550 \tValidation Loss: 2.333471\n",
      "Validation loss decreased (2.33740 --> 2.33347).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.377061 \tValidation Loss: 2.336445\n",
      "Epoch: 18 \tTraining Loss: 0.324728 \tValidation Loss: 2.340569\n",
      "Epoch: 19 \tTraining Loss: 0.285354 \tValidation Loss: 2.353141\n",
      "Epoch: 20 \tTraining Loss: 0.251187 \tValidation Loss: 2.365222\n",
      "Epoch: 1 \tTraining Loss: 5.967739 \tValidation Loss: 4.475471\n",
      "Validation loss decreased (inf --> 4.47547).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.073203 \tValidation Loss: 4.237472\n",
      "Validation loss decreased (4.47547 --> 4.23747).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.645683 \tValidation Loss: 3.979811\n",
      "Validation loss decreased (4.23747 --> 3.97981).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.109245 \tValidation Loss: 3.683918\n",
      "Validation loss decreased (3.97981 --> 3.68392).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.501855 \tValidation Loss: 3.395196\n",
      "Validation loss decreased (3.68392 --> 3.39520).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.908290 \tValidation Loss: 3.148185\n",
      "Validation loss decreased (3.39520 --> 3.14818).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.382504 \tValidation Loss: 2.946336\n",
      "Validation loss decreased (3.14818 --> 2.94634).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.946153 \tValidation Loss: 2.783952\n",
      "Validation loss decreased (2.94634 --> 2.78395).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.593880 \tValidation Loss: 2.654069\n",
      "Validation loss decreased (2.78395 --> 2.65407).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.306538 \tValidation Loss: 2.552050\n",
      "Validation loss decreased (2.65407 --> 2.55205).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.075475 \tValidation Loss: 2.471313\n",
      "Validation loss decreased (2.55205 --> 2.47131).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.888243 \tValidation Loss: 2.410207\n",
      "Validation loss decreased (2.47131 --> 2.41021).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.738800 \tValidation Loss: 2.365463\n",
      "Validation loss decreased (2.41021 --> 2.36546).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.617328 \tValidation Loss: 2.334098\n",
      "Validation loss decreased (2.36546 --> 2.33410).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.517257 \tValidation Loss: 2.313254\n",
      "Validation loss decreased (2.33410 --> 2.31325).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.437191 \tValidation Loss: 2.303733\n",
      "Validation loss decreased (2.31325 --> 2.30373).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.374319 \tValidation Loss: 2.300408\n",
      "Validation loss decreased (2.30373 --> 2.30041).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.321809 \tValidation Loss: 2.302790\n",
      "Epoch: 19 \tTraining Loss: 0.284589 \tValidation Loss: 2.308786\n",
      "Epoch: 20 \tTraining Loss: 0.250669 \tValidation Loss: 2.317187\n",
      "Epoch: 1 \tTraining Loss: 5.965048 \tValidation Loss: 4.485731\n",
      "Validation loss decreased (inf --> 4.48573).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 5.065623 \tValidation Loss: 4.237897\n",
      "Validation loss decreased (4.48573 --> 4.23790).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.643472 \tValidation Loss: 3.967063\n",
      "Validation loss decreased (4.23790 --> 3.96706).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.112489 \tValidation Loss: 3.659329\n",
      "Validation loss decreased (3.96706 --> 3.65933).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.508462 \tValidation Loss: 3.358801\n",
      "Validation loss decreased (3.65933 --> 3.35880).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.914673 \tValidation Loss: 3.097550\n",
      "Validation loss decreased (3.35880 --> 3.09755).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.388766 \tValidation Loss: 2.888896\n",
      "Validation loss decreased (3.09755 --> 2.88890).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.949642 \tValidation Loss: 2.727567\n",
      "Validation loss decreased (2.88890 --> 2.72757).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.596872 \tValidation Loss: 2.604601\n",
      "Validation loss decreased (2.72757 --> 2.60460).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.311173 \tValidation Loss: 2.509999\n",
      "Validation loss decreased (2.60460 --> 2.51000).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.078411 \tValidation Loss: 2.436625\n",
      "Validation loss decreased (2.51000 --> 2.43662).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.894109 \tValidation Loss: 2.382920\n",
      "Validation loss decreased (2.43662 --> 2.38292).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.741090 \tValidation Loss: 2.345641\n",
      "Validation loss decreased (2.38292 --> 2.34564).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.621402 \tValidation Loss: 2.320099\n",
      "Validation loss decreased (2.34564 --> 2.32010).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.522036 \tValidation Loss: 2.302330\n",
      "Validation loss decreased (2.32010 --> 2.30233).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.442562 \tValidation Loss: 2.293900\n",
      "Validation loss decreased (2.30233 --> 2.29390).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.378819 \tValidation Loss: 2.292242\n",
      "Validation loss decreased (2.29390 --> 2.29224).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.329405 \tValidation Loss: 2.293780\n",
      "Epoch: 19 \tTraining Loss: 0.287216 \tValidation Loss: 2.296281\n",
      "Epoch: 20 \tTraining Loss: 0.253476 \tValidation Loss: 2.306777\n",
      "Epoch: 1 \tTraining Loss: 5.967071 \tValidation Loss: 4.463674\n",
      "Validation loss decreased (inf --> 4.46367).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.062527 \tValidation Loss: 4.220857\n",
      "Validation loss decreased (4.46367 --> 4.22086).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.637892 \tValidation Loss: 3.950105\n",
      "Validation loss decreased (4.22086 --> 3.95010).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.105992 \tValidation Loss: 3.641827\n",
      "Validation loss decreased (3.95010 --> 3.64183).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.501934 \tValidation Loss: 3.337226\n",
      "Validation loss decreased (3.64183 --> 3.33723).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.903860 \tValidation Loss: 3.069694\n",
      "Validation loss decreased (3.33723 --> 3.06969).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.380064 \tValidation Loss: 2.847759\n",
      "Validation loss decreased (3.06969 --> 2.84776).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.938765 \tValidation Loss: 2.672075\n",
      "Validation loss decreased (2.84776 --> 2.67208).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.584683 \tValidation Loss: 2.537320\n",
      "Validation loss decreased (2.67208 --> 2.53732).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.303213 \tValidation Loss: 2.435292\n",
      "Validation loss decreased (2.53732 --> 2.43529).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.070375 \tValidation Loss: 2.360569\n",
      "Validation loss decreased (2.43529 --> 2.36057).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.885656 \tValidation Loss: 2.306804\n",
      "Validation loss decreased (2.36057 --> 2.30680).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.734741 \tValidation Loss: 2.268295\n",
      "Validation loss decreased (2.30680 --> 2.26830).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.612889 \tValidation Loss: 2.241276\n",
      "Validation loss decreased (2.26830 --> 2.24128).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.515475 \tValidation Loss: 2.228735\n",
      "Validation loss decreased (2.24128 --> 2.22873).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.436050 \tValidation Loss: 2.219782\n",
      "Validation loss decreased (2.22873 --> 2.21978).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.374421 \tValidation Loss: 2.215872\n",
      "Validation loss decreased (2.21978 --> 2.21587).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.319158 \tValidation Loss: 2.219032\n",
      "Epoch: 19 \tTraining Loss: 0.281556 \tValidation Loss: 2.228337\n",
      "Epoch: 20 \tTraining Loss: 0.247586 \tValidation Loss: 2.234967\n",
      "Epoch: 1 \tTraining Loss: 5.960477 \tValidation Loss: 4.482901\n",
      "Validation loss decreased (inf --> 4.48290).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.067896 \tValidation Loss: 4.257764\n",
      "Validation loss decreased (4.48290 --> 4.25776).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.644493 \tValidation Loss: 4.000488\n",
      "Validation loss decreased (4.25776 --> 4.00049).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.117135 \tValidation Loss: 3.717564\n",
      "Validation loss decreased (4.00049 --> 3.71756).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.517333 \tValidation Loss: 3.434567\n",
      "Validation loss decreased (3.71756 --> 3.43457).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.920624 \tValidation Loss: 3.187573\n",
      "Validation loss decreased (3.43457 --> 3.18757).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.390846 \tValidation Loss: 2.988791\n",
      "Validation loss decreased (3.18757 --> 2.98879).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.949131 \tValidation Loss: 2.831567\n",
      "Validation loss decreased (2.98879 --> 2.83157).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.589082 \tValidation Loss: 2.710981\n",
      "Validation loss decreased (2.83157 --> 2.71098).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.300109 \tValidation Loss: 2.619689\n",
      "Validation loss decreased (2.71098 --> 2.61969).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.068996 \tValidation Loss: 2.553173\n",
      "Validation loss decreased (2.61969 --> 2.55317).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.884637 \tValidation Loss: 2.502413\n",
      "Validation loss decreased (2.55317 --> 2.50241).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.732462 \tValidation Loss: 2.468776\n",
      "Validation loss decreased (2.50241 --> 2.46878).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.610381 \tValidation Loss: 2.443794\n",
      "Validation loss decreased (2.46878 --> 2.44379).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.514299 \tValidation Loss: 2.427407\n",
      "Validation loss decreased (2.44379 --> 2.42741).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.434171 \tValidation Loss: 2.420583\n",
      "Validation loss decreased (2.42741 --> 2.42058).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.370422 \tValidation Loss: 2.420676\n",
      "Epoch: 18 \tTraining Loss: 0.321653 \tValidation Loss: 2.424580\n",
      "Epoch: 19 \tTraining Loss: 0.279869 \tValidation Loss: 2.432997\n",
      "Epoch: 20 \tTraining Loss: 0.245881 \tValidation Loss: 2.446350\n",
      "Epoch: 1 \tTraining Loss: 5.958773 \tValidation Loss: 4.459571\n",
      "Validation loss decreased (inf --> 4.45957).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.065163 \tValidation Loss: 4.226041\n",
      "Validation loss decreased (4.45957 --> 4.22604).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.651567 \tValidation Loss: 3.960904\n",
      "Validation loss decreased (4.22604 --> 3.96090).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.124257 \tValidation Loss: 3.658158\n",
      "Validation loss decreased (3.96090 --> 3.65816).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.518138 \tValidation Loss: 3.361787\n",
      "Validation loss decreased (3.65816 --> 3.36179).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.917332 \tValidation Loss: 3.108739\n",
      "Validation loss decreased (3.36179 --> 3.10874).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.388458 \tValidation Loss: 2.905870\n",
      "Validation loss decreased (3.10874 --> 2.90587).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.948867 \tValidation Loss: 2.745917\n",
      "Validation loss decreased (2.90587 --> 2.74592).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.594905 \tValidation Loss: 2.626748\n",
      "Validation loss decreased (2.74592 --> 2.62675).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.304557 \tValidation Loss: 2.539146\n",
      "Validation loss decreased (2.62675 --> 2.53915).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.075426 \tValidation Loss: 2.473504\n",
      "Validation loss decreased (2.53915 --> 2.47350).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 \tTraining Loss: 0.886554 \tValidation Loss: 2.426220\n",
      "Validation loss decreased (2.47350 --> 2.42622).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.737543 \tValidation Loss: 2.393768\n",
      "Validation loss decreased (2.42622 --> 2.39377).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.613682 \tValidation Loss: 2.370705\n",
      "Validation loss decreased (2.39377 --> 2.37071).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.516989 \tValidation Loss: 2.358395\n",
      "Validation loss decreased (2.37071 --> 2.35840).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.440098 \tValidation Loss: 2.353539\n",
      "Validation loss decreased (2.35840 --> 2.35354).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.372031 \tValidation Loss: 2.356826\n",
      "Epoch: 18 \tTraining Loss: 0.322805 \tValidation Loss: 2.364465\n",
      "Epoch: 19 \tTraining Loss: 0.280691 \tValidation Loss: 2.374738\n",
      "Epoch: 20 \tTraining Loss: 0.248864 \tValidation Loss: 2.387572\n",
      "Epoch: 1 \tTraining Loss: 5.968136 \tValidation Loss: 4.452189\n",
      "Validation loss decreased (inf --> 4.45219).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.074148 \tValidation Loss: 4.212710\n",
      "Validation loss decreased (4.45219 --> 4.21271).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.659159 \tValidation Loss: 3.949074\n",
      "Validation loss decreased (4.21271 --> 3.94907).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.126161 \tValidation Loss: 3.655373\n",
      "Validation loss decreased (3.94907 --> 3.65537).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.519470 \tValidation Loss: 3.368348\n",
      "Validation loss decreased (3.65537 --> 3.36835).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.918295 \tValidation Loss: 3.115709\n",
      "Validation loss decreased (3.36835 --> 3.11571).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.387377 \tValidation Loss: 2.903551\n",
      "Validation loss decreased (3.11571 --> 2.90355).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.948225 \tValidation Loss: 2.735569\n",
      "Validation loss decreased (2.90355 --> 2.73557).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.593346 \tValidation Loss: 2.608337\n",
      "Validation loss decreased (2.73557 --> 2.60834).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.305529 \tValidation Loss: 2.512285\n",
      "Validation loss decreased (2.60834 --> 2.51229).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.072897 \tValidation Loss: 2.442523\n",
      "Validation loss decreased (2.51229 --> 2.44252).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.885113 \tValidation Loss: 2.393277\n",
      "Validation loss decreased (2.44252 --> 2.39328).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.736343 \tValidation Loss: 2.358818\n",
      "Validation loss decreased (2.39328 --> 2.35882).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.609823 \tValidation Loss: 2.339479\n",
      "Validation loss decreased (2.35882 --> 2.33948).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.512448 \tValidation Loss: 2.328215\n",
      "Validation loss decreased (2.33948 --> 2.32822).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.432799 \tValidation Loss: 2.326194\n",
      "Validation loss decreased (2.32822 --> 2.32619).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.373391 \tValidation Loss: 2.326252\n",
      "Epoch: 18 \tTraining Loss: 0.322178 \tValidation Loss: 2.334739\n",
      "Epoch: 19 \tTraining Loss: 0.279479 \tValidation Loss: 2.349537\n",
      "Epoch: 20 \tTraining Loss: 0.247865 \tValidation Loss: 2.363225\n",
      "Epoch: 1 \tTraining Loss: 5.962875 \tValidation Loss: 4.506183\n",
      "Validation loss decreased (inf --> 4.50618).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.066994 \tValidation Loss: 4.275266\n",
      "Validation loss decreased (4.50618 --> 4.27527).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.649995 \tValidation Loss: 4.005891\n",
      "Validation loss decreased (4.27527 --> 4.00589).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.128066 \tValidation Loss: 3.691211\n",
      "Validation loss decreased (4.00589 --> 3.69121).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.531828 \tValidation Loss: 3.371029\n",
      "Validation loss decreased (3.69121 --> 3.37103).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.940022 \tValidation Loss: 3.087423\n",
      "Validation loss decreased (3.37103 --> 3.08742).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.409991 \tValidation Loss: 2.859329\n",
      "Validation loss decreased (3.08742 --> 2.85933).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.966453 \tValidation Loss: 2.682310\n",
      "Validation loss decreased (2.85933 --> 2.68231).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.607024 \tValidation Loss: 2.545710\n",
      "Validation loss decreased (2.68231 --> 2.54571).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.318860 \tValidation Loss: 2.440127\n",
      "Validation loss decreased (2.54571 --> 2.44013).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.085585 \tValidation Loss: 2.359422\n",
      "Validation loss decreased (2.44013 --> 2.35942).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.895946 \tValidation Loss: 2.298603\n",
      "Validation loss decreased (2.35942 --> 2.29860).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.746801 \tValidation Loss: 2.253611\n",
      "Validation loss decreased (2.29860 --> 2.25361).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.619033 \tValidation Loss: 2.224483\n",
      "Validation loss decreased (2.25361 --> 2.22448).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.523138 \tValidation Loss: 2.205590\n",
      "Validation loss decreased (2.22448 --> 2.20559).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.442962 \tValidation Loss: 2.195317\n",
      "Validation loss decreased (2.20559 --> 2.19532).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.379997 \tValidation Loss: 2.192480\n",
      "Validation loss decreased (2.19532 --> 2.19248).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.329132 \tValidation Loss: 2.194310\n",
      "Epoch: 19 \tTraining Loss: 0.288117 \tValidation Loss: 2.200588\n",
      "Epoch: 20 \tTraining Loss: 0.255681 \tValidation Loss: 2.210096\n",
      "Epoch: 1 \tTraining Loss: 5.958783 \tValidation Loss: 4.482775\n",
      "Validation loss decreased (inf --> 4.48278).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.070644 \tValidation Loss: 4.242215\n",
      "Validation loss decreased (4.48278 --> 4.24221).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.651423 \tValidation Loss: 3.982878\n",
      "Validation loss decreased (4.24221 --> 3.98288).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.120494 \tValidation Loss: 3.687879\n",
      "Validation loss decreased (3.98288 --> 3.68788).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.513364 \tValidation Loss: 3.393797\n",
      "Validation loss decreased (3.68788 --> 3.39380).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.917225 \tValidation Loss: 3.129525\n",
      "Validation loss decreased (3.39380 --> 3.12952).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.387203 \tValidation Loss: 2.909195\n",
      "Validation loss decreased (3.12952 --> 2.90919).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.951112 \tValidation Loss: 2.734959\n",
      "Validation loss decreased (2.90919 --> 2.73496).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.594745 \tValidation Loss: 2.600765\n",
      "Validation loss decreased (2.73496 --> 2.60077).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.304588 \tValidation Loss: 2.498439\n",
      "Validation loss decreased (2.60077 --> 2.49844).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.074963 \tValidation Loss: 2.423025\n",
      "Validation loss decreased (2.49844 --> 2.42302).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.888300 \tValidation Loss: 2.368080\n",
      "Validation loss decreased (2.42302 --> 2.36808).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.737884 \tValidation Loss: 2.329048\n",
      "Validation loss decreased (2.36808 --> 2.32905).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.614061 \tValidation Loss: 2.304407\n",
      "Validation loss decreased (2.32905 --> 2.30441).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.513857 \tValidation Loss: 2.292544\n",
      "Validation loss decreased (2.30441 --> 2.29254).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.437468 \tValidation Loss: 2.287154\n",
      "Validation loss decreased (2.29254 --> 2.28715).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.373274 \tValidation Loss: 2.287138\n",
      "Validation loss decreased (2.28715 --> 2.28714).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.323165 \tValidation Loss: 2.290060\n",
      "Epoch: 19 \tTraining Loss: 0.282140 \tValidation Loss: 2.297791\n",
      "Epoch: 20 \tTraining Loss: 0.249529 \tValidation Loss: 2.307416\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 10 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.071332 \tValidation Loss: 3.814176\n",
      "Validation loss decreased (inf --> 3.81418).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.122152 \tValidation Loss: 3.518449\n",
      "Validation loss decreased (3.81418 --> 3.51845).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \tTraining Loss: 4.697572 \tValidation Loss: 3.315563\n",
      "Validation loss decreased (3.51845 --> 3.31556).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.210101 \tValidation Loss: 3.082255\n",
      "Validation loss decreased (3.31556 --> 3.08225).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.643682 \tValidation Loss: 2.845550\n",
      "Validation loss decreased (3.08225 --> 2.84555).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.069145 \tValidation Loss: 2.629346\n",
      "Validation loss decreased (2.84555 --> 2.62935).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.541294 \tValidation Loss: 2.447009\n",
      "Validation loss decreased (2.62935 --> 2.44701).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.090318 \tValidation Loss: 2.300923\n",
      "Validation loss decreased (2.44701 --> 2.30092).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.715400 \tValidation Loss: 2.185324\n",
      "Validation loss decreased (2.30092 --> 2.18532).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.408341 \tValidation Loss: 2.097098\n",
      "Validation loss decreased (2.18532 --> 2.09710).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.159843 \tValidation Loss: 2.030039\n",
      "Validation loss decreased (2.09710 --> 2.03004).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.956312 \tValidation Loss: 1.977737\n",
      "Validation loss decreased (2.03004 --> 1.97774).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.788048 \tValidation Loss: 1.940135\n",
      "Validation loss decreased (1.97774 --> 1.94013).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.653196 \tValidation Loss: 1.915640\n",
      "Validation loss decreased (1.94013 --> 1.91564).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.544813 \tValidation Loss: 1.902009\n",
      "Validation loss decreased (1.91564 --> 1.90201).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.458149 \tValidation Loss: 1.893270\n",
      "Validation loss decreased (1.90201 --> 1.89327).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.388597 \tValidation Loss: 1.889307\n",
      "Validation loss decreased (1.89327 --> 1.88931).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.331511 \tValidation Loss: 1.891172\n",
      "Epoch: 19 \tTraining Loss: 0.287091 \tValidation Loss: 1.895675\n",
      "Epoch: 20 \tTraining Loss: 0.251477 \tValidation Loss: 1.904082\n",
      "Epoch: 1 \tTraining Loss: 6.056782 \tValidation Loss: 3.764693\n",
      "Validation loss decreased (inf --> 3.76469).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.099050 \tValidation Loss: 3.481101\n",
      "Validation loss decreased (3.76469 --> 3.48110).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.690678 \tValidation Loss: 3.283823\n",
      "Validation loss decreased (3.48110 --> 3.28382).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.205076 \tValidation Loss: 3.060462\n",
      "Validation loss decreased (3.28382 --> 3.06046).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.643040 \tValidation Loss: 2.835198\n",
      "Validation loss decreased (3.06046 --> 2.83520).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.072882 \tValidation Loss: 2.632497\n",
      "Validation loss decreased (2.83520 --> 2.63250).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.548850 \tValidation Loss: 2.466071\n",
      "Validation loss decreased (2.63250 --> 2.46607).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.101181 \tValidation Loss: 2.337228\n",
      "Validation loss decreased (2.46607 --> 2.33723).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.726871 \tValidation Loss: 2.238932\n",
      "Validation loss decreased (2.33723 --> 2.23893).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.420064 \tValidation Loss: 2.160707\n",
      "Validation loss decreased (2.23893 --> 2.16071).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.172345 \tValidation Loss: 2.097919\n",
      "Validation loss decreased (2.16071 --> 2.09792).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.966456 \tValidation Loss: 2.049796\n",
      "Validation loss decreased (2.09792 --> 2.04980).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.796437 \tValidation Loss: 2.013451\n",
      "Validation loss decreased (2.04980 --> 2.01345).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.663271 \tValidation Loss: 1.990587\n",
      "Validation loss decreased (2.01345 --> 1.99059).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.551552 \tValidation Loss: 1.976470\n",
      "Validation loss decreased (1.99059 --> 1.97647).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.464233 \tValidation Loss: 1.968230\n",
      "Validation loss decreased (1.97647 --> 1.96823).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.391639 \tValidation Loss: 1.966068\n",
      "Validation loss decreased (1.96823 --> 1.96607).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.336424 \tValidation Loss: 1.969368\n",
      "Epoch: 19 \tTraining Loss: 0.288121 \tValidation Loss: 1.975229\n",
      "Epoch: 20 \tTraining Loss: 0.252798 \tValidation Loss: 1.985289\n",
      "Epoch: 1 \tTraining Loss: 6.075230 \tValidation Loss: 3.765958\n",
      "Validation loss decreased (inf --> 3.76596).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.117417 \tValidation Loss: 3.423536\n",
      "Validation loss decreased (3.76596 --> 3.42354).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.700696 \tValidation Loss: 3.218940\n",
      "Validation loss decreased (3.42354 --> 3.21894).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.211473 \tValidation Loss: 2.988875\n",
      "Validation loss decreased (3.21894 --> 2.98887).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.648541 \tValidation Loss: 2.756942\n",
      "Validation loss decreased (2.98887 --> 2.75694).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.076669 \tValidation Loss: 2.547133\n",
      "Validation loss decreased (2.75694 --> 2.54713).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.551677 \tValidation Loss: 2.372543\n",
      "Validation loss decreased (2.54713 --> 2.37254).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.101387 \tValidation Loss: 2.232567\n",
      "Validation loss decreased (2.37254 --> 2.23257).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.725433 \tValidation Loss: 2.125780\n",
      "Validation loss decreased (2.23257 --> 2.12578).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.420281 \tValidation Loss: 2.043809\n",
      "Validation loss decreased (2.12578 --> 2.04381).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.168687 \tValidation Loss: 1.979989\n",
      "Validation loss decreased (2.04381 --> 1.97999).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.962816 \tValidation Loss: 1.930492\n",
      "Validation loss decreased (1.97999 --> 1.93049).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.794843 \tValidation Loss: 1.893089\n",
      "Validation loss decreased (1.93049 --> 1.89309).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.662807 \tValidation Loss: 1.868851\n",
      "Validation loss decreased (1.89309 --> 1.86885).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.549756 \tValidation Loss: 1.852975\n",
      "Validation loss decreased (1.86885 --> 1.85298).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.462007 \tValidation Loss: 1.845978\n",
      "Validation loss decreased (1.85298 --> 1.84598).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.392013 \tValidation Loss: 1.844675\n",
      "Validation loss decreased (1.84598 --> 1.84468).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.336323 \tValidation Loss: 1.847706\n",
      "Epoch: 19 \tTraining Loss: 0.289765 \tValidation Loss: 1.854134\n",
      "Epoch: 20 \tTraining Loss: 0.253077 \tValidation Loss: 1.862453\n",
      "Epoch: 1 \tTraining Loss: 6.064132 \tValidation Loss: 3.755298\n",
      "Validation loss decreased (inf --> 3.75530).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.121477 \tValidation Loss: 3.425246\n",
      "Validation loss decreased (3.75530 --> 3.42525).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.709470 \tValidation Loss: 3.222442\n",
      "Validation loss decreased (3.42525 --> 3.22244).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.222511 \tValidation Loss: 2.995657\n",
      "Validation loss decreased (3.22244 --> 2.99566).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.660964 \tValidation Loss: 2.766555\n",
      "Validation loss decreased (2.99566 --> 2.76655).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.084329 \tValidation Loss: 2.560518\n",
      "Validation loss decreased (2.76655 --> 2.56052).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.559169 \tValidation Loss: 2.393234\n",
      "Validation loss decreased (2.56052 --> 2.39323).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.107381 \tValidation Loss: 2.263941\n",
      "Validation loss decreased (2.39323 --> 2.26394).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.731596 \tValidation Loss: 2.160920\n",
      "Validation loss decreased (2.26394 --> 2.16092).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.424718 \tValidation Loss: 2.077202\n",
      "Validation loss decreased (2.16092 --> 2.07720).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.169016 \tValidation Loss: 2.012136\n",
      "Validation loss decreased (2.07720 --> 2.01214).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 \tTraining Loss: 0.965402 \tValidation Loss: 1.959471\n",
      "Validation loss decreased (2.01214 --> 1.95947).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.797074 \tValidation Loss: 1.921638\n",
      "Validation loss decreased (1.95947 --> 1.92164).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.662668 \tValidation Loss: 1.894777\n",
      "Validation loss decreased (1.92164 --> 1.89478).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.554967 \tValidation Loss: 1.877373\n",
      "Validation loss decreased (1.89478 --> 1.87737).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.462677 \tValidation Loss: 1.866723\n",
      "Validation loss decreased (1.87737 --> 1.86672).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.397518 \tValidation Loss: 1.864145\n",
      "Validation loss decreased (1.86672 --> 1.86415).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.339710 \tValidation Loss: 1.865536\n",
      "Epoch: 19 \tTraining Loss: 0.295967 \tValidation Loss: 1.871594\n",
      "Epoch: 20 \tTraining Loss: 0.257574 \tValidation Loss: 1.876365\n",
      "Epoch: 1 \tTraining Loss: 6.060554 \tValidation Loss: 3.785509\n",
      "Validation loss decreased (inf --> 3.78551).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.109095 \tValidation Loss: 3.495738\n",
      "Validation loss decreased (3.78551 --> 3.49574).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.693801 \tValidation Loss: 3.296580\n",
      "Validation loss decreased (3.49574 --> 3.29658).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.203678 \tValidation Loss: 3.064305\n",
      "Validation loss decreased (3.29658 --> 3.06431).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.634313 \tValidation Loss: 2.834291\n",
      "Validation loss decreased (3.06431 --> 2.83429).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.057549 \tValidation Loss: 2.634758\n",
      "Validation loss decreased (2.83429 --> 2.63476).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.537897 \tValidation Loss: 2.472721\n",
      "Validation loss decreased (2.63476 --> 2.47272).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.089307 \tValidation Loss: 2.339351\n",
      "Validation loss decreased (2.47272 --> 2.33935).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.719375 \tValidation Loss: 2.233135\n",
      "Validation loss decreased (2.33935 --> 2.23314).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.407213 \tValidation Loss: 2.148553\n",
      "Validation loss decreased (2.23314 --> 2.14855).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.159751 \tValidation Loss: 2.084696\n",
      "Validation loss decreased (2.14855 --> 2.08470).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.958127 \tValidation Loss: 2.036298\n",
      "Validation loss decreased (2.08470 --> 2.03630).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.789583 \tValidation Loss: 1.999533\n",
      "Validation loss decreased (2.03630 --> 1.99953).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.656309 \tValidation Loss: 1.974681\n",
      "Validation loss decreased (1.99953 --> 1.97468).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.546245 \tValidation Loss: 1.961237\n",
      "Validation loss decreased (1.97468 --> 1.96124).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.459960 \tValidation Loss: 1.953188\n",
      "Validation loss decreased (1.96124 --> 1.95319).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.389896 \tValidation Loss: 1.952819\n",
      "Validation loss decreased (1.95319 --> 1.95282).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.332410 \tValidation Loss: 1.958060\n",
      "Epoch: 19 \tTraining Loss: 0.288910 \tValidation Loss: 1.964848\n",
      "Epoch: 20 \tTraining Loss: 0.250859 \tValidation Loss: 1.973653\n",
      "Epoch: 1 \tTraining Loss: 6.063138 \tValidation Loss: 3.794166\n",
      "Validation loss decreased (inf --> 3.79417).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.102434 \tValidation Loss: 3.503097\n",
      "Validation loss decreased (3.79417 --> 3.50310).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.675154 \tValidation Loss: 3.301865\n",
      "Validation loss decreased (3.50310 --> 3.30187).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.183944 \tValidation Loss: 3.062325\n",
      "Validation loss decreased (3.30187 --> 3.06232).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.614015 \tValidation Loss: 2.818129\n",
      "Validation loss decreased (3.06232 --> 2.81813).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.047742 \tValidation Loss: 2.601114\n",
      "Validation loss decreased (2.81813 --> 2.60111).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.532614 \tValidation Loss: 2.425234\n",
      "Validation loss decreased (2.60111 --> 2.42523).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.091830 \tValidation Loss: 2.285097\n",
      "Validation loss decreased (2.42523 --> 2.28510).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.722929 \tValidation Loss: 2.173937\n",
      "Validation loss decreased (2.28510 --> 2.17394).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.419585 \tValidation Loss: 2.087089\n",
      "Validation loss decreased (2.17394 --> 2.08709).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.167312 \tValidation Loss: 2.021723\n",
      "Validation loss decreased (2.08709 --> 2.02172).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.964799 \tValidation Loss: 1.971559\n",
      "Validation loss decreased (2.02172 --> 1.97156).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.795712 \tValidation Loss: 1.938304\n",
      "Validation loss decreased (1.97156 --> 1.93830).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.662083 \tValidation Loss: 1.918115\n",
      "Validation loss decreased (1.93830 --> 1.91811).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.551507 \tValidation Loss: 1.905802\n",
      "Validation loss decreased (1.91811 --> 1.90580).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.465703 \tValidation Loss: 1.899269\n",
      "Validation loss decreased (1.90580 --> 1.89927).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.392141 \tValidation Loss: 1.898523\n",
      "Validation loss decreased (1.89927 --> 1.89852).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.335698 \tValidation Loss: 1.899347\n",
      "Epoch: 19 \tTraining Loss: 0.289042 \tValidation Loss: 1.905939\n",
      "Epoch: 20 \tTraining Loss: 0.253586 \tValidation Loss: 1.914265\n",
      "Epoch: 1 \tTraining Loss: 6.060176 \tValidation Loss: 3.795539\n",
      "Validation loss decreased (inf --> 3.79554).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.117432 \tValidation Loss: 3.505196\n",
      "Validation loss decreased (3.79554 --> 3.50520).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.703558 \tValidation Loss: 3.313310\n",
      "Validation loss decreased (3.50520 --> 3.31331).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.218443 \tValidation Loss: 3.082461\n",
      "Validation loss decreased (3.31331 --> 3.08246).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.647923 \tValidation Loss: 2.839868\n",
      "Validation loss decreased (3.08246 --> 2.83987).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.070708 \tValidation Loss: 2.620916\n",
      "Validation loss decreased (2.83987 --> 2.62092).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.547513 \tValidation Loss: 2.441880\n",
      "Validation loss decreased (2.62092 --> 2.44188).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.100519 \tValidation Loss: 2.295025\n",
      "Validation loss decreased (2.44188 --> 2.29503).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.727537 \tValidation Loss: 2.175902\n",
      "Validation loss decreased (2.29503 --> 2.17590).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.422890 \tValidation Loss: 2.080631\n",
      "Validation loss decreased (2.17590 --> 2.08063).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.172891 \tValidation Loss: 2.004509\n",
      "Validation loss decreased (2.08063 --> 2.00451).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.966548 \tValidation Loss: 1.942885\n",
      "Validation loss decreased (2.00451 --> 1.94288).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.801057 \tValidation Loss: 1.896625\n",
      "Validation loss decreased (1.94288 --> 1.89662).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.665142 \tValidation Loss: 1.864559\n",
      "Validation loss decreased (1.89662 --> 1.86456).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.553467 \tValidation Loss: 1.843187\n",
      "Validation loss decreased (1.86456 --> 1.84319).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.468895 \tValidation Loss: 1.827869\n",
      "Validation loss decreased (1.84319 --> 1.82787).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.395444 \tValidation Loss: 1.818788\n",
      "Validation loss decreased (1.82787 --> 1.81879).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.340189 \tValidation Loss: 1.813602\n",
      "Validation loss decreased (1.81879 --> 1.81360).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.295033 \tValidation Loss: 1.811808\n",
      "Validation loss decreased (1.81360 --> 1.81181).  Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 0.254955 \tValidation Loss: 1.813121\n",
      "Epoch: 1 \tTraining Loss: 6.060314 \tValidation Loss: 3.775987\n",
      "Validation loss decreased (inf --> 3.77599).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 5.113593 \tValidation Loss: 3.479080\n",
      "Validation loss decreased (3.77599 --> 3.47908).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.700477 \tValidation Loss: 3.273981\n",
      "Validation loss decreased (3.47908 --> 3.27398).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.213911 \tValidation Loss: 3.039118\n",
      "Validation loss decreased (3.27398 --> 3.03912).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.651246 \tValidation Loss: 2.801902\n",
      "Validation loss decreased (3.03912 --> 2.80190).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.075761 \tValidation Loss: 2.589484\n",
      "Validation loss decreased (2.80190 --> 2.58948).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.551296 \tValidation Loss: 2.413683\n",
      "Validation loss decreased (2.58948 --> 2.41368).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.100022 \tValidation Loss: 2.273279\n",
      "Validation loss decreased (2.41368 --> 2.27328).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.722104 \tValidation Loss: 2.160836\n",
      "Validation loss decreased (2.27328 --> 2.16084).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.420059 \tValidation Loss: 2.073775\n",
      "Validation loss decreased (2.16084 --> 2.07378).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.167851 \tValidation Loss: 2.003964\n",
      "Validation loss decreased (2.07378 --> 2.00396).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.964938 \tValidation Loss: 1.949368\n",
      "Validation loss decreased (2.00396 --> 1.94937).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.796861 \tValidation Loss: 1.907338\n",
      "Validation loss decreased (1.94937 --> 1.90734).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.661656 \tValidation Loss: 1.875449\n",
      "Validation loss decreased (1.90734 --> 1.87545).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.551466 \tValidation Loss: 1.852067\n",
      "Validation loss decreased (1.87545 --> 1.85207).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.466402 \tValidation Loss: 1.839674\n",
      "Validation loss decreased (1.85207 --> 1.83967).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.394969 \tValidation Loss: 1.831486\n",
      "Validation loss decreased (1.83967 --> 1.83149).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.337356 \tValidation Loss: 1.827708\n",
      "Validation loss decreased (1.83149 --> 1.82771).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.291797 \tValidation Loss: 1.828411\n",
      "Epoch: 20 \tTraining Loss: 0.254952 \tValidation Loss: 1.830620\n",
      "Epoch: 1 \tTraining Loss: 6.064329 \tValidation Loss: 3.773895\n",
      "Validation loss decreased (inf --> 3.77389).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.106869 \tValidation Loss: 3.461099\n",
      "Validation loss decreased (3.77389 --> 3.46110).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.687632 \tValidation Loss: 3.271532\n",
      "Validation loss decreased (3.46110 --> 3.27153).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.195078 \tValidation Loss: 3.054052\n",
      "Validation loss decreased (3.27153 --> 3.05405).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.628944 \tValidation Loss: 2.833290\n",
      "Validation loss decreased (3.05405 --> 2.83329).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.052714 \tValidation Loss: 2.632747\n",
      "Validation loss decreased (2.83329 --> 2.63275).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.526931 \tValidation Loss: 2.467218\n",
      "Validation loss decreased (2.63275 --> 2.46722).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.075081 \tValidation Loss: 2.334556\n",
      "Validation loss decreased (2.46722 --> 2.33456).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.701812 \tValidation Loss: 2.228165\n",
      "Validation loss decreased (2.33456 --> 2.22816).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.391946 \tValidation Loss: 2.146484\n",
      "Validation loss decreased (2.22816 --> 2.14648).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.143485 \tValidation Loss: 2.083974\n",
      "Validation loss decreased (2.14648 --> 2.08397).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.941612 \tValidation Loss: 2.037162\n",
      "Validation loss decreased (2.08397 --> 2.03716).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.776385 \tValidation Loss: 2.003733\n",
      "Validation loss decreased (2.03716 --> 2.00373).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.643678 \tValidation Loss: 1.979336\n",
      "Validation loss decreased (2.00373 --> 1.97934).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.536548 \tValidation Loss: 1.963713\n",
      "Validation loss decreased (1.97934 --> 1.96371).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.447218 \tValidation Loss: 1.956810\n",
      "Validation loss decreased (1.96371 --> 1.95681).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.379437 \tValidation Loss: 1.953778\n",
      "Validation loss decreased (1.95681 --> 1.95378).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.325516 \tValidation Loss: 1.955965\n",
      "Epoch: 19 \tTraining Loss: 0.283263 \tValidation Loss: 1.962181\n",
      "Epoch: 20 \tTraining Loss: 0.246543 \tValidation Loss: 1.966470\n",
      "Epoch: 1 \tTraining Loss: 6.073672 \tValidation Loss: 3.800115\n",
      "Validation loss decreased (inf --> 3.80012).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.108167 \tValidation Loss: 3.487228\n",
      "Validation loss decreased (3.80012 --> 3.48723).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.681949 \tValidation Loss: 3.296076\n",
      "Validation loss decreased (3.48723 --> 3.29608).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.196155 \tValidation Loss: 3.072661\n",
      "Validation loss decreased (3.29608 --> 3.07266).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.636629 \tValidation Loss: 2.845013\n",
      "Validation loss decreased (3.07266 --> 2.84501).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.066999 \tValidation Loss: 2.641196\n",
      "Validation loss decreased (2.84501 --> 2.64120).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.548104 \tValidation Loss: 2.469613\n",
      "Validation loss decreased (2.64120 --> 2.46961).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.100186 \tValidation Loss: 2.329992\n",
      "Validation loss decreased (2.46961 --> 2.32999).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.722924 \tValidation Loss: 2.216865\n",
      "Validation loss decreased (2.32999 --> 2.21687).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.414433 \tValidation Loss: 2.126513\n",
      "Validation loss decreased (2.21687 --> 2.12651).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.164016 \tValidation Loss: 2.057111\n",
      "Validation loss decreased (2.12651 --> 2.05711).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.962545 \tValidation Loss: 2.004307\n",
      "Validation loss decreased (2.05711 --> 2.00431).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.793517 \tValidation Loss: 1.965807\n",
      "Validation loss decreased (2.00431 --> 1.96581).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.658499 \tValidation Loss: 1.936966\n",
      "Validation loss decreased (1.96581 --> 1.93697).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.550856 \tValidation Loss: 1.916604\n",
      "Validation loss decreased (1.93697 --> 1.91660).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.462165 \tValidation Loss: 1.906255\n",
      "Validation loss decreased (1.91660 --> 1.90626).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.391159 \tValidation Loss: 1.902736\n",
      "Validation loss decreased (1.90626 --> 1.90274).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.333987 \tValidation Loss: 1.900849\n",
      "Validation loss decreased (1.90274 --> 1.90085).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.292089 \tValidation Loss: 1.906028\n",
      "Epoch: 20 \tTraining Loss: 0.253716 \tValidation Loss: 1.912259\n"
     ]
    }
   ],
   "source": [
    "# Preparing the results dataframes:\n",
    "windows = list(range(3,11))\n",
    "columns = ['Predicted_top5_mean', 'Predicted_top5_std', 'Predicted_top10_mean', 'Predicted_top10_std']\n",
    "Results_Nolemmatize = pd.DataFrame(index=index, columns=columns)\n",
    "Results_lemmatize = pd.DataFrame(index=index, columns=columns)\n",
    "\n",
    "# Getting some results:\n",
    "for lemmatize in [False , True]:\n",
    "    \n",
    "    # Building the corpus\n",
    "    corpus = Corpus(meta = 'Corpus BBC '+category+' News, only verbs as target, no stopwords.')\n",
    "    import_bbc_folder(category,corpus , lemmatize = lemmatize)\n",
    "    \n",
    "    for window in windows:\n",
    "                \n",
    "        # Building the dataset:\n",
    "        sentences , verbs = Build_Dataset([category], corpus, window, one_hot=True , lemmatize=lemmatize)\n",
    "        \n",
    "        print('\\n Starting:...-> Lemmatize =',lemmatize,', window =', window , '\\n')\n",
    "        \n",
    "        lr=0.001\n",
    "        batch_size = 512\n",
    "        n_epochs = 20\n",
    "        file_name = 'CBOW_BBC_'+category+'_lemmatize='+str(lemmatize)+'_window='+str(window)+'_crossval.pt'\n",
    "        random_state = 123\n",
    "        K = 10\n",
    "        \n",
    "        # Cross validating the model:\n",
    "        training_losses, validation_losses, predicted_intop5, predicted_intop10 = K_fold_Cross_validate(K , sentences , verbs,\n",
    "                                                                                                corpus, lr,batch_size ,n_epochs,\n",
    "                                                                                                file_name, random_state)\n",
    "        \n",
    "        # Getting the prediction measures mean and standard deviation:\n",
    "        predicted_intop5_mean , predicted_intop5_std  = np.mean(predicted_intop5) , np.std(predicted_intop5)\n",
    "        predicted_intop10_mean , predicted_intop10_std  = np.mean(predicted_intop10) , np.std(predicted_intop10)\n",
    "        \n",
    "        # Adding the measures to the corresponding dataframe:\n",
    "        if lemmatize:\n",
    "            Results_lemmatize.loc[window , 'Predicted_top5_mean'] = predicted_intop5_mean\n",
    "            Results_lemmatize.loc[window , 'Predicted_top5_std'] = predicted_intop5_std\n",
    "            Results_lemmatize.loc[window , 'Predicted_top10_mean'] = predicted_intop10_mean\n",
    "            Results_lemmatize.loc[window , 'Predicted_top10_std'] = predicted_intop10_std\n",
    "        else:\n",
    "            Results_Nolemmatize.loc[window , 'Predicted_top5_mean'] = predicted_intop5_mean\n",
    "            Results_Nolemmatize.loc[window , 'Predicted_top5_std'] = predicted_intop5_std\n",
    "            Results_Nolemmatize.loc[window , 'Predicted_top10_mean'] = predicted_intop10_mean\n",
    "            Results_Nolemmatize.loc[window , 'Predicted_top10_std'] = predicted_intop10_std\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(category+'results.pkl', 'wb') as f:\n",
    "    pickle.dump((Results_lemmatize , Results_Nolemmatize),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(category+'results.pkl', 'rb') as f:\n",
    "    Results_lemmatize , Results_Nolemmatize = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_top5_mean</th>\n",
       "      <th>Predicted_top5_std</th>\n",
       "      <th>Predicted_top10_mean</th>\n",
       "      <th>Predicted_top10_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.416323</td>\n",
       "      <td>0.00699712</td>\n",
       "      <td>0.524888</td>\n",
       "      <td>0.00910454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.564174</td>\n",
       "      <td>0.00791251</td>\n",
       "      <td>0.661579</td>\n",
       "      <td>0.00743827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.658371</td>\n",
       "      <td>0.00712256</td>\n",
       "      <td>0.737137</td>\n",
       "      <td>0.0070437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.708138</td>\n",
       "      <td>0.0064272</td>\n",
       "      <td>0.770475</td>\n",
       "      <td>0.00655979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.717891</td>\n",
       "      <td>0.00666768</td>\n",
       "      <td>0.771875</td>\n",
       "      <td>0.00671375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.727393</td>\n",
       "      <td>0.00897973</td>\n",
       "      <td>0.775928</td>\n",
       "      <td>0.00731591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.718652</td>\n",
       "      <td>0.0102418</td>\n",
       "      <td>0.765039</td>\n",
       "      <td>0.0101506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.700391</td>\n",
       "      <td>0.0097038</td>\n",
       "      <td>0.742643</td>\n",
       "      <td>0.00911482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted_top5_mean Predicted_top5_std Predicted_top10_mean  \\\n",
       "3             0.416323         0.00699712             0.524888   \n",
       "4             0.564174         0.00791251             0.661579   \n",
       "5             0.658371         0.00712256             0.737137   \n",
       "6             0.708138          0.0064272             0.770475   \n",
       "7             0.717891         0.00666768             0.771875   \n",
       "8             0.727393         0.00897973             0.775928   \n",
       "9             0.718652          0.0102418             0.765039   \n",
       "10            0.700391          0.0097038             0.742643   \n",
       "\n",
       "   Predicted_top10_std  \n",
       "3           0.00910454  \n",
       "4           0.00743827  \n",
       "5            0.0070437  \n",
       "6           0.00655979  \n",
       "7           0.00671375  \n",
       "8           0.00731591  \n",
       "9            0.0101506  \n",
       "10          0.00911482  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Results_lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_top5_mean</th>\n",
       "      <th>Predicted_top5_std</th>\n",
       "      <th>Predicted_top10_mean</th>\n",
       "      <th>Predicted_top10_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.427116</td>\n",
       "      <td>0.00696713</td>\n",
       "      <td>0.529297</td>\n",
       "      <td>0.00684833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.624642</td>\n",
       "      <td>0.00657109</td>\n",
       "      <td>0.707943</td>\n",
       "      <td>0.00651172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.729134</td>\n",
       "      <td>0.00786717</td>\n",
       "      <td>0.787467</td>\n",
       "      <td>0.00656302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.76668</td>\n",
       "      <td>0.00870323</td>\n",
       "      <td>0.807852</td>\n",
       "      <td>0.00771709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.777031</td>\n",
       "      <td>0.00833012</td>\n",
       "      <td>0.814531</td>\n",
       "      <td>0.0106717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.776611</td>\n",
       "      <td>0.00775814</td>\n",
       "      <td>0.806689</td>\n",
       "      <td>0.00749937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.762109</td>\n",
       "      <td>0.0127817</td>\n",
       "      <td>0.788281</td>\n",
       "      <td>0.0101395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.754102</td>\n",
       "      <td>0.0125503</td>\n",
       "      <td>0.776953</td>\n",
       "      <td>0.0134198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted_top5_mean Predicted_top5_std Predicted_top10_mean  \\\n",
       "3             0.427116         0.00696713             0.529297   \n",
       "4             0.624642         0.00657109             0.707943   \n",
       "5             0.729134         0.00786717             0.787467   \n",
       "6              0.76668         0.00870323             0.807852   \n",
       "7             0.777031         0.00833012             0.814531   \n",
       "8             0.776611         0.00775814             0.806689   \n",
       "9             0.762109          0.0127817             0.788281   \n",
       "10            0.754102          0.0125503             0.776953   \n",
       "\n",
       "   Predicted_top10_std  \n",
       "3           0.00684833  \n",
       "4           0.00651172  \n",
       "5           0.00656302  \n",
       "6           0.00771709  \n",
       "7            0.0106717  \n",
       "8           0.00749937  \n",
       "9            0.0101395  \n",
       "10           0.0134198  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Results_Nolemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.bar(Results_lemmatize.index.values, Results_lemmatize['Predicted_top10_mean'].values, yerr=Results_lemmatize['Predicted_top10_std'].values, width=-0.4, align='edge', alpha=0.8, ecolor='black', capsize=4,  label='Top 10 +L')\n",
    "ax.bar(Results_lemmatize.index.values, Results_lemmatize['Predicted_top5_mean'].values, yerr=Results_lemmatize['Predicted_top5_std'].values, color='green', width=-0.4, align='edge', alpha=0.7, ecolor='black', capsize=4, label='Top 5 +L')\n",
    "ax.bar(Results_Nolemmatize.index.values, Results_Nolemmatize['Predicted_top10_mean'].values, yerr=Results_Nolemmatize['Predicted_top10_std'].values, width=0.4, align='edge', alpha=0.8, ecolor='black', capsize=4,  label='Top 10')\n",
    "ax.bar(Results_Nolemmatize.index.values, Results_Nolemmatize['Predicted_top5_mean'].values, yerr=Results_Nolemmatize['Predicted_top5_std'].values, color='purple', width=0.4, align='edge', alpha=0.7, ecolor='black', capsize=4, label='Top 5')\n",
    "ax.set_ylabel('Accuracy of Prediction')\n",
    "ax.set_xlabel('Window Size')\n",
    "ax.set_xticks(Results_lemmatize.index.values)\n",
    "ax.set_yticks(np.arange(0,1.1,0.1))\n",
    "ax.yaxis.grid(True)\n",
    "ax.legend()\n",
    "plt.savefig(category+'-bars.pdf', dpi=500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking a look at the predicted probabilities of the best setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 6.347361 \tValidation Loss: 5.038537\n",
      "Validation loss decreased (inf --> 5.03854).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.516086 \tValidation Loss: 4.754287\n",
      "Validation loss decreased (5.03854 --> 4.75429).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.984180 \tValidation Loss: 4.377631\n",
      "Validation loss decreased (4.75429 --> 4.37763).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.282314 \tValidation Loss: 3.930652\n",
      "Validation loss decreased (4.37763 --> 3.93065).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.482899 \tValidation Loss: 3.489529\n",
      "Validation loss decreased (3.93065 --> 3.48953).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.720307 \tValidation Loss: 3.110157\n",
      "Validation loss decreased (3.48953 --> 3.11016).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.089990 \tValidation Loss: 2.811416\n",
      "Validation loss decreased (3.11016 --> 2.81142).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.607737 \tValidation Loss: 2.588077\n",
      "Validation loss decreased (2.81142 --> 2.58808).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.247110 \tValidation Loss: 2.424615\n",
      "Validation loss decreased (2.58808 --> 2.42461).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.978143 \tValidation Loss: 2.305041\n",
      "Validation loss decreased (2.42461 --> 2.30504).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.776917 \tValidation Loss: 2.222144\n",
      "Validation loss decreased (2.30504 --> 2.22214).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.623655 \tValidation Loss: 2.160736\n",
      "Validation loss decreased (2.22214 --> 2.16074).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.507002 \tValidation Loss: 2.118155\n",
      "Validation loss decreased (2.16074 --> 2.11816).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.417941 \tValidation Loss: 2.089181\n",
      "Validation loss decreased (2.11816 --> 2.08918).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.351299 \tValidation Loss: 2.071469\n",
      "Validation loss decreased (2.08918 --> 2.07147).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.297813 \tValidation Loss: 2.060683\n",
      "Validation loss decreased (2.07147 --> 2.06068).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.256068 \tValidation Loss: 2.056428\n",
      "Validation loss decreased (2.06068 --> 2.05643).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.223575 \tValidation Loss: 2.056104\n",
      "Validation loss decreased (2.05643 --> 2.05610).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.198929 \tValidation Loss: 2.059265\n",
      "Epoch: 20 \tTraining Loss: 0.178444 \tValidation Loss: 2.066705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize = False\n",
    "window = 7\n",
    "\n",
    "# Building the corpus\n",
    "corpus = Corpus(meta = 'Corpus BBC '+category+' News, only verbs as target, no stopwords.')\n",
    "import_bbc_folder(category,corpus , lemmatize = lemmatize)\n",
    "\n",
    "# Building the dataset\n",
    "sentences , verbs = Build_Dataset([category], corpus, window, one_hot=True , lemmatize=lemmatize)\n",
    "\n",
    "# Getting the train_valid_test data:\n",
    "x_train, x_test, y_train, y_test = train_test_split(sentences, verbs, test_size=0.1, random_state=123)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.1, random_state=123)\n",
    "\n",
    "# Building the model\n",
    "vocab_size = len(corpus.get_vocabs_to_learn())\n",
    "verbs_size = len(corpus.get_verbs_to_learn())\n",
    "hidden_dim = 500\n",
    "\n",
    "model = CBOW(vocab_size, hidden_dim, verbs_size)\n",
    "model.cuda()\n",
    "\n",
    "# Training the model\n",
    "lr=0.001\n",
    "batch_size = 512\n",
    "n_epochs = 20\n",
    "file_name = 'CBOW_BBC'+category+'_window='+str(window)+'_forevaluation.pt'\n",
    "\n",
    "train_losses, valid_losses = Train_model(model, lr, batch_size, n_epochs, file_name, x_train, y_train, x_valid, y_valid)\n",
    "\n",
    "# Loading the best model parameters\n",
    "model.load_state_dict(torch.load(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1dc0fccb808>"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label = 'Training loss')\n",
    "plt.plot(valid_losses, label = 'Validation loss')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking into a sample of predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "getbatch = iter(get_batch(x_test, y_test , 16))\n",
    "sentences, verbs = next(getbatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "output = model(sentences.cuda().float())\n",
    "ps = torch.exp(output)\n",
    "top_p, top_class = ps.topk(10, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "band\n",
      "\tband\talbum\tbeat\tsees\tmoved\tsaid\tcame\thit\tback\tcharts\t\n",
      "starring\n",
      "\tstarring\thit\tgone\tstraight\tdirect\tfinding\trecording\tco-wrote\tsaid\tshown\t\n",
      "dance\n",
      "\tdance\tacknowledged\tgoing\tstars\talbum\treleased\tplayed\ttaking\tpicked\twork\t\n",
      "slipped\n",
      "\tslipped\tfell\ttaking\tchart\tfinished\tentered\twent\ttake\ttook\tnominated\t\n",
      "chart\n",
      "\tchart\tbest\ttop\tband\thost\ttrack\treturn\tinvolved\tfell\tdeveloping\t\n",
      "plays\n",
      "\tsaid\tplays\tstars\tthink\texpected\tshow\tlive\tnominated\twant\tfollowing\t\n",
      "coming\n",
      "\tsaid\ttop\tband\tback\ttake\tperform\tturned\tlive\tbrought\tappear\t\n",
      "filled\n",
      "\tshow\thosting\taged\tfilled\tbest\tlead\thost\tgot\tdied\tdrama\t\n",
      "home\n",
      "\tattend\tearn\tfalls\treceive\thome\taccording\tface\tgreeted\tusing\tfetch\t\n",
      "went\n",
      "\twent\tlead\thope\tdrama\tbecomes\tbeating\tbest\tinclude\ttaking\tplaying\t\n",
      "receive\n",
      "\treceive\tsinger\tfeature\tcreated\trecorded\ttop\talbum\tleading\tused\tperform\t\n",
      "topped\n",
      "\ttopped\ttop\topening\ttopping\trecord\tchart\tseek\tbiopic\tmeet\tdescribed\t\n",
      "thanked\n",
      "\ttaking\tthank\tbest\tlegend\testimated\ttook\tattended\tholds\ttold\texpected\t\n",
      "best\n",
      "\trecognise\tbest\tshowed\tused\tplaying\tinclude\tsaid\tmake\tmakes\tshow\t\n",
      "think\n",
      "\tthink\tnominated\tinclude\tknew\trun\tbegan\thappen\tlike\tmade\talbum\t\n",
      "think\n",
      "\taffected\tsaid\tbest\tscreen\tenter\tsays\tman\tbased\tfavourite\tcompete\t\n"
     ]
    }
   ],
   "source": [
    "for clas, t in zip(top_class, verbs):\n",
    "    print(corpus.get_verb_from_index(t.item()) , ': ')\n",
    "    print('\\t' ,  end='' )\n",
    "    for val in clas:\n",
    "        print(corpus.get_verb_from_index(val.item()), end='\\t' )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['julia', 'sequel', 'george', 'clooney', 'brad', 'pitt']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 1\n",
    "sent = np.where(np.array(sentences[i]) != 0)[0]\n",
    "corpus.get_vocab_from_index(sent.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = top_p[i].tolist()\n",
    "vrbs = corpus.get_verb_from_index(top_class[i].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "props = dict(boxstyle='round', facecolor='grey', alpha=0.2)\n",
    "ax.text(0.05, 0.95, 'Input: '+str(corpus.get_vocab_from_index(sent.tolist())), transform=ax.transAxes, fontsize=10, verticalalignment='top', bbox=props)\n",
    "ax.text(0.05, 0.85, 'Target: '+corpus.get_verb_from_index(verbs[i].item()), transform=ax.transAxes, fontsize=10, verticalalignment='top', bbox=props)\n",
    "ax.barh(vrbs, probs, align='center')\n",
    "plt.xlabel('Probabilities')\n",
    "plt.ylabel('Predicted Verbs')\n",
    "ax.set_xticks(np.arange(0,1.1,0.1))\n",
    "ax.xaxis.grid(True)\n",
    "plt.savefig(category+'-probs.pdf', dpi=500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Obtaining prediction results when learning the verbs in politics articles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'politics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting:...-> Lemmatize = False , window = 3 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.602493 \tValidation Loss: 5.757103\n",
      "Validation loss decreased (inf --> 5.75710).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.079985 \tValidation Loss: 5.635481\n",
      "Validation loss decreased (5.75710 --> 5.63548).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.837566 \tValidation Loss: 5.477341\n",
      "Validation loss decreased (5.63548 --> 5.47734).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.493571 \tValidation Loss: 5.282194\n",
      "Validation loss decreased (5.47734 --> 5.28219).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.053437 \tValidation Loss: 5.071109\n",
      "Validation loss decreased (5.28219 --> 5.07111).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.559289 \tValidation Loss: 4.874638\n",
      "Validation loss decreased (5.07111 --> 4.87464).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.062730 \tValidation Loss: 4.710167\n",
      "Validation loss decreased (4.87464 --> 4.71017).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.601697 \tValidation Loss: 4.586787\n",
      "Validation loss decreased (4.71017 --> 4.58679).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.200322 \tValidation Loss: 4.499325\n",
      "Validation loss decreased (4.58679 --> 4.49933).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.864857 \tValidation Loss: 4.443263\n",
      "Validation loss decreased (4.49933 --> 4.44326).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.592612 \tValidation Loss: 4.410164\n",
      "Validation loss decreased (4.44326 --> 4.41016).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.375021 \tValidation Loss: 4.394039\n",
      "Validation loss decreased (4.41016 --> 4.39404).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.195739 \tValidation Loss: 4.391436\n",
      "Validation loss decreased (4.39404 --> 4.39144).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 2.051600 \tValidation Loss: 4.398308\n",
      "Epoch: 15 \tTraining Loss: 1.939600 \tValidation Loss: 4.414292\n",
      "Epoch: 16 \tTraining Loss: 1.845652 \tValidation Loss: 4.437070\n",
      "Epoch: 17 \tTraining Loss: 1.766827 \tValidation Loss: 4.463042\n",
      "Epoch: 18 \tTraining Loss: 1.698963 \tValidation Loss: 4.495835\n",
      "Epoch: 19 \tTraining Loss: 1.646440 \tValidation Loss: 4.528475\n",
      "Epoch: 20 \tTraining Loss: 1.599442 \tValidation Loss: 4.566761\n",
      "Epoch: 1 \tTraining Loss: 6.592899 \tValidation Loss: 5.775826\n",
      "Validation loss decreased (inf --> 5.77583).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.074865 \tValidation Loss: 5.648430\n",
      "Validation loss decreased (5.77583 --> 5.64843).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.837933 \tValidation Loss: 5.478941\n",
      "Validation loss decreased (5.64843 --> 5.47894).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.503414 \tValidation Loss: 5.269837\n",
      "Validation loss decreased (5.47894 --> 5.26984).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.072125 \tValidation Loss: 5.046227\n",
      "Validation loss decreased (5.26984 --> 5.04623).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.580258 \tValidation Loss: 4.836172\n",
      "Validation loss decreased (5.04623 --> 4.83617).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.080553 \tValidation Loss: 4.659683\n",
      "Validation loss decreased (4.83617 --> 4.65968).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.615970 \tValidation Loss: 4.527338\n",
      "Validation loss decreased (4.65968 --> 4.52734).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.213956 \tValidation Loss: 4.435262\n",
      "Validation loss decreased (4.52734 --> 4.43526).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.874720 \tValidation Loss: 4.375268\n",
      "Validation loss decreased (4.43526 --> 4.37527).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.600479 \tValidation Loss: 4.340275\n",
      "Validation loss decreased (4.37527 --> 4.34027).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.380191 \tValidation Loss: 4.324203\n",
      "Validation loss decreased (4.34027 --> 4.32420).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.201397 \tValidation Loss: 4.322736\n",
      "Validation loss decreased (4.32420 --> 4.32274).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 2.060136 \tValidation Loss: 4.329981\n",
      "Epoch: 15 \tTraining Loss: 1.948666 \tValidation Loss: 4.346840\n",
      "Epoch: 16 \tTraining Loss: 1.849160 \tValidation Loss: 4.368393\n",
      "Epoch: 17 \tTraining Loss: 1.772306 \tValidation Loss: 4.394385\n",
      "Epoch: 18 \tTraining Loss: 1.706848 \tValidation Loss: 4.424358\n",
      "Epoch: 19 \tTraining Loss: 1.648897 \tValidation Loss: 4.459613\n",
      "Epoch: 20 \tTraining Loss: 1.600936 \tValidation Loss: 4.494009\n",
      "Epoch: 1 \tTraining Loss: 6.593631 \tValidation Loss: 5.780388\n",
      "Validation loss decreased (inf --> 5.78039).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.078370 \tValidation Loss: 5.652280\n",
      "Validation loss decreased (5.78039 --> 5.65228).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.839273 \tValidation Loss: 5.487612\n",
      "Validation loss decreased (5.65228 --> 5.48761).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.500356 \tValidation Loss: 5.279284\n",
      "Validation loss decreased (5.48761 --> 5.27928).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.062505 \tValidation Loss: 5.057157\n",
      "Validation loss decreased (5.27928 --> 5.05716).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.573795 \tValidation Loss: 4.851610\n",
      "Validation loss decreased (5.05716 --> 4.85161).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.077998 \tValidation Loss: 4.677451\n",
      "Validation loss decreased (4.85161 --> 4.67745).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.618072 \tValidation Loss: 4.543742\n",
      "Validation loss decreased (4.67745 --> 4.54374).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.216473 \tValidation Loss: 4.452271\n",
      "Validation loss decreased (4.54374 --> 4.45227).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.879908 \tValidation Loss: 4.396557\n",
      "Validation loss decreased (4.45227 --> 4.39656).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.604532 \tValidation Loss: 4.364661\n",
      "Validation loss decreased (4.39656 --> 4.36466).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.384429 \tValidation Loss: 4.351068\n",
      "Validation loss decreased (4.36466 --> 4.35107).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.205315 \tValidation Loss: 4.351284\n",
      "Epoch: 14 \tTraining Loss: 2.062225 \tValidation Loss: 4.360542\n",
      "Epoch: 15 \tTraining Loss: 1.946228 \tValidation Loss: 4.375861\n",
      "Epoch: 16 \tTraining Loss: 1.849401 \tValidation Loss: 4.398417\n",
      "Epoch: 17 \tTraining Loss: 1.775615 \tValidation Loss: 4.426466\n",
      "Epoch: 18 \tTraining Loss: 1.702140 \tValidation Loss: 4.458312\n",
      "Epoch: 19 \tTraining Loss: 1.646808 \tValidation Loss: 4.494136\n",
      "Epoch: 20 \tTraining Loss: 1.603819 \tValidation Loss: 4.528113\n",
      "Epoch: 1 \tTraining Loss: 6.596192 \tValidation Loss: 5.810620\n",
      "Validation loss decreased (inf --> 5.81062).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.066292 \tValidation Loss: 5.695738\n",
      "Validation loss decreased (5.81062 --> 5.69574).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.824675 \tValidation Loss: 5.542789\n",
      "Validation loss decreased (5.69574 --> 5.54279).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.490904 \tValidation Loss: 5.349264\n",
      "Validation loss decreased (5.54279 --> 5.34926).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.063415 \tValidation Loss: 5.133653\n",
      "Validation loss decreased (5.34926 --> 5.13365).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.577061 \tValidation Loss: 4.928713\n",
      "Validation loss decreased (5.13365 --> 4.92871).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.079489 \tValidation Loss: 4.757126\n",
      "Validation loss decreased (4.92871 --> 4.75713).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.616735 \tValidation Loss: 4.628551\n",
      "Validation loss decreased (4.75713 --> 4.62855).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.215091 \tValidation Loss: 4.539497\n",
      "Validation loss decreased (4.62855 --> 4.53950).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.876389 \tValidation Loss: 4.483708\n",
      "Validation loss decreased (4.53950 --> 4.48371).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.601454 \tValidation Loss: 4.451537\n",
      "Validation loss decreased (4.48371 --> 4.45154).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.381965 \tValidation Loss: 4.436687\n",
      "Validation loss decreased (4.45154 --> 4.43669).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.203022 \tValidation Loss: 4.436997\n",
      "Epoch: 14 \tTraining Loss: 2.058946 \tValidation Loss: 4.445669\n",
      "Epoch: 15 \tTraining Loss: 1.947546 \tValidation Loss: 4.462185\n",
      "Epoch: 16 \tTraining Loss: 1.849222 \tValidation Loss: 4.486595\n",
      "Epoch: 17 \tTraining Loss: 1.771631 \tValidation Loss: 4.516119\n",
      "Epoch: 18 \tTraining Loss: 1.706667 \tValidation Loss: 4.549707\n",
      "Epoch: 19 \tTraining Loss: 1.651324 \tValidation Loss: 4.584593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 \tTraining Loss: 1.601768 \tValidation Loss: 4.623549\n",
      "Epoch: 1 \tTraining Loss: 6.594622 \tValidation Loss: 5.781842\n",
      "Validation loss decreased (inf --> 5.78184).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.078552 \tValidation Loss: 5.658045\n",
      "Validation loss decreased (5.78184 --> 5.65804).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.838424 \tValidation Loss: 5.493433\n",
      "Validation loss decreased (5.65804 --> 5.49343).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.497876 \tValidation Loss: 5.288123\n",
      "Validation loss decreased (5.49343 --> 5.28812).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.061492 \tValidation Loss: 5.070256\n",
      "Validation loss decreased (5.28812 --> 5.07026).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.570103 \tValidation Loss: 4.865751\n",
      "Validation loss decreased (5.07026 --> 4.86575).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.072402 \tValidation Loss: 4.696083\n",
      "Validation loss decreased (4.86575 --> 4.69608).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.609546 \tValidation Loss: 4.568701\n",
      "Validation loss decreased (4.69608 --> 4.56870).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.207447 \tValidation Loss: 4.480355\n",
      "Validation loss decreased (4.56870 --> 4.48035).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.869979 \tValidation Loss: 4.424040\n",
      "Validation loss decreased (4.48035 --> 4.42404).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.595423 \tValidation Loss: 4.393036\n",
      "Validation loss decreased (4.42404 --> 4.39304).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.374258 \tValidation Loss: 4.379117\n",
      "Validation loss decreased (4.39304 --> 4.37912).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.196133 \tValidation Loss: 4.377070\n",
      "Validation loss decreased (4.37912 --> 4.37707).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 2.055086 \tValidation Loss: 4.385275\n",
      "Epoch: 15 \tTraining Loss: 1.939402 \tValidation Loss: 4.400212\n",
      "Epoch: 16 \tTraining Loss: 1.845010 \tValidation Loss: 4.421736\n",
      "Epoch: 17 \tTraining Loss: 1.765266 \tValidation Loss: 4.448766\n",
      "Epoch: 18 \tTraining Loss: 1.697782 \tValidation Loss: 4.479823\n",
      "Epoch: 19 \tTraining Loss: 1.640809 \tValidation Loss: 4.515430\n",
      "Epoch: 20 \tTraining Loss: 1.597043 \tValidation Loss: 4.549668\n",
      "Epoch: 1 \tTraining Loss: 6.596378 \tValidation Loss: 5.791689\n",
      "Validation loss decreased (inf --> 5.79169).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.072057 \tValidation Loss: 5.677232\n",
      "Validation loss decreased (5.79169 --> 5.67723).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.833223 \tValidation Loss: 5.528959\n",
      "Validation loss decreased (5.67723 --> 5.52896).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.494934 \tValidation Loss: 5.335384\n",
      "Validation loss decreased (5.52896 --> 5.33538).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.054790 \tValidation Loss: 5.121798\n",
      "Validation loss decreased (5.33538 --> 5.12180).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.558765 \tValidation Loss: 4.921598\n",
      "Validation loss decreased (5.12180 --> 4.92160).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.058809 \tValidation Loss: 4.755468\n",
      "Validation loss decreased (4.92160 --> 4.75547).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.595718 \tValidation Loss: 4.629650\n",
      "Validation loss decreased (4.75547 --> 4.62965).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.195713 \tValidation Loss: 4.540050\n",
      "Validation loss decreased (4.62965 --> 4.54005).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.861203 \tValidation Loss: 4.482040\n",
      "Validation loss decreased (4.54005 --> 4.48204).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.589519 \tValidation Loss: 4.448078\n",
      "Validation loss decreased (4.48204 --> 4.44808).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.370206 \tValidation Loss: 4.433175\n",
      "Validation loss decreased (4.44808 --> 4.43317).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.194022 \tValidation Loss: 4.431476\n",
      "Validation loss decreased (4.43317 --> 4.43148).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 2.050091 \tValidation Loss: 4.441538\n",
      "Epoch: 15 \tTraining Loss: 1.938807 \tValidation Loss: 4.456976\n",
      "Epoch: 16 \tTraining Loss: 1.841773 \tValidation Loss: 4.479768\n",
      "Epoch: 17 \tTraining Loss: 1.762722 \tValidation Loss: 4.508166\n",
      "Epoch: 18 \tTraining Loss: 1.700624 \tValidation Loss: 4.538782\n",
      "Epoch: 19 \tTraining Loss: 1.644637 \tValidation Loss: 4.571687\n",
      "Epoch: 20 \tTraining Loss: 1.596547 \tValidation Loss: 4.607815\n",
      "Epoch: 1 \tTraining Loss: 6.595639 \tValidation Loss: 5.765877\n",
      "Validation loss decreased (inf --> 5.76588).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.079130 \tValidation Loss: 5.642825\n",
      "Validation loss decreased (5.76588 --> 5.64283).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.841213 \tValidation Loss: 5.481856\n",
      "Validation loss decreased (5.64283 --> 5.48186).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.504970 \tValidation Loss: 5.278065\n",
      "Validation loss decreased (5.48186 --> 5.27806).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.071311 \tValidation Loss: 5.059257\n",
      "Validation loss decreased (5.27806 --> 5.05926).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.578914 \tValidation Loss: 4.859948\n",
      "Validation loss decreased (5.05926 --> 4.85995).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.081109 \tValidation Loss: 4.692745\n",
      "Validation loss decreased (4.85995 --> 4.69274).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.617934 \tValidation Loss: 4.565870\n",
      "Validation loss decreased (4.69274 --> 4.56587).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.213615 \tValidation Loss: 4.476341\n",
      "Validation loss decreased (4.56587 --> 4.47634).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.876788 \tValidation Loss: 4.416610\n",
      "Validation loss decreased (4.47634 --> 4.41661).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.601250 \tValidation Loss: 4.380497\n",
      "Validation loss decreased (4.41661 --> 4.38050).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.376865 \tValidation Loss: 4.363146\n",
      "Validation loss decreased (4.38050 --> 4.36315).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.200861 \tValidation Loss: 4.359805\n",
      "Validation loss decreased (4.36315 --> 4.35981).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 2.056896 \tValidation Loss: 4.365848\n",
      "Epoch: 15 \tTraining Loss: 1.943175 \tValidation Loss: 4.379618\n",
      "Epoch: 16 \tTraining Loss: 1.846320 \tValidation Loss: 4.398107\n",
      "Epoch: 17 \tTraining Loss: 1.769714 \tValidation Loss: 4.425041\n",
      "Epoch: 18 \tTraining Loss: 1.704854 \tValidation Loss: 4.455022\n",
      "Epoch: 19 \tTraining Loss: 1.642707 \tValidation Loss: 4.488456\n",
      "Epoch: 20 \tTraining Loss: 1.597610 \tValidation Loss: 4.523159\n",
      "Epoch: 1 \tTraining Loss: 6.591255 \tValidation Loss: 5.766212\n",
      "Validation loss decreased (inf --> 5.76621).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.074332 \tValidation Loss: 5.641608\n",
      "Validation loss decreased (5.76621 --> 5.64161).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.836698 \tValidation Loss: 5.470375\n",
      "Validation loss decreased (5.64161 --> 5.47037).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.500267 \tValidation Loss: 5.268866\n",
      "Validation loss decreased (5.47037 --> 5.26887).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.064204 \tValidation Loss: 5.057296\n",
      "Validation loss decreased (5.26887 --> 5.05730).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.571810 \tValidation Loss: 4.863121\n",
      "Validation loss decreased (5.05730 --> 4.86312).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.071727 \tValidation Loss: 4.703118\n",
      "Validation loss decreased (4.86312 --> 4.70312).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.609486 \tValidation Loss: 4.583168\n",
      "Validation loss decreased (4.70312 --> 4.58317).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.205766 \tValidation Loss: 4.499967\n",
      "Validation loss decreased (4.58317 --> 4.49997).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.868829 \tValidation Loss: 4.445996\n",
      "Validation loss decreased (4.49997 --> 4.44600).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.594976 \tValidation Loss: 4.414067\n",
      "Validation loss decreased (4.44600 --> 4.41407).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.374457 \tValidation Loss: 4.400935\n",
      "Validation loss decreased (4.41407 --> 4.40093).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.197473 \tValidation Loss: 4.401044\n",
      "Epoch: 14 \tTraining Loss: 2.052951 \tValidation Loss: 4.410682\n",
      "Epoch: 15 \tTraining Loss: 1.937103 \tValidation Loss: 4.428058\n",
      "Epoch: 16 \tTraining Loss: 1.840653 \tValidation Loss: 4.451465\n",
      "Epoch: 17 \tTraining Loss: 1.764814 \tValidation Loss: 4.477993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 \tTraining Loss: 1.699314 \tValidation Loss: 4.509748\n",
      "Epoch: 19 \tTraining Loss: 1.641925 \tValidation Loss: 4.546141\n",
      "Epoch: 20 \tTraining Loss: 1.595885 \tValidation Loss: 4.581863\n",
      "Epoch: 1 \tTraining Loss: 6.596967 \tValidation Loss: 5.784535\n",
      "Validation loss decreased (inf --> 5.78454).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.068922 \tValidation Loss: 5.657826\n",
      "Validation loss decreased (5.78454 --> 5.65783).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.827859 \tValidation Loss: 5.485883\n",
      "Validation loss decreased (5.65783 --> 5.48588).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.484680 \tValidation Loss: 5.281949\n",
      "Validation loss decreased (5.48588 --> 5.28195).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.047763 \tValidation Loss: 5.067071\n",
      "Validation loss decreased (5.28195 --> 5.06707).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.557560 \tValidation Loss: 4.869753\n",
      "Validation loss decreased (5.06707 --> 4.86975).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.062779 \tValidation Loss: 4.704700\n",
      "Validation loss decreased (4.86975 --> 4.70470).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.602685 \tValidation Loss: 4.577778\n",
      "Validation loss decreased (4.70470 --> 4.57778).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.200064 \tValidation Loss: 4.488588\n",
      "Validation loss decreased (4.57778 --> 4.48859).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.867209 \tValidation Loss: 4.430957\n",
      "Validation loss decreased (4.48859 --> 4.43096).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.596427 \tValidation Loss: 4.398452\n",
      "Validation loss decreased (4.43096 --> 4.39845).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.376342 \tValidation Loss: 4.383084\n",
      "Validation loss decreased (4.39845 --> 4.38308).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.196410 \tValidation Loss: 4.380536\n",
      "Validation loss decreased (4.38308 --> 4.38054).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 2.059367 \tValidation Loss: 4.389217\n",
      "Epoch: 15 \tTraining Loss: 1.943763 \tValidation Loss: 4.404463\n",
      "Epoch: 16 \tTraining Loss: 1.848944 \tValidation Loss: 4.427388\n",
      "Epoch: 17 \tTraining Loss: 1.771635 \tValidation Loss: 4.454912\n",
      "Epoch: 18 \tTraining Loss: 1.704931 \tValidation Loss: 4.487092\n",
      "Epoch: 19 \tTraining Loss: 1.648615 \tValidation Loss: 4.520512\n",
      "Epoch: 20 \tTraining Loss: 1.601958 \tValidation Loss: 4.556702\n",
      "Epoch: 1 \tTraining Loss: 6.592431 \tValidation Loss: 5.770367\n",
      "Validation loss decreased (inf --> 5.77037).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.074282 \tValidation Loss: 5.648417\n",
      "Validation loss decreased (5.77037 --> 5.64842).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.839452 \tValidation Loss: 5.487484\n",
      "Validation loss decreased (5.64842 --> 5.48748).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.500622 \tValidation Loss: 5.288957\n",
      "Validation loss decreased (5.48748 --> 5.28896).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.063605 \tValidation Loss: 5.070712\n",
      "Validation loss decreased (5.28896 --> 5.07071).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.570416 \tValidation Loss: 4.868865\n",
      "Validation loss decreased (5.07071 --> 4.86887).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.069921 \tValidation Loss: 4.703284\n",
      "Validation loss decreased (4.86887 --> 4.70328).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.607691 \tValidation Loss: 4.578914\n",
      "Validation loss decreased (4.70328 --> 4.57891).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.208644 \tValidation Loss: 4.490114\n",
      "Validation loss decreased (4.57891 --> 4.49011).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.874599 \tValidation Loss: 4.429672\n",
      "Validation loss decreased (4.49011 --> 4.42967).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.601912 \tValidation Loss: 4.393281\n",
      "Validation loss decreased (4.42967 --> 4.39328).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.381437 \tValidation Loss: 4.375229\n",
      "Validation loss decreased (4.39328 --> 4.37523).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.203587 \tValidation Loss: 4.369523\n",
      "Validation loss decreased (4.37523 --> 4.36952).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 2.059652 \tValidation Loss: 4.374171\n",
      "Epoch: 15 \tTraining Loss: 1.944918 \tValidation Loss: 4.389665\n",
      "Epoch: 16 \tTraining Loss: 1.849987 \tValidation Loss: 4.408049\n",
      "Epoch: 17 \tTraining Loss: 1.773284 \tValidation Loss: 4.433643\n",
      "Epoch: 18 \tTraining Loss: 1.702584 \tValidation Loss: 4.460955\n",
      "Epoch: 19 \tTraining Loss: 1.647206 \tValidation Loss: 4.493858\n",
      "Epoch: 20 \tTraining Loss: 1.602304 \tValidation Loss: 4.527664\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 4 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.576143 \tValidation Loss: 6.177144\n",
      "Validation loss decreased (inf --> 6.17714).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.002274 \tValidation Loss: 5.946302\n",
      "Validation loss decreased (6.17714 --> 5.94630).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.596669 \tValidation Loss: 5.620829\n",
      "Validation loss decreased (5.94630 --> 5.62083).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.019766 \tValidation Loss: 5.233918\n",
      "Validation loss decreased (5.62083 --> 5.23392).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.336165 \tValidation Loss: 4.863908\n",
      "Validation loss decreased (5.23392 --> 4.86391).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.654559 \tValidation Loss: 4.552723\n",
      "Validation loss decreased (4.86391 --> 4.55272).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.055913 \tValidation Loss: 4.309881\n",
      "Validation loss decreased (4.55272 --> 4.30988).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.560184 \tValidation Loss: 4.126488\n",
      "Validation loss decreased (4.30988 --> 4.12649).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.174563 \tValidation Loss: 3.993719\n",
      "Validation loss decreased (4.12649 --> 3.99372).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.878971 \tValidation Loss: 3.899640\n",
      "Validation loss decreased (3.99372 --> 3.89964).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.647290 \tValidation Loss: 3.835475\n",
      "Validation loss decreased (3.89964 --> 3.83548).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.469038 \tValidation Loss: 3.796191\n",
      "Validation loss decreased (3.83548 --> 3.79619).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.326916 \tValidation Loss: 3.772579\n",
      "Validation loss decreased (3.79619 --> 3.77258).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.209603 \tValidation Loss: 3.765173\n",
      "Validation loss decreased (3.77258 --> 3.76517).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.117214 \tValidation Loss: 3.771523\n",
      "Epoch: 16 \tTraining Loss: 1.039228 \tValidation Loss: 3.785847\n",
      "Epoch: 17 \tTraining Loss: 0.974793 \tValidation Loss: 3.807850\n",
      "Epoch: 18 \tTraining Loss: 0.923105 \tValidation Loss: 3.834244\n",
      "Epoch: 19 \tTraining Loss: 0.876716 \tValidation Loss: 3.862238\n",
      "Epoch: 20 \tTraining Loss: 0.839408 \tValidation Loss: 3.890789\n",
      "Epoch: 1 \tTraining Loss: 6.571443 \tValidation Loss: 6.147707\n",
      "Validation loss decreased (inf --> 6.14771).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.001504 \tValidation Loss: 5.918705\n",
      "Validation loss decreased (6.14771 --> 5.91870).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.601743 \tValidation Loss: 5.590619\n",
      "Validation loss decreased (5.91870 --> 5.59062).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.030490 \tValidation Loss: 5.203940\n",
      "Validation loss decreased (5.59062 --> 5.20394).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.354199 \tValidation Loss: 4.825734\n",
      "Validation loss decreased (5.20394 --> 4.82573).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.674696 \tValidation Loss: 4.505816\n",
      "Validation loss decreased (4.82573 --> 4.50582).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.070684 \tValidation Loss: 4.254749\n",
      "Validation loss decreased (4.50582 --> 4.25475).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.571575 \tValidation Loss: 4.065014\n",
      "Validation loss decreased (4.25475 --> 4.06501).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.183018 \tValidation Loss: 3.925207\n",
      "Validation loss decreased (4.06501 --> 3.92521).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.879375 \tValidation Loss: 3.823938\n",
      "Validation loss decreased (3.92521 --> 3.82394).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.647616 \tValidation Loss: 3.753743\n",
      "Validation loss decreased (3.82394 --> 3.75374).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.465460 \tValidation Loss: 3.709716\n",
      "Validation loss decreased (3.75374 --> 3.70972).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.325413 \tValidation Loss: 3.684721\n",
      "Validation loss decreased (3.70972 --> 3.68472).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 \tTraining Loss: 1.211197 \tValidation Loss: 3.674615\n",
      "Validation loss decreased (3.68472 --> 3.67462).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.114574 \tValidation Loss: 3.675869\n",
      "Epoch: 16 \tTraining Loss: 1.037335 \tValidation Loss: 3.687251\n",
      "Epoch: 17 \tTraining Loss: 0.971699 \tValidation Loss: 3.703788\n",
      "Epoch: 18 \tTraining Loss: 0.921084 \tValidation Loss: 3.726976\n",
      "Epoch: 19 \tTraining Loss: 0.876551 \tValidation Loss: 3.752549\n",
      "Epoch: 20 \tTraining Loss: 0.836548 \tValidation Loss: 3.783338\n",
      "Epoch: 1 \tTraining Loss: 6.576858 \tValidation Loss: 6.193385\n",
      "Validation loss decreased (inf --> 6.19338).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.992757 \tValidation Loss: 5.958534\n",
      "Validation loss decreased (6.19338 --> 5.95853).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.588002 \tValidation Loss: 5.635980\n",
      "Validation loss decreased (5.95853 --> 5.63598).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.015380 \tValidation Loss: 5.249780\n",
      "Validation loss decreased (5.63598 --> 5.24978).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.339922 \tValidation Loss: 4.876742\n",
      "Validation loss decreased (5.24978 --> 4.87674).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.662241 \tValidation Loss: 4.559359\n",
      "Validation loss decreased (4.87674 --> 4.55936).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.055824 \tValidation Loss: 4.311810\n",
      "Validation loss decreased (4.55936 --> 4.31181).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.561796 \tValidation Loss: 4.128193\n",
      "Validation loss decreased (4.31181 --> 4.12819).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.172541 \tValidation Loss: 3.995671\n",
      "Validation loss decreased (4.12819 --> 3.99567).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.871210 \tValidation Loss: 3.902513\n",
      "Validation loss decreased (3.99567 --> 3.90251).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.643718 \tValidation Loss: 3.839183\n",
      "Validation loss decreased (3.90251 --> 3.83918).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.462867 \tValidation Loss: 3.798085\n",
      "Validation loss decreased (3.83918 --> 3.79808).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.318649 \tValidation Loss: 3.776587\n",
      "Validation loss decreased (3.79808 --> 3.77659).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.205211 \tValidation Loss: 3.769436\n",
      "Validation loss decreased (3.77659 --> 3.76944).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.108050 \tValidation Loss: 3.772166\n",
      "Epoch: 16 \tTraining Loss: 1.033151 \tValidation Loss: 3.786591\n",
      "Epoch: 17 \tTraining Loss: 0.968660 \tValidation Loss: 3.805051\n",
      "Epoch: 18 \tTraining Loss: 0.914364 \tValidation Loss: 3.830406\n",
      "Epoch: 19 \tTraining Loss: 0.869649 \tValidation Loss: 3.859321\n",
      "Epoch: 20 \tTraining Loss: 0.833930 \tValidation Loss: 3.890906\n",
      "Epoch: 1 \tTraining Loss: 6.571053 \tValidation Loss: 6.171806\n",
      "Validation loss decreased (inf --> 6.17181).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.993184 \tValidation Loss: 5.944147\n",
      "Validation loss decreased (6.17181 --> 5.94415).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.586924 \tValidation Loss: 5.625578\n",
      "Validation loss decreased (5.94415 --> 5.62558).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.014199 \tValidation Loss: 5.238689\n",
      "Validation loss decreased (5.62558 --> 5.23869).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.336907 \tValidation Loss: 4.855266\n",
      "Validation loss decreased (5.23869 --> 4.85527).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.660994 \tValidation Loss: 4.524885\n",
      "Validation loss decreased (4.85527 --> 4.52489).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.057229 \tValidation Loss: 4.265513\n",
      "Validation loss decreased (4.52489 --> 4.26551).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.563121 \tValidation Loss: 4.070502\n",
      "Validation loss decreased (4.26551 --> 4.07050).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.174819 \tValidation Loss: 3.929216\n",
      "Validation loss decreased (4.07050 --> 3.92922).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.877043 \tValidation Loss: 3.828302\n",
      "Validation loss decreased (3.92922 --> 3.82830).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.645020 \tValidation Loss: 3.756837\n",
      "Validation loss decreased (3.82830 --> 3.75684).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.463413 \tValidation Loss: 3.711514\n",
      "Validation loss decreased (3.75684 --> 3.71151).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.322193 \tValidation Loss: 3.682280\n",
      "Validation loss decreased (3.71151 --> 3.68228).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.205679 \tValidation Loss: 3.667200\n",
      "Validation loss decreased (3.68228 --> 3.66720).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.113084 \tValidation Loss: 3.665964\n",
      "Validation loss decreased (3.66720 --> 3.66596).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 1.035585 \tValidation Loss: 3.671331\n",
      "Epoch: 17 \tTraining Loss: 0.973349 \tValidation Loss: 3.685087\n",
      "Epoch: 18 \tTraining Loss: 0.916864 \tValidation Loss: 3.705859\n",
      "Epoch: 19 \tTraining Loss: 0.870619 \tValidation Loss: 3.731624\n",
      "Epoch: 20 \tTraining Loss: 0.834242 \tValidation Loss: 3.759653\n",
      "Epoch: 1 \tTraining Loss: 6.584114 \tValidation Loss: 6.181294\n",
      "Validation loss decreased (inf --> 6.18129).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.999408 \tValidation Loss: 5.945855\n",
      "Validation loss decreased (6.18129 --> 5.94586).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.595899 \tValidation Loss: 5.621763\n",
      "Validation loss decreased (5.94586 --> 5.62176).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.019236 \tValidation Loss: 5.233228\n",
      "Validation loss decreased (5.62176 --> 5.23323).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.332132 \tValidation Loss: 4.861367\n",
      "Validation loss decreased (5.23323 --> 4.86137).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.650348 \tValidation Loss: 4.551671\n",
      "Validation loss decreased (4.86137 --> 4.55167).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.048942 \tValidation Loss: 4.304296\n",
      "Validation loss decreased (4.55167 --> 4.30430).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.558524 \tValidation Loss: 4.116984\n",
      "Validation loss decreased (4.30430 --> 4.11698).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.171208 \tValidation Loss: 3.978066\n",
      "Validation loss decreased (4.11698 --> 3.97807).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.872770 \tValidation Loss: 3.878610\n",
      "Validation loss decreased (3.97807 --> 3.87861).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.644041 \tValidation Loss: 3.811463\n",
      "Validation loss decreased (3.87861 --> 3.81146).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.464731 \tValidation Loss: 3.767768\n",
      "Validation loss decreased (3.81146 --> 3.76777).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.319084 \tValidation Loss: 3.743071\n",
      "Validation loss decreased (3.76777 --> 3.74307).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.207597 \tValidation Loss: 3.735730\n",
      "Validation loss decreased (3.74307 --> 3.73573).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.116207 \tValidation Loss: 3.737924\n",
      "Epoch: 16 \tTraining Loss: 1.041212 \tValidation Loss: 3.748094\n",
      "Epoch: 17 \tTraining Loss: 0.976805 \tValidation Loss: 3.765835\n",
      "Epoch: 18 \tTraining Loss: 0.918546 \tValidation Loss: 3.792737\n",
      "Epoch: 19 \tTraining Loss: 0.876508 \tValidation Loss: 3.820352\n",
      "Epoch: 20 \tTraining Loss: 0.834515 \tValidation Loss: 3.854712\n",
      "Epoch: 1 \tTraining Loss: 6.575382 \tValidation Loss: 6.186347\n",
      "Validation loss decreased (inf --> 6.18635).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.992318 \tValidation Loss: 5.953478\n",
      "Validation loss decreased (6.18635 --> 5.95348).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.589167 \tValidation Loss: 5.621523\n",
      "Validation loss decreased (5.95348 --> 5.62152).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.014449 \tValidation Loss: 5.226451\n",
      "Validation loss decreased (5.62152 --> 5.22645).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.334404 \tValidation Loss: 4.848614\n",
      "Validation loss decreased (5.22645 --> 4.84861).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.655353 \tValidation Loss: 4.526881\n",
      "Validation loss decreased (4.84861 --> 4.52688).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.053210 \tValidation Loss: 4.272736\n",
      "Validation loss decreased (4.52688 --> 4.27274).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.561075 \tValidation Loss: 4.082106\n",
      "Validation loss decreased (4.27274 --> 4.08211).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.172950 \tValidation Loss: 3.944935\n",
      "Validation loss decreased (4.08211 --> 3.94493).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 \tTraining Loss: 1.875973 \tValidation Loss: 3.848878\n",
      "Validation loss decreased (3.94493 --> 3.84888).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.642854 \tValidation Loss: 3.782452\n",
      "Validation loss decreased (3.84888 --> 3.78245).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.463762 \tValidation Loss: 3.738858\n",
      "Validation loss decreased (3.78245 --> 3.73886).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.320473 \tValidation Loss: 3.716489\n",
      "Validation loss decreased (3.73886 --> 3.71649).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.205529 \tValidation Loss: 3.710430\n",
      "Validation loss decreased (3.71649 --> 3.71043).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.114039 \tValidation Loss: 3.713247\n",
      "Epoch: 16 \tTraining Loss: 1.037506 \tValidation Loss: 3.729185\n",
      "Epoch: 17 \tTraining Loss: 0.971067 \tValidation Loss: 3.747082\n",
      "Epoch: 18 \tTraining Loss: 0.915217 \tValidation Loss: 3.772375\n",
      "Epoch: 19 \tTraining Loss: 0.870841 \tValidation Loss: 3.803377\n",
      "Epoch: 20 \tTraining Loss: 0.831505 \tValidation Loss: 3.833794\n",
      "Epoch: 1 \tTraining Loss: 6.581744 \tValidation Loss: 6.186002\n",
      "Validation loss decreased (inf --> 6.18600).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.998307 \tValidation Loss: 5.955398\n",
      "Validation loss decreased (6.18600 --> 5.95540).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.594887 \tValidation Loss: 5.626203\n",
      "Validation loss decreased (5.95540 --> 5.62620).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.019056 \tValidation Loss: 5.235874\n",
      "Validation loss decreased (5.62620 --> 5.23587).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.340334 \tValidation Loss: 4.864263\n",
      "Validation loss decreased (5.23587 --> 4.86426).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.660792 \tValidation Loss: 4.551042\n",
      "Validation loss decreased (4.86426 --> 4.55104).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.055234 \tValidation Loss: 4.307677\n",
      "Validation loss decreased (4.55104 --> 4.30768).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.557878 \tValidation Loss: 4.127336\n",
      "Validation loss decreased (4.30768 --> 4.12734).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.168028 \tValidation Loss: 3.999077\n",
      "Validation loss decreased (4.12734 --> 3.99908).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.872452 \tValidation Loss: 3.910430\n",
      "Validation loss decreased (3.99908 --> 3.91043).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.642078 \tValidation Loss: 3.852777\n",
      "Validation loss decreased (3.91043 --> 3.85278).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.465740 \tValidation Loss: 3.817485\n",
      "Validation loss decreased (3.85278 --> 3.81749).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.319864 \tValidation Loss: 3.797462\n",
      "Validation loss decreased (3.81749 --> 3.79746).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.203875 \tValidation Loss: 3.794628\n",
      "Validation loss decreased (3.79746 --> 3.79463).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.111120 \tValidation Loss: 3.802103\n",
      "Epoch: 16 \tTraining Loss: 1.034928 \tValidation Loss: 3.819022\n",
      "Epoch: 17 \tTraining Loss: 0.972363 \tValidation Loss: 3.838203\n",
      "Epoch: 18 \tTraining Loss: 0.921153 \tValidation Loss: 3.866535\n",
      "Epoch: 19 \tTraining Loss: 0.872529 \tValidation Loss: 3.894562\n",
      "Epoch: 20 \tTraining Loss: 0.833661 \tValidation Loss: 3.931419\n",
      "Epoch: 1 \tTraining Loss: 6.572867 \tValidation Loss: 6.159966\n",
      "Validation loss decreased (inf --> 6.15997).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.992525 \tValidation Loss: 5.931460\n",
      "Validation loss decreased (6.15997 --> 5.93146).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.590956 \tValidation Loss: 5.615965\n",
      "Validation loss decreased (5.93146 --> 5.61596).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.020732 \tValidation Loss: 5.237258\n",
      "Validation loss decreased (5.61596 --> 5.23726).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.340545 \tValidation Loss: 4.864735\n",
      "Validation loss decreased (5.23726 --> 4.86474).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.659882 \tValidation Loss: 4.550882\n",
      "Validation loss decreased (4.86474 --> 4.55088).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.054133 \tValidation Loss: 4.307282\n",
      "Validation loss decreased (4.55088 --> 4.30728).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.557673 \tValidation Loss: 4.128432\n",
      "Validation loss decreased (4.30728 --> 4.12843).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.173867 \tValidation Loss: 4.001178\n",
      "Validation loss decreased (4.12843 --> 4.00118).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.876353 \tValidation Loss: 3.912590\n",
      "Validation loss decreased (4.00118 --> 3.91259).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.645843 \tValidation Loss: 3.853180\n",
      "Validation loss decreased (3.91259 --> 3.85318).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.466280 \tValidation Loss: 3.817365\n",
      "Validation loss decreased (3.85318 --> 3.81737).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.324355 \tValidation Loss: 3.797383\n",
      "Validation loss decreased (3.81737 --> 3.79738).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.209980 \tValidation Loss: 3.793384\n",
      "Validation loss decreased (3.79738 --> 3.79338).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.116953 \tValidation Loss: 3.800388\n",
      "Epoch: 16 \tTraining Loss: 1.038917 \tValidation Loss: 3.814115\n",
      "Epoch: 17 \tTraining Loss: 0.971909 \tValidation Loss: 3.837646\n",
      "Epoch: 18 \tTraining Loss: 0.922499 \tValidation Loss: 3.862002\n",
      "Epoch: 19 \tTraining Loss: 0.873105 \tValidation Loss: 3.890235\n",
      "Epoch: 20 \tTraining Loss: 0.838091 \tValidation Loss: 3.925824\n",
      "Epoch: 1 \tTraining Loss: 6.572309 \tValidation Loss: 6.197626\n",
      "Validation loss decreased (inf --> 6.19763).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.981501 \tValidation Loss: 5.967729\n",
      "Validation loss decreased (6.19763 --> 5.96773).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.570502 \tValidation Loss: 5.652066\n",
      "Validation loss decreased (5.96773 --> 5.65207).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.996135 \tValidation Loss: 5.273573\n",
      "Validation loss decreased (5.65207 --> 5.27357).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.325206 \tValidation Loss: 4.899981\n",
      "Validation loss decreased (5.27357 --> 4.89998).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.655489 \tValidation Loss: 4.575130\n",
      "Validation loss decreased (4.89998 --> 4.57513).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.055870 \tValidation Loss: 4.318778\n",
      "Validation loss decreased (4.57513 --> 4.31878).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.564949 \tValidation Loss: 4.123488\n",
      "Validation loss decreased (4.31878 --> 4.12349).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.178472 \tValidation Loss: 3.983308\n",
      "Validation loss decreased (4.12349 --> 3.98331).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.877729 \tValidation Loss: 3.882773\n",
      "Validation loss decreased (3.98331 --> 3.88277).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.649632 \tValidation Loss: 3.812965\n",
      "Validation loss decreased (3.88277 --> 3.81296).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.466387 \tValidation Loss: 3.769708\n",
      "Validation loss decreased (3.81296 --> 3.76971).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.321141 \tValidation Loss: 3.740909\n",
      "Validation loss decreased (3.76971 --> 3.74091).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.209717 \tValidation Loss: 3.729513\n",
      "Validation loss decreased (3.74091 --> 3.72951).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.114551 \tValidation Loss: 3.731048\n",
      "Epoch: 16 \tTraining Loss: 1.036890 \tValidation Loss: 3.740784\n",
      "Epoch: 17 \tTraining Loss: 0.969432 \tValidation Loss: 3.757357\n",
      "Epoch: 18 \tTraining Loss: 0.913313 \tValidation Loss: 3.781275\n",
      "Epoch: 19 \tTraining Loss: 0.870178 \tValidation Loss: 3.809419\n",
      "Epoch: 20 \tTraining Loss: 0.831157 \tValidation Loss: 3.842889\n",
      "Epoch: 1 \tTraining Loss: 6.567775 \tValidation Loss: 6.224326\n",
      "Validation loss decreased (inf --> 6.22433).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.985100 \tValidation Loss: 5.987811\n",
      "Validation loss decreased (6.22433 --> 5.98781).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.575308 \tValidation Loss: 5.660656\n",
      "Validation loss decreased (5.98781 --> 5.66066).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.999471 \tValidation Loss: 5.273686\n",
      "Validation loss decreased (5.66066 --> 5.27369).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.327185 \tValidation Loss: 4.899770\n",
      "Validation loss decreased (5.27369 --> 4.89977).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.656408 \tValidation Loss: 4.576108\n",
      "Validation loss decreased (4.89977 --> 4.57611).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 \tTraining Loss: 3.056157 \tValidation Loss: 4.317452\n",
      "Validation loss decreased (4.57611 --> 4.31745).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.564634 \tValidation Loss: 4.124655\n",
      "Validation loss decreased (4.31745 --> 4.12465).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.173107 \tValidation Loss: 3.987649\n",
      "Validation loss decreased (4.12465 --> 3.98765).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.877831 \tValidation Loss: 3.892618\n",
      "Validation loss decreased (3.98765 --> 3.89262).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.647703 \tValidation Loss: 3.829364\n",
      "Validation loss decreased (3.89262 --> 3.82936).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.467404 \tValidation Loss: 3.789169\n",
      "Validation loss decreased (3.82936 --> 3.78917).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.326441 \tValidation Loss: 3.769052\n",
      "Validation loss decreased (3.78917 --> 3.76905).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.208436 \tValidation Loss: 3.761675\n",
      "Validation loss decreased (3.76905 --> 3.76167).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.114171 \tValidation Loss: 3.766403\n",
      "Epoch: 16 \tTraining Loss: 1.038609 \tValidation Loss: 3.779618\n",
      "Epoch: 17 \tTraining Loss: 0.973533 \tValidation Loss: 3.798121\n",
      "Epoch: 18 \tTraining Loss: 0.923117 \tValidation Loss: 3.821105\n",
      "Epoch: 19 \tTraining Loss: 0.871153 \tValidation Loss: 3.852368\n",
      "Epoch: 20 \tTraining Loss: 0.835853 \tValidation Loss: 3.885753\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 5 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.515142 \tValidation Loss: 5.705059\n",
      "Validation loss decreased (inf --> 5.70506).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.851091 \tValidation Loss: 5.424530\n",
      "Validation loss decreased (5.70506 --> 5.42453).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.316179 \tValidation Loss: 5.031020\n",
      "Validation loss decreased (5.42453 --> 5.03102).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.582200 \tValidation Loss: 4.593774\n",
      "Validation loss decreased (5.03102 --> 4.59377).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.781446 \tValidation Loss: 4.189198\n",
      "Validation loss decreased (4.59377 --> 4.18920).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.044656 \tValidation Loss: 3.854728\n",
      "Validation loss decreased (4.18920 --> 3.85473).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.434850 \tValidation Loss: 3.600212\n",
      "Validation loss decreased (3.85473 --> 3.60021).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.971777 \tValidation Loss: 3.414784\n",
      "Validation loss decreased (3.60021 --> 3.41478).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.620373 \tValidation Loss: 3.281214\n",
      "Validation loss decreased (3.41478 --> 3.28121).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.357618 \tValidation Loss: 3.187093\n",
      "Validation loss decreased (3.28121 --> 3.18709).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.155001 \tValidation Loss: 3.121682\n",
      "Validation loss decreased (3.18709 --> 3.12168).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.999250 \tValidation Loss: 3.077427\n",
      "Validation loss decreased (3.12168 --> 3.07743).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.874923 \tValidation Loss: 3.051707\n",
      "Validation loss decreased (3.07743 --> 3.05171).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.778443 \tValidation Loss: 3.040618\n",
      "Validation loss decreased (3.05171 --> 3.04062).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.699077 \tValidation Loss: 3.038541\n",
      "Validation loss decreased (3.04062 --> 3.03854).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.636213 \tValidation Loss: 3.046871\n",
      "Epoch: 17 \tTraining Loss: 0.582020 \tValidation Loss: 3.065441\n",
      "Epoch: 18 \tTraining Loss: 0.537695 \tValidation Loss: 3.085795\n",
      "Epoch: 19 \tTraining Loss: 0.501401 \tValidation Loss: 3.107284\n",
      "Epoch: 20 \tTraining Loss: 0.471521 \tValidation Loss: 3.135611\n",
      "Epoch: 1 \tTraining Loss: 6.501852 \tValidation Loss: 5.745800\n",
      "Validation loss decreased (inf --> 5.74580).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.851846 \tValidation Loss: 5.460361\n",
      "Validation loss decreased (5.74580 --> 5.46036).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.322617 \tValidation Loss: 5.054894\n",
      "Validation loss decreased (5.46036 --> 5.05489).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.592878 \tValidation Loss: 4.599920\n",
      "Validation loss decreased (5.05489 --> 4.59992).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.792003 \tValidation Loss: 4.183459\n",
      "Validation loss decreased (4.59992 --> 4.18346).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.051057 \tValidation Loss: 3.844508\n",
      "Validation loss decreased (4.18346 --> 3.84451).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.439964 \tValidation Loss: 3.588677\n",
      "Validation loss decreased (3.84451 --> 3.58868).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.972452 \tValidation Loss: 3.401979\n",
      "Validation loss decreased (3.58868 --> 3.40198).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.624217 \tValidation Loss: 3.267889\n",
      "Validation loss decreased (3.40198 --> 3.26789).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.360706 \tValidation Loss: 3.172580\n",
      "Validation loss decreased (3.26789 --> 3.17258).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.158909 \tValidation Loss: 3.108259\n",
      "Validation loss decreased (3.17258 --> 3.10826).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.003334 \tValidation Loss: 3.067069\n",
      "Validation loss decreased (3.10826 --> 3.06707).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.882459 \tValidation Loss: 3.044020\n",
      "Validation loss decreased (3.06707 --> 3.04402).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.782498 \tValidation Loss: 3.033927\n",
      "Validation loss decreased (3.04402 --> 3.03393).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.705156 \tValidation Loss: 3.034088\n",
      "Epoch: 16 \tTraining Loss: 0.641641 \tValidation Loss: 3.043052\n",
      "Epoch: 17 \tTraining Loss: 0.587407 \tValidation Loss: 3.059792\n",
      "Epoch: 18 \tTraining Loss: 0.544879 \tValidation Loss: 3.076073\n",
      "Epoch: 19 \tTraining Loss: 0.507643 \tValidation Loss: 3.103837\n",
      "Epoch: 20 \tTraining Loss: 0.475366 \tValidation Loss: 3.128793\n",
      "Epoch: 1 \tTraining Loss: 6.513547 \tValidation Loss: 5.743850\n",
      "Validation loss decreased (inf --> 5.74385).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.853092 \tValidation Loss: 5.461304\n",
      "Validation loss decreased (5.74385 --> 5.46130).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.321767 \tValidation Loss: 5.048384\n",
      "Validation loss decreased (5.46130 --> 5.04838).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.591530 \tValidation Loss: 4.583110\n",
      "Validation loss decreased (5.04838 --> 4.58311).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.791529 \tValidation Loss: 4.162233\n",
      "Validation loss decreased (4.58311 --> 4.16223).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.050051 \tValidation Loss: 3.824324\n",
      "Validation loss decreased (4.16223 --> 3.82432).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.441719 \tValidation Loss: 3.567210\n",
      "Validation loss decreased (3.82432 --> 3.56721).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.975784 \tValidation Loss: 3.375508\n",
      "Validation loss decreased (3.56721 --> 3.37551).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.623910 \tValidation Loss: 3.234972\n",
      "Validation loss decreased (3.37551 --> 3.23497).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.362541 \tValidation Loss: 3.135282\n",
      "Validation loss decreased (3.23497 --> 3.13528).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.162542 \tValidation Loss: 3.064644\n",
      "Validation loss decreased (3.13528 --> 3.06464).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.006472 \tValidation Loss: 3.019469\n",
      "Validation loss decreased (3.06464 --> 3.01947).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.884318 \tValidation Loss: 2.990742\n",
      "Validation loss decreased (3.01947 --> 2.99074).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.786319 \tValidation Loss: 2.978691\n",
      "Validation loss decreased (2.99074 --> 2.97869).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.704264 \tValidation Loss: 2.974331\n",
      "Validation loss decreased (2.97869 --> 2.97433).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.642911 \tValidation Loss: 2.983764\n",
      "Epoch: 17 \tTraining Loss: 0.589238 \tValidation Loss: 2.996784\n",
      "Epoch: 18 \tTraining Loss: 0.545002 \tValidation Loss: 3.015029\n",
      "Epoch: 19 \tTraining Loss: 0.508582 \tValidation Loss: 3.037468\n",
      "Epoch: 20 \tTraining Loss: 0.477621 \tValidation Loss: 3.062851\n",
      "Epoch: 1 \tTraining Loss: 6.514119 \tValidation Loss: 5.717489\n",
      "Validation loss decreased (inf --> 5.71749).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 5.851379 \tValidation Loss: 5.436335\n",
      "Validation loss decreased (5.71749 --> 5.43633).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.317012 \tValidation Loss: 5.039811\n",
      "Validation loss decreased (5.43633 --> 5.03981).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.580626 \tValidation Loss: 4.596670\n",
      "Validation loss decreased (5.03981 --> 4.59667).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.781910 \tValidation Loss: 4.184943\n",
      "Validation loss decreased (4.59667 --> 4.18494).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.044090 \tValidation Loss: 3.845764\n",
      "Validation loss decreased (4.18494 --> 3.84576).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.435180 \tValidation Loss: 3.588098\n",
      "Validation loss decreased (3.84576 --> 3.58810).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.974136 \tValidation Loss: 3.401104\n",
      "Validation loss decreased (3.58810 --> 3.40110).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.630126 \tValidation Loss: 3.264364\n",
      "Validation loss decreased (3.40110 --> 3.26436).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.367326 \tValidation Loss: 3.165208\n",
      "Validation loss decreased (3.26436 --> 3.16521).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.165463 \tValidation Loss: 3.096833\n",
      "Validation loss decreased (3.16521 --> 3.09683).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.014323 \tValidation Loss: 3.049620\n",
      "Validation loss decreased (3.09683 --> 3.04962).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.891575 \tValidation Loss: 3.021305\n",
      "Validation loss decreased (3.04962 --> 3.02131).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.789751 \tValidation Loss: 3.007387\n",
      "Validation loss decreased (3.02131 --> 3.00739).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.711091 \tValidation Loss: 3.004791\n",
      "Validation loss decreased (3.00739 --> 3.00479).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.645561 \tValidation Loss: 3.009042\n",
      "Epoch: 17 \tTraining Loss: 0.592100 \tValidation Loss: 3.021655\n",
      "Epoch: 18 \tTraining Loss: 0.548898 \tValidation Loss: 3.041470\n",
      "Epoch: 19 \tTraining Loss: 0.514424 \tValidation Loss: 3.058495\n",
      "Epoch: 20 \tTraining Loss: 0.482275 \tValidation Loss: 3.083649\n",
      "Epoch: 1 \tTraining Loss: 6.509105 \tValidation Loss: 5.735425\n",
      "Validation loss decreased (inf --> 5.73542).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.853018 \tValidation Loss: 5.448435\n",
      "Validation loss decreased (5.73542 --> 5.44843).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.320823 \tValidation Loss: 5.050982\n",
      "Validation loss decreased (5.44843 --> 5.05098).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.588263 \tValidation Loss: 4.602650\n",
      "Validation loss decreased (5.05098 --> 4.60265).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.791372 \tValidation Loss: 4.188998\n",
      "Validation loss decreased (4.60265 --> 4.18900).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.052582 \tValidation Loss: 3.850951\n",
      "Validation loss decreased (4.18900 --> 3.85095).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.443913 \tValidation Loss: 3.591137\n",
      "Validation loss decreased (3.85095 --> 3.59114).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.977700 \tValidation Loss: 3.398071\n",
      "Validation loss decreased (3.59114 --> 3.39807).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.629372 \tValidation Loss: 3.256163\n",
      "Validation loss decreased (3.39807 --> 3.25616).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.367047 \tValidation Loss: 3.156083\n",
      "Validation loss decreased (3.25616 --> 3.15608).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.164923 \tValidation Loss: 3.082726\n",
      "Validation loss decreased (3.15608 --> 3.08273).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.009623 \tValidation Loss: 3.034121\n",
      "Validation loss decreased (3.08273 --> 3.03412).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.884352 \tValidation Loss: 3.001467\n",
      "Validation loss decreased (3.03412 --> 3.00147).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.786787 \tValidation Loss: 2.985367\n",
      "Validation loss decreased (3.00147 --> 2.98537).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.705247 \tValidation Loss: 2.979606\n",
      "Validation loss decreased (2.98537 --> 2.97961).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.643563 \tValidation Loss: 2.981538\n",
      "Epoch: 17 \tTraining Loss: 0.588967 \tValidation Loss: 2.991346\n",
      "Epoch: 18 \tTraining Loss: 0.548988 \tValidation Loss: 3.005343\n",
      "Epoch: 19 \tTraining Loss: 0.509348 \tValidation Loss: 3.025484\n",
      "Epoch: 20 \tTraining Loss: 0.478284 \tValidation Loss: 3.041551\n",
      "Epoch: 1 \tTraining Loss: 6.499954 \tValidation Loss: 5.750839\n",
      "Validation loss decreased (inf --> 5.75084).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.848722 \tValidation Loss: 5.467935\n",
      "Validation loss decreased (5.75084 --> 5.46794).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.327853 \tValidation Loss: 5.061949\n",
      "Validation loss decreased (5.46794 --> 5.06195).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.604952 \tValidation Loss: 4.598460\n",
      "Validation loss decreased (5.06195 --> 4.59846).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.808317 \tValidation Loss: 4.173333\n",
      "Validation loss decreased (4.59846 --> 4.17333).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.065977 \tValidation Loss: 3.824912\n",
      "Validation loss decreased (4.17333 --> 3.82491).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.453682 \tValidation Loss: 3.555582\n",
      "Validation loss decreased (3.82491 --> 3.55558).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.983555 \tValidation Loss: 3.354845\n",
      "Validation loss decreased (3.55558 --> 3.35485).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.633738 \tValidation Loss: 3.207588\n",
      "Validation loss decreased (3.35485 --> 3.20759).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.368641 \tValidation Loss: 3.102631\n",
      "Validation loss decreased (3.20759 --> 3.10263).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.169295 \tValidation Loss: 3.030940\n",
      "Validation loss decreased (3.10263 --> 3.03094).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.011142 \tValidation Loss: 2.983738\n",
      "Validation loss decreased (3.03094 --> 2.98374).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.887925 \tValidation Loss: 2.952914\n",
      "Validation loss decreased (2.98374 --> 2.95291).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.789771 \tValidation Loss: 2.940336\n",
      "Validation loss decreased (2.95291 --> 2.94034).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.710338 \tValidation Loss: 2.936385\n",
      "Validation loss decreased (2.94034 --> 2.93639).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.646253 \tValidation Loss: 2.939471\n",
      "Epoch: 17 \tTraining Loss: 0.593954 \tValidation Loss: 2.953013\n",
      "Epoch: 18 \tTraining Loss: 0.548928 \tValidation Loss: 2.969667\n",
      "Epoch: 19 \tTraining Loss: 0.512575 \tValidation Loss: 2.989013\n",
      "Epoch: 20 \tTraining Loss: 0.483472 \tValidation Loss: 3.013161\n",
      "Epoch: 1 \tTraining Loss: 6.508424 \tValidation Loss: 5.734867\n",
      "Validation loss decreased (inf --> 5.73487).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.851589 \tValidation Loss: 5.450631\n",
      "Validation loss decreased (5.73487 --> 5.45063).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.322668 \tValidation Loss: 5.044742\n",
      "Validation loss decreased (5.45063 --> 5.04474).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.595373 \tValidation Loss: 4.587699\n",
      "Validation loss decreased (5.04474 --> 4.58770).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.795056 \tValidation Loss: 4.171117\n",
      "Validation loss decreased (4.58770 --> 4.17112).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.055975 \tValidation Loss: 3.827338\n",
      "Validation loss decreased (4.17112 --> 3.82734).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.452345 \tValidation Loss: 3.557738\n",
      "Validation loss decreased (3.82734 --> 3.55774).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.988289 \tValidation Loss: 3.356174\n",
      "Validation loss decreased (3.55774 --> 3.35617).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.638326 \tValidation Loss: 3.209648\n",
      "Validation loss decreased (3.35617 --> 3.20965).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.374467 \tValidation Loss: 3.102851\n",
      "Validation loss decreased (3.20965 --> 3.10285).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.174507 \tValidation Loss: 3.028649\n",
      "Validation loss decreased (3.10285 --> 3.02865).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.012953 \tValidation Loss: 2.978221\n",
      "Validation loss decreased (3.02865 --> 2.97822).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.889880 \tValidation Loss: 2.947931\n",
      "Validation loss decreased (2.97822 --> 2.94793).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 \tTraining Loss: 0.792911 \tValidation Loss: 2.929513\n",
      "Validation loss decreased (2.94793 --> 2.92951).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.712665 \tValidation Loss: 2.926174\n",
      "Validation loss decreased (2.92951 --> 2.92617).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.649385 \tValidation Loss: 2.930305\n",
      "Epoch: 17 \tTraining Loss: 0.595443 \tValidation Loss: 2.938882\n",
      "Epoch: 18 \tTraining Loss: 0.550406 \tValidation Loss: 2.954663\n",
      "Epoch: 19 \tTraining Loss: 0.516114 \tValidation Loss: 2.974927\n",
      "Epoch: 20 \tTraining Loss: 0.483367 \tValidation Loss: 2.999932\n",
      "Epoch: 1 \tTraining Loss: 6.515128 \tValidation Loss: 5.740471\n",
      "Validation loss decreased (inf --> 5.74047).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.855952 \tValidation Loss: 5.451816\n",
      "Validation loss decreased (5.74047 --> 5.45182).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.325132 \tValidation Loss: 5.035399\n",
      "Validation loss decreased (5.45182 --> 5.03540).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.595398 \tValidation Loss: 4.569148\n",
      "Validation loss decreased (5.03540 --> 4.56915).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.792440 \tValidation Loss: 4.145814\n",
      "Validation loss decreased (4.56915 --> 4.14581).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.046559 \tValidation Loss: 3.799652\n",
      "Validation loss decreased (4.14581 --> 3.79965).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.438459 \tValidation Loss: 3.532091\n",
      "Validation loss decreased (3.79965 --> 3.53209).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.971258 \tValidation Loss: 3.334373\n",
      "Validation loss decreased (3.53209 --> 3.33437).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.622964 \tValidation Loss: 3.192171\n",
      "Validation loss decreased (3.33437 --> 3.19217).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.363519 \tValidation Loss: 3.090708\n",
      "Validation loss decreased (3.19217 --> 3.09071).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.160273 \tValidation Loss: 3.019595\n",
      "Validation loss decreased (3.09071 --> 3.01960).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.003919 \tValidation Loss: 2.970182\n",
      "Validation loss decreased (3.01960 --> 2.97018).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.882550 \tValidation Loss: 2.943361\n",
      "Validation loss decreased (2.97018 --> 2.94336).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.787293 \tValidation Loss: 2.928173\n",
      "Validation loss decreased (2.94336 --> 2.92817).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.704522 \tValidation Loss: 2.923054\n",
      "Validation loss decreased (2.92817 --> 2.92305).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.643407 \tValidation Loss: 2.929068\n",
      "Epoch: 17 \tTraining Loss: 0.589333 \tValidation Loss: 2.940755\n",
      "Epoch: 18 \tTraining Loss: 0.546589 \tValidation Loss: 2.958361\n",
      "Epoch: 19 \tTraining Loss: 0.508415 \tValidation Loss: 2.982024\n",
      "Epoch: 20 \tTraining Loss: 0.479009 \tValidation Loss: 3.004760\n",
      "Epoch: 1 \tTraining Loss: 6.498566 \tValidation Loss: 5.757226\n",
      "Validation loss decreased (inf --> 5.75723).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.852217 \tValidation Loss: 5.490276\n",
      "Validation loss decreased (5.75723 --> 5.49028).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.325118 \tValidation Loss: 5.097070\n",
      "Validation loss decreased (5.49028 --> 5.09707).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.596192 \tValidation Loss: 4.651158\n",
      "Validation loss decreased (5.09707 --> 4.65116).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.801584 \tValidation Loss: 4.231968\n",
      "Validation loss decreased (4.65116 --> 4.23197).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.060312 \tValidation Loss: 3.880677\n",
      "Validation loss decreased (4.23197 --> 3.88068).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.449728 \tValidation Loss: 3.612302\n",
      "Validation loss decreased (3.88068 --> 3.61230).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.981216 \tValidation Loss: 3.417336\n",
      "Validation loss decreased (3.61230 --> 3.41734).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.630345 \tValidation Loss: 3.276356\n",
      "Validation loss decreased (3.41734 --> 3.27636).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.366985 \tValidation Loss: 3.178189\n",
      "Validation loss decreased (3.27636 --> 3.17819).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.165651 \tValidation Loss: 3.108801\n",
      "Validation loss decreased (3.17819 --> 3.10880).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.008219 \tValidation Loss: 3.064534\n",
      "Validation loss decreased (3.10880 --> 3.06453).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.884350 \tValidation Loss: 3.037381\n",
      "Validation loss decreased (3.06453 --> 3.03738).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.786556 \tValidation Loss: 3.027392\n",
      "Validation loss decreased (3.03738 --> 3.02739).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.705845 \tValidation Loss: 3.028251\n",
      "Epoch: 16 \tTraining Loss: 0.642392 \tValidation Loss: 3.037841\n",
      "Epoch: 17 \tTraining Loss: 0.588668 \tValidation Loss: 3.051668\n",
      "Epoch: 18 \tTraining Loss: 0.543199 \tValidation Loss: 3.070793\n",
      "Epoch: 19 \tTraining Loss: 0.507432 \tValidation Loss: 3.097098\n",
      "Epoch: 20 \tTraining Loss: 0.477272 \tValidation Loss: 3.122689\n",
      "Epoch: 1 \tTraining Loss: 6.507640 \tValidation Loss: 5.752631\n",
      "Validation loss decreased (inf --> 5.75263).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.851200 \tValidation Loss: 5.475657\n",
      "Validation loss decreased (5.75263 --> 5.47566).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.323921 \tValidation Loss: 5.084084\n",
      "Validation loss decreased (5.47566 --> 5.08408).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.598583 \tValidation Loss: 4.636620\n",
      "Validation loss decreased (5.08408 --> 4.63662).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.803694 \tValidation Loss: 4.217216\n",
      "Validation loss decreased (4.63662 --> 4.21722).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.064800 \tValidation Loss: 3.868301\n",
      "Validation loss decreased (4.21722 --> 3.86830).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.453250 \tValidation Loss: 3.600133\n",
      "Validation loss decreased (3.86830 --> 3.60013).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.986183 \tValidation Loss: 3.400489\n",
      "Validation loss decreased (3.60013 --> 3.40049).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.638443 \tValidation Loss: 3.256576\n",
      "Validation loss decreased (3.40049 --> 3.25658).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.371377 \tValidation Loss: 3.152557\n",
      "Validation loss decreased (3.25658 --> 3.15256).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.166294 \tValidation Loss: 3.079116\n",
      "Validation loss decreased (3.15256 --> 3.07912).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.009495 \tValidation Loss: 3.033506\n",
      "Validation loss decreased (3.07912 --> 3.03351).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.884542 \tValidation Loss: 3.004710\n",
      "Validation loss decreased (3.03351 --> 3.00471).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.786165 \tValidation Loss: 2.993551\n",
      "Validation loss decreased (3.00471 --> 2.99355).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.711142 \tValidation Loss: 2.990367\n",
      "Validation loss decreased (2.99355 --> 2.99037).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.643529 \tValidation Loss: 2.995842\n",
      "Epoch: 17 \tTraining Loss: 0.593025 \tValidation Loss: 3.008374\n",
      "Epoch: 18 \tTraining Loss: 0.547162 \tValidation Loss: 3.024949\n",
      "Epoch: 19 \tTraining Loss: 0.510207 \tValidation Loss: 3.046731\n",
      "Epoch: 20 \tTraining Loss: 0.479823 \tValidation Loss: 3.071889\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 6 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.509034 \tValidation Loss: 5.528165\n",
      "Validation loss decreased (inf --> 5.52817).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.801918 \tValidation Loss: 5.208195\n",
      "Validation loss decreased (5.52817 --> 5.20820).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.192095 \tValidation Loss: 4.747982\n",
      "Validation loss decreased (5.20820 --> 4.74798).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.379638 \tValidation Loss: 4.243073\n",
      "Validation loss decreased (4.74798 --> 4.24307).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.521437 \tValidation Loss: 3.797432\n",
      "Validation loss decreased (4.24307 --> 3.79743).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.760939 \tValidation Loss: 3.443248\n",
      "Validation loss decreased (3.79743 --> 3.44325).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.154989 \tValidation Loss: 3.178631\n",
      "Validation loss decreased (3.44325 --> 3.17863).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.702755 \tValidation Loss: 2.989035\n",
      "Validation loss decreased (3.17863 --> 2.98903).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 \tTraining Loss: 1.370592 \tValidation Loss: 2.853373\n",
      "Validation loss decreased (2.98903 --> 2.85337).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.119505 \tValidation Loss: 2.758869\n",
      "Validation loss decreased (2.85337 --> 2.75887).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.931083 \tValidation Loss: 2.694423\n",
      "Validation loss decreased (2.75887 --> 2.69442).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.784744 \tValidation Loss: 2.652266\n",
      "Validation loss decreased (2.69442 --> 2.65227).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.667612 \tValidation Loss: 2.629756\n",
      "Validation loss decreased (2.65227 --> 2.62976).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.580692 \tValidation Loss: 2.617136\n",
      "Validation loss decreased (2.62976 --> 2.61714).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.509031 \tValidation Loss: 2.615521\n",
      "Validation loss decreased (2.61714 --> 2.61552).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.455527 \tValidation Loss: 2.621366\n",
      "Epoch: 17 \tTraining Loss: 0.411023 \tValidation Loss: 2.633681\n",
      "Epoch: 18 \tTraining Loss: 0.370870 \tValidation Loss: 2.653474\n",
      "Epoch: 19 \tTraining Loss: 0.336950 \tValidation Loss: 2.674202\n",
      "Epoch: 20 \tTraining Loss: 0.315216 \tValidation Loss: 2.693905\n",
      "Epoch: 1 \tTraining Loss: 6.505555 \tValidation Loss: 5.562032\n",
      "Validation loss decreased (inf --> 5.56203).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.795153 \tValidation Loss: 5.254278\n",
      "Validation loss decreased (5.56203 --> 5.25428).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.185314 \tValidation Loss: 4.805490\n",
      "Validation loss decreased (5.25428 --> 4.80549).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.377436 \tValidation Loss: 4.304339\n",
      "Validation loss decreased (4.80549 --> 4.30434).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.526521 \tValidation Loss: 3.853635\n",
      "Validation loss decreased (4.30434 --> 3.85363).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.767065 \tValidation Loss: 3.489015\n",
      "Validation loss decreased (3.85363 --> 3.48902).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.166400 \tValidation Loss: 3.216552\n",
      "Validation loss decreased (3.48902 --> 3.21655).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.715551 \tValidation Loss: 3.021429\n",
      "Validation loss decreased (3.21655 --> 3.02143).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.380422 \tValidation Loss: 2.881532\n",
      "Validation loss decreased (3.02143 --> 2.88153).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.130548 \tValidation Loss: 2.780104\n",
      "Validation loss decreased (2.88153 --> 2.78010).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.939949 \tValidation Loss: 2.711917\n",
      "Validation loss decreased (2.78010 --> 2.71192).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.790803 \tValidation Loss: 2.663795\n",
      "Validation loss decreased (2.71192 --> 2.66379).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.678730 \tValidation Loss: 2.635068\n",
      "Validation loss decreased (2.66379 --> 2.63507).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.585856 \tValidation Loss: 2.620125\n",
      "Validation loss decreased (2.63507 --> 2.62012).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.516987 \tValidation Loss: 2.615057\n",
      "Validation loss decreased (2.62012 --> 2.61506).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.458890 \tValidation Loss: 2.620739\n",
      "Epoch: 17 \tTraining Loss: 0.412693 \tValidation Loss: 2.632450\n",
      "Epoch: 18 \tTraining Loss: 0.376885 \tValidation Loss: 2.645832\n",
      "Epoch: 19 \tTraining Loss: 0.345762 \tValidation Loss: 2.664416\n",
      "Epoch: 20 \tTraining Loss: 0.319495 \tValidation Loss: 2.685773\n",
      "Epoch: 1 \tTraining Loss: 6.515255 \tValidation Loss: 5.542465\n",
      "Validation loss decreased (inf --> 5.54246).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.800795 \tValidation Loss: 5.227778\n",
      "Validation loss decreased (5.54246 --> 5.22778).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.195410 \tValidation Loss: 4.769954\n",
      "Validation loss decreased (5.22778 --> 4.76995).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.379872 \tValidation Loss: 4.272757\n",
      "Validation loss decreased (4.76995 --> 4.27276).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.528291 \tValidation Loss: 3.824745\n",
      "Validation loss decreased (4.27276 --> 3.82475).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.770986 \tValidation Loss: 3.457467\n",
      "Validation loss decreased (3.82475 --> 3.45747).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.167486 \tValidation Loss: 3.180326\n",
      "Validation loss decreased (3.45747 --> 3.18033).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.713917 \tValidation Loss: 2.978426\n",
      "Validation loss decreased (3.18033 --> 2.97843).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.379407 \tValidation Loss: 2.837086\n",
      "Validation loss decreased (2.97843 --> 2.83709).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.128086 \tValidation Loss: 2.737355\n",
      "Validation loss decreased (2.83709 --> 2.73735).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.935277 \tValidation Loss: 2.668323\n",
      "Validation loss decreased (2.73735 --> 2.66832).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.789857 \tValidation Loss: 2.621832\n",
      "Validation loss decreased (2.66832 --> 2.62183).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.675739 \tValidation Loss: 2.594455\n",
      "Validation loss decreased (2.62183 --> 2.59445).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.582753 \tValidation Loss: 2.581923\n",
      "Validation loss decreased (2.59445 --> 2.58192).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.509407 \tValidation Loss: 2.581143\n",
      "Validation loss decreased (2.58192 --> 2.58114).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.455148 \tValidation Loss: 2.583820\n",
      "Epoch: 17 \tTraining Loss: 0.404481 \tValidation Loss: 2.597971\n",
      "Epoch: 18 \tTraining Loss: 0.371146 \tValidation Loss: 2.611437\n",
      "Epoch: 19 \tTraining Loss: 0.342664 \tValidation Loss: 2.629063\n",
      "Epoch: 20 \tTraining Loss: 0.315093 \tValidation Loss: 2.648884\n",
      "Epoch: 1 \tTraining Loss: 6.508306 \tValidation Loss: 5.513393\n",
      "Validation loss decreased (inf --> 5.51339).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.800723 \tValidation Loss: 5.197353\n",
      "Validation loss decreased (5.51339 --> 5.19735).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.193280 \tValidation Loss: 4.746883\n",
      "Validation loss decreased (5.19735 --> 4.74688).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.381777 \tValidation Loss: 4.257754\n",
      "Validation loss decreased (4.74688 --> 4.25775).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.524911 \tValidation Loss: 3.816028\n",
      "Validation loss decreased (4.25775 --> 3.81603).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.761245 \tValidation Loss: 3.460099\n",
      "Validation loss decreased (3.81603 --> 3.46010).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.156236 \tValidation Loss: 3.195584\n",
      "Validation loss decreased (3.46010 --> 3.19558).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.708014 \tValidation Loss: 3.007685\n",
      "Validation loss decreased (3.19558 --> 3.00768).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.372926 \tValidation Loss: 2.873832\n",
      "Validation loss decreased (3.00768 --> 2.87383).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.124827 \tValidation Loss: 2.780039\n",
      "Validation loss decreased (2.87383 --> 2.78004).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.933388 \tValidation Loss: 2.711989\n",
      "Validation loss decreased (2.78004 --> 2.71199).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.787754 \tValidation Loss: 2.668062\n",
      "Validation loss decreased (2.71199 --> 2.66806).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.673643 \tValidation Loss: 2.636418\n",
      "Validation loss decreased (2.66806 --> 2.63642).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.581341 \tValidation Loss: 2.620455\n",
      "Validation loss decreased (2.63642 --> 2.62045).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.511055 \tValidation Loss: 2.618023\n",
      "Validation loss decreased (2.62045 --> 2.61802).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.454674 \tValidation Loss: 2.620616\n",
      "Epoch: 17 \tTraining Loss: 0.408543 \tValidation Loss: 2.629155\n",
      "Epoch: 18 \tTraining Loss: 0.369404 \tValidation Loss: 2.642226\n",
      "Epoch: 19 \tTraining Loss: 0.340881 \tValidation Loss: 2.659927\n",
      "Epoch: 20 \tTraining Loss: 0.314943 \tValidation Loss: 2.680452\n",
      "Epoch: 1 \tTraining Loss: 6.508948 \tValidation Loss: 5.512294\n",
      "Validation loss decreased (inf --> 5.51229).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.801942 \tValidation Loss: 5.194416\n",
      "Validation loss decreased (5.51229 --> 5.19442).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.190936 \tValidation Loss: 4.749920\n",
      "Validation loss decreased (5.19442 --> 4.74992).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 \tTraining Loss: 4.372788 \tValidation Loss: 4.259867\n",
      "Validation loss decreased (4.74992 --> 4.25987).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.515148 \tValidation Loss: 3.825434\n",
      "Validation loss decreased (4.25987 --> 3.82543).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.751199 \tValidation Loss: 3.480658\n",
      "Validation loss decreased (3.82543 --> 3.48066).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.144962 \tValidation Loss: 3.223362\n",
      "Validation loss decreased (3.48066 --> 3.22336).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.695264 \tValidation Loss: 3.041387\n",
      "Validation loss decreased (3.22336 --> 3.04139).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.366876 \tValidation Loss: 2.908786\n",
      "Validation loss decreased (3.04139 --> 2.90879).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.119688 \tValidation Loss: 2.812321\n",
      "Validation loss decreased (2.90879 --> 2.81232).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.927076 \tValidation Loss: 2.746386\n",
      "Validation loss decreased (2.81232 --> 2.74639).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.781257 \tValidation Loss: 2.700078\n",
      "Validation loss decreased (2.74639 --> 2.70008).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.665381 \tValidation Loss: 2.674077\n",
      "Validation loss decreased (2.70008 --> 2.67408).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.576835 \tValidation Loss: 2.662379\n",
      "Validation loss decreased (2.67408 --> 2.66238).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.505091 \tValidation Loss: 2.658100\n",
      "Validation loss decreased (2.66238 --> 2.65810).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.448864 \tValidation Loss: 2.661776\n",
      "Epoch: 17 \tTraining Loss: 0.404325 \tValidation Loss: 2.678226\n",
      "Epoch: 18 \tTraining Loss: 0.365874 \tValidation Loss: 2.691313\n",
      "Epoch: 19 \tTraining Loss: 0.338168 \tValidation Loss: 2.710955\n",
      "Epoch: 20 \tTraining Loss: 0.312038 \tValidation Loss: 2.733439\n",
      "Epoch: 1 \tTraining Loss: 6.509886 \tValidation Loss: 5.517476\n",
      "Validation loss decreased (inf --> 5.51748).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.802015 \tValidation Loss: 5.199658\n",
      "Validation loss decreased (5.51748 --> 5.19966).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.194644 \tValidation Loss: 4.757422\n",
      "Validation loss decreased (5.19966 --> 4.75742).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.377664 \tValidation Loss: 4.283205\n",
      "Validation loss decreased (4.75742 --> 4.28320).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.519469 \tValidation Loss: 3.867330\n",
      "Validation loss decreased (4.28320 --> 3.86733).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.757870 \tValidation Loss: 3.531990\n",
      "Validation loss decreased (3.86733 --> 3.53199).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.158131 \tValidation Loss: 3.276893\n",
      "Validation loss decreased (3.53199 --> 3.27689).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.708292 \tValidation Loss: 3.088678\n",
      "Validation loss decreased (3.27689 --> 3.08868).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.377249 \tValidation Loss: 2.951142\n",
      "Validation loss decreased (3.08868 --> 2.95114).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.125438 \tValidation Loss: 2.854870\n",
      "Validation loss decreased (2.95114 --> 2.85487).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.936573 \tValidation Loss: 2.786263\n",
      "Validation loss decreased (2.85487 --> 2.78626).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.787005 \tValidation Loss: 2.740338\n",
      "Validation loss decreased (2.78626 --> 2.74034).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.675139 \tValidation Loss: 2.713420\n",
      "Validation loss decreased (2.74034 --> 2.71342).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.582961 \tValidation Loss: 2.697401\n",
      "Validation loss decreased (2.71342 --> 2.69740).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.511555 \tValidation Loss: 2.695848\n",
      "Validation loss decreased (2.69740 --> 2.69585).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.454943 \tValidation Loss: 2.703111\n",
      "Epoch: 17 \tTraining Loss: 0.410516 \tValidation Loss: 2.714087\n",
      "Epoch: 18 \tTraining Loss: 0.372060 \tValidation Loss: 2.731189\n",
      "Epoch: 19 \tTraining Loss: 0.342733 \tValidation Loss: 2.750501\n",
      "Epoch: 20 \tTraining Loss: 0.317042 \tValidation Loss: 2.771452\n",
      "Epoch: 1 \tTraining Loss: 6.502773 \tValidation Loss: 5.575125\n",
      "Validation loss decreased (inf --> 5.57512).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.804681 \tValidation Loss: 5.265039\n",
      "Validation loss decreased (5.57512 --> 5.26504).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.194684 \tValidation Loss: 4.813577\n",
      "Validation loss decreased (5.26504 --> 4.81358).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.373787 \tValidation Loss: 4.331404\n",
      "Validation loss decreased (4.81358 --> 4.33140).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.514148 \tValidation Loss: 3.904881\n",
      "Validation loss decreased (4.33140 --> 3.90488).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.752443 \tValidation Loss: 3.557191\n",
      "Validation loss decreased (3.90488 --> 3.55719).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.150154 \tValidation Loss: 3.292210\n",
      "Validation loss decreased (3.55719 --> 3.29221).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.699692 \tValidation Loss: 3.097595\n",
      "Validation loss decreased (3.29221 --> 3.09759).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.366793 \tValidation Loss: 2.958065\n",
      "Validation loss decreased (3.09759 --> 2.95806).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.115918 \tValidation Loss: 2.859707\n",
      "Validation loss decreased (2.95806 --> 2.85971).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.928062 \tValidation Loss: 2.792810\n",
      "Validation loss decreased (2.85971 --> 2.79281).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.781510 \tValidation Loss: 2.747989\n",
      "Validation loss decreased (2.79281 --> 2.74799).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.666868 \tValidation Loss: 2.721386\n",
      "Validation loss decreased (2.74799 --> 2.72139).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.578369 \tValidation Loss: 2.705538\n",
      "Validation loss decreased (2.72139 --> 2.70554).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.506089 \tValidation Loss: 2.707515\n",
      "Epoch: 16 \tTraining Loss: 0.449985 \tValidation Loss: 2.709925\n",
      "Epoch: 17 \tTraining Loss: 0.404751 \tValidation Loss: 2.718736\n",
      "Epoch: 18 \tTraining Loss: 0.368521 \tValidation Loss: 2.737153\n",
      "Epoch: 19 \tTraining Loss: 0.337913 \tValidation Loss: 2.757044\n",
      "Epoch: 20 \tTraining Loss: 0.312994 \tValidation Loss: 2.778248\n",
      "Epoch: 1 \tTraining Loss: 6.509322 \tValidation Loss: 5.503300\n",
      "Validation loss decreased (inf --> 5.50330).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.799352 \tValidation Loss: 5.181508\n",
      "Validation loss decreased (5.50330 --> 5.18151).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.187569 \tValidation Loss: 4.734611\n",
      "Validation loss decreased (5.18151 --> 4.73461).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.371132 \tValidation Loss: 4.254865\n",
      "Validation loss decreased (4.73461 --> 4.25486).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.515351 \tValidation Loss: 3.825998\n",
      "Validation loss decreased (4.25486 --> 3.82600).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.756281 \tValidation Loss: 3.479925\n",
      "Validation loss decreased (3.82600 --> 3.47992).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.158029 \tValidation Loss: 3.220179\n",
      "Validation loss decreased (3.47992 --> 3.22018).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.715245 \tValidation Loss: 3.029519\n",
      "Validation loss decreased (3.22018 --> 3.02952).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.382329 \tValidation Loss: 2.888679\n",
      "Validation loss decreased (3.02952 --> 2.88868).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.130935 \tValidation Loss: 2.786634\n",
      "Validation loss decreased (2.88868 --> 2.78663).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.939872 \tValidation Loss: 2.713244\n",
      "Validation loss decreased (2.78663 --> 2.71324).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.792817 \tValidation Loss: 2.666611\n",
      "Validation loss decreased (2.71324 --> 2.66661).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.677640 \tValidation Loss: 2.635990\n",
      "Validation loss decreased (2.66661 --> 2.63599).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.585899 \tValidation Loss: 2.620640\n",
      "Validation loss decreased (2.63599 --> 2.62064).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.514825 \tValidation Loss: 2.613088\n",
      "Validation loss decreased (2.62064 --> 2.61309).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.454839 \tValidation Loss: 2.617718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 \tTraining Loss: 0.412835 \tValidation Loss: 2.629611\n",
      "Epoch: 18 \tTraining Loss: 0.375248 \tValidation Loss: 2.643390\n",
      "Epoch: 19 \tTraining Loss: 0.343529 \tValidation Loss: 2.663854\n",
      "Epoch: 20 \tTraining Loss: 0.319095 \tValidation Loss: 2.682808\n",
      "Epoch: 1 \tTraining Loss: 6.506066 \tValidation Loss: 5.475199\n",
      "Validation loss decreased (inf --> 5.47520).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.804558 \tValidation Loss: 5.161728\n",
      "Validation loss decreased (5.47520 --> 5.16173).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.198942 \tValidation Loss: 4.725622\n",
      "Validation loss decreased (5.16173 --> 4.72562).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.382887 \tValidation Loss: 4.245787\n",
      "Validation loss decreased (4.72562 --> 4.24579).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.527272 \tValidation Loss: 3.820430\n",
      "Validation loss decreased (4.24579 --> 3.82043).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.770095 \tValidation Loss: 3.475663\n",
      "Validation loss decreased (3.82043 --> 3.47566).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.166937 \tValidation Loss: 3.215062\n",
      "Validation loss decreased (3.47566 --> 3.21506).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.715291 \tValidation Loss: 3.022428\n",
      "Validation loss decreased (3.21506 --> 3.02243).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.379045 \tValidation Loss: 2.883407\n",
      "Validation loss decreased (3.02243 --> 2.88341).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.131315 \tValidation Loss: 2.784482\n",
      "Validation loss decreased (2.88341 --> 2.78448).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.939679 \tValidation Loss: 2.717239\n",
      "Validation loss decreased (2.78448 --> 2.71724).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.790007 \tValidation Loss: 2.672601\n",
      "Validation loss decreased (2.71724 --> 2.67260).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.675821 \tValidation Loss: 2.644692\n",
      "Validation loss decreased (2.67260 --> 2.64469).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.582674 \tValidation Loss: 2.635697\n",
      "Validation loss decreased (2.64469 --> 2.63570).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.509533 \tValidation Loss: 2.632728\n",
      "Validation loss decreased (2.63570 --> 2.63273).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.456466 \tValidation Loss: 2.641129\n",
      "Epoch: 17 \tTraining Loss: 0.409521 \tValidation Loss: 2.655596\n",
      "Epoch: 18 \tTraining Loss: 0.370621 \tValidation Loss: 2.673630\n",
      "Epoch: 19 \tTraining Loss: 0.339419 \tValidation Loss: 2.694000\n",
      "Epoch: 20 \tTraining Loss: 0.316731 \tValidation Loss: 2.716682\n",
      "Epoch: 1 \tTraining Loss: 6.510103 \tValidation Loss: 5.565900\n",
      "Validation loss decreased (inf --> 5.56590).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.799207 \tValidation Loss: 5.256025\n",
      "Validation loss decreased (5.56590 --> 5.25602).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.196373 \tValidation Loss: 4.800236\n",
      "Validation loss decreased (5.25602 --> 4.80024).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.383145 \tValidation Loss: 4.303934\n",
      "Validation loss decreased (4.80024 --> 4.30393).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.527362 \tValidation Loss: 3.854148\n",
      "Validation loss decreased (4.30393 --> 3.85415).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.765882 \tValidation Loss: 3.498451\n",
      "Validation loss decreased (3.85415 --> 3.49845).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.159900 \tValidation Loss: 3.233064\n",
      "Validation loss decreased (3.49845 --> 3.23306).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.711527 \tValidation Loss: 3.045067\n",
      "Validation loss decreased (3.23306 --> 3.04507).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.376991 \tValidation Loss: 2.914595\n",
      "Validation loss decreased (3.04507 --> 2.91460).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.127752 \tValidation Loss: 2.824345\n",
      "Validation loss decreased (2.91460 --> 2.82435).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.939199 \tValidation Loss: 2.760221\n",
      "Validation loss decreased (2.82435 --> 2.76022).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.791890 \tValidation Loss: 2.717191\n",
      "Validation loss decreased (2.76022 --> 2.71719).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.676999 \tValidation Loss: 2.693450\n",
      "Validation loss decreased (2.71719 --> 2.69345).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.586118 \tValidation Loss: 2.679144\n",
      "Validation loss decreased (2.69345 --> 2.67914).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.512681 \tValidation Loss: 2.679680\n",
      "Epoch: 16 \tTraining Loss: 0.456950 \tValidation Loss: 2.683074\n",
      "Epoch: 17 \tTraining Loss: 0.411697 \tValidation Loss: 2.692797\n",
      "Epoch: 18 \tTraining Loss: 0.375705 \tValidation Loss: 2.710536\n",
      "Epoch: 19 \tTraining Loss: 0.342914 \tValidation Loss: 2.729223\n",
      "Epoch: 20 \tTraining Loss: 0.318915 \tValidation Loss: 2.751159\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 7 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.519894 \tValidation Loss: 5.415140\n",
      "Validation loss decreased (inf --> 5.41514).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.779254 \tValidation Loss: 5.083915\n",
      "Validation loss decreased (5.41514 --> 5.08391).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.141804 \tValidation Loss: 4.614553\n",
      "Validation loss decreased (5.08391 --> 4.61455).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.289635 \tValidation Loss: 4.108378\n",
      "Validation loss decreased (4.61455 --> 4.10838).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.401186 \tValidation Loss: 3.656207\n",
      "Validation loss decreased (4.10838 --> 3.65621).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.625142 \tValidation Loss: 3.287565\n",
      "Validation loss decreased (3.65621 --> 3.28756).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.023544 \tValidation Loss: 3.008172\n",
      "Validation loss decreased (3.28756 --> 3.00817).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.580711 \tValidation Loss: 2.803147\n",
      "Validation loss decreased (3.00817 --> 2.80315).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.253941 \tValidation Loss: 2.654690\n",
      "Validation loss decreased (2.80315 --> 2.65469).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.003437 \tValidation Loss: 2.545438\n",
      "Validation loss decreased (2.65469 --> 2.54544).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.815223 \tValidation Loss: 2.466766\n",
      "Validation loss decreased (2.54544 --> 2.46677).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.669808 \tValidation Loss: 2.411047\n",
      "Validation loss decreased (2.46677 --> 2.41105).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.557565 \tValidation Loss: 2.377256\n",
      "Validation loss decreased (2.41105 --> 2.37726).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.468951 \tValidation Loss: 2.357196\n",
      "Validation loss decreased (2.37726 --> 2.35720).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.403962 \tValidation Loss: 2.347846\n",
      "Validation loss decreased (2.35720 --> 2.34785).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.353470 \tValidation Loss: 2.346605\n",
      "Validation loss decreased (2.34785 --> 2.34661).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.310981 \tValidation Loss: 2.349796\n",
      "Epoch: 18 \tTraining Loss: 0.279090 \tValidation Loss: 2.358772\n",
      "Epoch: 19 \tTraining Loss: 0.251792 \tValidation Loss: 2.369836\n",
      "Epoch: 20 \tTraining Loss: 0.229127 \tValidation Loss: 2.381468\n",
      "Epoch: 1 \tTraining Loss: 6.514117 \tValidation Loss: 5.436355\n",
      "Validation loss decreased (inf --> 5.43636).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.773381 \tValidation Loss: 5.102178\n",
      "Validation loss decreased (5.43636 --> 5.10218).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.141799 \tValidation Loss: 4.630509\n",
      "Validation loss decreased (5.10218 --> 4.63051).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.293009 \tValidation Loss: 4.121552\n",
      "Validation loss decreased (4.63051 --> 4.12155).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.408295 \tValidation Loss: 3.673944\n",
      "Validation loss decreased (4.12155 --> 3.67394).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.623200 \tValidation Loss: 3.317424\n",
      "Validation loss decreased (3.67394 --> 3.31742).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.019671 \tValidation Loss: 3.051917\n",
      "Validation loss decreased (3.31742 --> 3.05192).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.575313 \tValidation Loss: 2.861216\n",
      "Validation loss decreased (3.05192 --> 2.86122).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.244740 \tValidation Loss: 2.724106\n",
      "Validation loss decreased (2.86122 --> 2.72411).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.997105 \tValidation Loss: 2.627600\n",
      "Validation loss decreased (2.72411 --> 2.62760).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 \tTraining Loss: 0.811586 \tValidation Loss: 2.561643\n",
      "Validation loss decreased (2.62760 --> 2.56164).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.667382 \tValidation Loss: 2.513071\n",
      "Validation loss decreased (2.56164 --> 2.51307).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.555653 \tValidation Loss: 2.482648\n",
      "Validation loss decreased (2.51307 --> 2.48265).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.468450 \tValidation Loss: 2.470631\n",
      "Validation loss decreased (2.48265 --> 2.47063).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.399949 \tValidation Loss: 2.467933\n",
      "Validation loss decreased (2.47063 --> 2.46793).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.351209 \tValidation Loss: 2.470615\n",
      "Epoch: 17 \tTraining Loss: 0.308476 \tValidation Loss: 2.481799\n",
      "Epoch: 18 \tTraining Loss: 0.274823 \tValidation Loss: 2.494687\n",
      "Epoch: 19 \tTraining Loss: 0.248562 \tValidation Loss: 2.508074\n",
      "Epoch: 20 \tTraining Loss: 0.227499 \tValidation Loss: 2.523810\n",
      "Epoch: 1 \tTraining Loss: 6.508945 \tValidation Loss: 5.433878\n",
      "Validation loss decreased (inf --> 5.43388).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.773318 \tValidation Loss: 5.109132\n",
      "Validation loss decreased (5.43388 --> 5.10913).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.139381 \tValidation Loss: 4.638991\n",
      "Validation loss decreased (5.10913 --> 4.63899).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.296822 \tValidation Loss: 4.133502\n",
      "Validation loss decreased (4.63899 --> 4.13350).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.421773 \tValidation Loss: 3.678417\n",
      "Validation loss decreased (4.13350 --> 3.67842).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.650168 \tValidation Loss: 3.306536\n",
      "Validation loss decreased (3.67842 --> 3.30654).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.041561 \tValidation Loss: 3.024255\n",
      "Validation loss decreased (3.30654 --> 3.02426).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.588587 \tValidation Loss: 2.815527\n",
      "Validation loss decreased (3.02426 --> 2.81553).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.255763 \tValidation Loss: 2.665776\n",
      "Validation loss decreased (2.81553 --> 2.66578).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.008256 \tValidation Loss: 2.558177\n",
      "Validation loss decreased (2.66578 --> 2.55818).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.818252 \tValidation Loss: 2.484195\n",
      "Validation loss decreased (2.55818 --> 2.48420).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.673102 \tValidation Loss: 2.434232\n",
      "Validation loss decreased (2.48420 --> 2.43423).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.559468 \tValidation Loss: 2.401066\n",
      "Validation loss decreased (2.43423 --> 2.40107).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.472205 \tValidation Loss: 2.384038\n",
      "Validation loss decreased (2.40107 --> 2.38404).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.404905 \tValidation Loss: 2.381322\n",
      "Validation loss decreased (2.38404 --> 2.38132).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.349179 \tValidation Loss: 2.384237\n",
      "Epoch: 17 \tTraining Loss: 0.311227 \tValidation Loss: 2.390894\n",
      "Epoch: 18 \tTraining Loss: 0.280241 \tValidation Loss: 2.402996\n",
      "Epoch: 19 \tTraining Loss: 0.251447 \tValidation Loss: 2.416958\n",
      "Epoch: 20 \tTraining Loss: 0.230297 \tValidation Loss: 2.432222\n",
      "Epoch: 1 \tTraining Loss: 6.511149 \tValidation Loss: 5.420534\n",
      "Validation loss decreased (inf --> 5.42053).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.775190 \tValidation Loss: 5.084858\n",
      "Validation loss decreased (5.42053 --> 5.08486).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.137284 \tValidation Loss: 4.604775\n",
      "Validation loss decreased (5.08486 --> 4.60477).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.291017 \tValidation Loss: 4.095435\n",
      "Validation loss decreased (4.60477 --> 4.09543).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.406042 \tValidation Loss: 3.650921\n",
      "Validation loss decreased (4.09543 --> 3.65092).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.625828 \tValidation Loss: 3.301357\n",
      "Validation loss decreased (3.65092 --> 3.30136).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.022274 \tValidation Loss: 3.043568\n",
      "Validation loss decreased (3.30136 --> 3.04357).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.577832 \tValidation Loss: 2.858781\n",
      "Validation loss decreased (3.04357 --> 2.85878).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.249316 \tValidation Loss: 2.725518\n",
      "Validation loss decreased (2.85878 --> 2.72552).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.004718 \tValidation Loss: 2.632041\n",
      "Validation loss decreased (2.72552 --> 2.63204).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.815114 \tValidation Loss: 2.563878\n",
      "Validation loss decreased (2.63204 --> 2.56388).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.671551 \tValidation Loss: 2.517357\n",
      "Validation loss decreased (2.56388 --> 2.51736).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.558924 \tValidation Loss: 2.490525\n",
      "Validation loss decreased (2.51736 --> 2.49053).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.471162 \tValidation Loss: 2.476772\n",
      "Validation loss decreased (2.49053 --> 2.47677).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.403605 \tValidation Loss: 2.474917\n",
      "Validation loss decreased (2.47677 --> 2.47492).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.352037 \tValidation Loss: 2.480550\n",
      "Epoch: 17 \tTraining Loss: 0.310748 \tValidation Loss: 2.490900\n",
      "Epoch: 18 \tTraining Loss: 0.277001 \tValidation Loss: 2.507569\n",
      "Epoch: 19 \tTraining Loss: 0.252096 \tValidation Loss: 2.520417\n",
      "Epoch: 20 \tTraining Loss: 0.228887 \tValidation Loss: 2.537421\n",
      "Epoch: 1 \tTraining Loss: 6.506287 \tValidation Loss: 5.470267\n",
      "Validation loss decreased (inf --> 5.47027).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.761958 \tValidation Loss: 5.140908\n",
      "Validation loss decreased (5.47027 --> 5.14091).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.123975 \tValidation Loss: 4.680562\n",
      "Validation loss decreased (5.14091 --> 4.68056).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.285813 \tValidation Loss: 4.182929\n",
      "Validation loss decreased (4.68056 --> 4.18293).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.411511 \tValidation Loss: 3.741142\n",
      "Validation loss decreased (4.18293 --> 3.74114).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.637468 \tValidation Loss: 3.381721\n",
      "Validation loss decreased (3.74114 --> 3.38172).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.030838 \tValidation Loss: 3.110005\n",
      "Validation loss decreased (3.38172 --> 3.11001).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.582989 \tValidation Loss: 2.910789\n",
      "Validation loss decreased (3.11001 --> 2.91079).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.253298 \tValidation Loss: 2.767433\n",
      "Validation loss decreased (2.91079 --> 2.76743).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.002453 \tValidation Loss: 2.661595\n",
      "Validation loss decreased (2.76743 --> 2.66159).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.811857 \tValidation Loss: 2.589942\n",
      "Validation loss decreased (2.66159 --> 2.58994).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.668312 \tValidation Loss: 2.542143\n",
      "Validation loss decreased (2.58994 --> 2.54214).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.556110 \tValidation Loss: 2.512540\n",
      "Validation loss decreased (2.54214 --> 2.51254).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.467526 \tValidation Loss: 2.500085\n",
      "Validation loss decreased (2.51254 --> 2.50008).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.400624 \tValidation Loss: 2.498902\n",
      "Validation loss decreased (2.50008 --> 2.49890).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.347441 \tValidation Loss: 2.501444\n",
      "Epoch: 17 \tTraining Loss: 0.308067 \tValidation Loss: 2.512893\n",
      "Epoch: 18 \tTraining Loss: 0.273158 \tValidation Loss: 2.527900\n",
      "Epoch: 19 \tTraining Loss: 0.247214 \tValidation Loss: 2.544372\n",
      "Epoch: 20 \tTraining Loss: 0.224779 \tValidation Loss: 2.563412\n",
      "Epoch: 1 \tTraining Loss: 6.519345 \tValidation Loss: 5.485799\n",
      "Validation loss decreased (inf --> 5.48580).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.767881 \tValidation Loss: 5.157887\n",
      "Validation loss decreased (5.48580 --> 5.15789).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.129533 \tValidation Loss: 4.684885\n",
      "Validation loss decreased (5.15789 --> 4.68489).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.284069 \tValidation Loss: 4.174925\n",
      "Validation loss decreased (4.68489 --> 4.17492).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.406716 \tValidation Loss: 3.720425\n",
      "Validation loss decreased (4.17492 --> 3.72042).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 \tTraining Loss: 2.631936 \tValidation Loss: 3.357261\n",
      "Validation loss decreased (3.72042 --> 3.35726).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.027875 \tValidation Loss: 3.089812\n",
      "Validation loss decreased (3.35726 --> 3.08981).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.581246 \tValidation Loss: 2.897419\n",
      "Validation loss decreased (3.08981 --> 2.89742).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.250503 \tValidation Loss: 2.758370\n",
      "Validation loss decreased (2.89742 --> 2.75837).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.003826 \tValidation Loss: 2.657016\n",
      "Validation loss decreased (2.75837 --> 2.65702).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.816738 \tValidation Loss: 2.586763\n",
      "Validation loss decreased (2.65702 --> 2.58676).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.672192 \tValidation Loss: 2.541777\n",
      "Validation loss decreased (2.58676 --> 2.54178).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.558163 \tValidation Loss: 2.515272\n",
      "Validation loss decreased (2.54178 --> 2.51527).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.472561 \tValidation Loss: 2.502008\n",
      "Validation loss decreased (2.51527 --> 2.50201).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.406644 \tValidation Loss: 2.499649\n",
      "Validation loss decreased (2.50201 --> 2.49965).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.352456 \tValidation Loss: 2.504216\n",
      "Epoch: 17 \tTraining Loss: 0.310005 \tValidation Loss: 2.513586\n",
      "Epoch: 18 \tTraining Loss: 0.277049 \tValidation Loss: 2.528699\n",
      "Epoch: 19 \tTraining Loss: 0.252190 \tValidation Loss: 2.546238\n",
      "Epoch: 20 \tTraining Loss: 0.228186 \tValidation Loss: 2.561229\n",
      "Epoch: 1 \tTraining Loss: 6.507119 \tValidation Loss: 5.460590\n",
      "Validation loss decreased (inf --> 5.46059).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.763257 \tValidation Loss: 5.134830\n",
      "Validation loss decreased (5.46059 --> 5.13483).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.124670 \tValidation Loss: 4.673419\n",
      "Validation loss decreased (5.13483 --> 4.67342).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.277877 \tValidation Loss: 4.176613\n",
      "Validation loss decreased (4.67342 --> 4.17661).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.399555 \tValidation Loss: 3.733086\n",
      "Validation loss decreased (4.17661 --> 3.73309).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.625622 \tValidation Loss: 3.377459\n",
      "Validation loss decreased (3.73309 --> 3.37746).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.023632 \tValidation Loss: 3.109889\n",
      "Validation loss decreased (3.37746 --> 3.10989).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.582016 \tValidation Loss: 2.908493\n",
      "Validation loss decreased (3.10989 --> 2.90849).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.254489 \tValidation Loss: 2.761893\n",
      "Validation loss decreased (2.90849 --> 2.76189).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.005970 \tValidation Loss: 2.654049\n",
      "Validation loss decreased (2.76189 --> 2.65405).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.816866 \tValidation Loss: 2.577500\n",
      "Validation loss decreased (2.65405 --> 2.57750).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.672240 \tValidation Loss: 2.527977\n",
      "Validation loss decreased (2.57750 --> 2.52798).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.557732 \tValidation Loss: 2.492482\n",
      "Validation loss decreased (2.52798 --> 2.49248).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.472654 \tValidation Loss: 2.475763\n",
      "Validation loss decreased (2.49248 --> 2.47576).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.405278 \tValidation Loss: 2.468239\n",
      "Validation loss decreased (2.47576 --> 2.46824).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.352902 \tValidation Loss: 2.468410\n",
      "Epoch: 17 \tTraining Loss: 0.310053 \tValidation Loss: 2.474537\n",
      "Epoch: 18 \tTraining Loss: 0.276981 \tValidation Loss: 2.486219\n",
      "Epoch: 19 \tTraining Loss: 0.249197 \tValidation Loss: 2.495552\n",
      "Epoch: 20 \tTraining Loss: 0.229778 \tValidation Loss: 2.508281\n",
      "Epoch: 1 \tTraining Loss: 6.504524 \tValidation Loss: 5.476830\n",
      "Validation loss decreased (inf --> 5.47683).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.778476 \tValidation Loss: 5.150221\n",
      "Validation loss decreased (5.47683 --> 5.15022).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.150028 \tValidation Loss: 4.683570\n",
      "Validation loss decreased (5.15022 --> 4.68357).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.302408 \tValidation Loss: 4.181760\n",
      "Validation loss decreased (4.68357 --> 4.18176).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.413219 \tValidation Loss: 3.737521\n",
      "Validation loss decreased (4.18176 --> 3.73752).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.632623 \tValidation Loss: 3.378697\n",
      "Validation loss decreased (3.73752 --> 3.37870).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.025548 \tValidation Loss: 3.106294\n",
      "Validation loss decreased (3.37870 --> 3.10629).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.575032 \tValidation Loss: 2.905652\n",
      "Validation loss decreased (3.10629 --> 2.90565).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.245246 \tValidation Loss: 2.757797\n",
      "Validation loss decreased (2.90565 --> 2.75780).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.996192 \tValidation Loss: 2.651436\n",
      "Validation loss decreased (2.75780 --> 2.65144).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.807410 \tValidation Loss: 2.573590\n",
      "Validation loss decreased (2.65144 --> 2.57359).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.664033 \tValidation Loss: 2.520917\n",
      "Validation loss decreased (2.57359 --> 2.52092).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.554019 \tValidation Loss: 2.483683\n",
      "Validation loss decreased (2.52092 --> 2.48368).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.466171 \tValidation Loss: 2.465427\n",
      "Validation loss decreased (2.48368 --> 2.46543).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.400021 \tValidation Loss: 2.458984\n",
      "Validation loss decreased (2.46543 --> 2.45898).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.345667 \tValidation Loss: 2.460053\n",
      "Epoch: 17 \tTraining Loss: 0.308064 \tValidation Loss: 2.464203\n",
      "Epoch: 18 \tTraining Loss: 0.276343 \tValidation Loss: 2.474777\n",
      "Epoch: 19 \tTraining Loss: 0.249800 \tValidation Loss: 2.490500\n",
      "Epoch: 20 \tTraining Loss: 0.227285 \tValidation Loss: 2.502687\n",
      "Epoch: 1 \tTraining Loss: 6.517120 \tValidation Loss: 5.433942\n",
      "Validation loss decreased (inf --> 5.43394).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.766626 \tValidation Loss: 5.091331\n",
      "Validation loss decreased (5.43394 --> 5.09133).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.125994 \tValidation Loss: 4.607984\n",
      "Validation loss decreased (5.09133 --> 4.60798).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.279585 \tValidation Loss: 4.094440\n",
      "Validation loss decreased (4.60798 --> 4.09444).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.399454 \tValidation Loss: 3.643333\n",
      "Validation loss decreased (4.09444 --> 3.64333).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.623829 \tValidation Loss: 3.283553\n",
      "Validation loss decreased (3.64333 --> 3.28355).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.014015 \tValidation Loss: 3.016044\n",
      "Validation loss decreased (3.28355 --> 3.01604).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.572965 \tValidation Loss: 2.821541\n",
      "Validation loss decreased (3.01604 --> 2.82154).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.241770 \tValidation Loss: 2.682087\n",
      "Validation loss decreased (2.82154 --> 2.68209).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.996566 \tValidation Loss: 2.582933\n",
      "Validation loss decreased (2.68209 --> 2.58293).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.809805 \tValidation Loss: 2.514235\n",
      "Validation loss decreased (2.58293 --> 2.51423).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.666633 \tValidation Loss: 2.469419\n",
      "Validation loss decreased (2.51423 --> 2.46942).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.553139 \tValidation Loss: 2.439242\n",
      "Validation loss decreased (2.46942 --> 2.43924).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.466584 \tValidation Loss: 2.425349\n",
      "Validation loss decreased (2.43924 --> 2.42535).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.399882 \tValidation Loss: 2.418110\n",
      "Validation loss decreased (2.42535 --> 2.41811).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.350033 \tValidation Loss: 2.421921\n",
      "Epoch: 17 \tTraining Loss: 0.307431 \tValidation Loss: 2.428242\n",
      "Epoch: 18 \tTraining Loss: 0.273974 \tValidation Loss: 2.443460\n",
      "Epoch: 19 \tTraining Loss: 0.247954 \tValidation Loss: 2.455945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 \tTraining Loss: 0.226722 \tValidation Loss: 2.471178\n",
      "Epoch: 1 \tTraining Loss: 6.511484 \tValidation Loss: 5.425161\n",
      "Validation loss decreased (inf --> 5.42516).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.773912 \tValidation Loss: 5.097219\n",
      "Validation loss decreased (5.42516 --> 5.09722).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.142662 \tValidation Loss: 4.631896\n",
      "Validation loss decreased (5.09722 --> 4.63190).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.300038 \tValidation Loss: 4.124652\n",
      "Validation loss decreased (4.63190 --> 4.12465).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.413617 \tValidation Loss: 3.669662\n",
      "Validation loss decreased (4.12465 --> 3.66966).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.634243 \tValidation Loss: 3.307758\n",
      "Validation loss decreased (3.66966 --> 3.30776).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.030540 \tValidation Loss: 3.038573\n",
      "Validation loss decreased (3.30776 --> 3.03857).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.584622 \tValidation Loss: 2.840369\n",
      "Validation loss decreased (3.03857 --> 2.84037).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.256004 \tValidation Loss: 2.696892\n",
      "Validation loss decreased (2.84037 --> 2.69689).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.008452 \tValidation Loss: 2.593846\n",
      "Validation loss decreased (2.69689 --> 2.59385).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.817347 \tValidation Loss: 2.522062\n",
      "Validation loss decreased (2.59385 --> 2.52206).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.672271 \tValidation Loss: 2.469200\n",
      "Validation loss decreased (2.52206 --> 2.46920).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.559994 \tValidation Loss: 2.437815\n",
      "Validation loss decreased (2.46920 --> 2.43781).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.471856 \tValidation Loss: 2.415781\n",
      "Validation loss decreased (2.43781 --> 2.41578).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.403389 \tValidation Loss: 2.410242\n",
      "Validation loss decreased (2.41578 --> 2.41024).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.353956 \tValidation Loss: 2.407689\n",
      "Validation loss decreased (2.41024 --> 2.40769).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.310667 \tValidation Loss: 2.412788\n",
      "Epoch: 18 \tTraining Loss: 0.276635 \tValidation Loss: 2.421683\n",
      "Epoch: 19 \tTraining Loss: 0.250722 \tValidation Loss: 2.436496\n",
      "Epoch: 20 \tTraining Loss: 0.229166 \tValidation Loss: 2.449469\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 8 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.589220 \tValidation Loss: 5.411817\n",
      "Validation loss decreased (inf --> 5.41182).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.823156 \tValidation Loss: 5.087512\n",
      "Validation loss decreased (5.41182 --> 5.08751).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.194214 \tValidation Loss: 4.629033\n",
      "Validation loss decreased (5.08751 --> 4.62903).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.343994 \tValidation Loss: 4.120021\n",
      "Validation loss decreased (4.62903 --> 4.12002).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.446184 \tValidation Loss: 3.658899\n",
      "Validation loss decreased (4.12002 --> 3.65890).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.651723 \tValidation Loss: 3.289138\n",
      "Validation loss decreased (3.65890 --> 3.28914).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.035808 \tValidation Loss: 3.013441\n",
      "Validation loss decreased (3.28914 --> 3.01344).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.576899 \tValidation Loss: 2.814168\n",
      "Validation loss decreased (3.01344 --> 2.81417).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.238243 \tValidation Loss: 2.669375\n",
      "Validation loss decreased (2.81417 --> 2.66938).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.978213 \tValidation Loss: 2.565864\n",
      "Validation loss decreased (2.66938 --> 2.56586).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.782720 \tValidation Loss: 2.491342\n",
      "Validation loss decreased (2.56586 --> 2.49134).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.633276 \tValidation Loss: 2.443601\n",
      "Validation loss decreased (2.49134 --> 2.44360).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.517209 \tValidation Loss: 2.412881\n",
      "Validation loss decreased (2.44360 --> 2.41288).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.425258 \tValidation Loss: 2.394235\n",
      "Validation loss decreased (2.41288 --> 2.39423).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.358700 \tValidation Loss: 2.385256\n",
      "Validation loss decreased (2.39423 --> 2.38526).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.304519 \tValidation Loss: 2.387070\n",
      "Epoch: 17 \tTraining Loss: 0.267225 \tValidation Loss: 2.393871\n",
      "Epoch: 18 \tTraining Loss: 0.233059 \tValidation Loss: 2.401336\n",
      "Epoch: 19 \tTraining Loss: 0.210618 \tValidation Loss: 2.413294\n",
      "Epoch: 20 \tTraining Loss: 0.191501 \tValidation Loss: 2.427311\n",
      "Epoch: 1 \tTraining Loss: 6.592412 \tValidation Loss: 5.448391\n",
      "Validation loss decreased (inf --> 5.44839).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.816960 \tValidation Loss: 5.121851\n",
      "Validation loss decreased (5.44839 --> 5.12185).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.181912 \tValidation Loss: 4.645766\n",
      "Validation loss decreased (5.12185 --> 4.64577).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.325350 \tValidation Loss: 4.126795\n",
      "Validation loss decreased (4.64577 --> 4.12679).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.424956 \tValidation Loss: 3.666617\n",
      "Validation loss decreased (4.12679 --> 3.66662).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.632599 \tValidation Loss: 3.301694\n",
      "Validation loss decreased (3.66662 --> 3.30169).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.022166 \tValidation Loss: 3.030426\n",
      "Validation loss decreased (3.30169 --> 3.03043).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.567449 \tValidation Loss: 2.828098\n",
      "Validation loss decreased (3.03043 --> 2.82810).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.226885 \tValidation Loss: 2.680226\n",
      "Validation loss decreased (2.82810 --> 2.68023).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.970710 \tValidation Loss: 2.574760\n",
      "Validation loss decreased (2.68023 --> 2.57476).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.773294 \tValidation Loss: 2.500785\n",
      "Validation loss decreased (2.57476 --> 2.50079).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.620867 \tValidation Loss: 2.453587\n",
      "Validation loss decreased (2.50079 --> 2.45359).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.507056 \tValidation Loss: 2.423869\n",
      "Validation loss decreased (2.45359 --> 2.42387).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.417297 \tValidation Loss: 2.409111\n",
      "Validation loss decreased (2.42387 --> 2.40911).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.351938 \tValidation Loss: 2.404844\n",
      "Validation loss decreased (2.40911 --> 2.40484).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.302285 \tValidation Loss: 2.407910\n",
      "Epoch: 17 \tTraining Loss: 0.261755 \tValidation Loss: 2.413652\n",
      "Epoch: 18 \tTraining Loss: 0.230451 \tValidation Loss: 2.426492\n",
      "Epoch: 19 \tTraining Loss: 0.206115 \tValidation Loss: 2.438055\n",
      "Epoch: 20 \tTraining Loss: 0.188283 \tValidation Loss: 2.451655\n",
      "Epoch: 1 \tTraining Loss: 6.600584 \tValidation Loss: 5.409587\n",
      "Validation loss decreased (inf --> 5.40959).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.818388 \tValidation Loss: 5.086940\n",
      "Validation loss decreased (5.40959 --> 5.08694).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.178944 \tValidation Loss: 4.632948\n",
      "Validation loss decreased (5.08694 --> 4.63295).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.325111 \tValidation Loss: 4.133618\n",
      "Validation loss decreased (4.63295 --> 4.13362).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.432944 \tValidation Loss: 3.678327\n",
      "Validation loss decreased (4.13362 --> 3.67833).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.648142 \tValidation Loss: 3.313550\n",
      "Validation loss decreased (3.67833 --> 3.31355).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.033430 \tValidation Loss: 3.044831\n",
      "Validation loss decreased (3.31355 --> 3.04483).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.577956 \tValidation Loss: 2.849745\n",
      "Validation loss decreased (3.04483 --> 2.84974).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.235277 \tValidation Loss: 2.708861\n",
      "Validation loss decreased (2.84974 --> 2.70886).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.976205 \tValidation Loss: 2.607782\n",
      "Validation loss decreased (2.70886 --> 2.60778).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.780062 \tValidation Loss: 2.540140\n",
      "Validation loss decreased (2.60778 --> 2.54014).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 \tTraining Loss: 0.631955 \tValidation Loss: 2.496216\n",
      "Validation loss decreased (2.54014 --> 2.49622).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.514932 \tValidation Loss: 2.467693\n",
      "Validation loss decreased (2.49622 --> 2.46769).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.427954 \tValidation Loss: 2.453537\n",
      "Validation loss decreased (2.46769 --> 2.45354).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.359690 \tValidation Loss: 2.452955\n",
      "Validation loss decreased (2.45354 --> 2.45295).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.309330 \tValidation Loss: 2.455353\n",
      "Epoch: 17 \tTraining Loss: 0.266157 \tValidation Loss: 2.462115\n",
      "Epoch: 18 \tTraining Loss: 0.237241 \tValidation Loss: 2.474634\n",
      "Epoch: 19 \tTraining Loss: 0.210581 \tValidation Loss: 2.488472\n",
      "Epoch: 20 \tTraining Loss: 0.192263 \tValidation Loss: 2.502761\n",
      "Epoch: 1 \tTraining Loss: 6.605650 \tValidation Loss: 5.448924\n",
      "Validation loss decreased (inf --> 5.44892).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.820345 \tValidation Loss: 5.123337\n",
      "Validation loss decreased (5.44892 --> 5.12334).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.185337 \tValidation Loss: 4.666164\n",
      "Validation loss decreased (5.12334 --> 4.66616).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.328432 \tValidation Loss: 4.168480\n",
      "Validation loss decreased (4.66616 --> 4.16848).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.429221 \tValidation Loss: 3.730209\n",
      "Validation loss decreased (4.16848 --> 3.73021).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.642687 \tValidation Loss: 3.384912\n",
      "Validation loss decreased (3.73021 --> 3.38491).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.027359 \tValidation Loss: 3.127767\n",
      "Validation loss decreased (3.38491 --> 3.12777).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.572922 \tValidation Loss: 2.938017\n",
      "Validation loss decreased (3.12777 --> 2.93802).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.233460 \tValidation Loss: 2.798258\n",
      "Validation loss decreased (2.93802 --> 2.79826).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.978323 \tValidation Loss: 2.695759\n",
      "Validation loss decreased (2.79826 --> 2.69576).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.779288 \tValidation Loss: 2.621914\n",
      "Validation loss decreased (2.69576 --> 2.62191).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.631902 \tValidation Loss: 2.571621\n",
      "Validation loss decreased (2.62191 --> 2.57162).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.514915 \tValidation Loss: 2.539686\n",
      "Validation loss decreased (2.57162 --> 2.53969).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.425334 \tValidation Loss: 2.519757\n",
      "Validation loss decreased (2.53969 --> 2.51976).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.358465 \tValidation Loss: 2.513013\n",
      "Validation loss decreased (2.51976 --> 2.51301).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.308186 \tValidation Loss: 2.513594\n",
      "Epoch: 17 \tTraining Loss: 0.264833 \tValidation Loss: 2.520472\n",
      "Epoch: 18 \tTraining Loss: 0.231758 \tValidation Loss: 2.529108\n",
      "Epoch: 19 \tTraining Loss: 0.209585 \tValidation Loss: 2.543096\n",
      "Epoch: 20 \tTraining Loss: 0.189749 \tValidation Loss: 2.555855\n",
      "Epoch: 1 \tTraining Loss: 6.592718 \tValidation Loss: 5.408639\n",
      "Validation loss decreased (inf --> 5.40864).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.824828 \tValidation Loss: 5.086912\n",
      "Validation loss decreased (5.40864 --> 5.08691).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.192615 \tValidation Loss: 4.635011\n",
      "Validation loss decreased (5.08691 --> 4.63501).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.343480 \tValidation Loss: 4.145058\n",
      "Validation loss decreased (4.63501 --> 4.14506).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.443211 \tValidation Loss: 3.705760\n",
      "Validation loss decreased (4.14506 --> 3.70576).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.654309 \tValidation Loss: 3.357870\n",
      "Validation loss decreased (3.70576 --> 3.35787).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.037752 \tValidation Loss: 3.098009\n",
      "Validation loss decreased (3.35787 --> 3.09801).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.580944 \tValidation Loss: 2.908391\n",
      "Validation loss decreased (3.09801 --> 2.90839).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.243006 \tValidation Loss: 2.769297\n",
      "Validation loss decreased (2.90839 --> 2.76930).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.983668 \tValidation Loss: 2.665535\n",
      "Validation loss decreased (2.76930 --> 2.66553).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.783737 \tValidation Loss: 2.594510\n",
      "Validation loss decreased (2.66553 --> 2.59451).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.633019 \tValidation Loss: 2.544517\n",
      "Validation loss decreased (2.59451 --> 2.54452).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.516355 \tValidation Loss: 2.510985\n",
      "Validation loss decreased (2.54452 --> 2.51098).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.428339 \tValidation Loss: 2.493086\n",
      "Validation loss decreased (2.51098 --> 2.49309).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.359166 \tValidation Loss: 2.484371\n",
      "Validation loss decreased (2.49309 --> 2.48437).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.306916 \tValidation Loss: 2.485364\n",
      "Epoch: 17 \tTraining Loss: 0.265298 \tValidation Loss: 2.492110\n",
      "Epoch: 18 \tTraining Loss: 0.234464 \tValidation Loss: 2.502332\n",
      "Epoch: 19 \tTraining Loss: 0.209043 \tValidation Loss: 2.515007\n",
      "Epoch: 20 \tTraining Loss: 0.187897 \tValidation Loss: 2.531159\n",
      "Epoch: 1 \tTraining Loss: 6.596222 \tValidation Loss: 5.438966\n",
      "Validation loss decreased (inf --> 5.43897).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.830819 \tValidation Loss: 5.115159\n",
      "Validation loss decreased (5.43897 --> 5.11516).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.199144 \tValidation Loss: 4.654261\n",
      "Validation loss decreased (5.11516 --> 4.65426).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.351216 \tValidation Loss: 4.148532\n",
      "Validation loss decreased (4.65426 --> 4.14853).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.455819 \tValidation Loss: 3.694695\n",
      "Validation loss decreased (4.14853 --> 3.69469).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.665653 \tValidation Loss: 3.332558\n",
      "Validation loss decreased (3.69469 --> 3.33256).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.048083 \tValidation Loss: 3.067551\n",
      "Validation loss decreased (3.33256 --> 3.06755).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.589151 \tValidation Loss: 2.874335\n",
      "Validation loss decreased (3.06755 --> 2.87433).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.246441 \tValidation Loss: 2.733506\n",
      "Validation loss decreased (2.87433 --> 2.73351).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.985093 \tValidation Loss: 2.632212\n",
      "Validation loss decreased (2.73351 --> 2.63221).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.787673 \tValidation Loss: 2.560102\n",
      "Validation loss decreased (2.63221 --> 2.56010).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.634506 \tValidation Loss: 2.512625\n",
      "Validation loss decreased (2.56010 --> 2.51263).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.516612 \tValidation Loss: 2.481750\n",
      "Validation loss decreased (2.51263 --> 2.48175).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.427552 \tValidation Loss: 2.467397\n",
      "Validation loss decreased (2.48175 --> 2.46740).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.359186 \tValidation Loss: 2.462254\n",
      "Validation loss decreased (2.46740 --> 2.46225).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.308345 \tValidation Loss: 2.464870\n",
      "Epoch: 17 \tTraining Loss: 0.264492 \tValidation Loss: 2.475179\n",
      "Epoch: 18 \tTraining Loss: 0.234738 \tValidation Loss: 2.483805\n",
      "Epoch: 19 \tTraining Loss: 0.210124 \tValidation Loss: 2.496013\n",
      "Epoch: 20 \tTraining Loss: 0.189822 \tValidation Loss: 2.508641\n",
      "Epoch: 1 \tTraining Loss: 6.590886 \tValidation Loss: 5.440776\n",
      "Validation loss decreased (inf --> 5.44078).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.823225 \tValidation Loss: 5.118446\n",
      "Validation loss decreased (5.44078 --> 5.11845).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.195351 \tValidation Loss: 4.657539\n",
      "Validation loss decreased (5.11845 --> 4.65754).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.353338 \tValidation Loss: 4.158998\n",
      "Validation loss decreased (4.65754 --> 4.15900).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.458570 \tValidation Loss: 3.712769\n",
      "Validation loss decreased (4.15900 --> 3.71277).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.669817 \tValidation Loss: 3.355753\n",
      "Validation loss decreased (3.71277 --> 3.35575).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 \tTraining Loss: 2.049189 \tValidation Loss: 3.091932\n",
      "Validation loss decreased (3.35575 --> 3.09193).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.588336 \tValidation Loss: 2.901727\n",
      "Validation loss decreased (3.09193 --> 2.90173).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.242647 \tValidation Loss: 2.764516\n",
      "Validation loss decreased (2.90173 --> 2.76452).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.985222 \tValidation Loss: 2.662628\n",
      "Validation loss decreased (2.76452 --> 2.66263).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.788049 \tValidation Loss: 2.587396\n",
      "Validation loss decreased (2.66263 --> 2.58740).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.628752 \tValidation Loss: 2.538939\n",
      "Validation loss decreased (2.58740 --> 2.53894).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.511725 \tValidation Loss: 2.508072\n",
      "Validation loss decreased (2.53894 --> 2.50807).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.429189 \tValidation Loss: 2.491338\n",
      "Validation loss decreased (2.50807 --> 2.49134).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.357828 \tValidation Loss: 2.483568\n",
      "Validation loss decreased (2.49134 --> 2.48357).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.305707 \tValidation Loss: 2.484545\n",
      "Epoch: 17 \tTraining Loss: 0.265298 \tValidation Loss: 2.489277\n",
      "Epoch: 18 \tTraining Loss: 0.234588 \tValidation Loss: 2.502054\n",
      "Epoch: 19 \tTraining Loss: 0.210074 \tValidation Loss: 2.511591\n",
      "Epoch: 20 \tTraining Loss: 0.188278 \tValidation Loss: 2.524137\n",
      "Epoch: 1 \tTraining Loss: 6.593806 \tValidation Loss: 5.430071\n",
      "Validation loss decreased (inf --> 5.43007).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.820379 \tValidation Loss: 5.130724\n",
      "Validation loss decreased (5.43007 --> 5.13072).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.189473 \tValidation Loss: 4.693666\n",
      "Validation loss decreased (5.13072 --> 4.69367).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.346223 \tValidation Loss: 4.209969\n",
      "Validation loss decreased (4.69367 --> 4.20997).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.451049 \tValidation Loss: 3.771198\n",
      "Validation loss decreased (4.20997 --> 3.77120).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.660416 \tValidation Loss: 3.420127\n",
      "Validation loss decreased (3.77120 --> 3.42013).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.040322 \tValidation Loss: 3.159299\n",
      "Validation loss decreased (3.42013 --> 3.15930).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.581242 \tValidation Loss: 2.967827\n",
      "Validation loss decreased (3.15930 --> 2.96783).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.237877 \tValidation Loss: 2.827377\n",
      "Validation loss decreased (2.96783 --> 2.82738).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.979379 \tValidation Loss: 2.728755\n",
      "Validation loss decreased (2.82738 --> 2.72876).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.781836 \tValidation Loss: 2.659632\n",
      "Validation loss decreased (2.72876 --> 2.65963).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.629856 \tValidation Loss: 2.611820\n",
      "Validation loss decreased (2.65963 --> 2.61182).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.514729 \tValidation Loss: 2.583524\n",
      "Validation loss decreased (2.61182 --> 2.58352).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.423096 \tValidation Loss: 2.568976\n",
      "Validation loss decreased (2.58352 --> 2.56898).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.354852 \tValidation Loss: 2.564881\n",
      "Validation loss decreased (2.56898 --> 2.56488).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.303769 \tValidation Loss: 2.566915\n",
      "Epoch: 17 \tTraining Loss: 0.264662 \tValidation Loss: 2.576838\n",
      "Epoch: 18 \tTraining Loss: 0.232740 \tValidation Loss: 2.584248\n",
      "Epoch: 19 \tTraining Loss: 0.207058 \tValidation Loss: 2.606015\n",
      "Epoch: 20 \tTraining Loss: 0.186863 \tValidation Loss: 2.625188\n",
      "Epoch: 1 \tTraining Loss: 6.607631 \tValidation Loss: 5.415128\n",
      "Validation loss decreased (inf --> 5.41513).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.823140 \tValidation Loss: 5.103182\n",
      "Validation loss decreased (5.41513 --> 5.10318).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.189792 \tValidation Loss: 4.652350\n",
      "Validation loss decreased (5.10318 --> 4.65235).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.341795 \tValidation Loss: 4.146128\n",
      "Validation loss decreased (4.65235 --> 4.14613).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.445357 \tValidation Loss: 3.686935\n",
      "Validation loss decreased (4.14613 --> 3.68694).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.655237 \tValidation Loss: 3.316643\n",
      "Validation loss decreased (3.68694 --> 3.31664).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.041934 \tValidation Loss: 3.036766\n",
      "Validation loss decreased (3.31664 --> 3.03677).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.581861 \tValidation Loss: 2.835226\n",
      "Validation loss decreased (3.03677 --> 2.83523).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.241925 \tValidation Loss: 2.684353\n",
      "Validation loss decreased (2.83523 --> 2.68435).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.980876 \tValidation Loss: 2.574414\n",
      "Validation loss decreased (2.68435 --> 2.57441).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.788363 \tValidation Loss: 2.493843\n",
      "Validation loss decreased (2.57441 --> 2.49384).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.633022 \tValidation Loss: 2.437625\n",
      "Validation loss decreased (2.49384 --> 2.43763).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.514565 \tValidation Loss: 2.398713\n",
      "Validation loss decreased (2.43763 --> 2.39871).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.425793 \tValidation Loss: 2.378121\n",
      "Validation loss decreased (2.39871 --> 2.37812).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.359521 \tValidation Loss: 2.367911\n",
      "Validation loss decreased (2.37812 --> 2.36791).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.306641 \tValidation Loss: 2.366823\n",
      "Validation loss decreased (2.36791 --> 2.36682).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.265002 \tValidation Loss: 2.367226\n",
      "Epoch: 18 \tTraining Loss: 0.233944 \tValidation Loss: 2.377495\n",
      "Epoch: 19 \tTraining Loss: 0.208482 \tValidation Loss: 2.388300\n",
      "Epoch: 20 \tTraining Loss: 0.188376 \tValidation Loss: 2.398068\n",
      "Epoch: 1 \tTraining Loss: 6.603503 \tValidation Loss: 5.413768\n",
      "Validation loss decreased (inf --> 5.41377).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.814301 \tValidation Loss: 5.082924\n",
      "Validation loss decreased (5.41377 --> 5.08292).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.170125 \tValidation Loss: 4.622365\n",
      "Validation loss decreased (5.08292 --> 4.62236).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.316793 \tValidation Loss: 4.125586\n",
      "Validation loss decreased (4.62236 --> 4.12559).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.417121 \tValidation Loss: 3.683332\n",
      "Validation loss decreased (4.12559 --> 3.68333).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.629353 \tValidation Loss: 3.332452\n",
      "Validation loss decreased (3.68333 --> 3.33245).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.014135 \tValidation Loss: 3.072325\n",
      "Validation loss decreased (3.33245 --> 3.07233).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.558513 \tValidation Loss: 2.883140\n",
      "Validation loss decreased (3.07233 --> 2.88314).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.219759 \tValidation Loss: 2.746074\n",
      "Validation loss decreased (2.88314 --> 2.74607).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.964959 \tValidation Loss: 2.647253\n",
      "Validation loss decreased (2.74607 --> 2.64725).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.772060 \tValidation Loss: 2.575826\n",
      "Validation loss decreased (2.64725 --> 2.57583).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.618811 \tValidation Loss: 2.529700\n",
      "Validation loss decreased (2.57583 --> 2.52970).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.504880 \tValidation Loss: 2.501757\n",
      "Validation loss decreased (2.52970 --> 2.50176).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.418575 \tValidation Loss: 2.486886\n",
      "Validation loss decreased (2.50176 --> 2.48689).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.350832 \tValidation Loss: 2.483878\n",
      "Validation loss decreased (2.48689 --> 2.48388).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.298321 \tValidation Loss: 2.483833\n",
      "Validation loss decreased (2.48388 --> 2.48383).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.260113 \tValidation Loss: 2.489628\n",
      "Epoch: 18 \tTraining Loss: 0.228848 \tValidation Loss: 2.500332\n",
      "Epoch: 19 \tTraining Loss: 0.204481 \tValidation Loss: 2.516679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 \tTraining Loss: 0.183977 \tValidation Loss: 2.530327\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 9 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.592699 \tValidation Loss: 5.347042\n",
      "Validation loss decreased (inf --> 5.34704).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.785119 \tValidation Loss: 5.047534\n",
      "Validation loss decreased (5.34704 --> 5.04753).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.190874 \tValidation Loss: 4.629550\n",
      "Validation loss decreased (5.04753 --> 4.62955).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.389088 \tValidation Loss: 4.156015\n",
      "Validation loss decreased (4.62955 --> 4.15602).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.516571 \tValidation Loss: 3.727236\n",
      "Validation loss decreased (4.15602 --> 3.72724).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.731479 \tValidation Loss: 3.386299\n",
      "Validation loss decreased (3.72724 --> 3.38630).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.111972 \tValidation Loss: 3.129750\n",
      "Validation loss decreased (3.38630 --> 3.12975).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.641924 \tValidation Loss: 2.933239\n",
      "Validation loss decreased (3.12975 --> 2.93324).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.283078 \tValidation Loss: 2.781624\n",
      "Validation loss decreased (2.93324 --> 2.78162).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.009359 \tValidation Loss: 2.668410\n",
      "Validation loss decreased (2.78162 --> 2.66841).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.796458 \tValidation Loss: 2.584659\n",
      "Validation loss decreased (2.66841 --> 2.58466).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.633242 \tValidation Loss: 2.525159\n",
      "Validation loss decreased (2.58466 --> 2.52516).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.511361 \tValidation Loss: 2.486527\n",
      "Validation loss decreased (2.52516 --> 2.48653).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.413704 \tValidation Loss: 2.460826\n",
      "Validation loss decreased (2.48653 --> 2.46083).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.340322 \tValidation Loss: 2.450032\n",
      "Validation loss decreased (2.46083 --> 2.45003).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.285170 \tValidation Loss: 2.446288\n",
      "Validation loss decreased (2.45003 --> 2.44629).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.245481 \tValidation Loss: 2.448474\n",
      "Epoch: 18 \tTraining Loss: 0.211373 \tValidation Loss: 2.453365\n",
      "Epoch: 19 \tTraining Loss: 0.186273 \tValidation Loss: 2.466585\n",
      "Epoch: 20 \tTraining Loss: 0.167365 \tValidation Loss: 2.476463\n",
      "Epoch: 1 \tTraining Loss: 6.591365 \tValidation Loss: 5.393577\n",
      "Validation loss decreased (inf --> 5.39358).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.774403 \tValidation Loss: 5.077117\n",
      "Validation loss decreased (5.39358 --> 5.07712).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.179037 \tValidation Loss: 4.670213\n",
      "Validation loss decreased (5.07712 --> 4.67021).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.376922 \tValidation Loss: 4.210724\n",
      "Validation loss decreased (4.67021 --> 4.21072).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.512272 \tValidation Loss: 3.780088\n",
      "Validation loss decreased (4.21072 --> 3.78009).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.734690 \tValidation Loss: 3.419515\n",
      "Validation loss decreased (3.78009 --> 3.41951).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.113231 \tValidation Loss: 3.140038\n",
      "Validation loss decreased (3.41951 --> 3.14004).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.637677 \tValidation Loss: 2.936125\n",
      "Validation loss decreased (3.14004 --> 2.93613).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.278744 \tValidation Loss: 2.783634\n",
      "Validation loss decreased (2.93613 --> 2.78363).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.007059 \tValidation Loss: 2.673326\n",
      "Validation loss decreased (2.78363 --> 2.67333).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.793364 \tValidation Loss: 2.592611\n",
      "Validation loss decreased (2.67333 --> 2.59261).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.631476 \tValidation Loss: 2.533285\n",
      "Validation loss decreased (2.59261 --> 2.53328).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.505969 \tValidation Loss: 2.493508\n",
      "Validation loss decreased (2.53328 --> 2.49351).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.413428 \tValidation Loss: 2.469944\n",
      "Validation loss decreased (2.49351 --> 2.46994).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.339991 \tValidation Loss: 2.457219\n",
      "Validation loss decreased (2.46994 --> 2.45722).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.284367 \tValidation Loss: 2.456414\n",
      "Validation loss decreased (2.45722 --> 2.45641).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.243555 \tValidation Loss: 2.456803\n",
      "Epoch: 18 \tTraining Loss: 0.210582 \tValidation Loss: 2.464303\n",
      "Epoch: 19 \tTraining Loss: 0.185541 \tValidation Loss: 2.474019\n",
      "Epoch: 20 \tTraining Loss: 0.165352 \tValidation Loss: 2.485127\n",
      "Epoch: 1 \tTraining Loss: 6.579906 \tValidation Loss: 5.393511\n",
      "Validation loss decreased (inf --> 5.39351).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.775303 \tValidation Loss: 5.100322\n",
      "Validation loss decreased (5.39351 --> 5.10032).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.189383 \tValidation Loss: 4.703805\n",
      "Validation loss decreased (5.10032 --> 4.70380).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.394926 \tValidation Loss: 4.242440\n",
      "Validation loss decreased (4.70380 --> 4.24244).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.526979 \tValidation Loss: 3.810500\n",
      "Validation loss decreased (4.24244 --> 3.81050).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.744290 \tValidation Loss: 3.457020\n",
      "Validation loss decreased (3.81050 --> 3.45702).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.121854 \tValidation Loss: 3.187706\n",
      "Validation loss decreased (3.45702 --> 3.18771).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.646411 \tValidation Loss: 2.986512\n",
      "Validation loss decreased (3.18771 --> 2.98651).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.288729 \tValidation Loss: 2.835660\n",
      "Validation loss decreased (2.98651 --> 2.83566).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.009127 \tValidation Loss: 2.726266\n",
      "Validation loss decreased (2.83566 --> 2.72627).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.797317 \tValidation Loss: 2.646396\n",
      "Validation loss decreased (2.72627 --> 2.64640).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.633744 \tValidation Loss: 2.593953\n",
      "Validation loss decreased (2.64640 --> 2.59395).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.510640 \tValidation Loss: 2.556245\n",
      "Validation loss decreased (2.59395 --> 2.55624).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.413827 \tValidation Loss: 2.536442\n",
      "Validation loss decreased (2.55624 --> 2.53644).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.341275 \tValidation Loss: 2.529374\n",
      "Validation loss decreased (2.53644 --> 2.52937).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.283513 \tValidation Loss: 2.530018\n",
      "Epoch: 17 \tTraining Loss: 0.245221 \tValidation Loss: 2.534753\n",
      "Epoch: 18 \tTraining Loss: 0.212939 \tValidation Loss: 2.543476\n",
      "Epoch: 19 \tTraining Loss: 0.187096 \tValidation Loss: 2.552837\n",
      "Epoch: 20 \tTraining Loss: 0.168112 \tValidation Loss: 2.566557\n",
      "Epoch: 1 \tTraining Loss: 6.589935 \tValidation Loss: 5.340786\n",
      "Validation loss decreased (inf --> 5.34079).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.789673 \tValidation Loss: 5.036238\n",
      "Validation loss decreased (5.34079 --> 5.03624).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.198735 \tValidation Loss: 4.631396\n",
      "Validation loss decreased (5.03624 --> 4.63140).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.401366 \tValidation Loss: 4.171249\n",
      "Validation loss decreased (4.63140 --> 4.17125).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.531253 \tValidation Loss: 3.742019\n",
      "Validation loss decreased (4.17125 --> 3.74202).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.745134 \tValidation Loss: 3.390953\n",
      "Validation loss decreased (3.74202 --> 3.39095).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.117202 \tValidation Loss: 3.121827\n",
      "Validation loss decreased (3.39095 --> 3.12183).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.639591 \tValidation Loss: 2.920955\n",
      "Validation loss decreased (3.12183 --> 2.92095).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.280890 \tValidation Loss: 2.769415\n",
      "Validation loss decreased (2.92095 --> 2.76941).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.002037 \tValidation Loss: 2.655893\n",
      "Validation loss decreased (2.76941 --> 2.65589).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 \tTraining Loss: 0.790301 \tValidation Loss: 2.572068\n",
      "Validation loss decreased (2.65589 --> 2.57207).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.628733 \tValidation Loss: 2.516129\n",
      "Validation loss decreased (2.57207 --> 2.51613).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.501491 \tValidation Loss: 2.477472\n",
      "Validation loss decreased (2.51613 --> 2.47747).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.409513 \tValidation Loss: 2.454414\n",
      "Validation loss decreased (2.47747 --> 2.45441).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.336489 \tValidation Loss: 2.442046\n",
      "Validation loss decreased (2.45441 --> 2.44205).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.282012 \tValidation Loss: 2.437975\n",
      "Validation loss decreased (2.44205 --> 2.43798).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.243159 \tValidation Loss: 2.440857\n",
      "Epoch: 18 \tTraining Loss: 0.210985 \tValidation Loss: 2.449254\n",
      "Epoch: 19 \tTraining Loss: 0.185622 \tValidation Loss: 2.456766\n",
      "Epoch: 20 \tTraining Loss: 0.165467 \tValidation Loss: 2.469628\n",
      "Epoch: 1 \tTraining Loss: 6.594218 \tValidation Loss: 5.370653\n",
      "Validation loss decreased (inf --> 5.37065).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.780466 \tValidation Loss: 5.069721\n",
      "Validation loss decreased (5.37065 --> 5.06972).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.187656 \tValidation Loss: 4.650297\n",
      "Validation loss decreased (5.06972 --> 4.65030).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.385664 \tValidation Loss: 4.172257\n",
      "Validation loss decreased (4.65030 --> 4.17226).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.514521 \tValidation Loss: 3.733694\n",
      "Validation loss decreased (4.17226 --> 3.73369).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.731311 \tValidation Loss: 3.375635\n",
      "Validation loss decreased (3.73369 --> 3.37564).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.109943 \tValidation Loss: 3.104850\n",
      "Validation loss decreased (3.37564 --> 3.10485).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.638041 \tValidation Loss: 2.900628\n",
      "Validation loss decreased (3.10485 --> 2.90063).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.280040 \tValidation Loss: 2.744820\n",
      "Validation loss decreased (2.90063 --> 2.74482).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.004387 \tValidation Loss: 2.626711\n",
      "Validation loss decreased (2.74482 --> 2.62671).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.793768 \tValidation Loss: 2.535688\n",
      "Validation loss decreased (2.62671 --> 2.53569).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.630508 \tValidation Loss: 2.474421\n",
      "Validation loss decreased (2.53569 --> 2.47442).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.504385 \tValidation Loss: 2.432448\n",
      "Validation loss decreased (2.47442 --> 2.43245).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.410884 \tValidation Loss: 2.407553\n",
      "Validation loss decreased (2.43245 --> 2.40755).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.340735 \tValidation Loss: 2.395071\n",
      "Validation loss decreased (2.40755 --> 2.39507).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.283079 \tValidation Loss: 2.391121\n",
      "Validation loss decreased (2.39507 --> 2.39112).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.244597 \tValidation Loss: 2.388413\n",
      "Validation loss decreased (2.39112 --> 2.38841).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.209298 \tValidation Loss: 2.394584\n",
      "Epoch: 19 \tTraining Loss: 0.185767 \tValidation Loss: 2.400403\n",
      "Epoch: 20 \tTraining Loss: 0.166132 \tValidation Loss: 2.410090\n",
      "Epoch: 1 \tTraining Loss: 6.591805 \tValidation Loss: 5.370760\n",
      "Validation loss decreased (inf --> 5.37076).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.785750 \tValidation Loss: 5.067338\n",
      "Validation loss decreased (5.37076 --> 5.06734).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.192330 \tValidation Loss: 4.658986\n",
      "Validation loss decreased (5.06734 --> 4.65899).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.393008 \tValidation Loss: 4.194279\n",
      "Validation loss decreased (4.65899 --> 4.19428).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.525429 \tValidation Loss: 3.758462\n",
      "Validation loss decreased (4.19428 --> 3.75846).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.740391 \tValidation Loss: 3.393094\n",
      "Validation loss decreased (3.75846 --> 3.39309).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.115456 \tValidation Loss: 3.112448\n",
      "Validation loss decreased (3.39309 --> 3.11245).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.644511 \tValidation Loss: 2.906261\n",
      "Validation loss decreased (3.11245 --> 2.90626).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.284090 \tValidation Loss: 2.752816\n",
      "Validation loss decreased (2.90626 --> 2.75282).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.007699 \tValidation Loss: 2.637543\n",
      "Validation loss decreased (2.75282 --> 2.63754).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.794750 \tValidation Loss: 2.553401\n",
      "Validation loss decreased (2.63754 --> 2.55340).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.631037 \tValidation Loss: 2.494070\n",
      "Validation loss decreased (2.55340 --> 2.49407).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.506496 \tValidation Loss: 2.455842\n",
      "Validation loss decreased (2.49407 --> 2.45584).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.408409 \tValidation Loss: 2.434908\n",
      "Validation loss decreased (2.45584 --> 2.43491).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.338394 \tValidation Loss: 2.427069\n",
      "Validation loss decreased (2.43491 --> 2.42707).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.281387 \tValidation Loss: 2.422738\n",
      "Validation loss decreased (2.42707 --> 2.42274).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.241062 \tValidation Loss: 2.428057\n",
      "Epoch: 18 \tTraining Loss: 0.209337 \tValidation Loss: 2.431865\n",
      "Epoch: 19 \tTraining Loss: 0.184406 \tValidation Loss: 2.444807\n",
      "Epoch: 20 \tTraining Loss: 0.164300 \tValidation Loss: 2.457381\n",
      "Epoch: 1 \tTraining Loss: 6.594020 \tValidation Loss: 5.382204\n",
      "Validation loss decreased (inf --> 5.38220).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.781761 \tValidation Loss: 5.086604\n",
      "Validation loss decreased (5.38220 --> 5.08660).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.193646 \tValidation Loss: 4.694246\n",
      "Validation loss decreased (5.08660 --> 4.69425).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.399592 \tValidation Loss: 4.236061\n",
      "Validation loss decreased (4.69425 --> 4.23606).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.527042 \tValidation Loss: 3.811504\n",
      "Validation loss decreased (4.23606 --> 3.81150).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.740787 \tValidation Loss: 3.467908\n",
      "Validation loss decreased (3.81150 --> 3.46791).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.119224 \tValidation Loss: 3.200696\n",
      "Validation loss decreased (3.46791 --> 3.20070).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.644703 \tValidation Loss: 2.996326\n",
      "Validation loss decreased (3.20070 --> 2.99633).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.287003 \tValidation Loss: 2.842750\n",
      "Validation loss decreased (2.99633 --> 2.84275).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.014109 \tValidation Loss: 2.726468\n",
      "Validation loss decreased (2.84275 --> 2.72647).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.802410 \tValidation Loss: 2.638599\n",
      "Validation loss decreased (2.72647 --> 2.63860).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.633787 \tValidation Loss: 2.576543\n",
      "Validation loss decreased (2.63860 --> 2.57654).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.510153 \tValidation Loss: 2.536042\n",
      "Validation loss decreased (2.57654 --> 2.53604).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.413636 \tValidation Loss: 2.507364\n",
      "Validation loss decreased (2.53604 --> 2.50736).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.341142 \tValidation Loss: 2.495454\n",
      "Validation loss decreased (2.50736 --> 2.49545).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.285189 \tValidation Loss: 2.492065\n",
      "Validation loss decreased (2.49545 --> 2.49206).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.245448 \tValidation Loss: 2.492575\n",
      "Epoch: 18 \tTraining Loss: 0.213444 \tValidation Loss: 2.501307\n",
      "Epoch: 19 \tTraining Loss: 0.187966 \tValidation Loss: 2.512570\n",
      "Epoch: 20 \tTraining Loss: 0.168366 \tValidation Loss: 2.523571\n",
      "Epoch: 1 \tTraining Loss: 6.584957 \tValidation Loss: 5.402182\n",
      "Validation loss decreased (inf --> 5.40218).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.780114 \tValidation Loss: 5.100995\n",
      "Validation loss decreased (5.40218 --> 5.10099).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \tTraining Loss: 5.188859 \tValidation Loss: 4.690429\n",
      "Validation loss decreased (5.10099 --> 4.69043).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.388584 \tValidation Loss: 4.215418\n",
      "Validation loss decreased (4.69043 --> 4.21542).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.515196 \tValidation Loss: 3.778765\n",
      "Validation loss decreased (4.21542 --> 3.77877).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.728667 \tValidation Loss: 3.427723\n",
      "Validation loss decreased (3.77877 --> 3.42772).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.106199 \tValidation Loss: 3.166251\n",
      "Validation loss decreased (3.42772 --> 3.16625).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.631887 \tValidation Loss: 2.979021\n",
      "Validation loss decreased (3.16625 --> 2.97902).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.275022 \tValidation Loss: 2.840807\n",
      "Validation loss decreased (2.97902 --> 2.84081).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.003335 \tValidation Loss: 2.740727\n",
      "Validation loss decreased (2.84081 --> 2.74073).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.791370 \tValidation Loss: 2.668007\n",
      "Validation loss decreased (2.74073 --> 2.66801).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.629156 \tValidation Loss: 2.622868\n",
      "Validation loss decreased (2.66801 --> 2.62287).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.504807 \tValidation Loss: 2.596498\n",
      "Validation loss decreased (2.62287 --> 2.59650).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.411894 \tValidation Loss: 2.583056\n",
      "Validation loss decreased (2.59650 --> 2.58306).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.340677 \tValidation Loss: 2.578125\n",
      "Validation loss decreased (2.58306 --> 2.57813).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.288019 \tValidation Loss: 2.580674\n",
      "Epoch: 17 \tTraining Loss: 0.245975 \tValidation Loss: 2.591158\n",
      "Epoch: 18 \tTraining Loss: 0.211473 \tValidation Loss: 2.604573\n",
      "Epoch: 19 \tTraining Loss: 0.188784 \tValidation Loss: 2.618003\n",
      "Epoch: 20 \tTraining Loss: 0.167430 \tValidation Loss: 2.636766\n",
      "Epoch: 1 \tTraining Loss: 6.588627 \tValidation Loss: 5.350535\n",
      "Validation loss decreased (inf --> 5.35053).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.778984 \tValidation Loss: 5.038000\n",
      "Validation loss decreased (5.35053 --> 5.03800).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.185835 \tValidation Loss: 4.630025\n",
      "Validation loss decreased (5.03800 --> 4.63003).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.386037 \tValidation Loss: 4.162007\n",
      "Validation loss decreased (4.63003 --> 4.16201).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.523104 \tValidation Loss: 3.725082\n",
      "Validation loss decreased (4.16201 --> 3.72508).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.740875 \tValidation Loss: 3.374342\n",
      "Validation loss decreased (3.72508 --> 3.37434).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.121446 \tValidation Loss: 3.112636\n",
      "Validation loss decreased (3.37434 --> 3.11264).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.650588 \tValidation Loss: 2.919069\n",
      "Validation loss decreased (3.11264 --> 2.91907).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.290976 \tValidation Loss: 2.775563\n",
      "Validation loss decreased (2.91907 --> 2.77556).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.014959 \tValidation Loss: 2.667257\n",
      "Validation loss decreased (2.77556 --> 2.66726).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.803951 \tValidation Loss: 2.590911\n",
      "Validation loss decreased (2.66726 --> 2.59091).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.642082 \tValidation Loss: 2.534400\n",
      "Validation loss decreased (2.59091 --> 2.53440).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.512021 \tValidation Loss: 2.496798\n",
      "Validation loss decreased (2.53440 --> 2.49680).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.417760 \tValidation Loss: 2.476115\n",
      "Validation loss decreased (2.49680 --> 2.47611).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.343276 \tValidation Loss: 2.463487\n",
      "Validation loss decreased (2.47611 --> 2.46349).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.288189 \tValidation Loss: 2.461441\n",
      "Validation loss decreased (2.46349 --> 2.46144).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.249525 \tValidation Loss: 2.464585\n",
      "Epoch: 18 \tTraining Loss: 0.213537 \tValidation Loss: 2.472005\n",
      "Epoch: 19 \tTraining Loss: 0.187773 \tValidation Loss: 2.485985\n",
      "Epoch: 20 \tTraining Loss: 0.168109 \tValidation Loss: 2.499043\n",
      "Epoch: 1 \tTraining Loss: 6.596471 \tValidation Loss: 5.365170\n",
      "Validation loss decreased (inf --> 5.36517).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.784658 \tValidation Loss: 5.064494\n",
      "Validation loss decreased (5.36517 --> 5.06449).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.198960 \tValidation Loss: 4.655787\n",
      "Validation loss decreased (5.06449 --> 4.65579).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.391904 \tValidation Loss: 4.192475\n",
      "Validation loss decreased (4.65579 --> 4.19247).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.508277 \tValidation Loss: 3.766723\n",
      "Validation loss decreased (4.19247 --> 3.76672).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.719673 \tValidation Loss: 3.422863\n",
      "Validation loss decreased (3.76672 --> 3.42286).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.097157 \tValidation Loss: 3.166018\n",
      "Validation loss decreased (3.42286 --> 3.16602).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.625024 \tValidation Loss: 2.974600\n",
      "Validation loss decreased (3.16602 --> 2.97460).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.274931 \tValidation Loss: 2.830593\n",
      "Validation loss decreased (2.97460 --> 2.83059).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.003215 \tValidation Loss: 2.724225\n",
      "Validation loss decreased (2.83059 --> 2.72422).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.793837 \tValidation Loss: 2.645963\n",
      "Validation loss decreased (2.72422 --> 2.64596).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.628042 \tValidation Loss: 2.594313\n",
      "Validation loss decreased (2.64596 --> 2.59431).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.505589 \tValidation Loss: 2.560385\n",
      "Validation loss decreased (2.59431 --> 2.56039).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.408760 \tValidation Loss: 2.538013\n",
      "Validation loss decreased (2.56039 --> 2.53801).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.336846 \tValidation Loss: 2.527353\n",
      "Validation loss decreased (2.53801 --> 2.52735).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.282875 \tValidation Loss: 2.526409\n",
      "Validation loss decreased (2.52735 --> 2.52641).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.240150 \tValidation Loss: 2.532520\n",
      "Epoch: 18 \tTraining Loss: 0.209739 \tValidation Loss: 2.542098\n",
      "Epoch: 19 \tTraining Loss: 0.184927 \tValidation Loss: 2.553692\n",
      "Epoch: 20 \tTraining Loss: 0.164866 \tValidation Loss: 2.567052\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 10 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.647871 \tValidation Loss: 5.246846\n",
      "Validation loss decreased (inf --> 5.24685).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.799199 \tValidation Loss: 4.986321\n",
      "Validation loss decreased (5.24685 --> 4.98632).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.249282 \tValidation Loss: 4.634953\n",
      "Validation loss decreased (4.98632 --> 4.63495).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.509325 \tValidation Loss: 4.218567\n",
      "Validation loss decreased (4.63495 --> 4.21857).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.671066 \tValidation Loss: 3.822562\n",
      "Validation loss decreased (4.21857 --> 3.82256).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.891104 \tValidation Loss: 3.495720\n",
      "Validation loss decreased (3.82256 --> 3.49572).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.253681 \tValidation Loss: 3.247662\n",
      "Validation loss decreased (3.49572 --> 3.24766).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.763735 \tValidation Loss: 3.066641\n",
      "Validation loss decreased (3.24766 --> 3.06664).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.388431 \tValidation Loss: 2.932896\n",
      "Validation loss decreased (3.06664 --> 2.93290).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.095073 \tValidation Loss: 2.834613\n",
      "Validation loss decreased (2.93290 --> 2.83461).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.864041 \tValidation Loss: 2.761963\n",
      "Validation loss decreased (2.83461 --> 2.76196).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.685063 \tValidation Loss: 2.709615\n",
      "Validation loss decreased (2.76196 --> 2.70961).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.546290 \tValidation Loss: 2.677540\n",
      "Validation loss decreased (2.70961 --> 2.67754).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 \tTraining Loss: 0.439943 \tValidation Loss: 2.657706\n",
      "Validation loss decreased (2.67754 --> 2.65771).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.359033 \tValidation Loss: 2.649060\n",
      "Validation loss decreased (2.65771 --> 2.64906).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.298126 \tValidation Loss: 2.646435\n",
      "Validation loss decreased (2.64906 --> 2.64644).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.250080 \tValidation Loss: 2.653567\n",
      "Epoch: 18 \tTraining Loss: 0.215407 \tValidation Loss: 2.662542\n",
      "Epoch: 19 \tTraining Loss: 0.189605 \tValidation Loss: 2.669652\n",
      "Epoch: 20 \tTraining Loss: 0.166304 \tValidation Loss: 2.684119\n",
      "Epoch: 1 \tTraining Loss: 6.643596 \tValidation Loss: 5.251075\n",
      "Validation loss decreased (inf --> 5.25108).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.806112 \tValidation Loss: 4.986092\n",
      "Validation loss decreased (5.25108 --> 4.98609).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.262002 \tValidation Loss: 4.619447\n",
      "Validation loss decreased (4.98609 --> 4.61945).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.530448 \tValidation Loss: 4.199606\n",
      "Validation loss decreased (4.61945 --> 4.19961).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.702817 \tValidation Loss: 3.794601\n",
      "Validation loss decreased (4.19961 --> 3.79460).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.917762 \tValidation Loss: 3.452251\n",
      "Validation loss decreased (3.79460 --> 3.45225).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.271259 \tValidation Loss: 3.186360\n",
      "Validation loss decreased (3.45225 --> 3.18636).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.770893 \tValidation Loss: 2.986004\n",
      "Validation loss decreased (3.18636 --> 2.98600).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.388685 \tValidation Loss: 2.837443\n",
      "Validation loss decreased (2.98600 --> 2.83744).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.090176 \tValidation Loss: 2.727903\n",
      "Validation loss decreased (2.83744 --> 2.72790).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.856111 \tValidation Loss: 2.646923\n",
      "Validation loss decreased (2.72790 --> 2.64692).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.678579 \tValidation Loss: 2.588973\n",
      "Validation loss decreased (2.64692 --> 2.58897).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.540018 \tValidation Loss: 2.550777\n",
      "Validation loss decreased (2.58897 --> 2.55078).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.434281 \tValidation Loss: 2.528647\n",
      "Validation loss decreased (2.55078 --> 2.52865).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.352967 \tValidation Loss: 2.515938\n",
      "Validation loss decreased (2.52865 --> 2.51594).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.294516 \tValidation Loss: 2.512356\n",
      "Validation loss decreased (2.51594 --> 2.51236).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.247108 \tValidation Loss: 2.516565\n",
      "Epoch: 18 \tTraining Loss: 0.212502 \tValidation Loss: 2.524549\n",
      "Epoch: 19 \tTraining Loss: 0.186427 \tValidation Loss: 2.533636\n",
      "Epoch: 20 \tTraining Loss: 0.165790 \tValidation Loss: 2.544623\n",
      "Epoch: 1 \tTraining Loss: 6.653286 \tValidation Loss: 5.193407\n",
      "Validation loss decreased (inf --> 5.19341).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.818926 \tValidation Loss: 4.937359\n",
      "Validation loss decreased (5.19341 --> 4.93736).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.268859 \tValidation Loss: 4.582908\n",
      "Validation loss decreased (4.93736 --> 4.58291).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.530427 \tValidation Loss: 4.170108\n",
      "Validation loss decreased (4.58291 --> 4.17011).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.694300 \tValidation Loss: 3.777018\n",
      "Validation loss decreased (4.17011 --> 3.77702).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.917296 \tValidation Loss: 3.458742\n",
      "Validation loss decreased (3.77702 --> 3.45874).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.273322 \tValidation Loss: 3.221276\n",
      "Validation loss decreased (3.45874 --> 3.22128).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.772959 \tValidation Loss: 3.044434\n",
      "Validation loss decreased (3.22128 --> 3.04443).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.392003 \tValidation Loss: 2.914586\n",
      "Validation loss decreased (3.04443 --> 2.91459).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.094685 \tValidation Loss: 2.817236\n",
      "Validation loss decreased (2.91459 --> 2.81724).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.864363 \tValidation Loss: 2.740977\n",
      "Validation loss decreased (2.81724 --> 2.74098).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.682889 \tValidation Loss: 2.688805\n",
      "Validation loss decreased (2.74098 --> 2.68881).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.543789 \tValidation Loss: 2.656486\n",
      "Validation loss decreased (2.68881 --> 2.65649).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.440266 \tValidation Loss: 2.638738\n",
      "Validation loss decreased (2.65649 --> 2.63874).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.356781 \tValidation Loss: 2.625700\n",
      "Validation loss decreased (2.63874 --> 2.62570).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.298542 \tValidation Loss: 2.625296\n",
      "Validation loss decreased (2.62570 --> 2.62530).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.249359 \tValidation Loss: 2.624975\n",
      "Validation loss decreased (2.62530 --> 2.62497).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.215465 \tValidation Loss: 2.633826\n",
      "Epoch: 19 \tTraining Loss: 0.188498 \tValidation Loss: 2.644268\n",
      "Epoch: 20 \tTraining Loss: 0.166490 \tValidation Loss: 2.654519\n",
      "Epoch: 1 \tTraining Loss: 6.650306 \tValidation Loss: 5.252144\n",
      "Validation loss decreased (inf --> 5.25214).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.802508 \tValidation Loss: 4.991379\n",
      "Validation loss decreased (5.25214 --> 4.99138).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.252905 \tValidation Loss: 4.629438\n",
      "Validation loss decreased (4.99138 --> 4.62944).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.523565 \tValidation Loss: 4.201797\n",
      "Validation loss decreased (4.62944 --> 4.20180).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.699954 \tValidation Loss: 3.792161\n",
      "Validation loss decreased (4.20180 --> 3.79216).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.919935 \tValidation Loss: 3.453079\n",
      "Validation loss decreased (3.79216 --> 3.45308).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.277637 \tValidation Loss: 3.196093\n",
      "Validation loss decreased (3.45308 --> 3.19609).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.779423 \tValidation Loss: 3.005205\n",
      "Validation loss decreased (3.19609 --> 3.00520).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.400016 \tValidation Loss: 2.860469\n",
      "Validation loss decreased (3.00520 --> 2.86047).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.102912 \tValidation Loss: 2.750981\n",
      "Validation loss decreased (2.86047 --> 2.75098).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.868652 \tValidation Loss: 2.667218\n",
      "Validation loss decreased (2.75098 --> 2.66722).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.689990 \tValidation Loss: 2.607812\n",
      "Validation loss decreased (2.66722 --> 2.60781).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.550274 \tValidation Loss: 2.567431\n",
      "Validation loss decreased (2.60781 --> 2.56743).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.441876 \tValidation Loss: 2.539877\n",
      "Validation loss decreased (2.56743 --> 2.53988).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.358736 \tValidation Loss: 2.524732\n",
      "Validation loss decreased (2.53988 --> 2.52473).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.296308 \tValidation Loss: 2.519570\n",
      "Validation loss decreased (2.52473 --> 2.51957).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.251202 \tValidation Loss: 2.518010\n",
      "Validation loss decreased (2.51957 --> 2.51801).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.216718 \tValidation Loss: 2.524360\n",
      "Epoch: 19 \tTraining Loss: 0.188065 \tValidation Loss: 2.531984\n",
      "Epoch: 20 \tTraining Loss: 0.166398 \tValidation Loss: 2.544862\n",
      "Epoch: 1 \tTraining Loss: 6.647269 \tValidation Loss: 5.218399\n",
      "Validation loss decreased (inf --> 5.21840).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.811578 \tValidation Loss: 4.955775\n",
      "Validation loss decreased (5.21840 --> 4.95578).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.264936 \tValidation Loss: 4.603213\n",
      "Validation loss decreased (4.95578 --> 4.60321).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.532825 \tValidation Loss: 4.199045\n",
      "Validation loss decreased (4.60321 --> 4.19904).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.704139 \tValidation Loss: 3.809515\n",
      "Validation loss decreased (4.19904 --> 3.80952).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 \tTraining Loss: 2.923057 \tValidation Loss: 3.486053\n",
      "Validation loss decreased (3.80952 --> 3.48605).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.274847 \tValidation Loss: 3.237571\n",
      "Validation loss decreased (3.48605 --> 3.23757).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.774833 \tValidation Loss: 3.054244\n",
      "Validation loss decreased (3.23757 --> 3.05424).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.390527 \tValidation Loss: 2.918096\n",
      "Validation loss decreased (3.05424 --> 2.91810).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.094655 \tValidation Loss: 2.817432\n",
      "Validation loss decreased (2.91810 --> 2.81743).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.863609 \tValidation Loss: 2.744345\n",
      "Validation loss decreased (2.81743 --> 2.74434).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.681347 \tValidation Loss: 2.689226\n",
      "Validation loss decreased (2.74434 --> 2.68923).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.540774 \tValidation Loss: 2.656557\n",
      "Validation loss decreased (2.68923 --> 2.65656).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.434882 \tValidation Loss: 2.638039\n",
      "Validation loss decreased (2.65656 --> 2.63804).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.352739 \tValidation Loss: 2.630992\n",
      "Validation loss decreased (2.63804 --> 2.63099).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.293742 \tValidation Loss: 2.627460\n",
      "Validation loss decreased (2.63099 --> 2.62746).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.245811 \tValidation Loss: 2.632129\n",
      "Epoch: 18 \tTraining Loss: 0.210314 \tValidation Loss: 2.640129\n",
      "Epoch: 19 \tTraining Loss: 0.183855 \tValidation Loss: 2.653349\n",
      "Epoch: 20 \tTraining Loss: 0.161389 \tValidation Loss: 2.668710\n",
      "Epoch: 1 \tTraining Loss: 6.652841 \tValidation Loss: 5.227213\n",
      "Validation loss decreased (inf --> 5.22721).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.796266 \tValidation Loss: 4.954023\n",
      "Validation loss decreased (5.22721 --> 4.95402).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.236749 \tValidation Loss: 4.591108\n",
      "Validation loss decreased (4.95402 --> 4.59111).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.499173 \tValidation Loss: 4.174840\n",
      "Validation loss decreased (4.59111 --> 4.17484).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.672049 \tValidation Loss: 3.789928\n",
      "Validation loss decreased (4.17484 --> 3.78993).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.897044 \tValidation Loss: 3.464661\n",
      "Validation loss decreased (3.78993 --> 3.46466).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.259501 \tValidation Loss: 3.208017\n",
      "Validation loss decreased (3.46466 --> 3.20802).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.765499 \tValidation Loss: 3.010113\n",
      "Validation loss decreased (3.20802 --> 3.01011).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.386382 \tValidation Loss: 2.857677\n",
      "Validation loss decreased (3.01011 --> 2.85768).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.094441 \tValidation Loss: 2.739884\n",
      "Validation loss decreased (2.85768 --> 2.73988).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.865200 \tValidation Loss: 2.650189\n",
      "Validation loss decreased (2.73988 --> 2.65019).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.680381 \tValidation Loss: 2.583314\n",
      "Validation loss decreased (2.65019 --> 2.58331).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.543517 \tValidation Loss: 2.535960\n",
      "Validation loss decreased (2.58331 --> 2.53596).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.437140 \tValidation Loss: 2.503814\n",
      "Validation loss decreased (2.53596 --> 2.50381).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.356115 \tValidation Loss: 2.487469\n",
      "Validation loss decreased (2.50381 --> 2.48747).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.293212 \tValidation Loss: 2.482082\n",
      "Validation loss decreased (2.48747 --> 2.48208).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.247500 \tValidation Loss: 2.476208\n",
      "Validation loss decreased (2.48208 --> 2.47621).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.214319 \tValidation Loss: 2.480438\n",
      "Epoch: 19 \tTraining Loss: 0.185967 \tValidation Loss: 2.483863\n",
      "Epoch: 20 \tTraining Loss: 0.164083 \tValidation Loss: 2.491133\n",
      "Epoch: 1 \tTraining Loss: 6.642371 \tValidation Loss: 5.296121\n",
      "Validation loss decreased (inf --> 5.29612).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.794303 \tValidation Loss: 5.023509\n",
      "Validation loss decreased (5.29612 --> 5.02351).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.248164 \tValidation Loss: 4.658519\n",
      "Validation loss decreased (5.02351 --> 4.65852).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.517760 \tValidation Loss: 4.226747\n",
      "Validation loss decreased (4.65852 --> 4.22675).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.697314 \tValidation Loss: 3.813237\n",
      "Validation loss decreased (4.22675 --> 3.81324).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.922458 \tValidation Loss: 3.474841\n",
      "Validation loss decreased (3.81324 --> 3.47484).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.283093 \tValidation Loss: 3.214849\n",
      "Validation loss decreased (3.47484 --> 3.21485).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.785112 \tValidation Loss: 3.019043\n",
      "Validation loss decreased (3.21485 --> 3.01904).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.400014 \tValidation Loss: 2.869650\n",
      "Validation loss decreased (3.01904 --> 2.86965).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.102097 \tValidation Loss: 2.757045\n",
      "Validation loss decreased (2.86965 --> 2.75704).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.867936 \tValidation Loss: 2.673894\n",
      "Validation loss decreased (2.75704 --> 2.67389).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.684530 \tValidation Loss: 2.616115\n",
      "Validation loss decreased (2.67389 --> 2.61612).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.544876 \tValidation Loss: 2.580241\n",
      "Validation loss decreased (2.61612 --> 2.58024).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.437169 \tValidation Loss: 2.554037\n",
      "Validation loss decreased (2.58024 --> 2.55404).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.356748 \tValidation Loss: 2.541722\n",
      "Validation loss decreased (2.55404 --> 2.54172).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.294153 \tValidation Loss: 2.539343\n",
      "Validation loss decreased (2.54172 --> 2.53934).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.248458 \tValidation Loss: 2.544533\n",
      "Epoch: 18 \tTraining Loss: 0.213565 \tValidation Loss: 2.550011\n",
      "Epoch: 19 \tTraining Loss: 0.187288 \tValidation Loss: 2.556124\n",
      "Epoch: 20 \tTraining Loss: 0.165875 \tValidation Loss: 2.567883\n",
      "Epoch: 1 \tTraining Loss: 6.631580 \tValidation Loss: 5.350706\n",
      "Validation loss decreased (inf --> 5.35071).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.800557 \tValidation Loss: 5.085703\n",
      "Validation loss decreased (5.35071 --> 5.08570).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.257909 \tValidation Loss: 4.740313\n",
      "Validation loss decreased (5.08570 --> 4.74031).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.528553 \tValidation Loss: 4.320237\n",
      "Validation loss decreased (4.74031 --> 4.32024).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.702801 \tValidation Loss: 3.909402\n",
      "Validation loss decreased (4.32024 --> 3.90940).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.928561 \tValidation Loss: 3.569588\n",
      "Validation loss decreased (3.90940 --> 3.56959).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.285155 \tValidation Loss: 3.299172\n",
      "Validation loss decreased (3.56959 --> 3.29917).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.788574 \tValidation Loss: 3.094835\n",
      "Validation loss decreased (3.29917 --> 3.09484).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.404810 \tValidation Loss: 2.943062\n",
      "Validation loss decreased (3.09484 --> 2.94306).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.102670 \tValidation Loss: 2.831815\n",
      "Validation loss decreased (2.94306 --> 2.83181).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.868045 \tValidation Loss: 2.750320\n",
      "Validation loss decreased (2.83181 --> 2.75032).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.686012 \tValidation Loss: 2.693888\n",
      "Validation loss decreased (2.75032 --> 2.69389).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.543053 \tValidation Loss: 2.654737\n",
      "Validation loss decreased (2.69389 --> 2.65474).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.435457 \tValidation Loss: 2.634452\n",
      "Validation loss decreased (2.65474 --> 2.63445).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.356369 \tValidation Loss: 2.621098\n",
      "Validation loss decreased (2.63445 --> 2.62110).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 \tTraining Loss: 0.295347 \tValidation Loss: 2.617561\n",
      "Validation loss decreased (2.62110 --> 2.61756).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.248324 \tValidation Loss: 2.617240\n",
      "Validation loss decreased (2.61756 --> 2.61724).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.213651 \tValidation Loss: 2.624421\n",
      "Epoch: 19 \tTraining Loss: 0.185710 \tValidation Loss: 2.630336\n",
      "Epoch: 20 \tTraining Loss: 0.166214 \tValidation Loss: 2.641747\n",
      "Epoch: 1 \tTraining Loss: 6.652801 \tValidation Loss: 5.183889\n",
      "Validation loss decreased (inf --> 5.18389).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.821271 \tValidation Loss: 4.933357\n",
      "Validation loss decreased (5.18389 --> 4.93336).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.275359 \tValidation Loss: 4.592891\n",
      "Validation loss decreased (4.93336 --> 4.59289).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.542557 \tValidation Loss: 4.184697\n",
      "Validation loss decreased (4.59289 --> 4.18470).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.714281 \tValidation Loss: 3.784657\n",
      "Validation loss decreased (4.18470 --> 3.78466).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.931702 \tValidation Loss: 3.452360\n",
      "Validation loss decreased (3.78466 --> 3.45236).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.281788 \tValidation Loss: 3.206378\n",
      "Validation loss decreased (3.45236 --> 3.20638).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.777049 \tValidation Loss: 3.029637\n",
      "Validation loss decreased (3.20638 --> 3.02964).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.393524 \tValidation Loss: 2.901981\n",
      "Validation loss decreased (3.02964 --> 2.90198).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.093915 \tValidation Loss: 2.811788\n",
      "Validation loss decreased (2.90198 --> 2.81179).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.861202 \tValidation Loss: 2.743723\n",
      "Validation loss decreased (2.81179 --> 2.74372).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.680029 \tValidation Loss: 2.695393\n",
      "Validation loss decreased (2.74372 --> 2.69539).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.538767 \tValidation Loss: 2.667803\n",
      "Validation loss decreased (2.69539 --> 2.66780).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.433025 \tValidation Loss: 2.652275\n",
      "Validation loss decreased (2.66780 --> 2.65228).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.353165 \tValidation Loss: 2.648636\n",
      "Validation loss decreased (2.65228 --> 2.64864).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.292852 \tValidation Loss: 2.651454\n",
      "Epoch: 17 \tTraining Loss: 0.245973 \tValidation Loss: 2.658604\n",
      "Epoch: 18 \tTraining Loss: 0.212257 \tValidation Loss: 2.671557\n",
      "Epoch: 19 \tTraining Loss: 0.184742 \tValidation Loss: 2.683169\n",
      "Epoch: 20 \tTraining Loss: 0.162763 \tValidation Loss: 2.696570\n",
      "Epoch: 1 \tTraining Loss: 6.650191 \tValidation Loss: 5.211260\n",
      "Validation loss decreased (inf --> 5.21126).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.812583 \tValidation Loss: 4.951061\n",
      "Validation loss decreased (5.21126 --> 4.95106).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.264690 \tValidation Loss: 4.599380\n",
      "Validation loss decreased (4.95106 --> 4.59938).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.524675 \tValidation Loss: 4.196446\n",
      "Validation loss decreased (4.59938 --> 4.19645).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.690046 \tValidation Loss: 3.818325\n",
      "Validation loss decreased (4.19645 --> 3.81832).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.910786 \tValidation Loss: 3.511603\n",
      "Validation loss decreased (3.81832 --> 3.51160).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.270315 \tValidation Loss: 3.274169\n",
      "Validation loss decreased (3.51160 --> 3.27417).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.774353 \tValidation Loss: 3.092160\n",
      "Validation loss decreased (3.27417 --> 3.09216).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.391740 \tValidation Loss: 2.956159\n",
      "Validation loss decreased (3.09216 --> 2.95616).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.094997 \tValidation Loss: 2.854224\n",
      "Validation loss decreased (2.95616 --> 2.85422).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.862800 \tValidation Loss: 2.783504\n",
      "Validation loss decreased (2.85422 --> 2.78350).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.679987 \tValidation Loss: 2.734469\n",
      "Validation loss decreased (2.78350 --> 2.73447).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.543144 \tValidation Loss: 2.703187\n",
      "Validation loss decreased (2.73447 --> 2.70319).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.437384 \tValidation Loss: 2.686092\n",
      "Validation loss decreased (2.70319 --> 2.68609).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.354045 \tValidation Loss: 2.678247\n",
      "Validation loss decreased (2.68609 --> 2.67825).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.294465 \tValidation Loss: 2.680594\n",
      "Epoch: 17 \tTraining Loss: 0.247096 \tValidation Loss: 2.690331\n",
      "Epoch: 18 \tTraining Loss: 0.214115 \tValidation Loss: 2.701151\n",
      "Epoch: 19 \tTraining Loss: 0.184906 \tValidation Loss: 2.717957\n",
      "Epoch: 20 \tTraining Loss: 0.165176 \tValidation Loss: 2.731500\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 3 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.060593 \tValidation Loss: 5.386400\n",
      "Validation loss decreased (inf --> 5.38640).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.561465 \tValidation Loss: 5.251041\n",
      "Validation loss decreased (5.38640 --> 5.25104).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.314022 \tValidation Loss: 5.072793\n",
      "Validation loss decreased (5.25104 --> 5.07279).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.987957 \tValidation Loss: 4.878831\n",
      "Validation loss decreased (5.07279 --> 4.87883).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.604848 \tValidation Loss: 4.692383\n",
      "Validation loss decreased (4.87883 --> 4.69238).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.201159 \tValidation Loss: 4.536295\n",
      "Validation loss decreased (4.69238 --> 4.53630).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.820167 \tValidation Loss: 4.420375\n",
      "Validation loss decreased (4.53630 --> 4.42038).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.488327 \tValidation Loss: 4.340857\n",
      "Validation loss decreased (4.42038 --> 4.34086).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.210709 \tValidation Loss: 4.289756\n",
      "Validation loss decreased (4.34086 --> 4.28976).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.980092 \tValidation Loss: 4.260511\n",
      "Validation loss decreased (4.28976 --> 4.26051).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.790264 \tValidation Loss: 4.247911\n",
      "Validation loss decreased (4.26051 --> 4.24791).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.634816 \tValidation Loss: 4.248715\n",
      "Epoch: 13 \tTraining Loss: 2.507234 \tValidation Loss: 4.257654\n",
      "Epoch: 14 \tTraining Loss: 2.400367 \tValidation Loss: 4.273331\n",
      "Epoch: 15 \tTraining Loss: 2.316326 \tValidation Loss: 4.292438\n",
      "Epoch: 16 \tTraining Loss: 2.241498 \tValidation Loss: 4.317910\n",
      "Epoch: 17 \tTraining Loss: 2.184519 \tValidation Loss: 4.344143\n",
      "Epoch: 18 \tTraining Loss: 2.130660 \tValidation Loss: 4.372535\n",
      "Epoch: 19 \tTraining Loss: 2.086465 \tValidation Loss: 4.400851\n",
      "Epoch: 20 \tTraining Loss: 2.048481 \tValidation Loss: 4.429601\n",
      "Epoch: 1 \tTraining Loss: 6.067218 \tValidation Loss: 5.363611\n",
      "Validation loss decreased (inf --> 5.36361).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.559372 \tValidation Loss: 5.217689\n",
      "Validation loss decreased (5.36361 --> 5.21769).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.309461 \tValidation Loss: 5.045713\n",
      "Validation loss decreased (5.21769 --> 5.04571).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.982630 \tValidation Loss: 4.863999\n",
      "Validation loss decreased (5.04571 --> 4.86400).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.600099 \tValidation Loss: 4.690968\n",
      "Validation loss decreased (4.86400 --> 4.69097).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.199779 \tValidation Loss: 4.548768\n",
      "Validation loss decreased (4.69097 --> 4.54877).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.821402 \tValidation Loss: 4.444216\n",
      "Validation loss decreased (4.54877 --> 4.44422).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.489226 \tValidation Loss: 4.375258\n",
      "Validation loss decreased (4.44422 --> 4.37526).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.210843 \tValidation Loss: 4.335210\n",
      "Validation loss decreased (4.37526 --> 4.33521).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.979205 \tValidation Loss: 4.314749\n",
      "Validation loss decreased (4.33521 --> 4.31475).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 \tTraining Loss: 2.788909 \tValidation Loss: 4.309131\n",
      "Validation loss decreased (4.31475 --> 4.30913).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.632560 \tValidation Loss: 4.313741\n",
      "Epoch: 13 \tTraining Loss: 2.504729 \tValidation Loss: 4.327376\n",
      "Epoch: 14 \tTraining Loss: 2.399368 \tValidation Loss: 4.346951\n",
      "Epoch: 15 \tTraining Loss: 2.314586 \tValidation Loss: 4.369634\n",
      "Epoch: 16 \tTraining Loss: 2.241797 \tValidation Loss: 4.395668\n",
      "Epoch: 17 \tTraining Loss: 2.181868 \tValidation Loss: 4.424498\n",
      "Epoch: 18 \tTraining Loss: 2.130760 \tValidation Loss: 4.453602\n",
      "Epoch: 19 \tTraining Loss: 2.086983 \tValidation Loss: 4.485979\n",
      "Epoch: 20 \tTraining Loss: 2.048886 \tValidation Loss: 4.518352\n",
      "Epoch: 1 \tTraining Loss: 6.060440 \tValidation Loss: 5.398031\n",
      "Validation loss decreased (inf --> 5.39803).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.554639 \tValidation Loss: 5.261236\n",
      "Validation loss decreased (5.39803 --> 5.26124).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.310211 \tValidation Loss: 5.088587\n",
      "Validation loss decreased (5.26124 --> 5.08859).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.983731 \tValidation Loss: 4.903879\n",
      "Validation loss decreased (5.08859 --> 4.90388).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.598489 \tValidation Loss: 4.724446\n",
      "Validation loss decreased (4.90388 --> 4.72445).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.194738 \tValidation Loss: 4.576568\n",
      "Validation loss decreased (4.72445 --> 4.57657).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.815353 \tValidation Loss: 4.469372\n",
      "Validation loss decreased (4.57657 --> 4.46937).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.485955 \tValidation Loss: 4.399683\n",
      "Validation loss decreased (4.46937 --> 4.39968).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.205862 \tValidation Loss: 4.360255\n",
      "Validation loss decreased (4.39968 --> 4.36026).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.976553 \tValidation Loss: 4.340755\n",
      "Validation loss decreased (4.36026 --> 4.34075).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.786764 \tValidation Loss: 4.336603\n",
      "Validation loss decreased (4.34075 --> 4.33660).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.629149 \tValidation Loss: 4.343119\n",
      "Epoch: 13 \tTraining Loss: 2.503110 \tValidation Loss: 4.358979\n",
      "Epoch: 14 \tTraining Loss: 2.399454 \tValidation Loss: 4.379566\n",
      "Epoch: 15 \tTraining Loss: 2.312584 \tValidation Loss: 4.405085\n",
      "Epoch: 16 \tTraining Loss: 2.241487 \tValidation Loss: 4.433727\n",
      "Epoch: 17 \tTraining Loss: 2.181516 \tValidation Loss: 4.466396\n",
      "Epoch: 18 \tTraining Loss: 2.129676 \tValidation Loss: 4.499585\n",
      "Epoch: 19 \tTraining Loss: 2.081460 \tValidation Loss: 4.535106\n",
      "Epoch: 20 \tTraining Loss: 2.046480 \tValidation Loss: 4.568636\n",
      "Epoch: 1 \tTraining Loss: 6.061893 \tValidation Loss: 5.394987\n",
      "Validation loss decreased (inf --> 5.39499).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.559803 \tValidation Loss: 5.257334\n",
      "Validation loss decreased (5.39499 --> 5.25733).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.315826 \tValidation Loss: 5.074945\n",
      "Validation loss decreased (5.25733 --> 5.07494).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.991647 \tValidation Loss: 4.881774\n",
      "Validation loss decreased (5.07494 --> 4.88177).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.606368 \tValidation Loss: 4.698470\n",
      "Validation loss decreased (4.88177 --> 4.69847).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.202694 \tValidation Loss: 4.545936\n",
      "Validation loss decreased (4.69847 --> 4.54594).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.823013 \tValidation Loss: 4.432829\n",
      "Validation loss decreased (4.54594 --> 4.43283).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.491981 \tValidation Loss: 4.357584\n",
      "Validation loss decreased (4.43283 --> 4.35758).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.212316 \tValidation Loss: 4.312075\n",
      "Validation loss decreased (4.35758 --> 4.31207).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.980030 \tValidation Loss: 4.290068\n",
      "Validation loss decreased (4.31207 --> 4.29007).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.790767 \tValidation Loss: 4.282900\n",
      "Validation loss decreased (4.29007 --> 4.28290).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.637573 \tValidation Loss: 4.286992\n",
      "Epoch: 13 \tTraining Loss: 2.509282 \tValidation Loss: 4.299820\n",
      "Epoch: 14 \tTraining Loss: 2.403962 \tValidation Loss: 4.317368\n",
      "Epoch: 15 \tTraining Loss: 2.317794 \tValidation Loss: 4.339455\n",
      "Epoch: 16 \tTraining Loss: 2.243744 \tValidation Loss: 4.368118\n",
      "Epoch: 17 \tTraining Loss: 2.182345 \tValidation Loss: 4.398348\n",
      "Epoch: 18 \tTraining Loss: 2.129619 \tValidation Loss: 4.428127\n",
      "Epoch: 19 \tTraining Loss: 2.086811 \tValidation Loss: 4.461617\n",
      "Epoch: 20 \tTraining Loss: 2.051444 \tValidation Loss: 4.495008\n",
      "Epoch: 1 \tTraining Loss: 6.060908 \tValidation Loss: 5.372577\n",
      "Validation loss decreased (inf --> 5.37258).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.561532 \tValidation Loss: 5.241391\n",
      "Validation loss decreased (5.37258 --> 5.24139).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.314202 \tValidation Loss: 5.065615\n",
      "Validation loss decreased (5.24139 --> 5.06562).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.984309 \tValidation Loss: 4.876680\n",
      "Validation loss decreased (5.06562 --> 4.87668).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.597123 \tValidation Loss: 4.696305\n",
      "Validation loss decreased (4.87668 --> 4.69631).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.195079 \tValidation Loss: 4.544627\n",
      "Validation loss decreased (4.69631 --> 4.54463).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.819447 \tValidation Loss: 4.434161\n",
      "Validation loss decreased (4.54463 --> 4.43416).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.489905 \tValidation Loss: 4.361734\n",
      "Validation loss decreased (4.43416 --> 4.36173).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.215554 \tValidation Loss: 4.318496\n",
      "Validation loss decreased (4.36173 --> 4.31850).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.982952 \tValidation Loss: 4.296970\n",
      "Validation loss decreased (4.31850 --> 4.29697).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.796908 \tValidation Loss: 4.289572\n",
      "Validation loss decreased (4.29697 --> 4.28957).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.637164 \tValidation Loss: 4.293883\n",
      "Epoch: 13 \tTraining Loss: 2.511731 \tValidation Loss: 4.306047\n",
      "Epoch: 14 \tTraining Loss: 2.408310 \tValidation Loss: 4.324857\n",
      "Epoch: 15 \tTraining Loss: 2.323505 \tValidation Loss: 4.346815\n",
      "Epoch: 16 \tTraining Loss: 2.247458 \tValidation Loss: 4.373022\n",
      "Epoch: 17 \tTraining Loss: 2.188458 \tValidation Loss: 4.402360\n",
      "Epoch: 18 \tTraining Loss: 2.133310 \tValidation Loss: 4.430662\n",
      "Epoch: 19 \tTraining Loss: 2.095004 \tValidation Loss: 4.459661\n",
      "Epoch: 20 \tTraining Loss: 2.053330 \tValidation Loss: 4.491286\n",
      "Epoch: 1 \tTraining Loss: 6.062486 \tValidation Loss: 5.375090\n",
      "Validation loss decreased (inf --> 5.37509).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.560631 \tValidation Loss: 5.232531\n",
      "Validation loss decreased (5.37509 --> 5.23253).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.318252 \tValidation Loss: 5.047833\n",
      "Validation loss decreased (5.23253 --> 5.04783).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.992137 \tValidation Loss: 4.844676\n",
      "Validation loss decreased (5.04783 --> 4.84468).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.607898 \tValidation Loss: 4.652310\n",
      "Validation loss decreased (4.84468 --> 4.65231).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.205705 \tValidation Loss: 4.493142\n",
      "Validation loss decreased (4.65231 --> 4.49314).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.828927 \tValidation Loss: 4.375799\n",
      "Validation loss decreased (4.49314 --> 4.37580).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.498873 \tValidation Loss: 4.294496\n",
      "Validation loss decreased (4.37580 --> 4.29450).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.221614 \tValidation Loss: 4.243645\n",
      "Validation loss decreased (4.29450 --> 4.24365).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.991327 \tValidation Loss: 4.214232\n",
      "Validation loss decreased (4.24365 --> 4.21423).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.797836 \tValidation Loss: 4.202785\n",
      "Validation loss decreased (4.21423 --> 4.20279).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.645126 \tValidation Loss: 4.203169\n",
      "Epoch: 13 \tTraining Loss: 2.517054 \tValidation Loss: 4.210946\n",
      "Epoch: 14 \tTraining Loss: 2.411442 \tValidation Loss: 4.228346\n",
      "Epoch: 15 \tTraining Loss: 2.321486 \tValidation Loss: 4.250110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 \tTraining Loss: 2.252162 \tValidation Loss: 4.274091\n",
      "Epoch: 17 \tTraining Loss: 2.190393 \tValidation Loss: 4.299767\n",
      "Epoch: 18 \tTraining Loss: 2.139206 \tValidation Loss: 4.327450\n",
      "Epoch: 19 \tTraining Loss: 2.095249 \tValidation Loss: 4.356952\n",
      "Epoch: 20 \tTraining Loss: 2.056545 \tValidation Loss: 4.388593\n",
      "Epoch: 1 \tTraining Loss: 6.057470 \tValidation Loss: 5.409010\n",
      "Validation loss decreased (inf --> 5.40901).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.555004 \tValidation Loss: 5.269162\n",
      "Validation loss decreased (5.40901 --> 5.26916).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.305924 \tValidation Loss: 5.094741\n",
      "Validation loss decreased (5.26916 --> 5.09474).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.981891 \tValidation Loss: 4.908140\n",
      "Validation loss decreased (5.09474 --> 4.90814).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.600681 \tValidation Loss: 4.724093\n",
      "Validation loss decreased (4.90814 --> 4.72409).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.200200 \tValidation Loss: 4.569060\n",
      "Validation loss decreased (4.72409 --> 4.56906).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.819982 \tValidation Loss: 4.452416\n",
      "Validation loss decreased (4.56906 --> 4.45242).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.487528 \tValidation Loss: 4.373532\n",
      "Validation loss decreased (4.45242 --> 4.37353).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.207896 \tValidation Loss: 4.324760\n",
      "Validation loss decreased (4.37353 --> 4.32476).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.975608 \tValidation Loss: 4.299882\n",
      "Validation loss decreased (4.32476 --> 4.29988).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.784869 \tValidation Loss: 4.291967\n",
      "Validation loss decreased (4.29988 --> 4.29197).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.628491 \tValidation Loss: 4.296313\n",
      "Epoch: 13 \tTraining Loss: 2.499022 \tValidation Loss: 4.309322\n",
      "Epoch: 14 \tTraining Loss: 2.399371 \tValidation Loss: 4.329352\n",
      "Epoch: 15 \tTraining Loss: 2.315642 \tValidation Loss: 4.353954\n",
      "Epoch: 16 \tTraining Loss: 2.240262 \tValidation Loss: 4.379689\n",
      "Epoch: 17 \tTraining Loss: 2.180336 \tValidation Loss: 4.408117\n",
      "Epoch: 18 \tTraining Loss: 2.131852 \tValidation Loss: 4.438589\n",
      "Epoch: 19 \tTraining Loss: 2.085451 \tValidation Loss: 4.471806\n",
      "Epoch: 20 \tTraining Loss: 2.046893 \tValidation Loss: 4.502646\n",
      "Epoch: 1 \tTraining Loss: 6.053387 \tValidation Loss: 5.392723\n",
      "Validation loss decreased (inf --> 5.39272).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.553591 \tValidation Loss: 5.251455\n",
      "Validation loss decreased (5.39272 --> 5.25146).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.308423 \tValidation Loss: 5.070565\n",
      "Validation loss decreased (5.25146 --> 5.07057).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.983755 \tValidation Loss: 4.874679\n",
      "Validation loss decreased (5.07057 --> 4.87468).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.603851 \tValidation Loss: 4.685476\n",
      "Validation loss decreased (4.87468 --> 4.68548).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.203856 \tValidation Loss: 4.527861\n",
      "Validation loss decreased (4.68548 --> 4.52786).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.827341 \tValidation Loss: 4.415116\n",
      "Validation loss decreased (4.52786 --> 4.41512).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.496915 \tValidation Loss: 4.340572\n",
      "Validation loss decreased (4.41512 --> 4.34057).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.215966 \tValidation Loss: 4.295772\n",
      "Validation loss decreased (4.34057 --> 4.29577).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.987881 \tValidation Loss: 4.270537\n",
      "Validation loss decreased (4.29577 --> 4.27054).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.798474 \tValidation Loss: 4.262140\n",
      "Validation loss decreased (4.27054 --> 4.26214).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.640809 \tValidation Loss: 4.265947\n",
      "Epoch: 13 \tTraining Loss: 2.514518 \tValidation Loss: 4.279727\n",
      "Epoch: 14 \tTraining Loss: 2.410626 \tValidation Loss: 4.299062\n",
      "Epoch: 15 \tTraining Loss: 2.324065 \tValidation Loss: 4.322289\n",
      "Epoch: 16 \tTraining Loss: 2.250817 \tValidation Loss: 4.349182\n",
      "Epoch: 17 \tTraining Loss: 2.192971 \tValidation Loss: 4.376908\n",
      "Epoch: 18 \tTraining Loss: 2.136341 \tValidation Loss: 4.407400\n",
      "Epoch: 19 \tTraining Loss: 2.091971 \tValidation Loss: 4.439029\n",
      "Epoch: 20 \tTraining Loss: 2.055704 \tValidation Loss: 4.469161\n",
      "Epoch: 1 \tTraining Loss: 6.061385 \tValidation Loss: 5.369916\n",
      "Validation loss decreased (inf --> 5.36992).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.566006 \tValidation Loss: 5.235826\n",
      "Validation loss decreased (5.36992 --> 5.23583).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.322513 \tValidation Loss: 5.065319\n",
      "Validation loss decreased (5.23583 --> 5.06532).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.997446 \tValidation Loss: 4.878582\n",
      "Validation loss decreased (5.06532 --> 4.87858).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.611202 \tValidation Loss: 4.696836\n",
      "Validation loss decreased (4.87858 --> 4.69684).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.203774 \tValidation Loss: 4.544402\n",
      "Validation loss decreased (4.69684 --> 4.54440).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.824171 \tValidation Loss: 4.433964\n",
      "Validation loss decreased (4.54440 --> 4.43396).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.488136 \tValidation Loss: 4.362592\n",
      "Validation loss decreased (4.43396 --> 4.36259).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.210508 \tValidation Loss: 4.319631\n",
      "Validation loss decreased (4.36259 --> 4.31963).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.979515 \tValidation Loss: 4.296981\n",
      "Validation loss decreased (4.31963 --> 4.29698).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.788963 \tValidation Loss: 4.289347\n",
      "Validation loss decreased (4.29698 --> 4.28935).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.636215 \tValidation Loss: 4.293835\n",
      "Epoch: 13 \tTraining Loss: 2.508549 \tValidation Loss: 4.306317\n",
      "Epoch: 14 \tTraining Loss: 2.404654 \tValidation Loss: 4.325804\n",
      "Epoch: 15 \tTraining Loss: 2.320234 \tValidation Loss: 4.348238\n",
      "Epoch: 16 \tTraining Loss: 2.251064 \tValidation Loss: 4.376700\n",
      "Epoch: 17 \tTraining Loss: 2.187001 \tValidation Loss: 4.405074\n",
      "Epoch: 18 \tTraining Loss: 2.134793 \tValidation Loss: 4.435287\n",
      "Epoch: 19 \tTraining Loss: 2.092026 \tValidation Loss: 4.466390\n",
      "Epoch: 20 \tTraining Loss: 2.051010 \tValidation Loss: 4.498138\n",
      "Epoch: 1 \tTraining Loss: 6.063001 \tValidation Loss: 5.341535\n",
      "Validation loss decreased (inf --> 5.34153).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.563479 \tValidation Loss: 5.200092\n",
      "Validation loss decreased (5.34153 --> 5.20009).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.316224 \tValidation Loss: 5.025261\n",
      "Validation loss decreased (5.20009 --> 5.02526).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.990275 \tValidation Loss: 4.834876\n",
      "Validation loss decreased (5.02526 --> 4.83488).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.607399 \tValidation Loss: 4.651021\n",
      "Validation loss decreased (4.83488 --> 4.65102).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.203801 \tValidation Loss: 4.499868\n",
      "Validation loss decreased (4.65102 --> 4.49987).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.825394 \tValidation Loss: 4.390017\n",
      "Validation loss decreased (4.49987 --> 4.39002).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.493286 \tValidation Loss: 4.316773\n",
      "Validation loss decreased (4.39002 --> 4.31677).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.211950 \tValidation Loss: 4.272979\n",
      "Validation loss decreased (4.31677 --> 4.27298).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.980574 \tValidation Loss: 4.249833\n",
      "Validation loss decreased (4.27298 --> 4.24983).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.789947 \tValidation Loss: 4.242056\n",
      "Validation loss decreased (4.24983 --> 4.24206).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.637337 \tValidation Loss: 4.244387\n",
      "Epoch: 13 \tTraining Loss: 2.510667 \tValidation Loss: 4.256280\n",
      "Epoch: 14 \tTraining Loss: 2.403152 \tValidation Loss: 4.272104\n",
      "Epoch: 15 \tTraining Loss: 2.321155 \tValidation Loss: 4.294621\n",
      "Epoch: 16 \tTraining Loss: 2.244995 \tValidation Loss: 4.319401\n",
      "Epoch: 17 \tTraining Loss: 2.184028 \tValidation Loss: 4.346720\n",
      "Epoch: 18 \tTraining Loss: 2.131337 \tValidation Loss: 4.375370\n",
      "Epoch: 19 \tTraining Loss: 2.087767 \tValidation Loss: 4.406489\n",
      "Epoch: 20 \tTraining Loss: 2.050702 \tValidation Loss: 4.438066\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 4 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 6.001582 \tValidation Loss: 5.227203\n",
      "Validation loss decreased (inf --> 5.22720).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.442060 \tValidation Loss: 5.011028\n",
      "Validation loss decreased (5.22720 --> 5.01103).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.051725 \tValidation Loss: 4.741380\n",
      "Validation loss decreased (5.01103 --> 4.74138).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.550277 \tValidation Loss: 4.460421\n",
      "Validation loss decreased (4.74138 --> 4.46042).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.007420 \tValidation Loss: 4.211595\n",
      "Validation loss decreased (4.46042 --> 4.21159).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.493914 \tValidation Loss: 4.015605\n",
      "Validation loss decreased (4.21159 --> 4.01561).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.055130 \tValidation Loss: 3.870418\n",
      "Validation loss decreased (4.01561 --> 3.87042).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.699114 \tValidation Loss: 3.766541\n",
      "Validation loss decreased (3.87042 --> 3.76654).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.413801 \tValidation Loss: 3.693611\n",
      "Validation loss decreased (3.76654 --> 3.69361).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.188207 \tValidation Loss: 3.645838\n",
      "Validation loss decreased (3.69361 --> 3.64584).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.006953 \tValidation Loss: 3.615284\n",
      "Validation loss decreased (3.64584 --> 3.61528).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.859243 \tValidation Loss: 3.597091\n",
      "Validation loss decreased (3.61528 --> 3.59709).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.739507 \tValidation Loss: 3.590695\n",
      "Validation loss decreased (3.59709 --> 3.59069).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.640977 \tValidation Loss: 3.594090\n",
      "Epoch: 15 \tTraining Loss: 1.557481 \tValidation Loss: 3.602247\n",
      "Epoch: 16 \tTraining Loss: 1.487488 \tValidation Loss: 3.616163\n",
      "Epoch: 17 \tTraining Loss: 1.428611 \tValidation Loss: 3.636439\n",
      "Epoch: 18 \tTraining Loss: 1.378639 \tValidation Loss: 3.659177\n",
      "Epoch: 19 \tTraining Loss: 1.329472 \tValidation Loss: 3.683744\n",
      "Epoch: 20 \tTraining Loss: 1.294917 \tValidation Loss: 3.711664\n",
      "Epoch: 1 \tTraining Loss: 5.992643 \tValidation Loss: 5.295649\n",
      "Validation loss decreased (inf --> 5.29565).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.430912 \tValidation Loss: 5.077281\n",
      "Validation loss decreased (5.29565 --> 5.07728).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.043353 \tValidation Loss: 4.800276\n",
      "Validation loss decreased (5.07728 --> 4.80028).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.545957 \tValidation Loss: 4.507621\n",
      "Validation loss decreased (4.80028 --> 4.50762).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.001355 \tValidation Loss: 4.246564\n",
      "Validation loss decreased (4.50762 --> 4.24656).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.488503 \tValidation Loss: 4.040211\n",
      "Validation loss decreased (4.24656 --> 4.04021).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.051380 \tValidation Loss: 3.889187\n",
      "Validation loss decreased (4.04021 --> 3.88919).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.691627 \tValidation Loss: 3.784408\n",
      "Validation loss decreased (3.88919 --> 3.78441).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.406473 \tValidation Loss: 3.715225\n",
      "Validation loss decreased (3.78441 --> 3.71522).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.179639 \tValidation Loss: 3.670619\n",
      "Validation loss decreased (3.71522 --> 3.67062).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.000844 \tValidation Loss: 3.645288\n",
      "Validation loss decreased (3.67062 --> 3.64529).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.851044 \tValidation Loss: 3.634230\n",
      "Validation loss decreased (3.64529 --> 3.63423).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.732000 \tValidation Loss: 3.635295\n",
      "Epoch: 14 \tTraining Loss: 1.633624 \tValidation Loss: 3.645377\n",
      "Epoch: 15 \tTraining Loss: 1.550302 \tValidation Loss: 3.657583\n",
      "Epoch: 16 \tTraining Loss: 1.477760 \tValidation Loss: 3.677217\n",
      "Epoch: 17 \tTraining Loss: 1.420319 \tValidation Loss: 3.700267\n",
      "Epoch: 18 \tTraining Loss: 1.370143 \tValidation Loss: 3.726310\n",
      "Epoch: 19 \tTraining Loss: 1.325354 \tValidation Loss: 3.753879\n",
      "Epoch: 20 \tTraining Loss: 1.285146 \tValidation Loss: 3.785204\n",
      "Epoch: 1 \tTraining Loss: 5.991726 \tValidation Loss: 5.286025\n",
      "Validation loss decreased (inf --> 5.28602).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.436320 \tValidation Loss: 5.069535\n",
      "Validation loss decreased (5.28602 --> 5.06953).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.053752 \tValidation Loss: 4.788409\n",
      "Validation loss decreased (5.06953 --> 4.78841).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.555947 \tValidation Loss: 4.492075\n",
      "Validation loss decreased (4.78841 --> 4.49208).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.008335 \tValidation Loss: 4.228879\n",
      "Validation loss decreased (4.49208 --> 4.22888).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.493005 \tValidation Loss: 4.022953\n",
      "Validation loss decreased (4.22888 --> 4.02295).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.051212 \tValidation Loss: 3.871301\n",
      "Validation loss decreased (4.02295 --> 3.87130).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.690596 \tValidation Loss: 3.763824\n",
      "Validation loss decreased (3.87130 --> 3.76382).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.405887 \tValidation Loss: 3.690887\n",
      "Validation loss decreased (3.76382 --> 3.69089).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.176551 \tValidation Loss: 3.642798\n",
      "Validation loss decreased (3.69089 --> 3.64280).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.995748 \tValidation Loss: 3.613466\n",
      "Validation loss decreased (3.64280 --> 3.61347).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.846939 \tValidation Loss: 3.598892\n",
      "Validation loss decreased (3.61347 --> 3.59889).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.729610 \tValidation Loss: 3.595466\n",
      "Validation loss decreased (3.59889 --> 3.59547).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.632976 \tValidation Loss: 3.598100\n",
      "Epoch: 15 \tTraining Loss: 1.545319 \tValidation Loss: 3.610461\n",
      "Epoch: 16 \tTraining Loss: 1.474703 \tValidation Loss: 3.630109\n",
      "Epoch: 17 \tTraining Loss: 1.418560 \tValidation Loss: 3.651060\n",
      "Epoch: 18 \tTraining Loss: 1.365801 \tValidation Loss: 3.676679\n",
      "Epoch: 19 \tTraining Loss: 1.323815 \tValidation Loss: 3.703044\n",
      "Epoch: 20 \tTraining Loss: 1.282871 \tValidation Loss: 3.734406\n",
      "Epoch: 1 \tTraining Loss: 5.991322 \tValidation Loss: 5.274035\n",
      "Validation loss decreased (inf --> 5.27404).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.435535 \tValidation Loss: 5.059975\n",
      "Validation loss decreased (5.27404 --> 5.05997).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.054323 \tValidation Loss: 4.779662\n",
      "Validation loss decreased (5.05997 --> 4.77966).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.555715 \tValidation Loss: 4.480300\n",
      "Validation loss decreased (4.77966 --> 4.48030).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.010084 \tValidation Loss: 4.218363\n",
      "Validation loss decreased (4.48030 --> 4.21836).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.498409 \tValidation Loss: 4.014960\n",
      "Validation loss decreased (4.21836 --> 4.01496).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.060413 \tValidation Loss: 3.862847\n",
      "Validation loss decreased (4.01496 --> 3.86285).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.706614 \tValidation Loss: 3.753709\n",
      "Validation loss decreased (3.86285 --> 3.75371).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.421443 \tValidation Loss: 3.676311\n",
      "Validation loss decreased (3.75371 --> 3.67631).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.194065 \tValidation Loss: 3.623802\n",
      "Validation loss decreased (3.67631 --> 3.62380).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.011418 \tValidation Loss: 3.589582\n",
      "Validation loss decreased (3.62380 --> 3.58958).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.868250 \tValidation Loss: 3.568526\n",
      "Validation loss decreased (3.58958 --> 3.56853).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.746959 \tValidation Loss: 3.560703\n",
      "Validation loss decreased (3.56853 --> 3.56070).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.646752 \tValidation Loss: 3.560326\n",
      "Validation loss decreased (3.56070 --> 3.56033).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.565089 \tValidation Loss: 3.570141\n",
      "Epoch: 16 \tTraining Loss: 1.493624 \tValidation Loss: 3.583392\n",
      "Epoch: 17 \tTraining Loss: 1.436124 \tValidation Loss: 3.600843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 \tTraining Loss: 1.385524 \tValidation Loss: 3.622333\n",
      "Epoch: 19 \tTraining Loss: 1.339248 \tValidation Loss: 3.644580\n",
      "Epoch: 20 \tTraining Loss: 1.298734 \tValidation Loss: 3.672305\n",
      "Epoch: 1 \tTraining Loss: 5.984845 \tValidation Loss: 5.252504\n",
      "Validation loss decreased (inf --> 5.25250).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.434978 \tValidation Loss: 5.039206\n",
      "Validation loss decreased (5.25250 --> 5.03921).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.052935 \tValidation Loss: 4.763868\n",
      "Validation loss decreased (5.03921 --> 4.76387).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.555809 \tValidation Loss: 4.468674\n",
      "Validation loss decreased (4.76387 --> 4.46867).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.011554 \tValidation Loss: 4.210672\n",
      "Validation loss decreased (4.46867 --> 4.21067).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.500109 \tValidation Loss: 4.008005\n",
      "Validation loss decreased (4.21067 --> 4.00801).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.061686 \tValidation Loss: 3.857463\n",
      "Validation loss decreased (4.00801 --> 3.85746).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.706204 \tValidation Loss: 3.750852\n",
      "Validation loss decreased (3.85746 --> 3.75085).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.414715 \tValidation Loss: 3.676925\n",
      "Validation loss decreased (3.75085 --> 3.67692).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.189222 \tValidation Loss: 3.627293\n",
      "Validation loss decreased (3.67692 --> 3.62729).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.008333 \tValidation Loss: 3.595947\n",
      "Validation loss decreased (3.62729 --> 3.59595).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.858781 \tValidation Loss: 3.578425\n",
      "Validation loss decreased (3.59595 --> 3.57843).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.742402 \tValidation Loss: 3.572695\n",
      "Validation loss decreased (3.57843 --> 3.57270).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.639813 \tValidation Loss: 3.575184\n",
      "Epoch: 15 \tTraining Loss: 1.556240 \tValidation Loss: 3.585337\n",
      "Epoch: 16 \tTraining Loss: 1.488437 \tValidation Loss: 3.601474\n",
      "Epoch: 17 \tTraining Loss: 1.426457 \tValidation Loss: 3.621328\n",
      "Epoch: 18 \tTraining Loss: 1.374295 \tValidation Loss: 3.644694\n",
      "Epoch: 19 \tTraining Loss: 1.329816 \tValidation Loss: 3.670281\n",
      "Epoch: 20 \tTraining Loss: 1.294475 \tValidation Loss: 3.697331\n",
      "Epoch: 1 \tTraining Loss: 5.985126 \tValidation Loss: 5.269190\n",
      "Validation loss decreased (inf --> 5.26919).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.434381 \tValidation Loss: 5.050033\n",
      "Validation loss decreased (5.26919 --> 5.05003).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.053828 \tValidation Loss: 4.767700\n",
      "Validation loss decreased (5.05003 --> 4.76770).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.558654 \tValidation Loss: 4.465533\n",
      "Validation loss decreased (4.76770 --> 4.46553).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.015678 \tValidation Loss: 4.201175\n",
      "Validation loss decreased (4.46553 --> 4.20117).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.500443 \tValidation Loss: 3.996011\n",
      "Validation loss decreased (4.20117 --> 3.99601).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.061283 \tValidation Loss: 3.843555\n",
      "Validation loss decreased (3.99601 --> 3.84356).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.702864 \tValidation Loss: 3.733962\n",
      "Validation loss decreased (3.84356 --> 3.73396).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.418336 \tValidation Loss: 3.658979\n",
      "Validation loss decreased (3.73396 --> 3.65898).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.189286 \tValidation Loss: 3.607390\n",
      "Validation loss decreased (3.65898 --> 3.60739).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.008870 \tValidation Loss: 3.577030\n",
      "Validation loss decreased (3.60739 --> 3.57703).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.860837 \tValidation Loss: 3.561285\n",
      "Validation loss decreased (3.57703 --> 3.56129).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.736929 \tValidation Loss: 3.556984\n",
      "Validation loss decreased (3.56129 --> 3.55698).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.640189 \tValidation Loss: 3.561253\n",
      "Epoch: 15 \tTraining Loss: 1.557842 \tValidation Loss: 3.569795\n",
      "Epoch: 16 \tTraining Loss: 1.485690 \tValidation Loss: 3.586337\n",
      "Epoch: 17 \tTraining Loss: 1.427493 \tValidation Loss: 3.607677\n",
      "Epoch: 18 \tTraining Loss: 1.375795 \tValidation Loss: 3.632767\n",
      "Epoch: 19 \tTraining Loss: 1.332471 \tValidation Loss: 3.659376\n",
      "Epoch: 20 \tTraining Loss: 1.296772 \tValidation Loss: 3.687455\n",
      "Epoch: 1 \tTraining Loss: 5.991744 \tValidation Loss: 5.253877\n",
      "Validation loss decreased (inf --> 5.25388).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.437930 \tValidation Loss: 5.043886\n",
      "Validation loss decreased (5.25388 --> 5.04389).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.051583 \tValidation Loss: 4.774938\n",
      "Validation loss decreased (5.04389 --> 4.77494).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.549831 \tValidation Loss: 4.490008\n",
      "Validation loss decreased (4.77494 --> 4.49001).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.005803 \tValidation Loss: 4.242737\n",
      "Validation loss decreased (4.49001 --> 4.24274).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.495162 \tValidation Loss: 4.052512\n",
      "Validation loss decreased (4.24274 --> 4.05251).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.057145 \tValidation Loss: 3.912546\n",
      "Validation loss decreased (4.05251 --> 3.91255).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.700320 \tValidation Loss: 3.813348\n",
      "Validation loss decreased (3.91255 --> 3.81335).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.415869 \tValidation Loss: 3.744283\n",
      "Validation loss decreased (3.81335 --> 3.74428).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.188704 \tValidation Loss: 3.697703\n",
      "Validation loss decreased (3.74428 --> 3.69770).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.003659 \tValidation Loss: 3.669919\n",
      "Validation loss decreased (3.69770 --> 3.66992).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.859279 \tValidation Loss: 3.654862\n",
      "Validation loss decreased (3.66992 --> 3.65486).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.735173 \tValidation Loss: 3.651265\n",
      "Validation loss decreased (3.65486 --> 3.65127).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.639273 \tValidation Loss: 3.655359\n",
      "Epoch: 15 \tTraining Loss: 1.556292 \tValidation Loss: 3.666433\n",
      "Epoch: 16 \tTraining Loss: 1.484810 \tValidation Loss: 3.683719\n",
      "Epoch: 17 \tTraining Loss: 1.425039 \tValidation Loss: 3.703898\n",
      "Epoch: 18 \tTraining Loss: 1.371651 \tValidation Loss: 3.731015\n",
      "Epoch: 19 \tTraining Loss: 1.326766 \tValidation Loss: 3.755781\n",
      "Epoch: 20 \tTraining Loss: 1.291164 \tValidation Loss: 3.786339\n",
      "Epoch: 1 \tTraining Loss: 5.996032 \tValidation Loss: 5.255439\n",
      "Validation loss decreased (inf --> 5.25544).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.441918 \tValidation Loss: 5.040928\n",
      "Validation loss decreased (5.25544 --> 5.04093).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.064297 \tValidation Loss: 4.759060\n",
      "Validation loss decreased (5.04093 --> 4.75906).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.567788 \tValidation Loss: 4.461153\n",
      "Validation loss decreased (4.75906 --> 4.46115).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.020012 \tValidation Loss: 4.202794\n",
      "Validation loss decreased (4.46115 --> 4.20279).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.503831 \tValidation Loss: 4.005985\n",
      "Validation loss decreased (4.20279 --> 4.00599).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.063936 \tValidation Loss: 3.862312\n",
      "Validation loss decreased (4.00599 --> 3.86231).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.708258 \tValidation Loss: 3.759020\n",
      "Validation loss decreased (3.86231 --> 3.75902).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.423049 \tValidation Loss: 3.686387\n",
      "Validation loss decreased (3.75902 --> 3.68639).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.194541 \tValidation Loss: 3.636400\n",
      "Validation loss decreased (3.68639 --> 3.63640).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.010667 \tValidation Loss: 3.602049\n",
      "Validation loss decreased (3.63640 --> 3.60205).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.864923 \tValidation Loss: 3.580979\n",
      "Validation loss decreased (3.60205 --> 3.58098).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.743740 \tValidation Loss: 3.572455\n",
      "Validation loss decreased (3.58098 --> 3.57246).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.645346 \tValidation Loss: 3.572197\n",
      "Validation loss decreased (3.57246 --> 3.57220).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 \tTraining Loss: 1.562105 \tValidation Loss: 3.578940\n",
      "Epoch: 16 \tTraining Loss: 1.492785 \tValidation Loss: 3.592496\n",
      "Epoch: 17 \tTraining Loss: 1.429093 \tValidation Loss: 3.610846\n",
      "Epoch: 18 \tTraining Loss: 1.380280 \tValidation Loss: 3.629347\n",
      "Epoch: 19 \tTraining Loss: 1.334066 \tValidation Loss: 3.654851\n",
      "Epoch: 20 \tTraining Loss: 1.295432 \tValidation Loss: 3.684747\n",
      "Epoch: 1 \tTraining Loss: 6.002129 \tValidation Loss: 5.247319\n",
      "Validation loss decreased (inf --> 5.24732).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.441111 \tValidation Loss: 5.033817\n",
      "Validation loss decreased (5.24732 --> 5.03382).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.056089 \tValidation Loss: 4.760374\n",
      "Validation loss decreased (5.03382 --> 4.76037).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.555835 \tValidation Loss: 4.468806\n",
      "Validation loss decreased (4.76037 --> 4.46881).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.012451 \tValidation Loss: 4.213418\n",
      "Validation loss decreased (4.46881 --> 4.21342).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.501788 \tValidation Loss: 4.014651\n",
      "Validation loss decreased (4.21342 --> 4.01465).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.062063 \tValidation Loss: 3.865268\n",
      "Validation loss decreased (4.01465 --> 3.86527).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.703174 \tValidation Loss: 3.757907\n",
      "Validation loss decreased (3.86527 --> 3.75791).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.417811 \tValidation Loss: 3.684924\n",
      "Validation loss decreased (3.75791 --> 3.68492).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.188971 \tValidation Loss: 3.635859\n",
      "Validation loss decreased (3.68492 --> 3.63586).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.004543 \tValidation Loss: 3.608192\n",
      "Validation loss decreased (3.63586 --> 3.60819).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.855854 \tValidation Loss: 3.593379\n",
      "Validation loss decreased (3.60819 --> 3.59338).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.735466 \tValidation Loss: 3.590291\n",
      "Validation loss decreased (3.59338 --> 3.59029).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.639110 \tValidation Loss: 3.595021\n",
      "Epoch: 15 \tTraining Loss: 1.553991 \tValidation Loss: 3.606295\n",
      "Epoch: 16 \tTraining Loss: 1.481660 \tValidation Loss: 3.626998\n",
      "Epoch: 17 \tTraining Loss: 1.422688 \tValidation Loss: 3.646732\n",
      "Epoch: 18 \tTraining Loss: 1.369896 \tValidation Loss: 3.672686\n",
      "Epoch: 19 \tTraining Loss: 1.325220 \tValidation Loss: 3.699502\n",
      "Epoch: 20 \tTraining Loss: 1.290970 \tValidation Loss: 3.728928\n",
      "Epoch: 1 \tTraining Loss: 5.983742 \tValidation Loss: 5.237164\n",
      "Validation loss decreased (inf --> 5.23716).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.435753 \tValidation Loss: 5.034617\n",
      "Validation loss decreased (5.23716 --> 5.03462).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.057819 \tValidation Loss: 4.765677\n",
      "Validation loss decreased (5.03462 --> 4.76568).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.564205 \tValidation Loss: 4.476056\n",
      "Validation loss decreased (4.76568 --> 4.47606).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.023871 \tValidation Loss: 4.217875\n",
      "Validation loss decreased (4.47606 --> 4.21787).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.509949 \tValidation Loss: 4.013993\n",
      "Validation loss decreased (4.21787 --> 4.01399).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.070627 \tValidation Loss: 3.861661\n",
      "Validation loss decreased (4.01399 --> 3.86166).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.711061 \tValidation Loss: 3.752916\n",
      "Validation loss decreased (3.86166 --> 3.75292).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.423902 \tValidation Loss: 3.678036\n",
      "Validation loss decreased (3.75292 --> 3.67804).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.197947 \tValidation Loss: 3.628585\n",
      "Validation loss decreased (3.67804 --> 3.62859).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.014872 \tValidation Loss: 3.598674\n",
      "Validation loss decreased (3.62859 --> 3.59867).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.863853 \tValidation Loss: 3.584298\n",
      "Validation loss decreased (3.59867 --> 3.58430).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.744577 \tValidation Loss: 3.580919\n",
      "Validation loss decreased (3.58430 --> 3.58092).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.641096 \tValidation Loss: 3.587518\n",
      "Epoch: 15 \tTraining Loss: 1.559942 \tValidation Loss: 3.601259\n",
      "Epoch: 16 \tTraining Loss: 1.486123 \tValidation Loss: 3.619534\n",
      "Epoch: 17 \tTraining Loss: 1.432199 \tValidation Loss: 3.641769\n",
      "Epoch: 18 \tTraining Loss: 1.377708 \tValidation Loss: 3.666361\n",
      "Epoch: 19 \tTraining Loss: 1.332794 \tValidation Loss: 3.694997\n",
      "Epoch: 20 \tTraining Loss: 1.292534 \tValidation Loss: 3.724366\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 5 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 5.958082 \tValidation Loss: 5.491712\n",
      "Validation loss decreased (inf --> 5.49171).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.348917 \tValidation Loss: 5.203316\n",
      "Validation loss decreased (5.49171 --> 5.20332).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.876805 \tValidation Loss: 4.821548\n",
      "Validation loss decreased (5.20332 --> 4.82155).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.273349 \tValidation Loss: 4.430018\n",
      "Validation loss decreased (4.82155 --> 4.43002).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.648519 \tValidation Loss: 4.096835\n",
      "Validation loss decreased (4.43002 --> 4.09684).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.085790 \tValidation Loss: 3.839130\n",
      "Validation loss decreased (4.09684 --> 3.83913).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.622285 \tValidation Loss: 3.648803\n",
      "Validation loss decreased (3.83913 --> 3.64880).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.252832 \tValidation Loss: 3.511330\n",
      "Validation loss decreased (3.64880 --> 3.51133).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.966062 \tValidation Loss: 3.413790\n",
      "Validation loss decreased (3.51133 --> 3.41379).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.738149 \tValidation Loss: 3.348666\n",
      "Validation loss decreased (3.41379 --> 3.34867).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.562575 \tValidation Loss: 3.304046\n",
      "Validation loss decreased (3.34867 --> 3.30405).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.415952 \tValidation Loss: 3.277043\n",
      "Validation loss decreased (3.30405 --> 3.27704).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.301513 \tValidation Loss: 3.261381\n",
      "Validation loss decreased (3.27704 --> 3.26138).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.201848 \tValidation Loss: 3.259365\n",
      "Validation loss decreased (3.26138 --> 3.25937).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.120095 \tValidation Loss: 3.267759\n",
      "Epoch: 16 \tTraining Loss: 1.047753 \tValidation Loss: 3.277162\n",
      "Epoch: 17 \tTraining Loss: 0.994015 \tValidation Loss: 3.297492\n",
      "Epoch: 18 \tTraining Loss: 0.942456 \tValidation Loss: 3.320948\n",
      "Epoch: 19 \tTraining Loss: 0.900361 \tValidation Loss: 3.343510\n",
      "Epoch: 20 \tTraining Loss: 0.861808 \tValidation Loss: 3.375887\n",
      "Epoch: 1 \tTraining Loss: 5.948312 \tValidation Loss: 5.543644\n",
      "Validation loss decreased (inf --> 5.54364).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.342735 \tValidation Loss: 5.255627\n",
      "Validation loss decreased (5.54364 --> 5.25563).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.864855 \tValidation Loss: 4.882471\n",
      "Validation loss decreased (5.25563 --> 4.88247).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.260218 \tValidation Loss: 4.500496\n",
      "Validation loss decreased (4.88247 --> 4.50050).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.637341 \tValidation Loss: 4.173448\n",
      "Validation loss decreased (4.50050 --> 4.17345).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.072845 \tValidation Loss: 3.921418\n",
      "Validation loss decreased (4.17345 --> 3.92142).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.612445 \tValidation Loss: 3.734542\n",
      "Validation loss decreased (3.92142 --> 3.73454).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.245761 \tValidation Loss: 3.599109\n",
      "Validation loss decreased (3.73454 --> 3.59911).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.957394 \tValidation Loss: 3.506659\n",
      "Validation loss decreased (3.59911 --> 3.50666).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.735336 \tValidation Loss: 3.443109\n",
      "Validation loss decreased (3.50666 --> 3.44311).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.554963 \tValidation Loss: 3.403658\n",
      "Validation loss decreased (3.44311 --> 3.40366).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.414051 \tValidation Loss: 3.379492\n",
      "Validation loss decreased (3.40366 --> 3.37949).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 \tTraining Loss: 1.296424 \tValidation Loss: 3.370471\n",
      "Validation loss decreased (3.37949 --> 3.37047).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.199493 \tValidation Loss: 3.369902\n",
      "Validation loss decreased (3.37047 --> 3.36990).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.118067 \tValidation Loss: 3.379089\n",
      "Epoch: 16 \tTraining Loss: 1.051006 \tValidation Loss: 3.393110\n",
      "Epoch: 17 \tTraining Loss: 0.992352 \tValidation Loss: 3.412065\n",
      "Epoch: 18 \tTraining Loss: 0.938962 \tValidation Loss: 3.439238\n",
      "Epoch: 19 \tTraining Loss: 0.898762 \tValidation Loss: 3.464174\n",
      "Epoch: 20 \tTraining Loss: 0.860432 \tValidation Loss: 3.495196\n",
      "Epoch: 1 \tTraining Loss: 5.956664 \tValidation Loss: 5.495702\n",
      "Validation loss decreased (inf --> 5.49570).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.342237 \tValidation Loss: 5.198994\n",
      "Validation loss decreased (5.49570 --> 5.19899).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.862377 \tValidation Loss: 4.831705\n",
      "Validation loss decreased (5.19899 --> 4.83171).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.257930 \tValidation Loss: 4.460003\n",
      "Validation loss decreased (4.83171 --> 4.46000).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.632129 \tValidation Loss: 4.142121\n",
      "Validation loss decreased (4.46000 --> 4.14212).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.074680 \tValidation Loss: 3.891472\n",
      "Validation loss decreased (4.14212 --> 3.89147).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.613504 \tValidation Loss: 3.704474\n",
      "Validation loss decreased (3.89147 --> 3.70447).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.248851 \tValidation Loss: 3.567960\n",
      "Validation loss decreased (3.70447 --> 3.56796).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.964394 \tValidation Loss: 3.469001\n",
      "Validation loss decreased (3.56796 --> 3.46900).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.737549 \tValidation Loss: 3.400972\n",
      "Validation loss decreased (3.46900 --> 3.40097).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.557032 \tValidation Loss: 3.354242\n",
      "Validation loss decreased (3.40097 --> 3.35424).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.412275 \tValidation Loss: 3.327199\n",
      "Validation loss decreased (3.35424 --> 3.32720).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.293125 \tValidation Loss: 3.313089\n",
      "Validation loss decreased (3.32720 --> 3.31309).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.199168 \tValidation Loss: 3.308470\n",
      "Validation loss decreased (3.31309 --> 3.30847).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.117703 \tValidation Loss: 3.315915\n",
      "Epoch: 16 \tTraining Loss: 1.049850 \tValidation Loss: 3.325852\n",
      "Epoch: 17 \tTraining Loss: 0.989524 \tValidation Loss: 3.349266\n",
      "Epoch: 18 \tTraining Loss: 0.935905 \tValidation Loss: 3.370853\n",
      "Epoch: 19 \tTraining Loss: 0.896583 \tValidation Loss: 3.397608\n",
      "Epoch: 20 \tTraining Loss: 0.855866 \tValidation Loss: 3.425806\n",
      "Epoch: 1 \tTraining Loss: 5.959743 \tValidation Loss: 5.468749\n",
      "Validation loss decreased (inf --> 5.46875).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.342148 \tValidation Loss: 5.179766\n",
      "Validation loss decreased (5.46875 --> 5.17977).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.861061 \tValidation Loss: 4.812343\n",
      "Validation loss decreased (5.17977 --> 4.81234).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.255564 \tValidation Loss: 4.444951\n",
      "Validation loss decreased (4.81234 --> 4.44495).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.630129 \tValidation Loss: 4.129641\n",
      "Validation loss decreased (4.44495 --> 4.12964).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.069797 \tValidation Loss: 3.883951\n",
      "Validation loss decreased (4.12964 --> 3.88395).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.608692 \tValidation Loss: 3.701333\n",
      "Validation loss decreased (3.88395 --> 3.70133).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.244619 \tValidation Loss: 3.565819\n",
      "Validation loss decreased (3.70133 --> 3.56582).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.959477 \tValidation Loss: 3.469432\n",
      "Validation loss decreased (3.56582 --> 3.46943).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.735994 \tValidation Loss: 3.401057\n",
      "Validation loss decreased (3.46943 --> 3.40106).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.558199 \tValidation Loss: 3.356132\n",
      "Validation loss decreased (3.40106 --> 3.35613).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.415624 \tValidation Loss: 3.327904\n",
      "Validation loss decreased (3.35613 --> 3.32790).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.297377 \tValidation Loss: 3.312934\n",
      "Validation loss decreased (3.32790 --> 3.31293).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.200402 \tValidation Loss: 3.308939\n",
      "Validation loss decreased (3.31293 --> 3.30894).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.120167 \tValidation Loss: 3.313051\n",
      "Epoch: 16 \tTraining Loss: 1.052040 \tValidation Loss: 3.325074\n",
      "Epoch: 17 \tTraining Loss: 0.993336 \tValidation Loss: 3.338407\n",
      "Epoch: 18 \tTraining Loss: 0.944500 \tValidation Loss: 3.358311\n",
      "Epoch: 19 \tTraining Loss: 0.898547 \tValidation Loss: 3.384334\n",
      "Epoch: 20 \tTraining Loss: 0.863217 \tValidation Loss: 3.411228\n",
      "Epoch: 1 \tTraining Loss: 5.960387 \tValidation Loss: 5.489376\n",
      "Validation loss decreased (inf --> 5.48938).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.351598 \tValidation Loss: 5.204068\n",
      "Validation loss decreased (5.48938 --> 5.20407).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.874805 \tValidation Loss: 4.828290\n",
      "Validation loss decreased (5.20407 --> 4.82829).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.264260 \tValidation Loss: 4.448632\n",
      "Validation loss decreased (4.82829 --> 4.44863).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.631081 \tValidation Loss: 4.133999\n",
      "Validation loss decreased (4.44863 --> 4.13400).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.064133 \tValidation Loss: 3.896397\n",
      "Validation loss decreased (4.13400 --> 3.89640).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.602408 \tValidation Loss: 3.721776\n",
      "Validation loss decreased (3.89640 --> 3.72178).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.238896 \tValidation Loss: 3.593235\n",
      "Validation loss decreased (3.72178 --> 3.59324).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.952807 \tValidation Loss: 3.502133\n",
      "Validation loss decreased (3.59324 --> 3.50213).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.732104 \tValidation Loss: 3.436441\n",
      "Validation loss decreased (3.50213 --> 3.43644).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.552285 \tValidation Loss: 3.391712\n",
      "Validation loss decreased (3.43644 --> 3.39171).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.408966 \tValidation Loss: 3.363829\n",
      "Validation loss decreased (3.39171 --> 3.36383).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.292206 \tValidation Loss: 3.349481\n",
      "Validation loss decreased (3.36383 --> 3.34948).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.198031 \tValidation Loss: 3.344632\n",
      "Validation loss decreased (3.34948 --> 3.34463).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.115808 \tValidation Loss: 3.347745\n",
      "Epoch: 16 \tTraining Loss: 1.048458 \tValidation Loss: 3.361842\n",
      "Epoch: 17 \tTraining Loss: 0.988897 \tValidation Loss: 3.376075\n",
      "Epoch: 18 \tTraining Loss: 0.938042 \tValidation Loss: 3.402470\n",
      "Epoch: 19 \tTraining Loss: 0.894566 \tValidation Loss: 3.428420\n",
      "Epoch: 20 \tTraining Loss: 0.854937 \tValidation Loss: 3.452521\n",
      "Epoch: 1 \tTraining Loss: 5.954163 \tValidation Loss: 5.523823\n",
      "Validation loss decreased (inf --> 5.52382).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.340477 \tValidation Loss: 5.246261\n",
      "Validation loss decreased (5.52382 --> 5.24626).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.867719 \tValidation Loss: 4.876334\n",
      "Validation loss decreased (5.24626 --> 4.87633).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.269073 \tValidation Loss: 4.494087\n",
      "Validation loss decreased (4.87633 --> 4.49409).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.644175 \tValidation Loss: 4.161418\n",
      "Validation loss decreased (4.49409 --> 4.16142).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.084504 \tValidation Loss: 3.898968\n",
      "Validation loss decreased (4.16142 --> 3.89897).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.621473 \tValidation Loss: 3.704503\n",
      "Validation loss decreased (3.89897 --> 3.70450).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.253448 \tValidation Loss: 3.564659\n",
      "Validation loss decreased (3.70450 --> 3.56466).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.965706 \tValidation Loss: 3.466674\n",
      "Validation loss decreased (3.56466 --> 3.46667).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 \tTraining Loss: 1.741540 \tValidation Loss: 3.398999\n",
      "Validation loss decreased (3.46667 --> 3.39900).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.561724 \tValidation Loss: 3.353251\n",
      "Validation loss decreased (3.39900 --> 3.35325).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.419703 \tValidation Loss: 3.324570\n",
      "Validation loss decreased (3.35325 --> 3.32457).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.304996 \tValidation Loss: 3.305555\n",
      "Validation loss decreased (3.32457 --> 3.30555).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.203239 \tValidation Loss: 3.300274\n",
      "Validation loss decreased (3.30555 --> 3.30027).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.119525 \tValidation Loss: 3.302441\n",
      "Epoch: 16 \tTraining Loss: 1.053198 \tValidation Loss: 3.309125\n",
      "Epoch: 17 \tTraining Loss: 0.997165 \tValidation Loss: 3.324840\n",
      "Epoch: 18 \tTraining Loss: 0.944747 \tValidation Loss: 3.341864\n",
      "Epoch: 19 \tTraining Loss: 0.898986 \tValidation Loss: 3.367007\n",
      "Epoch: 20 \tTraining Loss: 0.860351 \tValidation Loss: 3.390999\n",
      "Epoch: 1 \tTraining Loss: 5.957682 \tValidation Loss: 5.497510\n",
      "Validation loss decreased (inf --> 5.49751).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.347970 \tValidation Loss: 5.209001\n",
      "Validation loss decreased (5.49751 --> 5.20900).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.871725 \tValidation Loss: 4.835069\n",
      "Validation loss decreased (5.20900 --> 4.83507).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.267149 \tValidation Loss: 4.448989\n",
      "Validation loss decreased (4.83507 --> 4.44899).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.642297 \tValidation Loss: 4.118798\n",
      "Validation loss decreased (4.44899 --> 4.11880).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.078673 \tValidation Loss: 3.865853\n",
      "Validation loss decreased (4.11880 --> 3.86585).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.614686 \tValidation Loss: 3.681065\n",
      "Validation loss decreased (3.86585 --> 3.68106).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.252398 \tValidation Loss: 3.545497\n",
      "Validation loss decreased (3.68106 --> 3.54550).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.965817 \tValidation Loss: 3.449074\n",
      "Validation loss decreased (3.54550 --> 3.44907).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.744634 \tValidation Loss: 3.383005\n",
      "Validation loss decreased (3.44907 --> 3.38300).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.565743 \tValidation Loss: 3.338644\n",
      "Validation loss decreased (3.38300 --> 3.33864).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.420260 \tValidation Loss: 3.312059\n",
      "Validation loss decreased (3.33864 --> 3.31206).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.301523 \tValidation Loss: 3.295535\n",
      "Validation loss decreased (3.31206 --> 3.29553).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.204232 \tValidation Loss: 3.292191\n",
      "Validation loss decreased (3.29553 --> 3.29219).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.122447 \tValidation Loss: 3.295690\n",
      "Epoch: 16 \tTraining Loss: 1.056583 \tValidation Loss: 3.304542\n",
      "Epoch: 17 \tTraining Loss: 0.996848 \tValidation Loss: 3.324008\n",
      "Epoch: 18 \tTraining Loss: 0.948245 \tValidation Loss: 3.343259\n",
      "Epoch: 19 \tTraining Loss: 0.905426 \tValidation Loss: 3.367859\n",
      "Epoch: 20 \tTraining Loss: 0.862716 \tValidation Loss: 3.396914\n",
      "Epoch: 1 \tTraining Loss: 5.960283 \tValidation Loss: 5.481085\n",
      "Validation loss decreased (inf --> 5.48109).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.349406 \tValidation Loss: 5.182435\n",
      "Validation loss decreased (5.48109 --> 5.18244).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.876033 \tValidation Loss: 4.797188\n",
      "Validation loss decreased (5.18244 --> 4.79719).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.270055 \tValidation Loss: 4.411856\n",
      "Validation loss decreased (4.79719 --> 4.41186).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.640270 \tValidation Loss: 4.089525\n",
      "Validation loss decreased (4.41186 --> 4.08953).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.078059 \tValidation Loss: 3.840636\n",
      "Validation loss decreased (4.08953 --> 3.84064).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.614492 \tValidation Loss: 3.657061\n",
      "Validation loss decreased (3.84064 --> 3.65706).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.246171 \tValidation Loss: 3.526562\n",
      "Validation loss decreased (3.65706 --> 3.52656).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.960732 \tValidation Loss: 3.436426\n",
      "Validation loss decreased (3.52656 --> 3.43643).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.738717 \tValidation Loss: 3.376220\n",
      "Validation loss decreased (3.43643 --> 3.37622).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.560276 \tValidation Loss: 3.335945\n",
      "Validation loss decreased (3.37622 --> 3.33594).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.418351 \tValidation Loss: 3.310986\n",
      "Validation loss decreased (3.33594 --> 3.31099).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.299153 \tValidation Loss: 3.301003\n",
      "Validation loss decreased (3.31099 --> 3.30100).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.199071 \tValidation Loss: 3.298624\n",
      "Validation loss decreased (3.30100 --> 3.29862).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.117706 \tValidation Loss: 3.307417\n",
      "Epoch: 16 \tTraining Loss: 1.050516 \tValidation Loss: 3.318457\n",
      "Epoch: 17 \tTraining Loss: 0.991351 \tValidation Loss: 3.337521\n",
      "Epoch: 18 \tTraining Loss: 0.941820 \tValidation Loss: 3.359032\n",
      "Epoch: 19 \tTraining Loss: 0.899810 \tValidation Loss: 3.386604\n",
      "Epoch: 20 \tTraining Loss: 0.863390 \tValidation Loss: 3.413532\n",
      "Epoch: 1 \tTraining Loss: 5.955883 \tValidation Loss: 5.515962\n",
      "Validation loss decreased (inf --> 5.51596).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.342094 \tValidation Loss: 5.228453\n",
      "Validation loss decreased (5.51596 --> 5.22845).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.866339 \tValidation Loss: 4.858298\n",
      "Validation loss decreased (5.22845 --> 4.85830).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.260490 \tValidation Loss: 4.477111\n",
      "Validation loss decreased (4.85830 --> 4.47711).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.635885 \tValidation Loss: 4.150022\n",
      "Validation loss decreased (4.47711 --> 4.15002).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.075896 \tValidation Loss: 3.896093\n",
      "Validation loss decreased (4.15002 --> 3.89609).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.616620 \tValidation Loss: 3.707321\n",
      "Validation loss decreased (3.89609 --> 3.70732).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.250004 \tValidation Loss: 3.571788\n",
      "Validation loss decreased (3.70732 --> 3.57179).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.967978 \tValidation Loss: 3.475513\n",
      "Validation loss decreased (3.57179 --> 3.47551).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.741376 \tValidation Loss: 3.409448\n",
      "Validation loss decreased (3.47551 --> 3.40945).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.563842 \tValidation Loss: 3.367382\n",
      "Validation loss decreased (3.40945 --> 3.36738).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.418005 \tValidation Loss: 3.339557\n",
      "Validation loss decreased (3.36738 --> 3.33956).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.304539 \tValidation Loss: 3.327035\n",
      "Validation loss decreased (3.33956 --> 3.32703).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.203689 \tValidation Loss: 3.328252\n",
      "Epoch: 15 \tTraining Loss: 1.122956 \tValidation Loss: 3.334796\n",
      "Epoch: 16 \tTraining Loss: 1.056481 \tValidation Loss: 3.348379\n",
      "Epoch: 17 \tTraining Loss: 0.997187 \tValidation Loss: 3.367962\n",
      "Epoch: 18 \tTraining Loss: 0.948440 \tValidation Loss: 3.395086\n",
      "Epoch: 19 \tTraining Loss: 0.903586 \tValidation Loss: 3.418785\n",
      "Epoch: 20 \tTraining Loss: 0.862474 \tValidation Loss: 3.450262\n",
      "Epoch: 1 \tTraining Loss: 5.956802 \tValidation Loss: 5.520499\n",
      "Validation loss decreased (inf --> 5.52050).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.353766 \tValidation Loss: 5.231339\n",
      "Validation loss decreased (5.52050 --> 5.23134).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.886228 \tValidation Loss: 4.856262\n",
      "Validation loss decreased (5.23134 --> 4.85626).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.284367 \tValidation Loss: 4.466423\n",
      "Validation loss decreased (4.85626 --> 4.46642).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.651440 \tValidation Loss: 4.134503\n",
      "Validation loss decreased (4.46642 --> 4.13450).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.084096 \tValidation Loss: 3.885635\n",
      "Validation loss decreased (4.13450 --> 3.88564).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 \tTraining Loss: 2.619075 \tValidation Loss: 3.705757\n",
      "Validation loss decreased (3.88564 --> 3.70576).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.255587 \tValidation Loss: 3.577999\n",
      "Validation loss decreased (3.70576 --> 3.57800).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.969028 \tValidation Loss: 3.488615\n",
      "Validation loss decreased (3.57800 --> 3.48862).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.745755 \tValidation Loss: 3.424893\n",
      "Validation loss decreased (3.48862 --> 3.42489).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.567220 \tValidation Loss: 3.385337\n",
      "Validation loss decreased (3.42489 --> 3.38534).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.422168 \tValidation Loss: 3.360527\n",
      "Validation loss decreased (3.38534 --> 3.36053).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.300819 \tValidation Loss: 3.347697\n",
      "Validation loss decreased (3.36053 --> 3.34770).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.207302 \tValidation Loss: 3.345400\n",
      "Validation loss decreased (3.34770 --> 3.34540).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.125367 \tValidation Loss: 3.353568\n",
      "Epoch: 16 \tTraining Loss: 1.054990 \tValidation Loss: 3.366987\n",
      "Epoch: 17 \tTraining Loss: 0.997383 \tValidation Loss: 3.383851\n",
      "Epoch: 18 \tTraining Loss: 0.947094 \tValidation Loss: 3.407217\n",
      "Epoch: 19 \tTraining Loss: 0.904548 \tValidation Loss: 3.435440\n",
      "Epoch: 20 \tTraining Loss: 0.868773 \tValidation Loss: 3.466615\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 6 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 5.963321 \tValidation Loss: 5.390026\n",
      "Validation loss decreased (inf --> 5.39003).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.314962 \tValidation Loss: 5.092816\n",
      "Validation loss decreased (5.39003 --> 5.09282).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.783718 \tValidation Loss: 4.699898\n",
      "Validation loss decreased (5.09282 --> 4.69990).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.111294 \tValidation Loss: 4.294637\n",
      "Validation loss decreased (4.69990 --> 4.29464).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.428020 \tValidation Loss: 3.947851\n",
      "Validation loss decreased (4.29464 --> 3.94785).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.835646 \tValidation Loss: 3.676433\n",
      "Validation loss decreased (3.94785 --> 3.67643).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.358489 \tValidation Loss: 3.472120\n",
      "Validation loss decreased (3.67643 --> 3.47212).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.989265 \tValidation Loss: 3.322182\n",
      "Validation loss decreased (3.47212 --> 3.32218).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.707289 \tValidation Loss: 3.211811\n",
      "Validation loss decreased (3.32218 --> 3.21181).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.480739 \tValidation Loss: 3.134937\n",
      "Validation loss decreased (3.21181 --> 3.13494).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.301616 \tValidation Loss: 3.078600\n",
      "Validation loss decreased (3.13494 --> 3.07860).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.158925 \tValidation Loss: 3.042901\n",
      "Validation loss decreased (3.07860 --> 3.04290).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.041322 \tValidation Loss: 3.020105\n",
      "Validation loss decreased (3.04290 --> 3.02011).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.938530 \tValidation Loss: 3.012169\n",
      "Validation loss decreased (3.02011 --> 3.01217).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.856736 \tValidation Loss: 3.011267\n",
      "Validation loss decreased (3.01217 --> 3.01127).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.793173 \tValidation Loss: 3.020040\n",
      "Epoch: 17 \tTraining Loss: 0.735363 \tValidation Loss: 3.036697\n",
      "Epoch: 18 \tTraining Loss: 0.683398 \tValidation Loss: 3.053254\n",
      "Epoch: 19 \tTraining Loss: 0.643673 \tValidation Loss: 3.077743\n",
      "Epoch: 20 \tTraining Loss: 0.608758 \tValidation Loss: 3.103809\n",
      "Epoch: 1 \tTraining Loss: 5.963044 \tValidation Loss: 5.412057\n",
      "Validation loss decreased (inf --> 5.41206).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.307746 \tValidation Loss: 5.106182\n",
      "Validation loss decreased (5.41206 --> 5.10618).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.782089 \tValidation Loss: 4.695645\n",
      "Validation loss decreased (5.10618 --> 4.69565).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.116234 \tValidation Loss: 4.275324\n",
      "Validation loss decreased (4.69565 --> 4.27532).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.440475 \tValidation Loss: 3.920394\n",
      "Validation loss decreased (4.27532 --> 3.92039).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.849709 \tValidation Loss: 3.647397\n",
      "Validation loss decreased (3.92039 --> 3.64740).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.375265 \tValidation Loss: 3.444750\n",
      "Validation loss decreased (3.64740 --> 3.44475).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.003427 \tValidation Loss: 3.297170\n",
      "Validation loss decreased (3.44475 --> 3.29717).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.714346 \tValidation Loss: 3.191020\n",
      "Validation loss decreased (3.29717 --> 3.19102).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.487427 \tValidation Loss: 3.116948\n",
      "Validation loss decreased (3.19102 --> 3.11695).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.305851 \tValidation Loss: 3.067257\n",
      "Validation loss decreased (3.11695 --> 3.06726).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.159923 \tValidation Loss: 3.035734\n",
      "Validation loss decreased (3.06726 --> 3.03573).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.041166 \tValidation Loss: 3.019769\n",
      "Validation loss decreased (3.03573 --> 3.01977).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.942287 \tValidation Loss: 3.016215\n",
      "Validation loss decreased (3.01977 --> 3.01621).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.858923 \tValidation Loss: 3.021351\n",
      "Epoch: 16 \tTraining Loss: 0.793983 \tValidation Loss: 3.036871\n",
      "Epoch: 17 \tTraining Loss: 0.736184 \tValidation Loss: 3.055992\n",
      "Epoch: 18 \tTraining Loss: 0.683490 \tValidation Loss: 3.080529\n",
      "Epoch: 19 \tTraining Loss: 0.643745 \tValidation Loss: 3.105029\n",
      "Epoch: 20 \tTraining Loss: 0.606968 \tValidation Loss: 3.135479\n",
      "Epoch: 1 \tTraining Loss: 5.965589 \tValidation Loss: 5.402683\n",
      "Validation loss decreased (inf --> 5.40268).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.309821 \tValidation Loss: 5.098322\n",
      "Validation loss decreased (5.40268 --> 5.09832).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.782560 \tValidation Loss: 4.705861\n",
      "Validation loss decreased (5.09832 --> 4.70586).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.118073 \tValidation Loss: 4.303155\n",
      "Validation loss decreased (4.70586 --> 4.30316).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.438093 \tValidation Loss: 3.960093\n",
      "Validation loss decreased (4.30316 --> 3.96009).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.844707 \tValidation Loss: 3.691892\n",
      "Validation loss decreased (3.96009 --> 3.69189).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.368870 \tValidation Loss: 3.490912\n",
      "Validation loss decreased (3.69189 --> 3.49091).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.997073 \tValidation Loss: 3.342265\n",
      "Validation loss decreased (3.49091 --> 3.34227).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.714199 \tValidation Loss: 3.233546\n",
      "Validation loss decreased (3.34227 --> 3.23355).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.488691 \tValidation Loss: 3.157376\n",
      "Validation loss decreased (3.23355 --> 3.15738).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.309617 \tValidation Loss: 3.105128\n",
      "Validation loss decreased (3.15738 --> 3.10513).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.162242 \tValidation Loss: 3.073765\n",
      "Validation loss decreased (3.10513 --> 3.07377).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.041994 \tValidation Loss: 3.053475\n",
      "Validation loss decreased (3.07377 --> 3.05347).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.945540 \tValidation Loss: 3.050615\n",
      "Validation loss decreased (3.05347 --> 3.05061).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.869260 \tValidation Loss: 3.051879\n",
      "Epoch: 16 \tTraining Loss: 0.794748 \tValidation Loss: 3.061772\n",
      "Epoch: 17 \tTraining Loss: 0.740884 \tValidation Loss: 3.078722\n",
      "Epoch: 18 \tTraining Loss: 0.687788 \tValidation Loss: 3.099626\n",
      "Epoch: 19 \tTraining Loss: 0.648112 \tValidation Loss: 3.125124\n",
      "Epoch: 20 \tTraining Loss: 0.611894 \tValidation Loss: 3.155118\n",
      "Epoch: 1 \tTraining Loss: 5.958050 \tValidation Loss: 5.397452\n",
      "Validation loss decreased (inf --> 5.39745).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.306531 \tValidation Loss: 5.079524\n",
      "Validation loss decreased (5.39745 --> 5.07952).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \tTraining Loss: 4.783537 \tValidation Loss: 4.672633\n",
      "Validation loss decreased (5.07952 --> 4.67263).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.123041 \tValidation Loss: 4.255236\n",
      "Validation loss decreased (4.67263 --> 4.25524).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.447359 \tValidation Loss: 3.901744\n",
      "Validation loss decreased (4.25524 --> 3.90174).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.854540 \tValidation Loss: 3.631396\n",
      "Validation loss decreased (3.90174 --> 3.63140).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.373911 \tValidation Loss: 3.434142\n",
      "Validation loss decreased (3.63140 --> 3.43414).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.002276 \tValidation Loss: 3.292103\n",
      "Validation loss decreased (3.43414 --> 3.29210).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.714206 \tValidation Loss: 3.189462\n",
      "Validation loss decreased (3.29210 --> 3.18946).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.490599 \tValidation Loss: 3.118197\n",
      "Validation loss decreased (3.18946 --> 3.11820).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.310664 \tValidation Loss: 3.068992\n",
      "Validation loss decreased (3.11820 --> 3.06899).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.163183 \tValidation Loss: 3.036963\n",
      "Validation loss decreased (3.06899 --> 3.03696).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.043123 \tValidation Loss: 3.020539\n",
      "Validation loss decreased (3.03696 --> 3.02054).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.945788 \tValidation Loss: 3.016078\n",
      "Validation loss decreased (3.02054 --> 3.01608).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.861937 \tValidation Loss: 3.021268\n",
      "Epoch: 16 \tTraining Loss: 0.797086 \tValidation Loss: 3.029619\n",
      "Epoch: 17 \tTraining Loss: 0.739506 \tValidation Loss: 3.046382\n",
      "Epoch: 18 \tTraining Loss: 0.686836 \tValidation Loss: 3.068010\n",
      "Epoch: 19 \tTraining Loss: 0.646066 \tValidation Loss: 3.093448\n",
      "Epoch: 20 \tTraining Loss: 0.611199 \tValidation Loss: 3.122395\n",
      "Epoch: 1 \tTraining Loss: 5.957913 \tValidation Loss: 5.423005\n",
      "Validation loss decreased (inf --> 5.42300).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.306917 \tValidation Loss: 5.114025\n",
      "Validation loss decreased (5.42300 --> 5.11403).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.775248 \tValidation Loss: 4.714389\n",
      "Validation loss decreased (5.11403 --> 4.71439).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.110068 \tValidation Loss: 4.308681\n",
      "Validation loss decreased (4.71439 --> 4.30868).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.434120 \tValidation Loss: 3.958595\n",
      "Validation loss decreased (4.30868 --> 3.95859).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.845627 \tValidation Loss: 3.684605\n",
      "Validation loss decreased (3.95859 --> 3.68460).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.370665 \tValidation Loss: 3.477388\n",
      "Validation loss decreased (3.68460 --> 3.47739).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.000395 \tValidation Loss: 3.326602\n",
      "Validation loss decreased (3.47739 --> 3.32660).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.711431 \tValidation Loss: 3.218219\n",
      "Validation loss decreased (3.32660 --> 3.21822).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.487940 \tValidation Loss: 3.143518\n",
      "Validation loss decreased (3.21822 --> 3.14352).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.307045 \tValidation Loss: 3.094965\n",
      "Validation loss decreased (3.14352 --> 3.09497).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.159354 \tValidation Loss: 3.060986\n",
      "Validation loss decreased (3.09497 --> 3.06099).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.039611 \tValidation Loss: 3.040772\n",
      "Validation loss decreased (3.06099 --> 3.04077).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.944768 \tValidation Loss: 3.033925\n",
      "Validation loss decreased (3.04077 --> 3.03393).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.862004 \tValidation Loss: 3.036948\n",
      "Epoch: 16 \tTraining Loss: 0.790275 \tValidation Loss: 3.050771\n",
      "Epoch: 17 \tTraining Loss: 0.733771 \tValidation Loss: 3.069539\n",
      "Epoch: 18 \tTraining Loss: 0.683860 \tValidation Loss: 3.092623\n",
      "Epoch: 19 \tTraining Loss: 0.642666 \tValidation Loss: 3.116348\n",
      "Epoch: 20 \tTraining Loss: 0.605807 \tValidation Loss: 3.146223\n",
      "Epoch: 1 \tTraining Loss: 5.958756 \tValidation Loss: 5.445993\n",
      "Validation loss decreased (inf --> 5.44599).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.307841 \tValidation Loss: 5.149132\n",
      "Validation loss decreased (5.44599 --> 5.14913).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.782176 \tValidation Loss: 4.741227\n",
      "Validation loss decreased (5.14913 --> 4.74123).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.114486 \tValidation Loss: 4.324024\n",
      "Validation loss decreased (4.74123 --> 4.32402).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.432103 \tValidation Loss: 3.968165\n",
      "Validation loss decreased (4.32402 --> 3.96817).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.838173 \tValidation Loss: 3.691250\n",
      "Validation loss decreased (3.96817 --> 3.69125).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.363277 \tValidation Loss: 3.482121\n",
      "Validation loss decreased (3.69125 --> 3.48212).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.991012 \tValidation Loss: 3.329203\n",
      "Validation loss decreased (3.48212 --> 3.32920).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.708926 \tValidation Loss: 3.220005\n",
      "Validation loss decreased (3.32920 --> 3.22001).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.480616 \tValidation Loss: 3.141850\n",
      "Validation loss decreased (3.22001 --> 3.14185).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.303565 \tValidation Loss: 3.088081\n",
      "Validation loss decreased (3.14185 --> 3.08808).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.157656 \tValidation Loss: 3.050500\n",
      "Validation loss decreased (3.08808 --> 3.05050).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.039713 \tValidation Loss: 3.032066\n",
      "Validation loss decreased (3.05050 --> 3.03207).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.943744 \tValidation Loss: 3.022971\n",
      "Validation loss decreased (3.03207 --> 3.02297).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.861088 \tValidation Loss: 3.025385\n",
      "Epoch: 16 \tTraining Loss: 0.793015 \tValidation Loss: 3.032585\n",
      "Epoch: 17 \tTraining Loss: 0.733012 \tValidation Loss: 3.048629\n",
      "Epoch: 18 \tTraining Loss: 0.688156 \tValidation Loss: 3.070869\n",
      "Epoch: 19 \tTraining Loss: 0.644665 \tValidation Loss: 3.098574\n",
      "Epoch: 20 \tTraining Loss: 0.606889 \tValidation Loss: 3.119527\n",
      "Epoch: 1 \tTraining Loss: 5.959400 \tValidation Loss: 5.410003\n",
      "Validation loss decreased (inf --> 5.41000).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.314134 \tValidation Loss: 5.094760\n",
      "Validation loss decreased (5.41000 --> 5.09476).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.788196 \tValidation Loss: 4.682502\n",
      "Validation loss decreased (5.09476 --> 4.68250).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.120817 \tValidation Loss: 4.261608\n",
      "Validation loss decreased (4.68250 --> 4.26161).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.440786 \tValidation Loss: 3.902694\n",
      "Validation loss decreased (4.26161 --> 3.90269).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.841409 \tValidation Loss: 3.630306\n",
      "Validation loss decreased (3.90269 --> 3.63031).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.364516 \tValidation Loss: 3.432687\n",
      "Validation loss decreased (3.63031 --> 3.43269).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.994266 \tValidation Loss: 3.290010\n",
      "Validation loss decreased (3.43269 --> 3.29001).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.707330 \tValidation Loss: 3.186314\n",
      "Validation loss decreased (3.29001 --> 3.18631).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.482767 \tValidation Loss: 3.112574\n",
      "Validation loss decreased (3.18631 --> 3.11257).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.305173 \tValidation Loss: 3.066247\n",
      "Validation loss decreased (3.11257 --> 3.06625).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.156087 \tValidation Loss: 3.032144\n",
      "Validation loss decreased (3.06625 --> 3.03214).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.040800 \tValidation Loss: 3.015926\n",
      "Validation loss decreased (3.03214 --> 3.01593).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.941537 \tValidation Loss: 3.010023\n",
      "Validation loss decreased (3.01593 --> 3.01002).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.860333 \tValidation Loss: 3.009776\n",
      "Validation loss decreased (3.01002 --> 3.00978).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.792963 \tValidation Loss: 3.019874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 \tTraining Loss: 0.736171 \tValidation Loss: 3.035098\n",
      "Epoch: 18 \tTraining Loss: 0.689044 \tValidation Loss: 3.056703\n",
      "Epoch: 19 \tTraining Loss: 0.645951 \tValidation Loss: 3.080313\n",
      "Epoch: 20 \tTraining Loss: 0.609109 \tValidation Loss: 3.111246\n",
      "Epoch: 1 \tTraining Loss: 5.958264 \tValidation Loss: 5.404293\n",
      "Validation loss decreased (inf --> 5.40429).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.305842 \tValidation Loss: 5.094259\n",
      "Validation loss decreased (5.40429 --> 5.09426).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.776269 \tValidation Loss: 4.689417\n",
      "Validation loss decreased (5.09426 --> 4.68942).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.109057 \tValidation Loss: 4.285061\n",
      "Validation loss decreased (4.68942 --> 4.28506).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.434166 \tValidation Loss: 3.942246\n",
      "Validation loss decreased (4.28506 --> 3.94225).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.838163 \tValidation Loss: 3.676313\n",
      "Validation loss decreased (3.94225 --> 3.67631).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.361390 \tValidation Loss: 3.479365\n",
      "Validation loss decreased (3.67631 --> 3.47936).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.994941 \tValidation Loss: 3.334139\n",
      "Validation loss decreased (3.47936 --> 3.33414).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.708225 \tValidation Loss: 3.230575\n",
      "Validation loss decreased (3.33414 --> 3.23058).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.482254 \tValidation Loss: 3.156693\n",
      "Validation loss decreased (3.23058 --> 3.15669).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.304574 \tValidation Loss: 3.103992\n",
      "Validation loss decreased (3.15669 --> 3.10399).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.160359 \tValidation Loss: 3.068930\n",
      "Validation loss decreased (3.10399 --> 3.06893).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.042200 \tValidation Loss: 3.050562\n",
      "Validation loss decreased (3.06893 --> 3.05056).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.942851 \tValidation Loss: 3.042143\n",
      "Validation loss decreased (3.05056 --> 3.04214).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.858444 \tValidation Loss: 3.045374\n",
      "Epoch: 16 \tTraining Loss: 0.789121 \tValidation Loss: 3.053203\n",
      "Epoch: 17 \tTraining Loss: 0.732376 \tValidation Loss: 3.071770\n",
      "Epoch: 18 \tTraining Loss: 0.684749 \tValidation Loss: 3.096127\n",
      "Epoch: 19 \tTraining Loss: 0.641546 \tValidation Loss: 3.117338\n",
      "Epoch: 20 \tTraining Loss: 0.607136 \tValidation Loss: 3.145142\n",
      "Epoch: 1 \tTraining Loss: 5.964836 \tValidation Loss: 5.370536\n",
      "Validation loss decreased (inf --> 5.37054).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.313125 \tValidation Loss: 5.068677\n",
      "Validation loss decreased (5.37054 --> 5.06868).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.777114 \tValidation Loss: 4.675824\n",
      "Validation loss decreased (5.06868 --> 4.67582).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.105169 \tValidation Loss: 4.276549\n",
      "Validation loss decreased (4.67582 --> 4.27655).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.421511 \tValidation Loss: 3.948106\n",
      "Validation loss decreased (4.27655 --> 3.94811).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.829483 \tValidation Loss: 3.700883\n",
      "Validation loss decreased (3.94811 --> 3.70088).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.355939 \tValidation Loss: 3.516649\n",
      "Validation loss decreased (3.70088 --> 3.51665).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.989445 \tValidation Loss: 3.378926\n",
      "Validation loss decreased (3.51665 --> 3.37893).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.703110 \tValidation Loss: 3.275909\n",
      "Validation loss decreased (3.37893 --> 3.27591).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.482016 \tValidation Loss: 3.201903\n",
      "Validation loss decreased (3.27591 --> 3.20190).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.306011 \tValidation Loss: 3.147966\n",
      "Validation loss decreased (3.20190 --> 3.14797).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.161658 \tValidation Loss: 3.113460\n",
      "Validation loss decreased (3.14797 --> 3.11346).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.036300 \tValidation Loss: 3.094375\n",
      "Validation loss decreased (3.11346 --> 3.09437).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.940552 \tValidation Loss: 3.087832\n",
      "Validation loss decreased (3.09437 --> 3.08783).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.856651 \tValidation Loss: 3.092130\n",
      "Epoch: 16 \tTraining Loss: 0.789823 \tValidation Loss: 3.103221\n",
      "Epoch: 17 \tTraining Loss: 0.734928 \tValidation Loss: 3.120096\n",
      "Epoch: 18 \tTraining Loss: 0.681926 \tValidation Loss: 3.144545\n",
      "Epoch: 19 \tTraining Loss: 0.643478 \tValidation Loss: 3.170142\n",
      "Epoch: 20 \tTraining Loss: 0.605363 \tValidation Loss: 3.203545\n",
      "Epoch: 1 \tTraining Loss: 5.966402 \tValidation Loss: 5.391187\n",
      "Validation loss decreased (inf --> 5.39119).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.314114 \tValidation Loss: 5.079792\n",
      "Validation loss decreased (5.39119 --> 5.07979).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.782793 \tValidation Loss: 4.673578\n",
      "Validation loss decreased (5.07979 --> 4.67358).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.113946 \tValidation Loss: 4.262497\n",
      "Validation loss decreased (4.67358 --> 4.26250).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.434757 \tValidation Loss: 3.913128\n",
      "Validation loss decreased (4.26250 --> 3.91313).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.839344 \tValidation Loss: 3.645997\n",
      "Validation loss decreased (3.91313 --> 3.64600).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.359665 \tValidation Loss: 3.446917\n",
      "Validation loss decreased (3.64600 --> 3.44692).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.988066 \tValidation Loss: 3.302868\n",
      "Validation loss decreased (3.44692 --> 3.30287).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.702174 \tValidation Loss: 3.198654\n",
      "Validation loss decreased (3.30287 --> 3.19865).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.478541 \tValidation Loss: 3.126738\n",
      "Validation loss decreased (3.19865 --> 3.12674).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.298743 \tValidation Loss: 3.077332\n",
      "Validation loss decreased (3.12674 --> 3.07733).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.152797 \tValidation Loss: 3.044890\n",
      "Validation loss decreased (3.07733 --> 3.04489).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.033436 \tValidation Loss: 3.029190\n",
      "Validation loss decreased (3.04489 --> 3.02919).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.935816 \tValidation Loss: 3.024818\n",
      "Validation loss decreased (3.02919 --> 3.02482).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.853697 \tValidation Loss: 3.028727\n",
      "Epoch: 16 \tTraining Loss: 0.787560 \tValidation Loss: 3.038421\n",
      "Epoch: 17 \tTraining Loss: 0.733498 \tValidation Loss: 3.053440\n",
      "Epoch: 18 \tTraining Loss: 0.681990 \tValidation Loss: 3.076247\n",
      "Epoch: 19 \tTraining Loss: 0.639895 \tValidation Loss: 3.101173\n",
      "Epoch: 20 \tTraining Loss: 0.605898 \tValidation Loss: 3.128537\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 7 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 5.956293 \tValidation Loss: 5.450381\n",
      "Validation loss decreased (inf --> 5.45038).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.287639 \tValidation Loss: 5.140560\n",
      "Validation loss decreased (5.45038 --> 5.14056).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.750652 \tValidation Loss: 4.728888\n",
      "Validation loss decreased (5.14056 --> 4.72889).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.070666 \tValidation Loss: 4.300449\n",
      "Validation loss decreased (4.72889 --> 4.30045).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.374073 \tValidation Loss: 3.926677\n",
      "Validation loss decreased (4.30045 --> 3.92668).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.761135 \tValidation Loss: 3.640375\n",
      "Validation loss decreased (3.92668 --> 3.64038).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.265824 \tValidation Loss: 3.429075\n",
      "Validation loss decreased (3.64038 --> 3.42908).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.878844 \tValidation Loss: 3.274582\n",
      "Validation loss decreased (3.42908 --> 3.27458).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.578486 \tValidation Loss: 3.162864\n",
      "Validation loss decreased (3.27458 --> 3.16286).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.339191 \tValidation Loss: 3.079098\n",
      "Validation loss decreased (3.16286 --> 3.07910).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.149522 \tValidation Loss: 3.021060\n",
      "Validation loss decreased (3.07910 --> 3.02106).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 \tTraining Loss: 1.000173 \tValidation Loss: 2.984873\n",
      "Validation loss decreased (3.02106 --> 2.98487).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.872946 \tValidation Loss: 2.963420\n",
      "Validation loss decreased (2.98487 --> 2.96342).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.774619 \tValidation Loss: 2.953843\n",
      "Validation loss decreased (2.96342 --> 2.95384).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.689987 \tValidation Loss: 2.952202\n",
      "Validation loss decreased (2.95384 --> 2.95220).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.622757 \tValidation Loss: 2.960538\n",
      "Epoch: 17 \tTraining Loss: 0.565177 \tValidation Loss: 2.973235\n",
      "Epoch: 18 \tTraining Loss: 0.517507 \tValidation Loss: 2.994395\n",
      "Epoch: 19 \tTraining Loss: 0.475495 \tValidation Loss: 3.015255\n",
      "Epoch: 20 \tTraining Loss: 0.442620 \tValidation Loss: 3.045866\n",
      "Epoch: 1 \tTraining Loss: 5.957906 \tValidation Loss: 5.457618\n",
      "Validation loss decreased (inf --> 5.45762).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.279089 \tValidation Loss: 5.141509\n",
      "Validation loss decreased (5.45762 --> 5.14151).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.737799 \tValidation Loss: 4.721320\n",
      "Validation loss decreased (5.14151 --> 4.72132).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.052171 \tValidation Loss: 4.297912\n",
      "Validation loss decreased (4.72132 --> 4.29791).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.353214 \tValidation Loss: 3.933576\n",
      "Validation loss decreased (4.29791 --> 3.93358).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.740407 \tValidation Loss: 3.648200\n",
      "Validation loss decreased (3.93358 --> 3.64820).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.244894 \tValidation Loss: 3.432925\n",
      "Validation loss decreased (3.64820 --> 3.43292).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.857505 \tValidation Loss: 3.273171\n",
      "Validation loss decreased (3.43292 --> 3.27317).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.558606 \tValidation Loss: 3.153672\n",
      "Validation loss decreased (3.27317 --> 3.15367).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.324566 \tValidation Loss: 3.065350\n",
      "Validation loss decreased (3.15367 --> 3.06535).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.139506 \tValidation Loss: 3.001822\n",
      "Validation loss decreased (3.06535 --> 3.00182).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.987996 \tValidation Loss: 2.959663\n",
      "Validation loss decreased (3.00182 --> 2.95966).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.865416 \tValidation Loss: 2.933915\n",
      "Validation loss decreased (2.95966 --> 2.93391).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.769112 \tValidation Loss: 2.916805\n",
      "Validation loss decreased (2.93391 --> 2.91680).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.686139 \tValidation Loss: 2.915493\n",
      "Validation loss decreased (2.91680 --> 2.91549).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.617145 \tValidation Loss: 2.926829\n",
      "Epoch: 17 \tTraining Loss: 0.561731 \tValidation Loss: 2.941500\n",
      "Epoch: 18 \tTraining Loss: 0.513982 \tValidation Loss: 2.957727\n",
      "Epoch: 19 \tTraining Loss: 0.473112 \tValidation Loss: 2.981898\n",
      "Epoch: 20 \tTraining Loss: 0.437749 \tValidation Loss: 3.010346\n",
      "Epoch: 1 \tTraining Loss: 5.952619 \tValidation Loss: 5.463243\n",
      "Validation loss decreased (inf --> 5.46324).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.289119 \tValidation Loss: 5.147430\n",
      "Validation loss decreased (5.46324 --> 5.14743).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.751020 \tValidation Loss: 4.723459\n",
      "Validation loss decreased (5.14743 --> 4.72346).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.064303 \tValidation Loss: 4.289768\n",
      "Validation loss decreased (4.72346 --> 4.28977).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.368894 \tValidation Loss: 3.914038\n",
      "Validation loss decreased (4.28977 --> 3.91404).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.752758 \tValidation Loss: 3.619243\n",
      "Validation loss decreased (3.91404 --> 3.61924).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.256059 \tValidation Loss: 3.395703\n",
      "Validation loss decreased (3.61924 --> 3.39570).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.869521 \tValidation Loss: 3.226766\n",
      "Validation loss decreased (3.39570 --> 3.22677).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.568085 \tValidation Loss: 3.103917\n",
      "Validation loss decreased (3.22677 --> 3.10392).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.335443 \tValidation Loss: 3.011572\n",
      "Validation loss decreased (3.10392 --> 3.01157).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.143041 \tValidation Loss: 2.944956\n",
      "Validation loss decreased (3.01157 --> 2.94496).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.992356 \tValidation Loss: 2.903003\n",
      "Validation loss decreased (2.94496 --> 2.90300).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.870156 \tValidation Loss: 2.874670\n",
      "Validation loss decreased (2.90300 --> 2.87467).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.769224 \tValidation Loss: 2.860270\n",
      "Validation loss decreased (2.87467 --> 2.86027).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.685668 \tValidation Loss: 2.858229\n",
      "Validation loss decreased (2.86027 --> 2.85823).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.617540 \tValidation Loss: 2.863736\n",
      "Epoch: 17 \tTraining Loss: 0.559414 \tValidation Loss: 2.874818\n",
      "Epoch: 18 \tTraining Loss: 0.511010 \tValidation Loss: 2.891961\n",
      "Epoch: 19 \tTraining Loss: 0.471630 \tValidation Loss: 2.913481\n",
      "Epoch: 20 \tTraining Loss: 0.437385 \tValidation Loss: 2.937647\n",
      "Epoch: 1 \tTraining Loss: 5.956489 \tValidation Loss: 5.457975\n",
      "Validation loss decreased (inf --> 5.45798).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.280283 \tValidation Loss: 5.142349\n",
      "Validation loss decreased (5.45798 --> 5.14235).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.740109 \tValidation Loss: 4.726253\n",
      "Validation loss decreased (5.14235 --> 4.72625).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.057576 \tValidation Loss: 4.308030\n",
      "Validation loss decreased (4.72625 --> 4.30803).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.364827 \tValidation Loss: 3.949678\n",
      "Validation loss decreased (4.30803 --> 3.94968).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.756929 \tValidation Loss: 3.666771\n",
      "Validation loss decreased (3.94968 --> 3.66677).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.259233 \tValidation Loss: 3.453043\n",
      "Validation loss decreased (3.66677 --> 3.45304).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.872912 \tValidation Loss: 3.291990\n",
      "Validation loss decreased (3.45304 --> 3.29199).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.566083 \tValidation Loss: 3.174864\n",
      "Validation loss decreased (3.29199 --> 3.17486).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.333042 \tValidation Loss: 3.089175\n",
      "Validation loss decreased (3.17486 --> 3.08918).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.146415 \tValidation Loss: 3.028735\n",
      "Validation loss decreased (3.08918 --> 3.02873).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.994578 \tValidation Loss: 2.986613\n",
      "Validation loss decreased (3.02873 --> 2.98661).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.872132 \tValidation Loss: 2.962219\n",
      "Validation loss decreased (2.98661 --> 2.96222).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.773014 \tValidation Loss: 2.951581\n",
      "Validation loss decreased (2.96222 --> 2.95158).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.686763 \tValidation Loss: 2.950574\n",
      "Validation loss decreased (2.95158 --> 2.95057).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.617918 \tValidation Loss: 2.960025\n",
      "Epoch: 17 \tTraining Loss: 0.562708 \tValidation Loss: 2.971370\n",
      "Epoch: 18 \tTraining Loss: 0.514590 \tValidation Loss: 2.992431\n",
      "Epoch: 19 \tTraining Loss: 0.471106 \tValidation Loss: 3.013547\n",
      "Epoch: 20 \tTraining Loss: 0.440990 \tValidation Loss: 3.040467\n",
      "Epoch: 1 \tTraining Loss: 5.957938 \tValidation Loss: 5.490034\n",
      "Validation loss decreased (inf --> 5.49003).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.279693 \tValidation Loss: 5.167562\n",
      "Validation loss decreased (5.49003 --> 5.16756).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.734557 \tValidation Loss: 4.740784\n",
      "Validation loss decreased (5.16756 --> 4.74078).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.049447 \tValidation Loss: 4.309468\n",
      "Validation loss decreased (4.74078 --> 4.30947).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.357938 \tValidation Loss: 3.939908\n",
      "Validation loss decreased (4.30947 --> 3.93991).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.750102 \tValidation Loss: 3.652343\n",
      "Validation loss decreased (3.93991 --> 3.65234).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 \tTraining Loss: 2.259185 \tValidation Loss: 3.431954\n",
      "Validation loss decreased (3.65234 --> 3.43195).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.872179 \tValidation Loss: 3.268465\n",
      "Validation loss decreased (3.43195 --> 3.26847).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.569875 \tValidation Loss: 3.146210\n",
      "Validation loss decreased (3.26847 --> 3.14621).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.334745 \tValidation Loss: 3.056931\n",
      "Validation loss decreased (3.14621 --> 3.05693).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.147039 \tValidation Loss: 2.993505\n",
      "Validation loss decreased (3.05693 --> 2.99350).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.993906 \tValidation Loss: 2.952839\n",
      "Validation loss decreased (2.99350 --> 2.95284).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.868503 \tValidation Loss: 2.928936\n",
      "Validation loss decreased (2.95284 --> 2.92894).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.771170 \tValidation Loss: 2.919372\n",
      "Validation loss decreased (2.92894 --> 2.91937).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.688354 \tValidation Loss: 2.918722\n",
      "Validation loss decreased (2.91937 --> 2.91872).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.618385 \tValidation Loss: 2.928934\n",
      "Epoch: 17 \tTraining Loss: 0.562723 \tValidation Loss: 2.940276\n",
      "Epoch: 18 \tTraining Loss: 0.515221 \tValidation Loss: 2.958468\n",
      "Epoch: 19 \tTraining Loss: 0.472223 \tValidation Loss: 2.979078\n",
      "Epoch: 20 \tTraining Loss: 0.441210 \tValidation Loss: 3.010654\n",
      "Epoch: 1 \tTraining Loss: 5.955881 \tValidation Loss: 5.449857\n",
      "Validation loss decreased (inf --> 5.44986).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.287563 \tValidation Loss: 5.134919\n",
      "Validation loss decreased (5.44986 --> 5.13492).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.750819 \tValidation Loss: 4.716898\n",
      "Validation loss decreased (5.13492 --> 4.71690).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.066147 \tValidation Loss: 4.294657\n",
      "Validation loss decreased (4.71690 --> 4.29466).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.367081 \tValidation Loss: 3.932083\n",
      "Validation loss decreased (4.29466 --> 3.93208).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.749276 \tValidation Loss: 3.644755\n",
      "Validation loss decreased (3.93208 --> 3.64475).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.250240 \tValidation Loss: 3.424717\n",
      "Validation loss decreased (3.64475 --> 3.42472).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.863114 \tValidation Loss: 3.260875\n",
      "Validation loss decreased (3.42472 --> 3.26088).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.562261 \tValidation Loss: 3.138408\n",
      "Validation loss decreased (3.26088 --> 3.13841).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.324910 \tValidation Loss: 3.048297\n",
      "Validation loss decreased (3.13841 --> 3.04830).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.137289 \tValidation Loss: 2.987663\n",
      "Validation loss decreased (3.04830 --> 2.98766).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.986147 \tValidation Loss: 2.948490\n",
      "Validation loss decreased (2.98766 --> 2.94849).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.864235 \tValidation Loss: 2.924655\n",
      "Validation loss decreased (2.94849 --> 2.92466).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.763427 \tValidation Loss: 2.914714\n",
      "Validation loss decreased (2.92466 --> 2.91471).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.679431 \tValidation Loss: 2.912992\n",
      "Validation loss decreased (2.91471 --> 2.91299).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.612933 \tValidation Loss: 2.920022\n",
      "Epoch: 17 \tTraining Loss: 0.556307 \tValidation Loss: 2.935233\n",
      "Epoch: 18 \tTraining Loss: 0.506192 \tValidation Loss: 2.955549\n",
      "Epoch: 19 \tTraining Loss: 0.465507 \tValidation Loss: 2.980536\n",
      "Epoch: 20 \tTraining Loss: 0.432417 \tValidation Loss: 3.005792\n",
      "Epoch: 1 \tTraining Loss: 5.959348 \tValidation Loss: 5.438685\n",
      "Validation loss decreased (inf --> 5.43868).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.291538 \tValidation Loss: 5.121307\n",
      "Validation loss decreased (5.43868 --> 5.12131).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.748038 \tValidation Loss: 4.701358\n",
      "Validation loss decreased (5.12131 --> 4.70136).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.062534 \tValidation Loss: 4.269309\n",
      "Validation loss decreased (4.70136 --> 4.26931).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.364728 \tValidation Loss: 3.895165\n",
      "Validation loss decreased (4.26931 --> 3.89517).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.756646 \tValidation Loss: 3.600736\n",
      "Validation loss decreased (3.89517 --> 3.60074).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.258608 \tValidation Loss: 3.378116\n",
      "Validation loss decreased (3.60074 --> 3.37812).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.870522 \tValidation Loss: 3.212412\n",
      "Validation loss decreased (3.37812 --> 3.21241).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.572700 \tValidation Loss: 3.086870\n",
      "Validation loss decreased (3.21241 --> 3.08687).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.334499 \tValidation Loss: 2.995833\n",
      "Validation loss decreased (3.08687 --> 2.99583).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.149717 \tValidation Loss: 2.931697\n",
      "Validation loss decreased (2.99583 --> 2.93170).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.994286 \tValidation Loss: 2.885530\n",
      "Validation loss decreased (2.93170 --> 2.88553).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.875445 \tValidation Loss: 2.856157\n",
      "Validation loss decreased (2.88553 --> 2.85616).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.768144 \tValidation Loss: 2.842111\n",
      "Validation loss decreased (2.85616 --> 2.84211).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.687543 \tValidation Loss: 2.837279\n",
      "Validation loss decreased (2.84211 --> 2.83728).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.617112 \tValidation Loss: 2.842156\n",
      "Epoch: 17 \tTraining Loss: 0.560299 \tValidation Loss: 2.852901\n",
      "Epoch: 18 \tTraining Loss: 0.513768 \tValidation Loss: 2.867806\n",
      "Epoch: 19 \tTraining Loss: 0.474561 \tValidation Loss: 2.890305\n",
      "Epoch: 20 \tTraining Loss: 0.436671 \tValidation Loss: 2.914911\n",
      "Epoch: 1 \tTraining Loss: 5.955930 \tValidation Loss: 5.422393\n",
      "Validation loss decreased (inf --> 5.42239).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.283188 \tValidation Loss: 5.097440\n",
      "Validation loss decreased (5.42239 --> 5.09744).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.737035 \tValidation Loss: 4.679512\n",
      "Validation loss decreased (5.09744 --> 4.67951).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.048400 \tValidation Loss: 4.256358\n",
      "Validation loss decreased (4.67951 --> 4.25636).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.350844 \tValidation Loss: 3.898444\n",
      "Validation loss decreased (4.25636 --> 3.89844).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.738758 \tValidation Loss: 3.622298\n",
      "Validation loss decreased (3.89844 --> 3.62230).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.247477 \tValidation Loss: 3.413505\n",
      "Validation loss decreased (3.62230 --> 3.41351).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.864072 \tValidation Loss: 3.254504\n",
      "Validation loss decreased (3.41351 --> 3.25450).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.568289 \tValidation Loss: 3.135022\n",
      "Validation loss decreased (3.25450 --> 3.13502).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.336723 \tValidation Loss: 3.046458\n",
      "Validation loss decreased (3.13502 --> 3.04646).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.146944 \tValidation Loss: 2.982321\n",
      "Validation loss decreased (3.04646 --> 2.98232).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.997711 \tValidation Loss: 2.938634\n",
      "Validation loss decreased (2.98232 --> 2.93863).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.873229 \tValidation Loss: 2.908378\n",
      "Validation loss decreased (2.93863 --> 2.90838).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.769474 \tValidation Loss: 2.892285\n",
      "Validation loss decreased (2.90838 --> 2.89229).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.687745 \tValidation Loss: 2.888697\n",
      "Validation loss decreased (2.89229 --> 2.88870).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.622901 \tValidation Loss: 2.890898\n",
      "Epoch: 17 \tTraining Loss: 0.562521 \tValidation Loss: 2.902555\n",
      "Epoch: 18 \tTraining Loss: 0.515773 \tValidation Loss: 2.923136\n",
      "Epoch: 19 \tTraining Loss: 0.474244 \tValidation Loss: 2.945575\n",
      "Epoch: 20 \tTraining Loss: 0.441130 \tValidation Loss: 2.966932\n",
      "Epoch: 1 \tTraining Loss: 5.956348 \tValidation Loss: 5.438943\n",
      "Validation loss decreased (inf --> 5.43894).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 5.284727 \tValidation Loss: 5.118187\n",
      "Validation loss decreased (5.43894 --> 5.11819).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.744340 \tValidation Loss: 4.705053\n",
      "Validation loss decreased (5.11819 --> 4.70505).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.061608 \tValidation Loss: 4.280979\n",
      "Validation loss decreased (4.70505 --> 4.28098).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.363444 \tValidation Loss: 3.918647\n",
      "Validation loss decreased (4.28098 --> 3.91865).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.749114 \tValidation Loss: 3.637559\n",
      "Validation loss decreased (3.91865 --> 3.63756).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.253420 \tValidation Loss: 3.424952\n",
      "Validation loss decreased (3.63756 --> 3.42495).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.864447 \tValidation Loss: 3.267062\n",
      "Validation loss decreased (3.42495 --> 3.26706).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.561452 \tValidation Loss: 3.151037\n",
      "Validation loss decreased (3.26706 --> 3.15104).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.326415 \tValidation Loss: 3.066649\n",
      "Validation loss decreased (3.15104 --> 3.06665).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.137936 \tValidation Loss: 3.006033\n",
      "Validation loss decreased (3.06665 --> 3.00603).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.988802 \tValidation Loss: 2.967156\n",
      "Validation loss decreased (3.00603 --> 2.96716).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.865491 \tValidation Loss: 2.945906\n",
      "Validation loss decreased (2.96716 --> 2.94591).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.766354 \tValidation Loss: 2.935061\n",
      "Validation loss decreased (2.94591 --> 2.93506).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.686808 \tValidation Loss: 2.934787\n",
      "Validation loss decreased (2.93506 --> 2.93479).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.615140 \tValidation Loss: 2.941073\n",
      "Epoch: 17 \tTraining Loss: 0.559454 \tValidation Loss: 2.957230\n",
      "Epoch: 18 \tTraining Loss: 0.513033 \tValidation Loss: 2.978683\n",
      "Epoch: 19 \tTraining Loss: 0.471743 \tValidation Loss: 3.005443\n",
      "Epoch: 20 \tTraining Loss: 0.436177 \tValidation Loss: 3.033567\n",
      "Epoch: 1 \tTraining Loss: 5.965643 \tValidation Loss: 5.442161\n",
      "Validation loss decreased (inf --> 5.44216).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.288733 \tValidation Loss: 5.116654\n",
      "Validation loss decreased (5.44216 --> 5.11665).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.741491 \tValidation Loss: 4.695628\n",
      "Validation loss decreased (5.11665 --> 4.69563).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.051735 \tValidation Loss: 4.272599\n",
      "Validation loss decreased (4.69563 --> 4.27260).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.352959 \tValidation Loss: 3.911965\n",
      "Validation loss decreased (4.27260 --> 3.91196).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.737373 \tValidation Loss: 3.630850\n",
      "Validation loss decreased (3.91196 --> 3.63085).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.245017 \tValidation Loss: 3.419275\n",
      "Validation loss decreased (3.63085 --> 3.41927).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.863320 \tValidation Loss: 3.264105\n",
      "Validation loss decreased (3.41927 --> 3.26410).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.561592 \tValidation Loss: 3.149777\n",
      "Validation loss decreased (3.26410 --> 3.14978).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.326183 \tValidation Loss: 3.069498\n",
      "Validation loss decreased (3.14978 --> 3.06950).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.140393 \tValidation Loss: 3.012892\n",
      "Validation loss decreased (3.06950 --> 3.01289).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.987187 \tValidation Loss: 2.979074\n",
      "Validation loss decreased (3.01289 --> 2.97907).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.865039 \tValidation Loss: 2.955324\n",
      "Validation loss decreased (2.97907 --> 2.95532).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.767533 \tValidation Loss: 2.945370\n",
      "Validation loss decreased (2.95532 --> 2.94537).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.682433 \tValidation Loss: 2.946206\n",
      "Epoch: 16 \tTraining Loss: 0.616681 \tValidation Loss: 2.954848\n",
      "Epoch: 17 \tTraining Loss: 0.557016 \tValidation Loss: 2.968383\n",
      "Epoch: 18 \tTraining Loss: 0.506884 \tValidation Loss: 2.991886\n",
      "Epoch: 19 \tTraining Loss: 0.469491 \tValidation Loss: 3.014776\n",
      "Epoch: 20 \tTraining Loss: 0.436857 \tValidation Loss: 3.044277\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 8 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.013680 \tValidation Loss: 5.574079\n",
      "Validation loss decreased (inf --> 5.57408).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.306146 \tValidation Loss: 5.248860\n",
      "Validation loss decreased (5.57408 --> 5.24886).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.761636 \tValidation Loss: 4.818100\n",
      "Validation loss decreased (5.24886 --> 4.81810).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.074296 \tValidation Loss: 4.384474\n",
      "Validation loss decreased (4.81810 --> 4.38447).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.369383 \tValidation Loss: 4.010933\n",
      "Validation loss decreased (4.38447 --> 4.01093).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.743864 \tValidation Loss: 3.711082\n",
      "Validation loss decreased (4.01093 --> 3.71108).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.233628 \tValidation Loss: 3.482017\n",
      "Validation loss decreased (3.71108 --> 3.48202).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.834620 \tValidation Loss: 3.310782\n",
      "Validation loss decreased (3.48202 --> 3.31078).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.520214 \tValidation Loss: 3.184027\n",
      "Validation loss decreased (3.31078 --> 3.18403).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.267631 \tValidation Loss: 3.090325\n",
      "Validation loss decreased (3.18403 --> 3.09032).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.067820 \tValidation Loss: 3.021660\n",
      "Validation loss decreased (3.09032 --> 3.02166).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.905337 \tValidation Loss: 2.979470\n",
      "Validation loss decreased (3.02166 --> 2.97947).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.775773 \tValidation Loss: 2.952332\n",
      "Validation loss decreased (2.97947 --> 2.95233).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.669835 \tValidation Loss: 2.941548\n",
      "Validation loss decreased (2.95233 --> 2.94155).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.584002 \tValidation Loss: 2.941782\n",
      "Epoch: 16 \tTraining Loss: 0.513603 \tValidation Loss: 2.947442\n",
      "Epoch: 17 \tTraining Loss: 0.459831 \tValidation Loss: 2.964086\n",
      "Epoch: 18 \tTraining Loss: 0.409626 \tValidation Loss: 2.982392\n",
      "Epoch: 19 \tTraining Loss: 0.369582 \tValidation Loss: 3.006910\n",
      "Epoch: 20 \tTraining Loss: 0.340122 \tValidation Loss: 3.033107\n",
      "Epoch: 1 \tTraining Loss: 5.996667 \tValidation Loss: 5.572694\n",
      "Validation loss decreased (inf --> 5.57269).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.306255 \tValidation Loss: 5.273017\n",
      "Validation loss decreased (5.57269 --> 5.27302).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.772039 \tValidation Loss: 4.857367\n",
      "Validation loss decreased (5.27302 --> 4.85737).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.087434 \tValidation Loss: 4.421492\n",
      "Validation loss decreased (4.85737 --> 4.42149).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.381103 \tValidation Loss: 4.040317\n",
      "Validation loss decreased (4.42149 --> 4.04032).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.755916 \tValidation Loss: 3.737961\n",
      "Validation loss decreased (4.04032 --> 3.73796).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.244645 \tValidation Loss: 3.505333\n",
      "Validation loss decreased (3.73796 --> 3.50533).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.846406 \tValidation Loss: 3.330270\n",
      "Validation loss decreased (3.50533 --> 3.33027).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.533747 \tValidation Loss: 3.197671\n",
      "Validation loss decreased (3.33027 --> 3.19767).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.284377 \tValidation Loss: 3.098397\n",
      "Validation loss decreased (3.19767 --> 3.09840).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.080714 \tValidation Loss: 3.029284\n",
      "Validation loss decreased (3.09840 --> 3.02928).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.921143 \tValidation Loss: 2.979416\n",
      "Validation loss decreased (3.02928 --> 2.97942).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.789517 \tValidation Loss: 2.952403\n",
      "Validation loss decreased (2.97942 --> 2.95240).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.680840 \tValidation Loss: 2.937513\n",
      "Validation loss decreased (2.95240 --> 2.93751).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 \tTraining Loss: 0.596226 \tValidation Loss: 2.932477\n",
      "Validation loss decreased (2.93751 --> 2.93248).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.522939 \tValidation Loss: 2.939974\n",
      "Epoch: 17 \tTraining Loss: 0.468391 \tValidation Loss: 2.954835\n",
      "Epoch: 18 \tTraining Loss: 0.419582 \tValidation Loss: 2.968322\n",
      "Epoch: 19 \tTraining Loss: 0.375117 \tValidation Loss: 2.990252\n",
      "Epoch: 20 \tTraining Loss: 0.344017 \tValidation Loss: 3.014962\n",
      "Epoch: 1 \tTraining Loss: 6.012833 \tValidation Loss: 5.517867\n",
      "Validation loss decreased (inf --> 5.51787).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.313182 \tValidation Loss: 5.207750\n",
      "Validation loss decreased (5.51787 --> 5.20775).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.779736 \tValidation Loss: 4.800119\n",
      "Validation loss decreased (5.20775 --> 4.80012).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.092192 \tValidation Loss: 4.382438\n",
      "Validation loss decreased (4.80012 --> 4.38244).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.383703 \tValidation Loss: 4.017862\n",
      "Validation loss decreased (4.38244 --> 4.01786).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.757485 \tValidation Loss: 3.722924\n",
      "Validation loss decreased (4.01786 --> 3.72292).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.250287 \tValidation Loss: 3.497419\n",
      "Validation loss decreased (3.72292 --> 3.49742).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.848273 \tValidation Loss: 3.328679\n",
      "Validation loss decreased (3.49742 --> 3.32868).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.533809 \tValidation Loss: 3.202687\n",
      "Validation loss decreased (3.32868 --> 3.20269).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.282777 \tValidation Loss: 3.111041\n",
      "Validation loss decreased (3.20269 --> 3.11104).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.079634 \tValidation Loss: 3.044495\n",
      "Validation loss decreased (3.11104 --> 3.04450).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.920512 \tValidation Loss: 2.995407\n",
      "Validation loss decreased (3.04450 --> 2.99541).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.790513 \tValidation Loss: 2.964776\n",
      "Validation loss decreased (2.99541 --> 2.96478).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.683168 \tValidation Loss: 2.948553\n",
      "Validation loss decreased (2.96478 --> 2.94855).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.596675 \tValidation Loss: 2.943793\n",
      "Validation loss decreased (2.94855 --> 2.94379).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.528611 \tValidation Loss: 2.946285\n",
      "Epoch: 17 \tTraining Loss: 0.466142 \tValidation Loss: 2.955843\n",
      "Epoch: 18 \tTraining Loss: 0.421260 \tValidation Loss: 2.969443\n",
      "Epoch: 19 \tTraining Loss: 0.379107 \tValidation Loss: 2.984437\n",
      "Epoch: 20 \tTraining Loss: 0.346333 \tValidation Loss: 3.005215\n",
      "Epoch: 1 \tTraining Loss: 6.005493 \tValidation Loss: 5.557925\n",
      "Validation loss decreased (inf --> 5.55793).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.310706 \tValidation Loss: 5.246128\n",
      "Validation loss decreased (5.55793 --> 5.24613).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.777871 \tValidation Loss: 4.824751\n",
      "Validation loss decreased (5.24613 --> 4.82475).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.090029 \tValidation Loss: 4.383684\n",
      "Validation loss decreased (4.82475 --> 4.38368).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.378271 \tValidation Loss: 4.005011\n",
      "Validation loss decreased (4.38368 --> 4.00501).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.745900 \tValidation Loss: 3.710821\n",
      "Validation loss decreased (4.00501 --> 3.71082).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.238014 \tValidation Loss: 3.485633\n",
      "Validation loss decreased (3.71082 --> 3.48563).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.836786 \tValidation Loss: 3.315347\n",
      "Validation loss decreased (3.48563 --> 3.31535).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.521094 \tValidation Loss: 3.186114\n",
      "Validation loss decreased (3.31535 --> 3.18611).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.271300 \tValidation Loss: 3.090978\n",
      "Validation loss decreased (3.18611 --> 3.09098).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.076672 \tValidation Loss: 3.021110\n",
      "Validation loss decreased (3.09098 --> 3.02111).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.917403 \tValidation Loss: 2.975638\n",
      "Validation loss decreased (3.02111 --> 2.97564).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.786642 \tValidation Loss: 2.942422\n",
      "Validation loss decreased (2.97564 --> 2.94242).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.677078 \tValidation Loss: 2.927396\n",
      "Validation loss decreased (2.94242 --> 2.92740).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.591479 \tValidation Loss: 2.921193\n",
      "Validation loss decreased (2.92740 --> 2.92119).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.521230 \tValidation Loss: 2.927096\n",
      "Epoch: 17 \tTraining Loss: 0.462274 \tValidation Loss: 2.938871\n",
      "Epoch: 18 \tTraining Loss: 0.416490 \tValidation Loss: 2.952309\n",
      "Epoch: 19 \tTraining Loss: 0.377160 \tValidation Loss: 2.976518\n",
      "Epoch: 20 \tTraining Loss: 0.341859 \tValidation Loss: 2.998203\n",
      "Epoch: 1 \tTraining Loss: 5.998119 \tValidation Loss: 5.589873\n",
      "Validation loss decreased (inf --> 5.58987).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.304789 \tValidation Loss: 5.285446\n",
      "Validation loss decreased (5.58987 --> 5.28545).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.770548 \tValidation Loss: 4.861595\n",
      "Validation loss decreased (5.28545 --> 4.86159).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.082945 \tValidation Loss: 4.419989\n",
      "Validation loss decreased (4.86159 --> 4.41999).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.373627 \tValidation Loss: 4.041355\n",
      "Validation loss decreased (4.41999 --> 4.04135).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.745217 \tValidation Loss: 3.740265\n",
      "Validation loss decreased (4.04135 --> 3.74027).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.233801 \tValidation Loss: 3.509512\n",
      "Validation loss decreased (3.74027 --> 3.50951).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.834213 \tValidation Loss: 3.335158\n",
      "Validation loss decreased (3.50951 --> 3.33516).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.519741 \tValidation Loss: 3.202655\n",
      "Validation loss decreased (3.33516 --> 3.20265).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.269598 \tValidation Loss: 3.105165\n",
      "Validation loss decreased (3.20265 --> 3.10516).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.074130 \tValidation Loss: 3.033389\n",
      "Validation loss decreased (3.10516 --> 3.03339).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.910276 \tValidation Loss: 2.983712\n",
      "Validation loss decreased (3.03339 --> 2.98371).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.781452 \tValidation Loss: 2.949128\n",
      "Validation loss decreased (2.98371 --> 2.94913).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.675328 \tValidation Loss: 2.928975\n",
      "Validation loss decreased (2.94913 --> 2.92898).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.588303 \tValidation Loss: 2.920097\n",
      "Validation loss decreased (2.92898 --> 2.92010).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.516680 \tValidation Loss: 2.925299\n",
      "Epoch: 17 \tTraining Loss: 0.461043 \tValidation Loss: 2.930902\n",
      "Epoch: 18 \tTraining Loss: 0.410774 \tValidation Loss: 2.946263\n",
      "Epoch: 19 \tTraining Loss: 0.374756 \tValidation Loss: 2.967282\n",
      "Epoch: 20 \tTraining Loss: 0.340577 \tValidation Loss: 2.989309\n",
      "Epoch: 1 \tTraining Loss: 6.009581 \tValidation Loss: 5.575225\n",
      "Validation loss decreased (inf --> 5.57522).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.314788 \tValidation Loss: 5.256200\n",
      "Validation loss decreased (5.57522 --> 5.25620).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.781684 \tValidation Loss: 4.820635\n",
      "Validation loss decreased (5.25620 --> 4.82064).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.091692 \tValidation Loss: 4.368896\n",
      "Validation loss decreased (4.82064 --> 4.36890).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.382239 \tValidation Loss: 3.972894\n",
      "Validation loss decreased (4.36890 --> 3.97289).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.749414 \tValidation Loss: 3.657502\n",
      "Validation loss decreased (3.97289 --> 3.65750).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.235937 \tValidation Loss: 3.419641\n",
      "Validation loss decreased (3.65750 --> 3.41964).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.837410 \tValidation Loss: 3.241958\n",
      "Validation loss decreased (3.41964 --> 3.24196).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.523581 \tValidation Loss: 3.114441\n",
      "Validation loss decreased (3.24196 --> 3.11444).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 \tTraining Loss: 1.275101 \tValidation Loss: 3.020180\n",
      "Validation loss decreased (3.11444 --> 3.02018).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.076066 \tValidation Loss: 2.953948\n",
      "Validation loss decreased (3.02018 --> 2.95395).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.915118 \tValidation Loss: 2.908149\n",
      "Validation loss decreased (2.95395 --> 2.90815).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.784986 \tValidation Loss: 2.880772\n",
      "Validation loss decreased (2.90815 --> 2.88077).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.677319 \tValidation Loss: 2.864777\n",
      "Validation loss decreased (2.88077 --> 2.86478).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.591314 \tValidation Loss: 2.860641\n",
      "Validation loss decreased (2.86478 --> 2.86064).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.520362 \tValidation Loss: 2.863217\n",
      "Epoch: 17 \tTraining Loss: 0.463143 \tValidation Loss: 2.870560\n",
      "Epoch: 18 \tTraining Loss: 0.414199 \tValidation Loss: 2.886152\n",
      "Epoch: 19 \tTraining Loss: 0.374747 \tValidation Loss: 2.903493\n",
      "Epoch: 20 \tTraining Loss: 0.342224 \tValidation Loss: 2.927925\n",
      "Epoch: 1 \tTraining Loss: 6.003675 \tValidation Loss: 5.592468\n",
      "Validation loss decreased (inf --> 5.59247).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.313311 \tValidation Loss: 5.274281\n",
      "Validation loss decreased (5.59247 --> 5.27428).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.780146 \tValidation Loss: 4.847949\n",
      "Validation loss decreased (5.27428 --> 4.84795).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.090924 \tValidation Loss: 4.403976\n",
      "Validation loss decreased (4.84795 --> 4.40398).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.376177 \tValidation Loss: 4.027854\n",
      "Validation loss decreased (4.40398 --> 4.02785).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.746442 \tValidation Loss: 3.733445\n",
      "Validation loss decreased (4.02785 --> 3.73344).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.239944 \tValidation Loss: 3.508774\n",
      "Validation loss decreased (3.73344 --> 3.50877).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.840882 \tValidation Loss: 3.339710\n",
      "Validation loss decreased (3.50877 --> 3.33971).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.525337 \tValidation Loss: 3.211496\n",
      "Validation loss decreased (3.33971 --> 3.21150).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.276976 \tValidation Loss: 3.120501\n",
      "Validation loss decreased (3.21150 --> 3.12050).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.074504 \tValidation Loss: 3.053924\n",
      "Validation loss decreased (3.12050 --> 3.05392).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.912204 \tValidation Loss: 3.009868\n",
      "Validation loss decreased (3.05392 --> 3.00987).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.785199 \tValidation Loss: 2.978860\n",
      "Validation loss decreased (3.00987 --> 2.97886).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.678808 \tValidation Loss: 2.962845\n",
      "Validation loss decreased (2.97886 --> 2.96285).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.591756 \tValidation Loss: 2.960615\n",
      "Validation loss decreased (2.96285 --> 2.96062).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.520058 \tValidation Loss: 2.968031\n",
      "Epoch: 17 \tTraining Loss: 0.463670 \tValidation Loss: 2.977439\n",
      "Epoch: 18 \tTraining Loss: 0.415814 \tValidation Loss: 2.990991\n",
      "Epoch: 19 \tTraining Loss: 0.375218 \tValidation Loss: 3.013712\n",
      "Epoch: 20 \tTraining Loss: 0.342914 \tValidation Loss: 3.037773\n",
      "Epoch: 1 \tTraining Loss: 6.006210 \tValidation Loss: 5.543340\n",
      "Validation loss decreased (inf --> 5.54334).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.313805 \tValidation Loss: 5.234540\n",
      "Validation loss decreased (5.54334 --> 5.23454).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.781413 \tValidation Loss: 4.825585\n",
      "Validation loss decreased (5.23454 --> 4.82558).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.098283 \tValidation Loss: 4.400921\n",
      "Validation loss decreased (4.82558 --> 4.40092).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.387602 \tValidation Loss: 4.028631\n",
      "Validation loss decreased (4.40092 --> 4.02863).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.756568 \tValidation Loss: 3.737799\n",
      "Validation loss decreased (4.02863 --> 3.73780).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.245130 \tValidation Loss: 3.515561\n",
      "Validation loss decreased (3.73780 --> 3.51556).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.844934 \tValidation Loss: 3.346301\n",
      "Validation loss decreased (3.51556 --> 3.34630).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.528296 \tValidation Loss: 3.216506\n",
      "Validation loss decreased (3.34630 --> 3.21651).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.283042 \tValidation Loss: 3.121542\n",
      "Validation loss decreased (3.21651 --> 3.12154).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.084711 \tValidation Loss: 3.050160\n",
      "Validation loss decreased (3.12154 --> 3.05016).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.921791 \tValidation Loss: 3.005395\n",
      "Validation loss decreased (3.05016 --> 3.00540).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.790654 \tValidation Loss: 2.976169\n",
      "Validation loss decreased (3.00540 --> 2.97617).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.682519 \tValidation Loss: 2.963218\n",
      "Validation loss decreased (2.97617 --> 2.96322).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.597160 \tValidation Loss: 2.961558\n",
      "Validation loss decreased (2.96322 --> 2.96156).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.523111 \tValidation Loss: 2.969864\n",
      "Epoch: 17 \tTraining Loss: 0.468862 \tValidation Loss: 2.982061\n",
      "Epoch: 18 \tTraining Loss: 0.417861 \tValidation Loss: 2.998741\n",
      "Epoch: 19 \tTraining Loss: 0.380169 \tValidation Loss: 3.017992\n",
      "Epoch: 20 \tTraining Loss: 0.348346 \tValidation Loss: 3.043095\n",
      "Epoch: 1 \tTraining Loss: 6.005188 \tValidation Loss: 5.582244\n",
      "Validation loss decreased (inf --> 5.58224).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.304706 \tValidation Loss: 5.258095\n",
      "Validation loss decreased (5.58224 --> 5.25810).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.770261 \tValidation Loss: 4.830210\n",
      "Validation loss decreased (5.25810 --> 4.83021).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.087901 \tValidation Loss: 4.381855\n",
      "Validation loss decreased (4.83021 --> 4.38185).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.383246 \tValidation Loss: 3.983052\n",
      "Validation loss decreased (4.38185 --> 3.98305).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.759140 \tValidation Loss: 3.665649\n",
      "Validation loss decreased (3.98305 --> 3.66565).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.250157 \tValidation Loss: 3.424063\n",
      "Validation loss decreased (3.66565 --> 3.42406).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.850474 \tValidation Loss: 3.245654\n",
      "Validation loss decreased (3.42406 --> 3.24565).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.534103 \tValidation Loss: 3.109990\n",
      "Validation loss decreased (3.24565 --> 3.10999).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.286412 \tValidation Loss: 3.011031\n",
      "Validation loss decreased (3.10999 --> 3.01103).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.083024 \tValidation Loss: 2.938069\n",
      "Validation loss decreased (3.01103 --> 2.93807).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.923398 \tValidation Loss: 2.889429\n",
      "Validation loss decreased (2.93807 --> 2.88943).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.789790 \tValidation Loss: 2.857357\n",
      "Validation loss decreased (2.88943 --> 2.85736).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.683707 \tValidation Loss: 2.842861\n",
      "Validation loss decreased (2.85736 --> 2.84286).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.596559 \tValidation Loss: 2.836660\n",
      "Validation loss decreased (2.84286 --> 2.83666).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.525943 \tValidation Loss: 2.840513\n",
      "Epoch: 17 \tTraining Loss: 0.469587 \tValidation Loss: 2.851355\n",
      "Epoch: 18 \tTraining Loss: 0.420871 \tValidation Loss: 2.867067\n",
      "Epoch: 19 \tTraining Loss: 0.379096 \tValidation Loss: 2.886223\n",
      "Epoch: 20 \tTraining Loss: 0.347759 \tValidation Loss: 2.904694\n",
      "Epoch: 1 \tTraining Loss: 6.004838 \tValidation Loss: 5.568213\n",
      "Validation loss decreased (inf --> 5.56821).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.306873 \tValidation Loss: 5.246637\n",
      "Validation loss decreased (5.56821 --> 5.24664).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.772347 \tValidation Loss: 4.824043\n",
      "Validation loss decreased (5.24664 --> 4.82404).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.086447 \tValidation Loss: 4.392230\n",
      "Validation loss decreased (4.82404 --> 4.39223).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \tTraining Loss: 3.378842 \tValidation Loss: 4.023484\n",
      "Validation loss decreased (4.39223 --> 4.02348).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.754110 \tValidation Loss: 3.728717\n",
      "Validation loss decreased (4.02348 --> 3.72872).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.244128 \tValidation Loss: 3.502862\n",
      "Validation loss decreased (3.72872 --> 3.50286).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.845877 \tValidation Loss: 3.329763\n",
      "Validation loss decreased (3.50286 --> 3.32976).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.527116 \tValidation Loss: 3.199086\n",
      "Validation loss decreased (3.32976 --> 3.19909).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.278811 \tValidation Loss: 3.102655\n",
      "Validation loss decreased (3.19909 --> 3.10266).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.078702 \tValidation Loss: 3.033012\n",
      "Validation loss decreased (3.10266 --> 3.03301).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.917544 \tValidation Loss: 2.984371\n",
      "Validation loss decreased (3.03301 --> 2.98437).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.786315 \tValidation Loss: 2.953946\n",
      "Validation loss decreased (2.98437 --> 2.95395).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.677454 \tValidation Loss: 2.937766\n",
      "Validation loss decreased (2.95395 --> 2.93777).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.592436 \tValidation Loss: 2.930127\n",
      "Validation loss decreased (2.93777 --> 2.93013).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.522848 \tValidation Loss: 2.934813\n",
      "Epoch: 17 \tTraining Loss: 0.462924 \tValidation Loss: 2.947094\n",
      "Epoch: 18 \tTraining Loss: 0.413325 \tValidation Loss: 2.961272\n",
      "Epoch: 19 \tTraining Loss: 0.374751 \tValidation Loss: 2.982407\n",
      "Epoch: 20 \tTraining Loss: 0.341717 \tValidation Loss: 3.002204\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 9 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.038929 \tValidation Loss: 4.732639\n",
      "Validation loss decreased (inf --> 4.73264).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.324346 \tValidation Loss: 4.498781\n",
      "Validation loss decreased (4.73264 --> 4.49878).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.829274 \tValidation Loss: 4.181811\n",
      "Validation loss decreased (4.49878 --> 4.18181).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.177977 \tValidation Loss: 3.836375\n",
      "Validation loss decreased (4.18181 --> 3.83638).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.481980 \tValidation Loss: 3.519263\n",
      "Validation loss decreased (3.83638 --> 3.51926).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.842604 \tValidation Loss: 3.256756\n",
      "Validation loss decreased (3.51926 --> 3.25676).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.308427 \tValidation Loss: 3.053098\n",
      "Validation loss decreased (3.25676 --> 3.05310).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.880000 \tValidation Loss: 2.897967\n",
      "Validation loss decreased (3.05310 --> 2.89797).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.544607 \tValidation Loss: 2.779194\n",
      "Validation loss decreased (2.89797 --> 2.77919).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.275135 \tValidation Loss: 2.690208\n",
      "Validation loss decreased (2.77919 --> 2.69021).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.055887 \tValidation Loss: 2.627840\n",
      "Validation loss decreased (2.69021 --> 2.62784).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.886714 \tValidation Loss: 2.580776\n",
      "Validation loss decreased (2.62784 --> 2.58078).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.746749 \tValidation Loss: 2.551561\n",
      "Validation loss decreased (2.58078 --> 2.55156).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.629843 \tValidation Loss: 2.535202\n",
      "Validation loss decreased (2.55156 --> 2.53520).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.538697 \tValidation Loss: 2.527036\n",
      "Validation loss decreased (2.53520 --> 2.52704).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.464522 \tValidation Loss: 2.525798\n",
      "Validation loss decreased (2.52704 --> 2.52580).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.405761 \tValidation Loss: 2.534437\n",
      "Epoch: 18 \tTraining Loss: 0.358022 \tValidation Loss: 2.547040\n",
      "Epoch: 19 \tTraining Loss: 0.319385 \tValidation Loss: 2.561063\n",
      "Epoch: 20 \tTraining Loss: 0.286216 \tValidation Loss: 2.573803\n",
      "Epoch: 1 \tTraining Loss: 6.036959 \tValidation Loss: 4.728538\n",
      "Validation loss decreased (inf --> 4.72854).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.314311 \tValidation Loss: 4.495549\n",
      "Validation loss decreased (4.72854 --> 4.49555).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.811794 \tValidation Loss: 4.190721\n",
      "Validation loss decreased (4.49555 --> 4.19072).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.157608 \tValidation Loss: 3.864419\n",
      "Validation loss decreased (4.19072 --> 3.86442).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.464902 \tValidation Loss: 3.568279\n",
      "Validation loss decreased (3.86442 --> 3.56828).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.826178 \tValidation Loss: 3.326757\n",
      "Validation loss decreased (3.56828 --> 3.32676).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.297459 \tValidation Loss: 3.132208\n",
      "Validation loss decreased (3.32676 --> 3.13221).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.875085 \tValidation Loss: 2.982190\n",
      "Validation loss decreased (3.13221 --> 2.98219).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.538689 \tValidation Loss: 2.867153\n",
      "Validation loss decreased (2.98219 --> 2.86715).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.268817 \tValidation Loss: 2.780372\n",
      "Validation loss decreased (2.86715 --> 2.78037).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.058732 \tValidation Loss: 2.715955\n",
      "Validation loss decreased (2.78037 --> 2.71595).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.880591 \tValidation Loss: 2.672243\n",
      "Validation loss decreased (2.71595 --> 2.67224).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.739076 \tValidation Loss: 2.645417\n",
      "Validation loss decreased (2.67224 --> 2.64542).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.626414 \tValidation Loss: 2.632841\n",
      "Validation loss decreased (2.64542 --> 2.63284).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.537719 \tValidation Loss: 2.630843\n",
      "Validation loss decreased (2.63284 --> 2.63084).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.465919 \tValidation Loss: 2.634109\n",
      "Epoch: 17 \tTraining Loss: 0.400146 \tValidation Loss: 2.646012\n",
      "Epoch: 18 \tTraining Loss: 0.353673 \tValidation Loss: 2.662017\n",
      "Epoch: 19 \tTraining Loss: 0.314430 \tValidation Loss: 2.681827\n",
      "Epoch: 20 \tTraining Loss: 0.283726 \tValidation Loss: 2.706197\n",
      "Epoch: 1 \tTraining Loss: 6.038461 \tValidation Loss: 4.731471\n",
      "Validation loss decreased (inf --> 4.73147).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.321725 \tValidation Loss: 4.481917\n",
      "Validation loss decreased (4.73147 --> 4.48192).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.827968 \tValidation Loss: 4.150672\n",
      "Validation loss decreased (4.48192 --> 4.15067).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.174631 \tValidation Loss: 3.793897\n",
      "Validation loss decreased (4.15067 --> 3.79390).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.475716 \tValidation Loss: 3.477141\n",
      "Validation loss decreased (3.79390 --> 3.47714).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.835843 \tValidation Loss: 3.221776\n",
      "Validation loss decreased (3.47714 --> 3.22178).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.303993 \tValidation Loss: 3.022240\n",
      "Validation loss decreased (3.22178 --> 3.02224).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.879573 \tValidation Loss: 2.870912\n",
      "Validation loss decreased (3.02224 --> 2.87091).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.545026 \tValidation Loss: 2.755474\n",
      "Validation loss decreased (2.87091 --> 2.75547).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.276190 \tValidation Loss: 2.668788\n",
      "Validation loss decreased (2.75547 --> 2.66879).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.059758 \tValidation Loss: 2.607479\n",
      "Validation loss decreased (2.66879 --> 2.60748).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.885555 \tValidation Loss: 2.564077\n",
      "Validation loss decreased (2.60748 --> 2.56408).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.745861 \tValidation Loss: 2.539204\n",
      "Validation loss decreased (2.56408 --> 2.53920).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.632586 \tValidation Loss: 2.526707\n",
      "Validation loss decreased (2.53920 --> 2.52671).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.538163 \tValidation Loss: 2.524293\n",
      "Validation loss decreased (2.52671 --> 2.52429).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 \tTraining Loss: 0.466096 \tValidation Loss: 2.529364\n",
      "Epoch: 17 \tTraining Loss: 0.402582 \tValidation Loss: 2.541089\n",
      "Epoch: 18 \tTraining Loss: 0.357539 \tValidation Loss: 2.556116\n",
      "Epoch: 19 \tTraining Loss: 0.317711 \tValidation Loss: 2.572178\n",
      "Epoch: 20 \tTraining Loss: 0.287492 \tValidation Loss: 2.592109\n",
      "Epoch: 1 \tTraining Loss: 6.037843 \tValidation Loss: 4.752257\n",
      "Validation loss decreased (inf --> 4.75226).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.314086 \tValidation Loss: 4.504449\n",
      "Validation loss decreased (4.75226 --> 4.50445).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.813431 \tValidation Loss: 4.179581\n",
      "Validation loss decreased (4.50445 --> 4.17958).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.162142 \tValidation Loss: 3.842660\n",
      "Validation loss decreased (4.17958 --> 3.84266).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.475229 \tValidation Loss: 3.543992\n",
      "Validation loss decreased (3.84266 --> 3.54399).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.841486 \tValidation Loss: 3.294679\n",
      "Validation loss decreased (3.54399 --> 3.29468).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.311171 \tValidation Loss: 3.095614\n",
      "Validation loss decreased (3.29468 --> 3.09561).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.885618 \tValidation Loss: 2.941185\n",
      "Validation loss decreased (3.09561 --> 2.94118).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.551173 \tValidation Loss: 2.824011\n",
      "Validation loss decreased (2.94118 --> 2.82401).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.281873 \tValidation Loss: 2.734846\n",
      "Validation loss decreased (2.82401 --> 2.73485).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.066578 \tValidation Loss: 2.670865\n",
      "Validation loss decreased (2.73485 --> 2.67087).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.889691 \tValidation Loss: 2.624827\n",
      "Validation loss decreased (2.67087 --> 2.62483).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.751439 \tValidation Loss: 2.597576\n",
      "Validation loss decreased (2.62483 --> 2.59758).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.636362 \tValidation Loss: 2.580391\n",
      "Validation loss decreased (2.59758 --> 2.58039).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.545757 \tValidation Loss: 2.576212\n",
      "Validation loss decreased (2.58039 --> 2.57621).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.471621 \tValidation Loss: 2.577727\n",
      "Epoch: 17 \tTraining Loss: 0.412804 \tValidation Loss: 2.584890\n",
      "Epoch: 18 \tTraining Loss: 0.362715 \tValidation Loss: 2.598667\n",
      "Epoch: 19 \tTraining Loss: 0.324903 \tValidation Loss: 2.615944\n",
      "Epoch: 20 \tTraining Loss: 0.291595 \tValidation Loss: 2.631433\n",
      "Epoch: 1 \tTraining Loss: 6.037691 \tValidation Loss: 4.736177\n",
      "Validation loss decreased (inf --> 4.73618).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.325391 \tValidation Loss: 4.494977\n",
      "Validation loss decreased (4.73618 --> 4.49498).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.829972 \tValidation Loss: 4.176771\n",
      "Validation loss decreased (4.49498 --> 4.17677).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.185711 \tValidation Loss: 3.835187\n",
      "Validation loss decreased (4.17677 --> 3.83519).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.495765 \tValidation Loss: 3.522987\n",
      "Validation loss decreased (3.83519 --> 3.52299).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.858352 \tValidation Loss: 3.267741\n",
      "Validation loss decreased (3.52299 --> 3.26774).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.328195 \tValidation Loss: 3.068934\n",
      "Validation loss decreased (3.26774 --> 3.06893).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.898308 \tValidation Loss: 2.915376\n",
      "Validation loss decreased (3.06893 --> 2.91538).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.560978 \tValidation Loss: 2.797630\n",
      "Validation loss decreased (2.91538 --> 2.79763).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.290823 \tValidation Loss: 2.707717\n",
      "Validation loss decreased (2.79763 --> 2.70772).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.074184 \tValidation Loss: 2.638180\n",
      "Validation loss decreased (2.70772 --> 2.63818).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.896884 \tValidation Loss: 2.585971\n",
      "Validation loss decreased (2.63818 --> 2.58597).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.756681 \tValidation Loss: 2.551101\n",
      "Validation loss decreased (2.58597 --> 2.55110).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.638176 \tValidation Loss: 2.529953\n",
      "Validation loss decreased (2.55110 --> 2.52995).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.544847 \tValidation Loss: 2.519738\n",
      "Validation loss decreased (2.52995 --> 2.51974).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.473984 \tValidation Loss: 2.520726\n",
      "Epoch: 17 \tTraining Loss: 0.411350 \tValidation Loss: 2.526760\n",
      "Epoch: 18 \tTraining Loss: 0.361484 \tValidation Loss: 2.538920\n",
      "Epoch: 19 \tTraining Loss: 0.321772 \tValidation Loss: 2.556595\n",
      "Epoch: 20 \tTraining Loss: 0.288309 \tValidation Loss: 2.573625\n",
      "Epoch: 1 \tTraining Loss: 6.042964 \tValidation Loss: 4.704518\n",
      "Validation loss decreased (inf --> 4.70452).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.322054 \tValidation Loss: 4.453048\n",
      "Validation loss decreased (4.70452 --> 4.45305).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.818664 \tValidation Loss: 4.119413\n",
      "Validation loss decreased (4.45305 --> 4.11941).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.169434 \tValidation Loss: 3.766480\n",
      "Validation loss decreased (4.11941 --> 3.76648).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.480048 \tValidation Loss: 3.443232\n",
      "Validation loss decreased (3.76648 --> 3.44323).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.844352 \tValidation Loss: 3.182440\n",
      "Validation loss decreased (3.44323 --> 3.18244).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.312039 \tValidation Loss: 2.978237\n",
      "Validation loss decreased (3.18244 --> 2.97824).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.888725 \tValidation Loss: 2.822754\n",
      "Validation loss decreased (2.97824 --> 2.82275).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.549819 \tValidation Loss: 2.707920\n",
      "Validation loss decreased (2.82275 --> 2.70792).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.283688 \tValidation Loss: 2.622078\n",
      "Validation loss decreased (2.70792 --> 2.62208).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.065693 \tValidation Loss: 2.559467\n",
      "Validation loss decreased (2.62208 --> 2.55947).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.894135 \tValidation Loss: 2.516898\n",
      "Validation loss decreased (2.55947 --> 2.51690).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.750046 \tValidation Loss: 2.489081\n",
      "Validation loss decreased (2.51690 --> 2.48908).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.638193 \tValidation Loss: 2.475227\n",
      "Validation loss decreased (2.48908 --> 2.47523).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.549885 \tValidation Loss: 2.469147\n",
      "Validation loss decreased (2.47523 --> 2.46915).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.474083 \tValidation Loss: 2.470931\n",
      "Epoch: 17 \tTraining Loss: 0.414647 \tValidation Loss: 2.480072\n",
      "Epoch: 18 \tTraining Loss: 0.365688 \tValidation Loss: 2.496148\n",
      "Epoch: 19 \tTraining Loss: 0.324295 \tValidation Loss: 2.507868\n",
      "Epoch: 20 \tTraining Loss: 0.291150 \tValidation Loss: 2.527793\n",
      "Epoch: 1 \tTraining Loss: 6.042812 \tValidation Loss: 4.686401\n",
      "Validation loss decreased (inf --> 4.68640).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.322739 \tValidation Loss: 4.437226\n",
      "Validation loss decreased (4.68640 --> 4.43723).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.828031 \tValidation Loss: 4.110284\n",
      "Validation loss decreased (4.43723 --> 4.11028).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.183112 \tValidation Loss: 3.769030\n",
      "Validation loss decreased (4.11028 --> 3.76903).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.489648 \tValidation Loss: 3.473143\n",
      "Validation loss decreased (3.76903 --> 3.47314).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.850816 \tValidation Loss: 3.238128\n",
      "Validation loss decreased (3.47314 --> 3.23813).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.319429 \tValidation Loss: 3.054565\n",
      "Validation loss decreased (3.23813 --> 3.05457).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.888422 \tValidation Loss: 2.915299\n",
      "Validation loss decreased (3.05457 --> 2.91530).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.550102 \tValidation Loss: 2.806531\n",
      "Validation loss decreased (2.91530 --> 2.80653).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.281802 \tValidation Loss: 2.726498\n",
      "Validation loss decreased (2.80653 --> 2.72650).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 \tTraining Loss: 1.062336 \tValidation Loss: 2.665742\n",
      "Validation loss decreased (2.72650 --> 2.66574).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.888182 \tValidation Loss: 2.623089\n",
      "Validation loss decreased (2.66574 --> 2.62309).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.746287 \tValidation Loss: 2.595758\n",
      "Validation loss decreased (2.62309 --> 2.59576).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.634879 \tValidation Loss: 2.580642\n",
      "Validation loss decreased (2.59576 --> 2.58064).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.538824 \tValidation Loss: 2.577574\n",
      "Validation loss decreased (2.58064 --> 2.57757).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.468762 \tValidation Loss: 2.579954\n",
      "Epoch: 17 \tTraining Loss: 0.407964 \tValidation Loss: 2.587907\n",
      "Epoch: 18 \tTraining Loss: 0.359864 \tValidation Loss: 2.602940\n",
      "Epoch: 19 \tTraining Loss: 0.316564 \tValidation Loss: 2.619446\n",
      "Epoch: 20 \tTraining Loss: 0.288263 \tValidation Loss: 2.638075\n",
      "Epoch: 1 \tTraining Loss: 6.039215 \tValidation Loss: 4.731825\n",
      "Validation loss decreased (inf --> 4.73182).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.316890 \tValidation Loss: 4.487011\n",
      "Validation loss decreased (4.73182 --> 4.48701).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.821884 \tValidation Loss: 4.149016\n",
      "Validation loss decreased (4.48701 --> 4.14902).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.174629 \tValidation Loss: 3.793036\n",
      "Validation loss decreased (4.14902 --> 3.79304).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.479527 \tValidation Loss: 3.477592\n",
      "Validation loss decreased (3.79304 --> 3.47759).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.841138 \tValidation Loss: 3.222953\n",
      "Validation loss decreased (3.47759 --> 3.22295).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.311836 \tValidation Loss: 3.025009\n",
      "Validation loss decreased (3.22295 --> 3.02501).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.885509 \tValidation Loss: 2.876687\n",
      "Validation loss decreased (3.02501 --> 2.87669).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.546140 \tValidation Loss: 2.763916\n",
      "Validation loss decreased (2.87669 --> 2.76392).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.278194 \tValidation Loss: 2.682634\n",
      "Validation loss decreased (2.76392 --> 2.68263).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.060617 \tValidation Loss: 2.621875\n",
      "Validation loss decreased (2.68263 --> 2.62188).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.888284 \tValidation Loss: 2.582677\n",
      "Validation loss decreased (2.62188 --> 2.58268).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.744118 \tValidation Loss: 2.557033\n",
      "Validation loss decreased (2.58268 --> 2.55703).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.632340 \tValidation Loss: 2.545009\n",
      "Validation loss decreased (2.55703 --> 2.54501).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.542580 \tValidation Loss: 2.547039\n",
      "Epoch: 16 \tTraining Loss: 0.469401 \tValidation Loss: 2.552280\n",
      "Epoch: 17 \tTraining Loss: 0.407830 \tValidation Loss: 2.560839\n",
      "Epoch: 18 \tTraining Loss: 0.359702 \tValidation Loss: 2.578972\n",
      "Epoch: 19 \tTraining Loss: 0.318504 \tValidation Loss: 2.597625\n",
      "Epoch: 20 \tTraining Loss: 0.286357 \tValidation Loss: 2.615669\n",
      "Epoch: 1 \tTraining Loss: 6.039132 \tValidation Loss: 4.670561\n",
      "Validation loss decreased (inf --> 4.67056).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.327219 \tValidation Loss: 4.435502\n",
      "Validation loss decreased (4.67056 --> 4.43550).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.837379 \tValidation Loss: 4.107902\n",
      "Validation loss decreased (4.43550 --> 4.10790).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.192136 \tValidation Loss: 3.749409\n",
      "Validation loss decreased (4.10790 --> 3.74941).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.495163 \tValidation Loss: 3.429305\n",
      "Validation loss decreased (3.74941 --> 3.42931).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.853972 \tValidation Loss: 3.172445\n",
      "Validation loss decreased (3.42931 --> 3.17244).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.324068 \tValidation Loss: 2.975750\n",
      "Validation loss decreased (3.17244 --> 2.97575).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.895777 \tValidation Loss: 2.825351\n",
      "Validation loss decreased (2.97575 --> 2.82535).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.560699 \tValidation Loss: 2.708164\n",
      "Validation loss decreased (2.82535 --> 2.70816).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.288589 \tValidation Loss: 2.619925\n",
      "Validation loss decreased (2.70816 --> 2.61992).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.073095 \tValidation Loss: 2.551916\n",
      "Validation loss decreased (2.61992 --> 2.55192).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.897946 \tValidation Loss: 2.502900\n",
      "Validation loss decreased (2.55192 --> 2.50290).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.754953 \tValidation Loss: 2.470474\n",
      "Validation loss decreased (2.50290 --> 2.47047).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.644199 \tValidation Loss: 2.449560\n",
      "Validation loss decreased (2.47047 --> 2.44956).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.547380 \tValidation Loss: 2.437453\n",
      "Validation loss decreased (2.44956 --> 2.43745).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.473968 \tValidation Loss: 2.433552\n",
      "Validation loss decreased (2.43745 --> 2.43355).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.415103 \tValidation Loss: 2.435266\n",
      "Epoch: 18 \tTraining Loss: 0.364418 \tValidation Loss: 2.444401\n",
      "Epoch: 19 \tTraining Loss: 0.324496 \tValidation Loss: 2.458986\n",
      "Epoch: 20 \tTraining Loss: 0.291272 \tValidation Loss: 2.469956\n",
      "Epoch: 1 \tTraining Loss: 6.038047 \tValidation Loss: 4.723964\n",
      "Validation loss decreased (inf --> 4.72396).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.312212 \tValidation Loss: 4.472158\n",
      "Validation loss decreased (4.72396 --> 4.47216).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.810006 \tValidation Loss: 4.139294\n",
      "Validation loss decreased (4.47216 --> 4.13929).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.154281 \tValidation Loss: 3.784594\n",
      "Validation loss decreased (4.13929 --> 3.78459).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.455398 \tValidation Loss: 3.477223\n",
      "Validation loss decreased (3.78459 --> 3.47722).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.822826 \tValidation Loss: 3.232478\n",
      "Validation loss decreased (3.47722 --> 3.23248).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.289492 \tValidation Loss: 3.045415\n",
      "Validation loss decreased (3.23248 --> 3.04542).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.867472 \tValidation Loss: 2.905048\n",
      "Validation loss decreased (3.04542 --> 2.90505).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.533372 \tValidation Loss: 2.802563\n",
      "Validation loss decreased (2.90505 --> 2.80256).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.267540 \tValidation Loss: 2.725787\n",
      "Validation loss decreased (2.80256 --> 2.72579).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.053324 \tValidation Loss: 2.668547\n",
      "Validation loss decreased (2.72579 --> 2.66855).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.880585 \tValidation Loss: 2.628762\n",
      "Validation loss decreased (2.66855 --> 2.62876).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.741340 \tValidation Loss: 2.604672\n",
      "Validation loss decreased (2.62876 --> 2.60467).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.626649 \tValidation Loss: 2.590787\n",
      "Validation loss decreased (2.60467 --> 2.59079).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.534633 \tValidation Loss: 2.589981\n",
      "Validation loss decreased (2.59079 --> 2.58998).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.461683 \tValidation Loss: 2.593726\n",
      "Epoch: 17 \tTraining Loss: 0.403303 \tValidation Loss: 2.609923\n",
      "Epoch: 18 \tTraining Loss: 0.356010 \tValidation Loss: 2.622839\n",
      "Epoch: 19 \tTraining Loss: 0.316152 \tValidation Loss: 2.639690\n",
      "Epoch: 20 \tTraining Loss: 0.283651 \tValidation Loss: 2.662245\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 10 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.128102 \tValidation Loss: 4.694052\n",
      "Validation loss decreased (inf --> 4.69405).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.382759 \tValidation Loss: 4.440218\n",
      "Validation loss decreased (4.69405 --> 4.44022).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.914525 \tValidation Loss: 4.140089\n",
      "Validation loss decreased (4.44022 --> 4.14009).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.298577 \tValidation Loss: 3.813932\n",
      "Validation loss decreased (4.14009 --> 3.81393).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \tTraining Loss: 3.619637 \tValidation Loss: 3.511621\n",
      "Validation loss decreased (3.81393 --> 3.51162).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.982598 \tValidation Loss: 3.260003\n",
      "Validation loss decreased (3.51162 --> 3.26000).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.435794 \tValidation Loss: 3.058995\n",
      "Validation loss decreased (3.26000 --> 3.05900).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.992717 \tValidation Loss: 2.900537\n",
      "Validation loss decreased (3.05900 --> 2.90054).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.631530 \tValidation Loss: 2.777397\n",
      "Validation loss decreased (2.90054 --> 2.77740).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.341316 \tValidation Loss: 2.679424\n",
      "Validation loss decreased (2.77740 --> 2.67942).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.103808 \tValidation Loss: 2.605532\n",
      "Validation loss decreased (2.67942 --> 2.60553).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.913239 \tValidation Loss: 2.551673\n",
      "Validation loss decreased (2.60553 --> 2.55167).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.757583 \tValidation Loss: 2.515392\n",
      "Validation loss decreased (2.55167 --> 2.51539).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.635646 \tValidation Loss: 2.493736\n",
      "Validation loss decreased (2.51539 --> 2.49374).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.532880 \tValidation Loss: 2.482237\n",
      "Validation loss decreased (2.49374 --> 2.48224).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.452389 \tValidation Loss: 2.476931\n",
      "Validation loss decreased (2.48224 --> 2.47693).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.389018 \tValidation Loss: 2.480223\n",
      "Epoch: 18 \tTraining Loss: 0.338767 \tValidation Loss: 2.489851\n",
      "Epoch: 19 \tTraining Loss: 0.297118 \tValidation Loss: 2.498942\n",
      "Epoch: 20 \tTraining Loss: 0.261803 \tValidation Loss: 2.514912\n",
      "Epoch: 1 \tTraining Loss: 6.147387 \tValidation Loss: 4.564130\n",
      "Validation loss decreased (inf --> 4.56413).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.386643 \tValidation Loss: 4.339430\n",
      "Validation loss decreased (4.56413 --> 4.33943).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.911969 \tValidation Loss: 4.047495\n",
      "Validation loss decreased (4.33943 --> 4.04749).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.288168 \tValidation Loss: 3.725411\n",
      "Validation loss decreased (4.04749 --> 3.72541).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.606521 \tValidation Loss: 3.441071\n",
      "Validation loss decreased (3.72541 --> 3.44107).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.966343 \tValidation Loss: 3.214438\n",
      "Validation loss decreased (3.44107 --> 3.21444).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.423352 \tValidation Loss: 3.034126\n",
      "Validation loss decreased (3.21444 --> 3.03413).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.978482 \tValidation Loss: 2.893953\n",
      "Validation loss decreased (3.03413 --> 2.89395).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.622077 \tValidation Loss: 2.782065\n",
      "Validation loss decreased (2.89395 --> 2.78207).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.331760 \tValidation Loss: 2.696240\n",
      "Validation loss decreased (2.78207 --> 2.69624).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.097925 \tValidation Loss: 2.632942\n",
      "Validation loss decreased (2.69624 --> 2.63294).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.906002 \tValidation Loss: 2.587295\n",
      "Validation loss decreased (2.63294 --> 2.58730).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.757348 \tValidation Loss: 2.555042\n",
      "Validation loss decreased (2.58730 --> 2.55504).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.631126 \tValidation Loss: 2.539079\n",
      "Validation loss decreased (2.55504 --> 2.53908).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.532319 \tValidation Loss: 2.531266\n",
      "Validation loss decreased (2.53908 --> 2.53127).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.451144 \tValidation Loss: 2.530327\n",
      "Validation loss decreased (2.53127 --> 2.53033).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.386599 \tValidation Loss: 2.537965\n",
      "Epoch: 18 \tTraining Loss: 0.336570 \tValidation Loss: 2.548133\n",
      "Epoch: 19 \tTraining Loss: 0.294118 \tValidation Loss: 2.563095\n",
      "Epoch: 20 \tTraining Loss: 0.262022 \tValidation Loss: 2.579869\n",
      "Epoch: 1 \tTraining Loss: 6.138477 \tValidation Loss: 4.659266\n",
      "Validation loss decreased (inf --> 4.65927).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.389932 \tValidation Loss: 4.413926\n",
      "Validation loss decreased (4.65927 --> 4.41393).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.922547 \tValidation Loss: 4.120960\n",
      "Validation loss decreased (4.41393 --> 4.12096).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.294616 \tValidation Loss: 3.801724\n",
      "Validation loss decreased (4.12096 --> 3.80172).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.608392 \tValidation Loss: 3.512461\n",
      "Validation loss decreased (3.80172 --> 3.51246).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.964021 \tValidation Loss: 3.279356\n",
      "Validation loss decreased (3.51246 --> 3.27936).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.415105 \tValidation Loss: 3.099586\n",
      "Validation loss decreased (3.27936 --> 3.09959).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.969745 \tValidation Loss: 2.961619\n",
      "Validation loss decreased (3.09959 --> 2.96162).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.614460 \tValidation Loss: 2.856205\n",
      "Validation loss decreased (2.96162 --> 2.85620).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.325157 \tValidation Loss: 2.773529\n",
      "Validation loss decreased (2.85620 --> 2.77353).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.097116 \tValidation Loss: 2.711934\n",
      "Validation loss decreased (2.77353 --> 2.71193).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.908644 \tValidation Loss: 2.668510\n",
      "Validation loss decreased (2.71193 --> 2.66851).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.756436 \tValidation Loss: 2.640017\n",
      "Validation loss decreased (2.66851 --> 2.64002).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.631048 \tValidation Loss: 2.625786\n",
      "Validation loss decreased (2.64002 --> 2.62579).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.533889 \tValidation Loss: 2.624706\n",
      "Validation loss decreased (2.62579 --> 2.62471).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.454598 \tValidation Loss: 2.628758\n",
      "Epoch: 17 \tTraining Loss: 0.387975 \tValidation Loss: 2.635374\n",
      "Epoch: 18 \tTraining Loss: 0.338294 \tValidation Loss: 2.652769\n",
      "Epoch: 19 \tTraining Loss: 0.298109 \tValidation Loss: 2.671103\n",
      "Epoch: 20 \tTraining Loss: 0.264104 \tValidation Loss: 2.688060\n",
      "Epoch: 1 \tTraining Loss: 6.142215 \tValidation Loss: 4.622598\n",
      "Validation loss decreased (inf --> 4.62260).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.382536 \tValidation Loss: 4.399877\n",
      "Validation loss decreased (4.62260 --> 4.39988).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.914206 \tValidation Loss: 4.108383\n",
      "Validation loss decreased (4.39988 --> 4.10838).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.299148 \tValidation Loss: 3.789097\n",
      "Validation loss decreased (4.10838 --> 3.78910).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.625115 \tValidation Loss: 3.495947\n",
      "Validation loss decreased (3.78910 --> 3.49595).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.984800 \tValidation Loss: 3.255120\n",
      "Validation loss decreased (3.49595 --> 3.25512).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.438117 \tValidation Loss: 3.065021\n",
      "Validation loss decreased (3.25512 --> 3.06502).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.991703 \tValidation Loss: 2.915303\n",
      "Validation loss decreased (3.06502 --> 2.91530).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.631868 \tValidation Loss: 2.798797\n",
      "Validation loss decreased (2.91530 --> 2.79880).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.340534 \tValidation Loss: 2.707397\n",
      "Validation loss decreased (2.79880 --> 2.70740).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.107953 \tValidation Loss: 2.639602\n",
      "Validation loss decreased (2.70740 --> 2.63960).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.916632 \tValidation Loss: 2.591224\n",
      "Validation loss decreased (2.63960 --> 2.59122).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.759673 \tValidation Loss: 2.556389\n",
      "Validation loss decreased (2.59122 --> 2.55639).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.636086 \tValidation Loss: 2.537916\n",
      "Validation loss decreased (2.55639 --> 2.53792).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.535000 \tValidation Loss: 2.527262\n",
      "Validation loss decreased (2.53792 --> 2.52726).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 \tTraining Loss: 0.454700 \tValidation Loss: 2.525743\n",
      "Validation loss decreased (2.52726 --> 2.52574).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.391542 \tValidation Loss: 2.533397\n",
      "Epoch: 18 \tTraining Loss: 0.340013 \tValidation Loss: 2.541823\n",
      "Epoch: 19 \tTraining Loss: 0.297038 \tValidation Loss: 2.554331\n",
      "Epoch: 20 \tTraining Loss: 0.262306 \tValidation Loss: 2.570964\n",
      "Epoch: 1 \tTraining Loss: 6.139158 \tValidation Loss: 4.625447\n",
      "Validation loss decreased (inf --> 4.62545).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.392133 \tValidation Loss: 4.406219\n",
      "Validation loss decreased (4.62545 --> 4.40622).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.931888 \tValidation Loss: 4.126392\n",
      "Validation loss decreased (4.40622 --> 4.12639).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.319281 \tValidation Loss: 3.807262\n",
      "Validation loss decreased (4.12639 --> 3.80726).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.639569 \tValidation Loss: 3.510553\n",
      "Validation loss decreased (3.80726 --> 3.51055).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.000085 \tValidation Loss: 3.264233\n",
      "Validation loss decreased (3.51055 --> 3.26423).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.446249 \tValidation Loss: 3.074392\n",
      "Validation loss decreased (3.26423 --> 3.07439).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.996570 \tValidation Loss: 2.928921\n",
      "Validation loss decreased (3.07439 --> 2.92892).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.635549 \tValidation Loss: 2.815743\n",
      "Validation loss decreased (2.92892 --> 2.81574).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.347606 \tValidation Loss: 2.730022\n",
      "Validation loss decreased (2.81574 --> 2.73002).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.111310 \tValidation Loss: 2.663505\n",
      "Validation loss decreased (2.73002 --> 2.66350).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.916713 \tValidation Loss: 2.618852\n",
      "Validation loss decreased (2.66350 --> 2.61885).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.762359 \tValidation Loss: 2.587174\n",
      "Validation loss decreased (2.61885 --> 2.58717).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.636504 \tValidation Loss: 2.569022\n",
      "Validation loss decreased (2.58717 --> 2.56902).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.535657 \tValidation Loss: 2.562478\n",
      "Validation loss decreased (2.56902 --> 2.56248).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.456239 \tValidation Loss: 2.564291\n",
      "Epoch: 17 \tTraining Loss: 0.391090 \tValidation Loss: 2.571621\n",
      "Epoch: 18 \tTraining Loss: 0.338094 \tValidation Loss: 2.581969\n",
      "Epoch: 19 \tTraining Loss: 0.296271 \tValidation Loss: 2.595274\n",
      "Epoch: 20 \tTraining Loss: 0.262652 \tValidation Loss: 2.615146\n",
      "Epoch: 1 \tTraining Loss: 6.144606 \tValidation Loss: 4.629855\n",
      "Validation loss decreased (inf --> 4.62986).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.388060 \tValidation Loss: 4.394344\n",
      "Validation loss decreased (4.62986 --> 4.39434).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.921471 \tValidation Loss: 4.105890\n",
      "Validation loss decreased (4.39434 --> 4.10589).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.308760 \tValidation Loss: 3.779228\n",
      "Validation loss decreased (4.10589 --> 3.77923).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.632141 \tValidation Loss: 3.478766\n",
      "Validation loss decreased (3.77923 --> 3.47877).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.991154 \tValidation Loss: 3.231043\n",
      "Validation loss decreased (3.47877 --> 3.23104).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.441487 \tValidation Loss: 3.039471\n",
      "Validation loss decreased (3.23104 --> 3.03947).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.986287 \tValidation Loss: 2.891828\n",
      "Validation loss decreased (3.03947 --> 2.89183).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.626801 \tValidation Loss: 2.779862\n",
      "Validation loss decreased (2.89183 --> 2.77986).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.336438 \tValidation Loss: 2.694076\n",
      "Validation loss decreased (2.77986 --> 2.69408).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.107411 \tValidation Loss: 2.627991\n",
      "Validation loss decreased (2.69408 --> 2.62799).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.913229 \tValidation Loss: 2.580957\n",
      "Validation loss decreased (2.62799 --> 2.58096).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.757479 \tValidation Loss: 2.546541\n",
      "Validation loss decreased (2.58096 --> 2.54654).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.634646 \tValidation Loss: 2.527054\n",
      "Validation loss decreased (2.54654 --> 2.52705).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.533081 \tValidation Loss: 2.514431\n",
      "Validation loss decreased (2.52705 --> 2.51443).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.453980 \tValidation Loss: 2.509926\n",
      "Validation loss decreased (2.51443 --> 2.50993).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.390479 \tValidation Loss: 2.514462\n",
      "Epoch: 18 \tTraining Loss: 0.335099 \tValidation Loss: 2.525709\n",
      "Epoch: 19 \tTraining Loss: 0.298020 \tValidation Loss: 2.538477\n",
      "Epoch: 20 \tTraining Loss: 0.261388 \tValidation Loss: 2.552482\n",
      "Epoch: 1 \tTraining Loss: 6.146766 \tValidation Loss: 4.578791\n",
      "Validation loss decreased (inf --> 4.57879).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.397123 \tValidation Loss: 4.347460\n",
      "Validation loss decreased (4.57879 --> 4.34746).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.934785 \tValidation Loss: 4.061346\n",
      "Validation loss decreased (4.34746 --> 4.06135).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.324546 \tValidation Loss: 3.744168\n",
      "Validation loss decreased (4.06135 --> 3.74417).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.648867 \tValidation Loss: 3.445425\n",
      "Validation loss decreased (3.74417 --> 3.44543).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.000216 \tValidation Loss: 3.197315\n",
      "Validation loss decreased (3.44543 --> 3.19731).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.450598 \tValidation Loss: 3.003545\n",
      "Validation loss decreased (3.19731 --> 3.00354).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.000439 \tValidation Loss: 2.851725\n",
      "Validation loss decreased (3.00354 --> 2.85173).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.635034 \tValidation Loss: 2.731970\n",
      "Validation loss decreased (2.85173 --> 2.73197).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.339982 \tValidation Loss: 2.638184\n",
      "Validation loss decreased (2.73197 --> 2.63818).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.107321 \tValidation Loss: 2.567760\n",
      "Validation loss decreased (2.63818 --> 2.56776).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.912285 \tValidation Loss: 2.518916\n",
      "Validation loss decreased (2.56776 --> 2.51892).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.762286 \tValidation Loss: 2.482291\n",
      "Validation loss decreased (2.51892 --> 2.48229).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.636077 \tValidation Loss: 2.459123\n",
      "Validation loss decreased (2.48229 --> 2.45912).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.535678 \tValidation Loss: 2.447406\n",
      "Validation loss decreased (2.45912 --> 2.44741).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.455146 \tValidation Loss: 2.442619\n",
      "Validation loss decreased (2.44741 --> 2.44262).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.389578 \tValidation Loss: 2.446184\n",
      "Epoch: 18 \tTraining Loss: 0.340397 \tValidation Loss: 2.453306\n",
      "Epoch: 19 \tTraining Loss: 0.295559 \tValidation Loss: 2.463076\n",
      "Epoch: 20 \tTraining Loss: 0.263113 \tValidation Loss: 2.478317\n",
      "Epoch: 1 \tTraining Loss: 6.146391 \tValidation Loss: 4.609525\n",
      "Validation loss decreased (inf --> 4.60953).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.393529 \tValidation Loss: 4.370405\n",
      "Validation loss decreased (4.60953 --> 4.37041).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.932607 \tValidation Loss: 4.075761\n",
      "Validation loss decreased (4.37041 --> 4.07576).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.320720 \tValidation Loss: 3.744189\n",
      "Validation loss decreased (4.07576 --> 3.74419).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.641297 \tValidation Loss: 3.427166\n",
      "Validation loss decreased (3.74419 --> 3.42717).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.997396 \tValidation Loss: 3.161496\n",
      "Validation loss decreased (3.42717 --> 3.16150).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.443929 \tValidation Loss: 2.956242\n",
      "Validation loss decreased (3.16150 --> 2.95624).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.993958 \tValidation Loss: 2.804502\n",
      "Validation loss decreased (2.95624 --> 2.80450).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 \tTraining Loss: 1.632121 \tValidation Loss: 2.692589\n",
      "Validation loss decreased (2.80450 --> 2.69259).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.341983 \tValidation Loss: 2.609262\n",
      "Validation loss decreased (2.69259 --> 2.60926).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.104759 \tValidation Loss: 2.549848\n",
      "Validation loss decreased (2.60926 --> 2.54985).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.914904 \tValidation Loss: 2.506688\n",
      "Validation loss decreased (2.54985 --> 2.50669).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.759535 \tValidation Loss: 2.477704\n",
      "Validation loss decreased (2.50669 --> 2.47770).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.634938 \tValidation Loss: 2.461852\n",
      "Validation loss decreased (2.47770 --> 2.46185).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.535738 \tValidation Loss: 2.456907\n",
      "Validation loss decreased (2.46185 --> 2.45691).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.452970 \tValidation Loss: 2.458153\n",
      "Epoch: 17 \tTraining Loss: 0.390974 \tValidation Loss: 2.466794\n",
      "Epoch: 18 \tTraining Loss: 0.339818 \tValidation Loss: 2.479178\n",
      "Epoch: 19 \tTraining Loss: 0.296429 \tValidation Loss: 2.494915\n",
      "Epoch: 20 \tTraining Loss: 0.264329 \tValidation Loss: 2.513639\n",
      "Epoch: 1 \tTraining Loss: 6.138090 \tValidation Loss: 4.683811\n",
      "Validation loss decreased (inf --> 4.68381).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.386991 \tValidation Loss: 4.450127\n",
      "Validation loss decreased (4.68381 --> 4.45013).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.925889 \tValidation Loss: 4.163074\n",
      "Validation loss decreased (4.45013 --> 4.16307).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.306801 \tValidation Loss: 3.845724\n",
      "Validation loss decreased (4.16307 --> 3.84572).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.623292 \tValidation Loss: 3.556559\n",
      "Validation loss decreased (3.84572 --> 3.55656).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.978874 \tValidation Loss: 3.318159\n",
      "Validation loss decreased (3.55656 --> 3.31816).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.434774 \tValidation Loss: 3.128513\n",
      "Validation loss decreased (3.31816 --> 3.12851).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.991342 \tValidation Loss: 2.976738\n",
      "Validation loss decreased (3.12851 --> 2.97674).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.632931 \tValidation Loss: 2.857313\n",
      "Validation loss decreased (2.97674 --> 2.85731).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.343620 \tValidation Loss: 2.763363\n",
      "Validation loss decreased (2.85731 --> 2.76336).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.108071 \tValidation Loss: 2.694137\n",
      "Validation loss decreased (2.76336 --> 2.69414).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.919250 \tValidation Loss: 2.643025\n",
      "Validation loss decreased (2.69414 --> 2.64302).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.759552 \tValidation Loss: 2.608577\n",
      "Validation loss decreased (2.64302 --> 2.60858).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.637065 \tValidation Loss: 2.591537\n",
      "Validation loss decreased (2.60858 --> 2.59154).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.537532 \tValidation Loss: 2.581810\n",
      "Validation loss decreased (2.59154 --> 2.58181).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.456625 \tValidation Loss: 2.586781\n",
      "Epoch: 17 \tTraining Loss: 0.390457 \tValidation Loss: 2.593091\n",
      "Epoch: 18 \tTraining Loss: 0.339223 \tValidation Loss: 2.604581\n",
      "Epoch: 19 \tTraining Loss: 0.296742 \tValidation Loss: 2.617271\n",
      "Epoch: 20 \tTraining Loss: 0.264388 \tValidation Loss: 2.634832\n",
      "Epoch: 1 \tTraining Loss: 6.144838 \tValidation Loss: 4.636302\n",
      "Validation loss decreased (inf --> 4.63630).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.378886 \tValidation Loss: 4.388457\n",
      "Validation loss decreased (4.63630 --> 4.38846).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.902191 \tValidation Loss: 4.089832\n",
      "Validation loss decreased (4.38846 --> 4.08983).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.283729 \tValidation Loss: 3.773762\n",
      "Validation loss decreased (4.08983 --> 3.77376).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.605378 \tValidation Loss: 3.481115\n",
      "Validation loss decreased (3.77376 --> 3.48111).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.965880 \tValidation Loss: 3.234996\n",
      "Validation loss decreased (3.48111 --> 3.23500).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.421788 \tValidation Loss: 3.040950\n",
      "Validation loss decreased (3.23500 --> 3.04095).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.978767 \tValidation Loss: 2.891399\n",
      "Validation loss decreased (3.04095 --> 2.89140).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.625194 \tValidation Loss: 2.774969\n",
      "Validation loss decreased (2.89140 --> 2.77497).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.338818 \tValidation Loss: 2.685086\n",
      "Validation loss decreased (2.77497 --> 2.68509).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.106102 \tValidation Loss: 2.614177\n",
      "Validation loss decreased (2.68509 --> 2.61418).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.911701 \tValidation Loss: 2.563504\n",
      "Validation loss decreased (2.61418 --> 2.56350).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.759903 \tValidation Loss: 2.528457\n",
      "Validation loss decreased (2.56350 --> 2.52846).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.633828 \tValidation Loss: 2.506645\n",
      "Validation loss decreased (2.52846 --> 2.50664).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.535269 \tValidation Loss: 2.494234\n",
      "Validation loss decreased (2.50664 --> 2.49423).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.455113 \tValidation Loss: 2.492425\n",
      "Validation loss decreased (2.49423 --> 2.49243).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.386235 \tValidation Loss: 2.496241\n",
      "Epoch: 18 \tTraining Loss: 0.336463 \tValidation Loss: 2.509646\n",
      "Epoch: 19 \tTraining Loss: 0.294724 \tValidation Loss: 2.521491\n",
      "Epoch: 20 \tTraining Loss: 0.261462 \tValidation Loss: 2.539447\n"
     ]
    }
   ],
   "source": [
    "# Preparing the results dataframes:\n",
    "windows = list(range(3,11))\n",
    "columns = ['Predicted_top5_mean', 'Predicted_top5_std', 'Predicted_top10_mean', 'Predicted_top10_std']\n",
    "Results_Nolemmatize = pd.DataFrame(index=index, columns=columns)\n",
    "Results_lemmatize = pd.DataFrame(index=index, columns=columns)\n",
    "\n",
    "# Getting some results:\n",
    "for lemmatize in [False , True]:\n",
    "    \n",
    "    # Building the corpus\n",
    "    corpus = Corpus(meta = 'Corpus BBC '+category+' News, only verbs as target, no stopwords.')\n",
    "    import_bbc_folder(category,corpus , lemmatize = lemmatize)\n",
    "    \n",
    "    for window in windows:\n",
    "                \n",
    "        # Building the dataset:\n",
    "        sentences , verbs = Build_Dataset([category], corpus, window, one_hot=True , lemmatize=lemmatize)\n",
    "        \n",
    "        print('\\n Starting:...-> Lemmatize =',lemmatize,', window =', window , '\\n')\n",
    "        \n",
    "        lr=0.001\n",
    "        batch_size = 512\n",
    "        n_epochs = 20\n",
    "        file_name = 'CBOW_BBC_'+category+'_lemmatize='+str(lemmatize)+'_window='+str(window)+'_crossval.pt'\n",
    "        random_state = 123\n",
    "        K = 10\n",
    "        \n",
    "        # Cross validating the model:\n",
    "        training_losses, validation_losses, predicted_intop5, predicted_intop10 = K_fold_Cross_validate(K , sentences , verbs,\n",
    "                                                                                                corpus, lr,batch_size ,n_epochs,\n",
    "                                                                                                file_name, random_state)\n",
    "        \n",
    "        # Getting the prediction measures mean and standard deviation:\n",
    "        predicted_intop5_mean , predicted_intop5_std  = np.mean(predicted_intop5) , np.std(predicted_intop5)\n",
    "        predicted_intop10_mean , predicted_intop10_std  = np.mean(predicted_intop10) , np.std(predicted_intop10)\n",
    "        \n",
    "        # Adding the measures to the corresponding dataframe:\n",
    "        if lemmatize:\n",
    "            Results_lemmatize.loc[window , 'Predicted_top5_mean'] = predicted_intop5_mean\n",
    "            Results_lemmatize.loc[window , 'Predicted_top5_std'] = predicted_intop5_std\n",
    "            Results_lemmatize.loc[window , 'Predicted_top10_mean'] = predicted_intop10_mean\n",
    "            Results_lemmatize.loc[window , 'Predicted_top10_std'] = predicted_intop10_std\n",
    "        else:\n",
    "            Results_Nolemmatize.loc[window , 'Predicted_top5_mean'] = predicted_intop5_mean\n",
    "            Results_Nolemmatize.loc[window , 'Predicted_top5_std'] = predicted_intop5_std\n",
    "            Results_Nolemmatize.loc[window , 'Predicted_top10_mean'] = predicted_intop10_mean\n",
    "            Results_Nolemmatize.loc[window , 'Predicted_top10_std'] = predicted_intop10_std\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(category+'results.pkl', 'wb') as f:\n",
    "    pickle.dump((Results_lemmatize , Results_Nolemmatize),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(category+'results.pkl', 'rb') as f:\n",
    "    Results_lemmatize , Results_Nolemmatize = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_top5_mean</th>\n",
       "      <th>Predicted_top5_std</th>\n",
       "      <th>Predicted_top10_mean</th>\n",
       "      <th>Predicted_top10_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.384446</td>\n",
       "      <td>0.00584364</td>\n",
       "      <td>0.480114</td>\n",
       "      <td>0.00479666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.526349</td>\n",
       "      <td>0.00833504</td>\n",
       "      <td>0.619283</td>\n",
       "      <td>0.00644842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.612305</td>\n",
       "      <td>0.00618104</td>\n",
       "      <td>0.694123</td>\n",
       "      <td>0.00515958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.665215</td>\n",
       "      <td>0.00482422</td>\n",
       "      <td>0.732852</td>\n",
       "      <td>0.00221281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.691819</td>\n",
       "      <td>0.00416808</td>\n",
       "      <td>0.752322</td>\n",
       "      <td>0.00425375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.70505</td>\n",
       "      <td>0.00585067</td>\n",
       "      <td>0.753655</td>\n",
       "      <td>0.00549524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.695736</td>\n",
       "      <td>0.00673922</td>\n",
       "      <td>0.740625</td>\n",
       "      <td>0.00687581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.691719</td>\n",
       "      <td>0.00726563</td>\n",
       "      <td>0.733789</td>\n",
       "      <td>0.0061348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted_top5_mean Predicted_top5_std Predicted_top10_mean  \\\n",
       "3             0.384446         0.00584364             0.480114   \n",
       "4             0.526349         0.00833504             0.619283   \n",
       "5             0.612305         0.00618104             0.694123   \n",
       "6             0.665215         0.00482422             0.732852   \n",
       "7             0.691819         0.00416808             0.752322   \n",
       "8              0.70505         0.00585067             0.753655   \n",
       "9             0.695736         0.00673922             0.740625   \n",
       "10            0.691719         0.00726563             0.733789   \n",
       "\n",
       "   Predicted_top10_std  \n",
       "3           0.00479666  \n",
       "4           0.00644842  \n",
       "5           0.00515958  \n",
       "6           0.00221281  \n",
       "7           0.00425375  \n",
       "8           0.00549524  \n",
       "9           0.00687581  \n",
       "10           0.0061348  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Results_lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_top5_mean</th>\n",
       "      <th>Predicted_top5_std</th>\n",
       "      <th>Predicted_top10_mean</th>\n",
       "      <th>Predicted_top10_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.390059</td>\n",
       "      <td>0.00502864</td>\n",
       "      <td>0.478359</td>\n",
       "      <td>0.00396614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.563406</td>\n",
       "      <td>0.00721434</td>\n",
       "      <td>0.648544</td>\n",
       "      <td>0.00670225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.674492</td>\n",
       "      <td>0.00643536</td>\n",
       "      <td>0.741895</td>\n",
       "      <td>0.00528446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.724132</td>\n",
       "      <td>0.00773605</td>\n",
       "      <td>0.774132</td>\n",
       "      <td>0.00570693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.744727</td>\n",
       "      <td>0.00786284</td>\n",
       "      <td>0.784888</td>\n",
       "      <td>0.00619218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.743136</td>\n",
       "      <td>0.00742229</td>\n",
       "      <td>0.777679</td>\n",
       "      <td>0.00757656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.73444</td>\n",
       "      <td>0.00973498</td>\n",
       "      <td>0.766146</td>\n",
       "      <td>0.00950521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.715078</td>\n",
       "      <td>0.0105457</td>\n",
       "      <td>0.744531</td>\n",
       "      <td>0.00825874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted_top5_mean Predicted_top5_std Predicted_top10_mean  \\\n",
       "3             0.390059         0.00502864             0.478359   \n",
       "4             0.563406         0.00721434             0.648544   \n",
       "5             0.674492         0.00643536             0.741895   \n",
       "6             0.724132         0.00773605             0.774132   \n",
       "7             0.744727         0.00786284             0.784888   \n",
       "8             0.743136         0.00742229             0.777679   \n",
       "9              0.73444         0.00973498             0.766146   \n",
       "10            0.715078          0.0105457             0.744531   \n",
       "\n",
       "   Predicted_top10_std  \n",
       "3           0.00396614  \n",
       "4           0.00670225  \n",
       "5           0.00528446  \n",
       "6           0.00570693  \n",
       "7           0.00619218  \n",
       "8           0.00757656  \n",
       "9           0.00950521  \n",
       "10          0.00825874  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Results_Nolemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.bar(Results_lemmatize.index.values, Results_lemmatize['Predicted_top10_mean'].values, yerr=Results_lemmatize['Predicted_top10_std'].values, width=-0.4, align='edge', alpha=0.8, ecolor='black', capsize=4,  label='Top 10 +L')\n",
    "ax.bar(Results_lemmatize.index.values, Results_lemmatize['Predicted_top5_mean'].values, yerr=Results_lemmatize['Predicted_top5_std'].values, color='green', width=-0.4, align='edge', alpha=0.7, ecolor='black', capsize=4, label='Top 5 +L')\n",
    "ax.bar(Results_Nolemmatize.index.values, Results_Nolemmatize['Predicted_top10_mean'].values, yerr=Results_Nolemmatize['Predicted_top10_std'].values, width=0.4, align='edge', alpha=0.8, ecolor='black', capsize=4,  label='Top 10')\n",
    "ax.bar(Results_Nolemmatize.index.values, Results_Nolemmatize['Predicted_top5_mean'].values, yerr=Results_Nolemmatize['Predicted_top5_std'].values, color='purple', width=0.4, align='edge', alpha=0.7, ecolor='black', capsize=4, label='Top 5')\n",
    "ax.set_ylabel('Accuracy of Prediction')\n",
    "ax.set_xlabel('Window Size')\n",
    "ax.set_xticks(Results_lemmatize.index.values)\n",
    "ax.set_yticks(np.arange(0,1.1,0.1))\n",
    "ax.yaxis.grid(True)\n",
    "ax.legend()\n",
    "plt.savefig(category+'-bars.pdf', dpi=500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking a look at the predicted probabilities of the best setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 6.507046 \tValidation Loss: 5.458319\n",
      "Validation loss decreased (inf --> 5.45832).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.774628 \tValidation Loss: 5.137485\n",
      "Validation loss decreased (5.45832 --> 5.13748).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.141758 \tValidation Loss: 4.665634\n",
      "Validation loss decreased (5.13748 --> 4.66563).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.280815 \tValidation Loss: 4.150757\n",
      "Validation loss decreased (4.66563 --> 4.15076).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.384668 \tValidation Loss: 3.705372\n",
      "Validation loss decreased (4.15076 --> 3.70537).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.612399 \tValidation Loss: 3.358110\n",
      "Validation loss decreased (3.70537 --> 3.35811).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.015650 \tValidation Loss: 3.101007\n",
      "Validation loss decreased (3.35811 --> 3.10101).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.575697 \tValidation Loss: 2.915132\n",
      "Validation loss decreased (3.10101 --> 2.91513).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.248275 \tValidation Loss: 2.783119\n",
      "Validation loss decreased (2.91513 --> 2.78312).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.001534 \tValidation Loss: 2.688824\n",
      "Validation loss decreased (2.78312 --> 2.68882).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.815440 \tValidation Loss: 2.622280\n",
      "Validation loss decreased (2.68882 --> 2.62228).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.669203 \tValidation Loss: 2.578428\n",
      "Validation loss decreased (2.62228 --> 2.57843).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.556102 \tValidation Loss: 2.553556\n",
      "Validation loss decreased (2.57843 --> 2.55356).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.470620 \tValidation Loss: 2.538402\n",
      "Validation loss decreased (2.55356 --> 2.53840).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.400900 \tValidation Loss: 2.535589\n",
      "Validation loss decreased (2.53840 --> 2.53559).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.350205 \tValidation Loss: 2.542075\n",
      "Epoch: 17 \tTraining Loss: 0.309125 \tValidation Loss: 2.553237\n",
      "Epoch: 18 \tTraining Loss: 0.277369 \tValidation Loss: 2.568153\n",
      "Epoch: 19 \tTraining Loss: 0.250151 \tValidation Loss: 2.580777\n",
      "Epoch: 20 \tTraining Loss: 0.231278 \tValidation Loss: 2.600409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize = False\n",
    "window = 7\n",
    "\n",
    "# Building the corpus\n",
    "corpus = Corpus(meta = 'Corpus BBC '+category+' News, only verbs as target, no stopwords.')\n",
    "import_bbc_folder(category,corpus , lemmatize = lemmatize)\n",
    "\n",
    "# Building the dataset\n",
    "sentences , verbs = Build_Dataset([category], corpus, window, one_hot=True , lemmatize=lemmatize)\n",
    "\n",
    "# Getting the train_valid_test data:\n",
    "x_train, x_test, y_train, y_test = train_test_split(sentences, verbs, test_size=0.1, random_state=123)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.1, random_state=123)\n",
    "\n",
    "# Building the model\n",
    "vocab_size = len(corpus.get_vocabs_to_learn())\n",
    "verbs_size = len(corpus.get_verbs_to_learn())\n",
    "hidden_dim = 500\n",
    "\n",
    "model = CBOW(vocab_size, hidden_dim, verbs_size)\n",
    "model.cuda()\n",
    "\n",
    "# Training the model\n",
    "lr=0.001\n",
    "batch_size = 512\n",
    "n_epochs = 20\n",
    "file_name = 'CBOW_BBC'+category+'_window='+str(window)+'_forevaluation.pt'\n",
    "\n",
    "train_losses, valid_losses = Train_model(model, lr, batch_size, n_epochs, file_name, x_train, y_train, x_valid, y_valid)\n",
    "\n",
    "# Loading the best model parameters\n",
    "model.load_state_dict(torch.load(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1dc0fcabd88>"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label = 'Training loss')\n",
    "plt.plot(valid_losses, label = 'Validation loss')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking into a sample of predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "getbatch = iter(get_batch(x_test, y_test , 16))\n",
    "sentences, verbs = next(getbatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "output = model(sentences.cuda().float())\n",
    "ps = torch.exp(output)\n",
    "top_p, top_class = ps.topk(10, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "told\n",
      "\tsaid\ttold\tdone\tdebate\trest\tdefended\tsuggested\tbegin\tcomes\tlook\t\n",
      "asked\n",
      "\tsay\tsays\tget\tspending\tamounted\tcomment\tsticking\tplanned\temerged\twin\t\n",
      "downing\n",
      "\tdowning\tfollowing\treport\tdenied\tcriticised\twarned\tstressed\ttold\tset\tmean\t\n",
      "building\n",
      "\tundermine\tfind\tmake\tget\tstart\tfound\tabused\tgetting\tset\tstop\t\n",
      "broken\n",
      "\tbroken\tsaid\ttold\tspeaking\tclaims\tmeeting\tmaking\trejected\trefused\tdeal\t\n",
      "making\n",
      "\ttelephoning\tlists\tlabour\tavoided\tcalling\tmaking\tsigned\twaiting\tmake\tdoubt\t\n",
      "close\n",
      "\tclose\tincluded\tsign\trepresent\tliving\tsays\trecommended\tacknowledge\tmet\tquestioning\t\n",
      "rejected\n",
      "\trejected\tsaw\tright\treduced\tsaying\tmeasures\tpublished\tintroduce\tamount\tclaims\t\n",
      "remain\n",
      "\tremain\toffered\trenewed\tcome\tintervened\tclaims\tpredicted\tstand\tdelivered\tdraw\t\n",
      "increase\n",
      "\tincrease\tlabour\tplan\tneeded\tdesigned\texpected\tcall\trestore\tbacking\twin\t\n",
      "said\n",
      "\tlearned\tmaking\tmade\tmake\tsaid\tinsisted\tget\texpected\treached\tstand\t\n",
      "labour\n",
      "\tlabour\tpersuade\tachieved\tlooming\tthink\tfund\thopes\tplanning\tgo\tappointed\t\n",
      "agree\n",
      "\tcampaigning\tbecome\tsort\tback\tsay\thighlight\tincluding\tleaving\tcannot\tlabour\t\n",
      "asylum\n",
      "\tlimit\tsaid\taffect\tsaying\tlabour\tensure\tasylum\tmake\tlives\ttrust\t\n",
      "discuss\n",
      "\twant\tsaid\tdiscuss\tlives\tmake\tallowed\twants\ttaken\tshowed\tuse\t\n",
      "think\n",
      "\tthink\twaiting\tlabour\tpay\thappen\tseen\tlists\tallow\tsaid\tlike\t\n"
     ]
    }
   ],
   "source": [
    "for clas, t in zip(top_class, verbs):\n",
    "    print(corpus.get_verb_from_index(t.item()) , ': ')\n",
    "    print('\\t' ,  end='' )\n",
    "    for val in clas:\n",
    "        print(corpus.get_verb_from_index(val.item()), end='\\t' )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['commons', 'jack', 'straw', 'us', 'agreed', 'release']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "sent = np.where(np.array(sentences[i]) != 0)[0]\n",
    "corpus.get_vocab_from_index(sent.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = top_p[i].tolist()\n",
    "vrbs = corpus.get_verb_from_index(top_class[i].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "props = dict(boxstyle='round', facecolor='grey', alpha=0.2)\n",
    "ax.text(0.05, 0.95, 'Input: '+str(corpus.get_vocab_from_index(sent.tolist())), transform=ax.transAxes, fontsize=10, verticalalignment='top', bbox=props)\n",
    "ax.text(0.05, 0.85, 'Target: '+corpus.get_verb_from_index(verbs[i].item()), transform=ax.transAxes, fontsize=10, verticalalignment='top', bbox=props)\n",
    "ax.barh(vrbs, probs, align='center')\n",
    "plt.xlabel('Probabilities')\n",
    "plt.ylabel('Predicted Verbs')\n",
    "ax.set_xticks(np.arange(0,1.1,0.1))\n",
    "ax.xaxis.grid(True)\n",
    "plt.savefig(category+'-probs.pdf', dpi=500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4- Obtaining prediction results when learning the verbs in sport articles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'sport'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbc/sport\\199.txt  had a problem\n",
      "bbc/sport\\199.txt  had a problem\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 3 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.503159 \tValidation Loss: 5.516802\n",
      "Validation loss decreased (inf --> 5.51680).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.002865 \tValidation Loss: 5.408037\n",
      "Validation loss decreased (5.51680 --> 5.40804).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.788478 \tValidation Loss: 5.253484\n",
      "Validation loss decreased (5.40804 --> 5.25348).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.469777 \tValidation Loss: 5.054372\n",
      "Validation loss decreased (5.25348 --> 5.05437).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.060573 \tValidation Loss: 4.848137\n",
      "Validation loss decreased (5.05437 --> 4.84814).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.599783 \tValidation Loss: 4.663158\n",
      "Validation loss decreased (4.84814 --> 4.66316).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.130731 \tValidation Loss: 4.511779\n",
      "Validation loss decreased (4.66316 --> 4.51178).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.690073 \tValidation Loss: 4.398953\n",
      "Validation loss decreased (4.51178 --> 4.39895).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.293363 \tValidation Loss: 4.319804\n",
      "Validation loss decreased (4.39895 --> 4.31980).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.954011 \tValidation Loss: 4.269024\n",
      "Validation loss decreased (4.31980 --> 4.26902).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.671015 \tValidation Loss: 4.239620\n",
      "Validation loss decreased (4.26902 --> 4.23962).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.433480 \tValidation Loss: 4.227882\n",
      "Validation loss decreased (4.23962 --> 4.22788).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.241741 \tValidation Loss: 4.227573\n",
      "Validation loss decreased (4.22788 --> 4.22757).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 2.083866 \tValidation Loss: 4.238082\n",
      "Epoch: 15 \tTraining Loss: 1.953337 \tValidation Loss: 4.255512\n",
      "Epoch: 16 \tTraining Loss: 1.848015 \tValidation Loss: 4.278534\n",
      "Epoch: 17 \tTraining Loss: 1.760241 \tValidation Loss: 4.306719\n",
      "Epoch: 18 \tTraining Loss: 1.686362 \tValidation Loss: 4.337474\n",
      "Epoch: 19 \tTraining Loss: 1.620465 \tValidation Loss: 4.370413\n",
      "Epoch: 20 \tTraining Loss: 1.569632 \tValidation Loss: 4.406751\n",
      "Epoch: 1 \tTraining Loss: 6.498650 \tValidation Loss: 5.506319\n",
      "Validation loss decreased (inf --> 5.50632).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.002790 \tValidation Loss: 5.401130\n",
      "Validation loss decreased (5.50632 --> 5.40113).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.794506 \tValidation Loss: 5.249385\n",
      "Validation loss decreased (5.40113 --> 5.24938).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.481713 \tValidation Loss: 5.052079\n",
      "Validation loss decreased (5.24938 --> 5.05208).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.078455 \tValidation Loss: 4.850828\n",
      "Validation loss decreased (5.05208 --> 4.85083).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.620634 \tValidation Loss: 4.667405\n",
      "Validation loss decreased (4.85083 --> 4.66740).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.153977 \tValidation Loss: 4.512053\n",
      "Validation loss decreased (4.66740 --> 4.51205).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.712718 \tValidation Loss: 4.390868\n",
      "Validation loss decreased (4.51205 --> 4.39087).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.315840 \tValidation Loss: 4.305656\n",
      "Validation loss decreased (4.39087 --> 4.30566).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.975118 \tValidation Loss: 4.250475\n",
      "Validation loss decreased (4.30566 --> 4.25047).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.686192 \tValidation Loss: 4.219965\n",
      "Validation loss decreased (4.25047 --> 4.21996).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.450835 \tValidation Loss: 4.208006\n",
      "Validation loss decreased (4.21996 --> 4.20801).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.256564 \tValidation Loss: 4.208292\n",
      "Epoch: 14 \tTraining Loss: 2.097023 \tValidation Loss: 4.218679\n",
      "Epoch: 15 \tTraining Loss: 1.965885 \tValidation Loss: 4.236427\n",
      "Epoch: 16 \tTraining Loss: 1.861112 \tValidation Loss: 4.260874\n",
      "Epoch: 17 \tTraining Loss: 1.773384 \tValidation Loss: 4.288329\n",
      "Epoch: 18 \tTraining Loss: 1.697351 \tValidation Loss: 4.320537\n",
      "Epoch: 19 \tTraining Loss: 1.632741 \tValidation Loss: 4.354322\n",
      "Epoch: 20 \tTraining Loss: 1.578308 \tValidation Loss: 4.390900\n",
      "Epoch: 1 \tTraining Loss: 6.502685 \tValidation Loss: 5.520372\n",
      "Validation loss decreased (inf --> 5.52037).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.003974 \tValidation Loss: 5.418133\n",
      "Validation loss decreased (5.52037 --> 5.41813).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.785831 \tValidation Loss: 5.273354\n",
      "Validation loss decreased (5.41813 --> 5.27335).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.470122 \tValidation Loss: 5.081688\n",
      "Validation loss decreased (5.27335 --> 5.08169).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.063827 \tValidation Loss: 4.884726\n",
      "Validation loss decreased (5.08169 --> 4.88473).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.606223 \tValidation Loss: 4.704929\n",
      "Validation loss decreased (4.88473 --> 4.70493).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.144877 \tValidation Loss: 4.551613\n",
      "Validation loss decreased (4.70493 --> 4.55161).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.703819 \tValidation Loss: 4.430499\n",
      "Validation loss decreased (4.55161 --> 4.43050).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.306588 \tValidation Loss: 4.344625\n",
      "Validation loss decreased (4.43050 --> 4.34463).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.965302 \tValidation Loss: 4.287764\n",
      "Validation loss decreased (4.34463 --> 4.28776).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.675853 \tValidation Loss: 4.255157\n",
      "Validation loss decreased (4.28776 --> 4.25516).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.439949 \tValidation Loss: 4.240859\n",
      "Validation loss decreased (4.25516 --> 4.24086).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.245417 \tValidation Loss: 4.240926\n",
      "Epoch: 14 \tTraining Loss: 2.083440 \tValidation Loss: 4.249888\n",
      "Epoch: 15 \tTraining Loss: 1.955073 \tValidation Loss: 4.264751\n",
      "Epoch: 16 \tTraining Loss: 1.851158 \tValidation Loss: 4.286015\n",
      "Epoch: 17 \tTraining Loss: 1.758240 \tValidation Loss: 4.313806\n",
      "Epoch: 18 \tTraining Loss: 1.687729 \tValidation Loss: 4.344252\n",
      "Epoch: 19 \tTraining Loss: 1.622087 \tValidation Loss: 4.377325\n",
      "Epoch: 20 \tTraining Loss: 1.567899 \tValidation Loss: 4.412665\n",
      "Epoch: 1 \tTraining Loss: 6.500075 \tValidation Loss: 5.531082\n",
      "Validation loss decreased (inf --> 5.53108).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.005624 \tValidation Loss: 5.429745\n",
      "Validation loss decreased (5.53108 --> 5.42975).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.794829 \tValidation Loss: 5.289279\n",
      "Validation loss decreased (5.42975 --> 5.28928).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.481522 \tValidation Loss: 5.103288\n",
      "Validation loss decreased (5.28928 --> 5.10329).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.075663 \tValidation Loss: 4.903680\n",
      "Validation loss decreased (5.10329 --> 4.90368).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.616532 \tValidation Loss: 4.719749\n",
      "Validation loss decreased (4.90368 --> 4.71975).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.146605 \tValidation Loss: 4.566806\n",
      "Validation loss decreased (4.71975 --> 4.56681).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.702579 \tValidation Loss: 4.451107\n",
      "Validation loss decreased (4.56681 --> 4.45111).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.308713 \tValidation Loss: 4.368859\n",
      "Validation loss decreased (4.45111 --> 4.36886).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.966980 \tValidation Loss: 4.313888\n",
      "Validation loss decreased (4.36886 --> 4.31389).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.680050 \tValidation Loss: 4.280017\n",
      "Validation loss decreased (4.31389 --> 4.28002).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.443389 \tValidation Loss: 4.264266\n",
      "Validation loss decreased (4.28002 --> 4.26427).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.249811 \tValidation Loss: 4.260626\n",
      "Validation loss decreased (4.26427 --> 4.26063).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 2.095016 \tValidation Loss: 4.266645\n",
      "Epoch: 15 \tTraining Loss: 1.962583 \tValidation Loss: 4.281742\n",
      "Epoch: 16 \tTraining Loss: 1.858337 \tValidation Loss: 4.301608\n",
      "Epoch: 17 \tTraining Loss: 1.770280 \tValidation Loss: 4.327521\n",
      "Epoch: 18 \tTraining Loss: 1.692845 \tValidation Loss: 4.357565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 \tTraining Loss: 1.630790 \tValidation Loss: 4.389479\n",
      "Epoch: 20 \tTraining Loss: 1.575731 \tValidation Loss: 4.423532\n",
      "Epoch: 1 \tTraining Loss: 6.511426 \tValidation Loss: 5.536744\n",
      "Validation loss decreased (inf --> 5.53674).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.999760 \tValidation Loss: 5.438513\n",
      "Validation loss decreased (5.53674 --> 5.43851).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.785919 \tValidation Loss: 5.292811\n",
      "Validation loss decreased (5.43851 --> 5.29281).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.472261 \tValidation Loss: 5.101660\n",
      "Validation loss decreased (5.29281 --> 5.10166).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.066582 \tValidation Loss: 4.905209\n",
      "Validation loss decreased (5.10166 --> 4.90521).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.607760 \tValidation Loss: 4.729720\n",
      "Validation loss decreased (4.90521 --> 4.72972).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.143534 \tValidation Loss: 4.585755\n",
      "Validation loss decreased (4.72972 --> 4.58576).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.701616 \tValidation Loss: 4.474964\n",
      "Validation loss decreased (4.58576 --> 4.47496).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.306458 \tValidation Loss: 4.395656\n",
      "Validation loss decreased (4.47496 --> 4.39566).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.964526 \tValidation Loss: 4.342774\n",
      "Validation loss decreased (4.39566 --> 4.34277).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.681225 \tValidation Loss: 4.310887\n",
      "Validation loss decreased (4.34277 --> 4.31089).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.441198 \tValidation Loss: 4.297420\n",
      "Validation loss decreased (4.31089 --> 4.29742).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.247322 \tValidation Loss: 4.296765\n",
      "Validation loss decreased (4.29742 --> 4.29677).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 2.086527 \tValidation Loss: 4.305649\n",
      "Epoch: 15 \tTraining Loss: 1.957509 \tValidation Loss: 4.323438\n",
      "Epoch: 16 \tTraining Loss: 1.853756 \tValidation Loss: 4.345265\n",
      "Epoch: 17 \tTraining Loss: 1.762685 \tValidation Loss: 4.373153\n",
      "Epoch: 18 \tTraining Loss: 1.688984 \tValidation Loss: 4.404177\n",
      "Epoch: 19 \tTraining Loss: 1.625273 \tValidation Loss: 4.438414\n",
      "Epoch: 20 \tTraining Loss: 1.567614 \tValidation Loss: 4.475582\n",
      "Epoch: 1 \tTraining Loss: 6.503991 \tValidation Loss: 5.502470\n",
      "Validation loss decreased (inf --> 5.50247).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.004486 \tValidation Loss: 5.400131\n",
      "Validation loss decreased (5.50247 --> 5.40013).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.788448 \tValidation Loss: 5.252981\n",
      "Validation loss decreased (5.40013 --> 5.25298).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.473714 \tValidation Loss: 5.057503\n",
      "Validation loss decreased (5.25298 --> 5.05750).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.067095 \tValidation Loss: 4.857268\n",
      "Validation loss decreased (5.05750 --> 4.85727).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.609711 \tValidation Loss: 4.678460\n",
      "Validation loss decreased (4.85727 --> 4.67846).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.140717 \tValidation Loss: 4.536432\n",
      "Validation loss decreased (4.67846 --> 4.53643).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.701007 \tValidation Loss: 4.430807\n",
      "Validation loss decreased (4.53643 --> 4.43081).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.304193 \tValidation Loss: 4.354958\n",
      "Validation loss decreased (4.43081 --> 4.35496).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.961349 \tValidation Loss: 4.305919\n",
      "Validation loss decreased (4.35496 --> 4.30592).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.671115 \tValidation Loss: 4.279424\n",
      "Validation loss decreased (4.30592 --> 4.27942).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.436414 \tValidation Loss: 4.270431\n",
      "Validation loss decreased (4.27942 --> 4.27043).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.244115 \tValidation Loss: 4.273676\n",
      "Epoch: 14 \tTraining Loss: 2.085651 \tValidation Loss: 4.288642\n",
      "Epoch: 15 \tTraining Loss: 1.953930 \tValidation Loss: 4.309111\n",
      "Epoch: 16 \tTraining Loss: 1.847322 \tValidation Loss: 4.337032\n",
      "Epoch: 17 \tTraining Loss: 1.760702 \tValidation Loss: 4.366739\n",
      "Epoch: 18 \tTraining Loss: 1.683653 \tValidation Loss: 4.399746\n",
      "Epoch: 19 \tTraining Loss: 1.618568 \tValidation Loss: 4.434308\n",
      "Epoch: 20 \tTraining Loss: 1.567580 \tValidation Loss: 4.473259\n",
      "Epoch: 1 \tTraining Loss: 6.508611 \tValidation Loss: 5.497333\n",
      "Validation loss decreased (inf --> 5.49733).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.003553 \tValidation Loss: 5.400235\n",
      "Validation loss decreased (5.49733 --> 5.40024).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.782769 \tValidation Loss: 5.263453\n",
      "Validation loss decreased (5.40024 --> 5.26345).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.459049 \tValidation Loss: 5.086015\n",
      "Validation loss decreased (5.26345 --> 5.08602).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.049763 \tValidation Loss: 4.903497\n",
      "Validation loss decreased (5.08602 --> 4.90350).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.593923 \tValidation Loss: 4.733293\n",
      "Validation loss decreased (4.90350 --> 4.73329).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.132577 \tValidation Loss: 4.588565\n",
      "Validation loss decreased (4.73329 --> 4.58857).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.695630 \tValidation Loss: 4.477619\n",
      "Validation loss decreased (4.58857 --> 4.47762).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.300704 \tValidation Loss: 4.400161\n",
      "Validation loss decreased (4.47762 --> 4.40016).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.963831 \tValidation Loss: 4.349836\n",
      "Validation loss decreased (4.40016 --> 4.34984).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.678875 \tValidation Loss: 4.320612\n",
      "Validation loss decreased (4.34984 --> 4.32061).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.442697 \tValidation Loss: 4.309465\n",
      "Validation loss decreased (4.32061 --> 4.30947).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.252112 \tValidation Loss: 4.310074\n",
      "Epoch: 14 \tTraining Loss: 2.091923 \tValidation Loss: 4.321573\n",
      "Epoch: 15 \tTraining Loss: 1.965379 \tValidation Loss: 4.340168\n",
      "Epoch: 16 \tTraining Loss: 1.857970 \tValidation Loss: 4.363399\n",
      "Epoch: 17 \tTraining Loss: 1.767868 \tValidation Loss: 4.392174\n",
      "Epoch: 18 \tTraining Loss: 1.691544 \tValidation Loss: 4.424726\n",
      "Epoch: 19 \tTraining Loss: 1.627843 \tValidation Loss: 4.459294\n",
      "Epoch: 20 \tTraining Loss: 1.576292 \tValidation Loss: 4.494678\n",
      "Epoch: 1 \tTraining Loss: 6.506374 \tValidation Loss: 5.462293\n",
      "Validation loss decreased (inf --> 5.46229).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.008684 \tValidation Loss: 5.365222\n",
      "Validation loss decreased (5.46229 --> 5.36522).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.793350 \tValidation Loss: 5.218033\n",
      "Validation loss decreased (5.36522 --> 5.21803).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.479637 \tValidation Loss: 5.029869\n",
      "Validation loss decreased (5.21803 --> 5.02987).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.073348 \tValidation Loss: 4.833973\n",
      "Validation loss decreased (5.02987 --> 4.83397).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.614985 \tValidation Loss: 4.656839\n",
      "Validation loss decreased (4.83397 --> 4.65684).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.148841 \tValidation Loss: 4.508418\n",
      "Validation loss decreased (4.65684 --> 4.50842).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.704321 \tValidation Loss: 4.394210\n",
      "Validation loss decreased (4.50842 --> 4.39421).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.308348 \tValidation Loss: 4.312510\n",
      "Validation loss decreased (4.39421 --> 4.31251).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.966183 \tValidation Loss: 4.256732\n",
      "Validation loss decreased (4.31251 --> 4.25673).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.679536 \tValidation Loss: 4.223811\n",
      "Validation loss decreased (4.25673 --> 4.22381).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.446158 \tValidation Loss: 4.208524\n",
      "Validation loss decreased (4.22381 --> 4.20852).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.247669 \tValidation Loss: 4.204888\n",
      "Validation loss decreased (4.20852 --> 4.20489).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 2.094067 \tValidation Loss: 4.210727\n",
      "Epoch: 15 \tTraining Loss: 1.965553 \tValidation Loss: 4.224856\n",
      "Epoch: 16 \tTraining Loss: 1.855736 \tValidation Loss: 4.245798\n",
      "Epoch: 17 \tTraining Loss: 1.762976 \tValidation Loss: 4.270549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 \tTraining Loss: 1.689148 \tValidation Loss: 4.297832\n",
      "Epoch: 19 \tTraining Loss: 1.628873 \tValidation Loss: 4.329140\n",
      "Epoch: 20 \tTraining Loss: 1.572278 \tValidation Loss: 4.362075\n",
      "Epoch: 1 \tTraining Loss: 6.506100 \tValidation Loss: 5.522712\n",
      "Validation loss decreased (inf --> 5.52271).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.004022 \tValidation Loss: 5.419883\n",
      "Validation loss decreased (5.52271 --> 5.41988).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.787334 \tValidation Loss: 5.278086\n",
      "Validation loss decreased (5.41988 --> 5.27809).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.468678 \tValidation Loss: 5.090201\n",
      "Validation loss decreased (5.27809 --> 5.09020).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.060212 \tValidation Loss: 4.893157\n",
      "Validation loss decreased (5.09020 --> 4.89316).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.602539 \tValidation Loss: 4.711950\n",
      "Validation loss decreased (4.89316 --> 4.71195).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.137863 \tValidation Loss: 4.562361\n",
      "Validation loss decreased (4.71195 --> 4.56236).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.701373 \tValidation Loss: 4.446843\n",
      "Validation loss decreased (4.56236 --> 4.44684).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.307513 \tValidation Loss: 4.362950\n",
      "Validation loss decreased (4.44684 --> 4.36295).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.967604 \tValidation Loss: 4.305683\n",
      "Validation loss decreased (4.36295 --> 4.30568).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.684933 \tValidation Loss: 4.269898\n",
      "Validation loss decreased (4.30568 --> 4.26990).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.447359 \tValidation Loss: 4.250930\n",
      "Validation loss decreased (4.26990 --> 4.25093).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.256718 \tValidation Loss: 4.245212\n",
      "Validation loss decreased (4.25093 --> 4.24521).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 2.099486 \tValidation Loss: 4.250617\n",
      "Epoch: 15 \tTraining Loss: 1.969736 \tValidation Loss: 4.262946\n",
      "Epoch: 16 \tTraining Loss: 1.863411 \tValidation Loss: 4.280812\n",
      "Epoch: 17 \tTraining Loss: 1.772576 \tValidation Loss: 4.304545\n",
      "Epoch: 18 \tTraining Loss: 1.695351 \tValidation Loss: 4.330868\n",
      "Epoch: 19 \tTraining Loss: 1.637516 \tValidation Loss: 4.360542\n",
      "Epoch: 20 \tTraining Loss: 1.581658 \tValidation Loss: 4.392934\n",
      "Epoch: 1 \tTraining Loss: 6.507523 \tValidation Loss: 5.462132\n",
      "Validation loss decreased (inf --> 5.46213).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.002441 \tValidation Loss: 5.361379\n",
      "Validation loss decreased (5.46213 --> 5.36138).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.782907 \tValidation Loss: 5.219512\n",
      "Validation loss decreased (5.36138 --> 5.21951).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.465004 \tValidation Loss: 5.035906\n",
      "Validation loss decreased (5.21951 --> 5.03591).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 5.061838 \tValidation Loss: 4.840601\n",
      "Validation loss decreased (5.03591 --> 4.84060).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.607162 \tValidation Loss: 4.658096\n",
      "Validation loss decreased (4.84060 --> 4.65810).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 4.143229 \tValidation Loss: 4.507155\n",
      "Validation loss decreased (4.65810 --> 4.50716).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.705253 \tValidation Loss: 4.391031\n",
      "Validation loss decreased (4.50716 --> 4.39103).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.313125 \tValidation Loss: 4.308168\n",
      "Validation loss decreased (4.39103 --> 4.30817).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.972749 \tValidation Loss: 4.254245\n",
      "Validation loss decreased (4.30817 --> 4.25425).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.687517 \tValidation Loss: 4.220950\n",
      "Validation loss decreased (4.25425 --> 4.22095).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.448408 \tValidation Loss: 4.204752\n",
      "Validation loss decreased (4.22095 --> 4.20475).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.256342 \tValidation Loss: 4.203585\n",
      "Validation loss decreased (4.20475 --> 4.20358).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 2.097205 \tValidation Loss: 4.211256\n",
      "Epoch: 15 \tTraining Loss: 1.967338 \tValidation Loss: 4.226494\n",
      "Epoch: 16 \tTraining Loss: 1.858946 \tValidation Loss: 4.247422\n",
      "Epoch: 17 \tTraining Loss: 1.770478 \tValidation Loss: 4.274334\n",
      "Epoch: 18 \tTraining Loss: 1.694212 \tValidation Loss: 4.301933\n",
      "Epoch: 19 \tTraining Loss: 1.634987 \tValidation Loss: 4.332818\n",
      "Epoch: 20 \tTraining Loss: 1.578002 \tValidation Loss: 4.368398\n",
      "bbc/sport\\199.txt  had a problem\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 4 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.483341 \tValidation Loss: 5.490670\n",
      "Validation loss decreased (inf --> 5.49067).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.935117 \tValidation Loss: 5.319832\n",
      "Validation loss decreased (5.49067 --> 5.31983).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.578274 \tValidation Loss: 5.055618\n",
      "Validation loss decreased (5.31983 --> 5.05562).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.061038 \tValidation Loss: 4.742852\n",
      "Validation loss decreased (5.05562 --> 4.74285).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.447208 \tValidation Loss: 4.442099\n",
      "Validation loss decreased (4.74285 --> 4.44210).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.820129 \tValidation Loss: 4.187612\n",
      "Validation loss decreased (4.44210 --> 4.18761).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.244008 \tValidation Loss: 3.982185\n",
      "Validation loss decreased (4.18761 --> 3.98218).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.747078 \tValidation Loss: 3.821832\n",
      "Validation loss decreased (3.98218 --> 3.82183).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.339322 \tValidation Loss: 3.703295\n",
      "Validation loss decreased (3.82183 --> 3.70329).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.015887 \tValidation Loss: 3.616741\n",
      "Validation loss decreased (3.70329 --> 3.61674).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.759618 \tValidation Loss: 3.556365\n",
      "Validation loss decreased (3.61674 --> 3.55636).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.555827 \tValidation Loss: 3.517385\n",
      "Validation loss decreased (3.55636 --> 3.51738).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.393495 \tValidation Loss: 3.493450\n",
      "Validation loss decreased (3.51738 --> 3.49345).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.260542 \tValidation Loss: 3.484491\n",
      "Validation loss decreased (3.49345 --> 3.48449).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.156473 \tValidation Loss: 3.485069\n",
      "Epoch: 16 \tTraining Loss: 1.068712 \tValidation Loss: 3.493866\n",
      "Epoch: 17 \tTraining Loss: 0.992932 \tValidation Loss: 3.510691\n",
      "Epoch: 18 \tTraining Loss: 0.929845 \tValidation Loss: 3.532457\n",
      "Epoch: 19 \tTraining Loss: 0.880610 \tValidation Loss: 3.558049\n",
      "Epoch: 20 \tTraining Loss: 0.831716 \tValidation Loss: 3.585300\n",
      "Epoch: 1 \tTraining Loss: 6.484327 \tValidation Loss: 5.498389\n",
      "Validation loss decreased (inf --> 5.49839).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.939258 \tValidation Loss: 5.322860\n",
      "Validation loss decreased (5.49839 --> 5.32286).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.582699 \tValidation Loss: 5.057233\n",
      "Validation loss decreased (5.32286 --> 5.05723).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.063207 \tValidation Loss: 4.740585\n",
      "Validation loss decreased (5.05723 --> 4.74058).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.439724 \tValidation Loss: 4.436789\n",
      "Validation loss decreased (4.74058 --> 4.43679).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.808534 \tValidation Loss: 4.178660\n",
      "Validation loss decreased (4.43679 --> 4.17866).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.230026 \tValidation Loss: 3.974914\n",
      "Validation loss decreased (4.17866 --> 3.97491).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.731992 \tValidation Loss: 3.819416\n",
      "Validation loss decreased (3.97491 --> 3.81942).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.323006 \tValidation Loss: 3.705760\n",
      "Validation loss decreased (3.81942 --> 3.70576).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.002250 \tValidation Loss: 3.623793\n",
      "Validation loss decreased (3.70576 --> 3.62379).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.746065 \tValidation Loss: 3.566205\n",
      "Validation loss decreased (3.62379 --> 3.56620).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.546561 \tValidation Loss: 3.529802\n",
      "Validation loss decreased (3.56620 --> 3.52980).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.384057 \tValidation Loss: 3.508885\n",
      "Validation loss decreased (3.52980 --> 3.50889).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 \tTraining Loss: 1.256829 \tValidation Loss: 3.501190\n",
      "Validation loss decreased (3.50889 --> 3.50119).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.151502 \tValidation Loss: 3.503302\n",
      "Epoch: 16 \tTraining Loss: 1.056873 \tValidation Loss: 3.514009\n",
      "Epoch: 17 \tTraining Loss: 0.991092 \tValidation Loss: 3.528372\n",
      "Epoch: 18 \tTraining Loss: 0.927563 \tValidation Loss: 3.549983\n",
      "Epoch: 19 \tTraining Loss: 0.876268 \tValidation Loss: 3.573579\n",
      "Epoch: 20 \tTraining Loss: 0.829411 \tValidation Loss: 3.602604\n",
      "Epoch: 1 \tTraining Loss: 6.482304 \tValidation Loss: 5.472974\n",
      "Validation loss decreased (inf --> 5.47297).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.933061 \tValidation Loss: 5.297021\n",
      "Validation loss decreased (5.47297 --> 5.29702).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.570046 \tValidation Loss: 5.034884\n",
      "Validation loss decreased (5.29702 --> 5.03488).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.050521 \tValidation Loss: 4.719244\n",
      "Validation loss decreased (5.03488 --> 4.71924).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.433763 \tValidation Loss: 4.409139\n",
      "Validation loss decreased (4.71924 --> 4.40914).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.810082 \tValidation Loss: 4.138943\n",
      "Validation loss decreased (4.40914 --> 4.13894).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.233623 \tValidation Loss: 3.922841\n",
      "Validation loss decreased (4.13894 --> 3.92284).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.734002 \tValidation Loss: 3.755789\n",
      "Validation loss decreased (3.92284 --> 3.75579).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.327505 \tValidation Loss: 3.632964\n",
      "Validation loss decreased (3.75579 --> 3.63296).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.999673 \tValidation Loss: 3.545275\n",
      "Validation loss decreased (3.63296 --> 3.54528).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.744664 \tValidation Loss: 3.485746\n",
      "Validation loss decreased (3.54528 --> 3.48575).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.543817 \tValidation Loss: 3.446115\n",
      "Validation loss decreased (3.48575 --> 3.44611).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.380913 \tValidation Loss: 3.423889\n",
      "Validation loss decreased (3.44611 --> 3.42389).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.249974 \tValidation Loss: 3.414231\n",
      "Validation loss decreased (3.42389 --> 3.41423).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.141821 \tValidation Loss: 3.415980\n",
      "Epoch: 16 \tTraining Loss: 1.053144 \tValidation Loss: 3.423906\n",
      "Epoch: 17 \tTraining Loss: 0.979302 \tValidation Loss: 3.440397\n",
      "Epoch: 18 \tTraining Loss: 0.920840 \tValidation Loss: 3.463216\n",
      "Epoch: 19 \tTraining Loss: 0.868399 \tValidation Loss: 3.486798\n",
      "Epoch: 20 \tTraining Loss: 0.822805 \tValidation Loss: 3.516320\n",
      "Epoch: 1 \tTraining Loss: 6.480965 \tValidation Loss: 5.487363\n",
      "Validation loss decreased (inf --> 5.48736).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.931512 \tValidation Loss: 5.305912\n",
      "Validation loss decreased (5.48736 --> 5.30591).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.561466 \tValidation Loss: 5.039192\n",
      "Validation loss decreased (5.30591 --> 5.03919).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.036894 \tValidation Loss: 4.726981\n",
      "Validation loss decreased (5.03919 --> 4.72698).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.417695 \tValidation Loss: 4.422338\n",
      "Validation loss decreased (4.72698 --> 4.42234).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.789142 \tValidation Loss: 4.161675\n",
      "Validation loss decreased (4.42234 --> 4.16167).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.212142 \tValidation Loss: 3.954411\n",
      "Validation loss decreased (4.16167 --> 3.95441).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.717918 \tValidation Loss: 3.796142\n",
      "Validation loss decreased (3.95441 --> 3.79614).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.314903 \tValidation Loss: 3.680040\n",
      "Validation loss decreased (3.79614 --> 3.68004).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.992995 \tValidation Loss: 3.595421\n",
      "Validation loss decreased (3.68004 --> 3.59542).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.741587 \tValidation Loss: 3.537697\n",
      "Validation loss decreased (3.59542 --> 3.53770).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.535234 \tValidation Loss: 3.502348\n",
      "Validation loss decreased (3.53770 --> 3.50235).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.374686 \tValidation Loss: 3.482633\n",
      "Validation loss decreased (3.50235 --> 3.48263).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.248109 \tValidation Loss: 3.476609\n",
      "Validation loss decreased (3.48263 --> 3.47661).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.139720 \tValidation Loss: 3.480729\n",
      "Epoch: 16 \tTraining Loss: 1.051986 \tValidation Loss: 3.491214\n",
      "Epoch: 17 \tTraining Loss: 0.980070 \tValidation Loss: 3.508205\n",
      "Epoch: 18 \tTraining Loss: 0.917588 \tValidation Loss: 3.529957\n",
      "Epoch: 19 \tTraining Loss: 0.865527 \tValidation Loss: 3.555901\n",
      "Epoch: 20 \tTraining Loss: 0.824839 \tValidation Loss: 3.586376\n",
      "Epoch: 1 \tTraining Loss: 6.488505 \tValidation Loss: 5.442489\n",
      "Validation loss decreased (inf --> 5.44249).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.945525 \tValidation Loss: 5.272685\n",
      "Validation loss decreased (5.44249 --> 5.27269).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.593514 \tValidation Loss: 5.009759\n",
      "Validation loss decreased (5.27269 --> 5.00976).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.076840 \tValidation Loss: 4.686229\n",
      "Validation loss decreased (5.00976 --> 4.68623).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.455990 \tValidation Loss: 4.368787\n",
      "Validation loss decreased (4.68623 --> 4.36879).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.820456 \tValidation Loss: 4.098730\n",
      "Validation loss decreased (4.36879 --> 4.09873).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.238927 \tValidation Loss: 3.884815\n",
      "Validation loss decreased (4.09873 --> 3.88481).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.739344 \tValidation Loss: 3.721393\n",
      "Validation loss decreased (3.88481 --> 3.72139).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.332725 \tValidation Loss: 3.599632\n",
      "Validation loss decreased (3.72139 --> 3.59963).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.004017 \tValidation Loss: 3.512864\n",
      "Validation loss decreased (3.59963 --> 3.51286).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.749392 \tValidation Loss: 3.453833\n",
      "Validation loss decreased (3.51286 --> 3.45383).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.548434 \tValidation Loss: 3.416332\n",
      "Validation loss decreased (3.45383 --> 3.41633).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.389112 \tValidation Loss: 3.393080\n",
      "Validation loss decreased (3.41633 --> 3.39308).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.255005 \tValidation Loss: 3.386028\n",
      "Validation loss decreased (3.39308 --> 3.38603).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.148433 \tValidation Loss: 3.387649\n",
      "Epoch: 16 \tTraining Loss: 1.062348 \tValidation Loss: 3.399382\n",
      "Epoch: 17 \tTraining Loss: 0.990389 \tValidation Loss: 3.417811\n",
      "Epoch: 18 \tTraining Loss: 0.927759 \tValidation Loss: 3.438575\n",
      "Epoch: 19 \tTraining Loss: 0.876233 \tValidation Loss: 3.465667\n",
      "Epoch: 20 \tTraining Loss: 0.830321 \tValidation Loss: 3.492372\n",
      "Epoch: 1 \tTraining Loss: 6.486165 \tValidation Loss: 5.458355\n",
      "Validation loss decreased (inf --> 5.45836).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.934931 \tValidation Loss: 5.287644\n",
      "Validation loss decreased (5.45836 --> 5.28764).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.573832 \tValidation Loss: 5.033388\n",
      "Validation loss decreased (5.28764 --> 5.03339).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.061312 \tValidation Loss: 4.726305\n",
      "Validation loss decreased (5.03339 --> 4.72630).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.448920 \tValidation Loss: 4.421255\n",
      "Validation loss decreased (4.72630 --> 4.42126).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.823778 \tValidation Loss: 4.158936\n",
      "Validation loss decreased (4.42126 --> 4.15894).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.247160 \tValidation Loss: 3.944444\n",
      "Validation loss decreased (4.15894 --> 3.94444).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.748085 \tValidation Loss: 3.777443\n",
      "Validation loss decreased (3.94444 --> 3.77744).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.337663 \tValidation Loss: 3.652912\n",
      "Validation loss decreased (3.77744 --> 3.65291).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.012417 \tValidation Loss: 3.564542\n",
      "Validation loss decreased (3.65291 --> 3.56454).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 \tTraining Loss: 1.755789 \tValidation Loss: 3.503640\n",
      "Validation loss decreased (3.56454 --> 3.50364).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.551622 \tValidation Loss: 3.463841\n",
      "Validation loss decreased (3.50364 --> 3.46384).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.387731 \tValidation Loss: 3.440670\n",
      "Validation loss decreased (3.46384 --> 3.44067).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.258354 \tValidation Loss: 3.430684\n",
      "Validation loss decreased (3.44067 --> 3.43068).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.151673 \tValidation Loss: 3.430716\n",
      "Epoch: 16 \tTraining Loss: 1.061907 \tValidation Loss: 3.439545\n",
      "Epoch: 17 \tTraining Loss: 0.990203 \tValidation Loss: 3.454464\n",
      "Epoch: 18 \tTraining Loss: 0.926698 \tValidation Loss: 3.474563\n",
      "Epoch: 19 \tTraining Loss: 0.874620 \tValidation Loss: 3.496038\n",
      "Epoch: 20 \tTraining Loss: 0.832099 \tValidation Loss: 3.523427\n",
      "Epoch: 1 \tTraining Loss: 6.488021 \tValidation Loss: 5.463436\n",
      "Validation loss decreased (inf --> 5.46344).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.936035 \tValidation Loss: 5.283497\n",
      "Validation loss decreased (5.46344 --> 5.28350).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.575857 \tValidation Loss: 5.006318\n",
      "Validation loss decreased (5.28350 --> 5.00632).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.057803 \tValidation Loss: 4.673434\n",
      "Validation loss decreased (5.00632 --> 4.67343).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.442405 \tValidation Loss: 4.349769\n",
      "Validation loss decreased (4.67343 --> 4.34977).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.816257 \tValidation Loss: 4.077896\n",
      "Validation loss decreased (4.34977 --> 4.07790).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.240459 \tValidation Loss: 3.858874\n",
      "Validation loss decreased (4.07790 --> 3.85887).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.746099 \tValidation Loss: 3.689662\n",
      "Validation loss decreased (3.85887 --> 3.68966).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.339659 \tValidation Loss: 3.563850\n",
      "Validation loss decreased (3.68966 --> 3.56385).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.014632 \tValidation Loss: 3.471457\n",
      "Validation loss decreased (3.56385 --> 3.47146).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.758943 \tValidation Loss: 3.407689\n",
      "Validation loss decreased (3.47146 --> 3.40769).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.555161 \tValidation Loss: 3.365398\n",
      "Validation loss decreased (3.40769 --> 3.36540).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.393423 \tValidation Loss: 3.341409\n",
      "Validation loss decreased (3.36540 --> 3.34141).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.261510 \tValidation Loss: 3.328905\n",
      "Validation loss decreased (3.34141 --> 3.32891).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.154780 \tValidation Loss: 3.325987\n",
      "Validation loss decreased (3.32891 --> 3.32599).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 1.065142 \tValidation Loss: 3.332234\n",
      "Epoch: 17 \tTraining Loss: 0.994313 \tValidation Loss: 3.343728\n",
      "Epoch: 18 \tTraining Loss: 0.926732 \tValidation Loss: 3.359954\n",
      "Epoch: 19 \tTraining Loss: 0.877284 \tValidation Loss: 3.377808\n",
      "Epoch: 20 \tTraining Loss: 0.830123 \tValidation Loss: 3.402756\n",
      "Epoch: 1 \tTraining Loss: 6.484841 \tValidation Loss: 5.493876\n",
      "Validation loss decreased (inf --> 5.49388).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.933567 \tValidation Loss: 5.316239\n",
      "Validation loss decreased (5.49388 --> 5.31624).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.581906 \tValidation Loss: 5.046834\n",
      "Validation loss decreased (5.31624 --> 5.04683).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.068005 \tValidation Loss: 4.732187\n",
      "Validation loss decreased (5.04683 --> 4.73219).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.454070 \tValidation Loss: 4.427864\n",
      "Validation loss decreased (4.73219 --> 4.42786).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.824704 \tValidation Loss: 4.165752\n",
      "Validation loss decreased (4.42786 --> 4.16575).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.246818 \tValidation Loss: 3.952845\n",
      "Validation loss decreased (4.16575 --> 3.95285).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.748565 \tValidation Loss: 3.786910\n",
      "Validation loss decreased (3.95285 --> 3.78691).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.339636 \tValidation Loss: 3.663864\n",
      "Validation loss decreased (3.78691 --> 3.66386).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.010612 \tValidation Loss: 3.574584\n",
      "Validation loss decreased (3.66386 --> 3.57458).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.756436 \tValidation Loss: 3.511247\n",
      "Validation loss decreased (3.57458 --> 3.51125).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.554454 \tValidation Loss: 3.469335\n",
      "Validation loss decreased (3.51125 --> 3.46933).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.388538 \tValidation Loss: 3.445618\n",
      "Validation loss decreased (3.46933 --> 3.44562).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.259977 \tValidation Loss: 3.434992\n",
      "Validation loss decreased (3.44562 --> 3.43499).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.151981 \tValidation Loss: 3.435444\n",
      "Epoch: 16 \tTraining Loss: 1.064972 \tValidation Loss: 3.441959\n",
      "Epoch: 17 \tTraining Loss: 0.991521 \tValidation Loss: 3.456173\n",
      "Epoch: 18 \tTraining Loss: 0.928037 \tValidation Loss: 3.477701\n",
      "Epoch: 19 \tTraining Loss: 0.874941 \tValidation Loss: 3.499932\n",
      "Epoch: 20 \tTraining Loss: 0.832272 \tValidation Loss: 3.529325\n",
      "Epoch: 1 \tTraining Loss: 6.489011 \tValidation Loss: 5.494691\n",
      "Validation loss decreased (inf --> 5.49469).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.926658 \tValidation Loss: 5.314083\n",
      "Validation loss decreased (5.49469 --> 5.31408).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.558947 \tValidation Loss: 5.043550\n",
      "Validation loss decreased (5.31408 --> 5.04355).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.037708 \tValidation Loss: 4.731312\n",
      "Validation loss decreased (5.04355 --> 4.73131).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.426909 \tValidation Loss: 4.423656\n",
      "Validation loss decreased (4.73131 --> 4.42366).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.808954 \tValidation Loss: 4.156330\n",
      "Validation loss decreased (4.42366 --> 4.15633).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.241368 \tValidation Loss: 3.936074\n",
      "Validation loss decreased (4.15633 --> 3.93607).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.746917 \tValidation Loss: 3.761405\n",
      "Validation loss decreased (3.93607 --> 3.76140).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.341762 \tValidation Loss: 3.626982\n",
      "Validation loss decreased (3.76140 --> 3.62698).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.015117 \tValidation Loss: 3.529569\n",
      "Validation loss decreased (3.62698 --> 3.52957).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.759627 \tValidation Loss: 3.461840\n",
      "Validation loss decreased (3.52957 --> 3.46184).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.555950 \tValidation Loss: 3.415926\n",
      "Validation loss decreased (3.46184 --> 3.41593).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.396046 \tValidation Loss: 3.388925\n",
      "Validation loss decreased (3.41593 --> 3.38892).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.261257 \tValidation Loss: 3.374785\n",
      "Validation loss decreased (3.38892 --> 3.37478).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.157029 \tValidation Loss: 3.373963\n",
      "Validation loss decreased (3.37478 --> 3.37396).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 1.064703 \tValidation Loss: 3.377624\n",
      "Epoch: 17 \tTraining Loss: 0.989090 \tValidation Loss: 3.391458\n",
      "Epoch: 18 \tTraining Loss: 0.933088 \tValidation Loss: 3.411767\n",
      "Epoch: 19 \tTraining Loss: 0.876265 \tValidation Loss: 3.433922\n",
      "Epoch: 20 \tTraining Loss: 0.831193 \tValidation Loss: 3.461193\n",
      "Epoch: 1 \tTraining Loss: 6.481452 \tValidation Loss: 5.494411\n",
      "Validation loss decreased (inf --> 5.49441).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.934112 \tValidation Loss: 5.327617\n",
      "Validation loss decreased (5.49441 --> 5.32762).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.577858 \tValidation Loss: 5.078550\n",
      "Validation loss decreased (5.32762 --> 5.07855).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.060805 \tValidation Loss: 4.774788\n",
      "Validation loss decreased (5.07855 --> 4.77479).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.439797 \tValidation Loss: 4.481019\n",
      "Validation loss decreased (4.77479 --> 4.48102).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.812804 \tValidation Loss: 4.227172\n",
      "Validation loss decreased (4.48102 --> 4.22717).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 \tTraining Loss: 3.235051 \tValidation Loss: 4.024913\n",
      "Validation loss decreased (4.22717 --> 4.02491).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.738231 \tValidation Loss: 3.871699\n",
      "Validation loss decreased (4.02491 --> 3.87170).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.334575 \tValidation Loss: 3.756489\n",
      "Validation loss decreased (3.87170 --> 3.75649).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.009195 \tValidation Loss: 3.672379\n",
      "Validation loss decreased (3.75649 --> 3.67238).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.752782 \tValidation Loss: 3.614456\n",
      "Validation loss decreased (3.67238 --> 3.61446).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.549910 \tValidation Loss: 3.577448\n",
      "Validation loss decreased (3.61446 --> 3.57745).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.387404 \tValidation Loss: 3.556853\n",
      "Validation loss decreased (3.57745 --> 3.55685).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.253991 \tValidation Loss: 3.549471\n",
      "Validation loss decreased (3.55685 --> 3.54947).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.148976 \tValidation Loss: 3.551319\n",
      "Epoch: 16 \tTraining Loss: 1.060661 \tValidation Loss: 3.560489\n",
      "Epoch: 17 \tTraining Loss: 0.986625 \tValidation Loss: 3.577044\n",
      "Epoch: 18 \tTraining Loss: 0.922963 \tValidation Loss: 3.599307\n",
      "Epoch: 19 \tTraining Loss: 0.872183 \tValidation Loss: 3.625599\n",
      "Epoch: 20 \tTraining Loss: 0.828022 \tValidation Loss: 3.657499\n",
      "bbc/sport\\199.txt  had a problem\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 5 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.453465 \tValidation Loss: 5.857801\n",
      "Validation loss decreased (inf --> 5.85780).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.850166 \tValidation Loss: 5.607532\n",
      "Validation loss decreased (5.85780 --> 5.60753).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.389330 \tValidation Loss: 5.239885\n",
      "Validation loss decreased (5.60753 --> 5.23989).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.738457 \tValidation Loss: 4.814272\n",
      "Validation loss decreased (5.23989 --> 4.81427).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.003555 \tValidation Loss: 4.413763\n",
      "Validation loss decreased (4.81427 --> 4.41376).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.295836 \tValidation Loss: 4.074573\n",
      "Validation loss decreased (4.41376 --> 4.07457).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.679250 \tValidation Loss: 3.797602\n",
      "Validation loss decreased (4.07457 --> 3.79760).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.181711 \tValidation Loss: 3.582699\n",
      "Validation loss decreased (3.79760 --> 3.58270).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.796663 \tValidation Loss: 3.420212\n",
      "Validation loss decreased (3.58270 --> 3.42021).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.502147 \tValidation Loss: 3.300703\n",
      "Validation loss decreased (3.42021 --> 3.30070).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.270168 \tValidation Loss: 3.214707\n",
      "Validation loss decreased (3.30070 --> 3.21471).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.088503 \tValidation Loss: 3.158274\n",
      "Validation loss decreased (3.21471 --> 3.15827).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.944008 \tValidation Loss: 3.124031\n",
      "Validation loss decreased (3.15827 --> 3.12403).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.831004 \tValidation Loss: 3.104610\n",
      "Validation loss decreased (3.12403 --> 3.10461).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.739558 \tValidation Loss: 3.097428\n",
      "Validation loss decreased (3.10461 --> 3.09743).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.664981 \tValidation Loss: 3.097440\n",
      "Epoch: 17 \tTraining Loss: 0.600335 \tValidation Loss: 3.109350\n",
      "Epoch: 18 \tTraining Loss: 0.553032 \tValidation Loss: 3.127003\n",
      "Epoch: 19 \tTraining Loss: 0.505598 \tValidation Loss: 3.146643\n",
      "Epoch: 20 \tTraining Loss: 0.470746 \tValidation Loss: 3.170719\n",
      "Epoch: 1 \tTraining Loss: 6.455158 \tValidation Loss: 5.869226\n",
      "Validation loss decreased (inf --> 5.86923).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.846113 \tValidation Loss: 5.624800\n",
      "Validation loss decreased (5.86923 --> 5.62480).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.385659 \tValidation Loss: 5.254412\n",
      "Validation loss decreased (5.62480 --> 5.25441).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.735334 \tValidation Loss: 4.824912\n",
      "Validation loss decreased (5.25441 --> 4.82491).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.999708 \tValidation Loss: 4.425495\n",
      "Validation loss decreased (4.82491 --> 4.42550).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.292777 \tValidation Loss: 4.084613\n",
      "Validation loss decreased (4.42550 --> 4.08461).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.683971 \tValidation Loss: 3.809580\n",
      "Validation loss decreased (4.08461 --> 3.80958).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.185960 \tValidation Loss: 3.596161\n",
      "Validation loss decreased (3.80958 --> 3.59616).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.796247 \tValidation Loss: 3.435416\n",
      "Validation loss decreased (3.59616 --> 3.43542).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.498362 \tValidation Loss: 3.317352\n",
      "Validation loss decreased (3.43542 --> 3.31735).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.266005 \tValidation Loss: 3.234270\n",
      "Validation loss decreased (3.31735 --> 3.23427).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.085762 \tValidation Loss: 3.176496\n",
      "Validation loss decreased (3.23427 --> 3.17650).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.944813 \tValidation Loss: 3.139517\n",
      "Validation loss decreased (3.17650 --> 3.13952).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.831544 \tValidation Loss: 3.118876\n",
      "Validation loss decreased (3.13952 --> 3.11888).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.738403 \tValidation Loss: 3.111335\n",
      "Validation loss decreased (3.11888 --> 3.11134).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.663516 \tValidation Loss: 3.111720\n",
      "Epoch: 17 \tTraining Loss: 0.600479 \tValidation Loss: 3.121504\n",
      "Epoch: 18 \tTraining Loss: 0.544767 \tValidation Loss: 3.138080\n",
      "Epoch: 19 \tTraining Loss: 0.505987 \tValidation Loss: 3.158004\n",
      "Epoch: 20 \tTraining Loss: 0.469178 \tValidation Loss: 3.179499\n",
      "Epoch: 1 \tTraining Loss: 6.449635 \tValidation Loss: 5.823677\n",
      "Validation loss decreased (inf --> 5.82368).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.849479 \tValidation Loss: 5.580753\n",
      "Validation loss decreased (5.82368 --> 5.58075).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.394372 \tValidation Loss: 5.204224\n",
      "Validation loss decreased (5.58075 --> 5.20422).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.736490 \tValidation Loss: 4.774905\n",
      "Validation loss decreased (5.20422 --> 4.77490).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.994557 \tValidation Loss: 4.375358\n",
      "Validation loss decreased (4.77490 --> 4.37536).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.283614 \tValidation Loss: 4.039391\n",
      "Validation loss decreased (4.37536 --> 4.03939).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.668485 \tValidation Loss: 3.773420\n",
      "Validation loss decreased (4.03939 --> 3.77342).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.175207 \tValidation Loss: 3.567774\n",
      "Validation loss decreased (3.77342 --> 3.56777).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.787844 \tValidation Loss: 3.412808\n",
      "Validation loss decreased (3.56777 --> 3.41281).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.487945 \tValidation Loss: 3.300118\n",
      "Validation loss decreased (3.41281 --> 3.30012).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.257065 \tValidation Loss: 3.217874\n",
      "Validation loss decreased (3.30012 --> 3.21787).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.081098 \tValidation Loss: 3.161325\n",
      "Validation loss decreased (3.21787 --> 3.16132).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.935062 \tValidation Loss: 3.124381\n",
      "Validation loss decreased (3.16132 --> 3.12438).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.824559 \tValidation Loss: 3.104552\n",
      "Validation loss decreased (3.12438 --> 3.10455).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.730890 \tValidation Loss: 3.095367\n",
      "Validation loss decreased (3.10455 --> 3.09537).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.655335 \tValidation Loss: 3.097102\n",
      "Epoch: 17 \tTraining Loss: 0.592431 \tValidation Loss: 3.105745\n",
      "Epoch: 18 \tTraining Loss: 0.542921 \tValidation Loss: 3.122343\n",
      "Epoch: 19 \tTraining Loss: 0.499886 \tValidation Loss: 3.144808\n",
      "Epoch: 20 \tTraining Loss: 0.463236 \tValidation Loss: 3.167184\n",
      "Epoch: 1 \tTraining Loss: 6.455163 \tValidation Loss: 5.844344\n",
      "Validation loss decreased (inf --> 5.84434).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 5.847627 \tValidation Loss: 5.603664\n",
      "Validation loss decreased (5.84434 --> 5.60366).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.388114 \tValidation Loss: 5.229800\n",
      "Validation loss decreased (5.60366 --> 5.22980).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.734548 \tValidation Loss: 4.797598\n",
      "Validation loss decreased (5.22980 --> 4.79760).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.001418 \tValidation Loss: 4.396634\n",
      "Validation loss decreased (4.79760 --> 4.39663).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.293406 \tValidation Loss: 4.056138\n",
      "Validation loss decreased (4.39663 --> 4.05614).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.681263 \tValidation Loss: 3.782597\n",
      "Validation loss decreased (4.05614 --> 3.78260).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.181682 \tValidation Loss: 3.572829\n",
      "Validation loss decreased (3.78260 --> 3.57283).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.796790 \tValidation Loss: 3.417458\n",
      "Validation loss decreased (3.57283 --> 3.41746).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.498656 \tValidation Loss: 3.302091\n",
      "Validation loss decreased (3.41746 --> 3.30209).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.267139 \tValidation Loss: 3.220972\n",
      "Validation loss decreased (3.30209 --> 3.22097).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.089497 \tValidation Loss: 3.163686\n",
      "Validation loss decreased (3.22097 --> 3.16369).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.942884 \tValidation Loss: 3.127373\n",
      "Validation loss decreased (3.16369 --> 3.12737).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.829995 \tValidation Loss: 3.106777\n",
      "Validation loss decreased (3.12737 --> 3.10678).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.734483 \tValidation Loss: 3.096149\n",
      "Validation loss decreased (3.10678 --> 3.09615).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.661082 \tValidation Loss: 3.096208\n",
      "Epoch: 17 \tTraining Loss: 0.596967 \tValidation Loss: 3.106486\n",
      "Epoch: 18 \tTraining Loss: 0.546510 \tValidation Loss: 3.125735\n",
      "Epoch: 19 \tTraining Loss: 0.500761 \tValidation Loss: 3.144704\n",
      "Epoch: 20 \tTraining Loss: 0.467050 \tValidation Loss: 3.170999\n",
      "Epoch: 1 \tTraining Loss: 6.448278 \tValidation Loss: 5.915087\n",
      "Validation loss decreased (inf --> 5.91509).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.838653 \tValidation Loss: 5.668550\n",
      "Validation loss decreased (5.91509 --> 5.66855).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.372771 \tValidation Loss: 5.313779\n",
      "Validation loss decreased (5.66855 --> 5.31378).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.721792 \tValidation Loss: 4.897552\n",
      "Validation loss decreased (5.31378 --> 4.89755).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.988067 \tValidation Loss: 4.504039\n",
      "Validation loss decreased (4.89755 --> 4.50404).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.284839 \tValidation Loss: 4.169449\n",
      "Validation loss decreased (4.50404 --> 4.16945).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.679248 \tValidation Loss: 3.896299\n",
      "Validation loss decreased (4.16945 --> 3.89630).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.184557 \tValidation Loss: 3.682214\n",
      "Validation loss decreased (3.89630 --> 3.68221).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.799542 \tValidation Loss: 3.521950\n",
      "Validation loss decreased (3.68221 --> 3.52195).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.499218 \tValidation Loss: 3.403281\n",
      "Validation loss decreased (3.52195 --> 3.40328).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.269927 \tValidation Loss: 3.317948\n",
      "Validation loss decreased (3.40328 --> 3.31795).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.089683 \tValidation Loss: 3.259408\n",
      "Validation loss decreased (3.31795 --> 3.25941).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.944989 \tValidation Loss: 3.219235\n",
      "Validation loss decreased (3.25941 --> 3.21924).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.827260 \tValidation Loss: 3.195786\n",
      "Validation loss decreased (3.21924 --> 3.19579).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.739141 \tValidation Loss: 3.185750\n",
      "Validation loss decreased (3.19579 --> 3.18575).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.661982 \tValidation Loss: 3.185206\n",
      "Validation loss decreased (3.18575 --> 3.18521).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.596936 \tValidation Loss: 3.196174\n",
      "Epoch: 18 \tTraining Loss: 0.544227 \tValidation Loss: 3.208743\n",
      "Epoch: 19 \tTraining Loss: 0.502383 \tValidation Loss: 3.227772\n",
      "Epoch: 20 \tTraining Loss: 0.466917 \tValidation Loss: 3.248437\n",
      "Epoch: 1 \tTraining Loss: 6.446471 \tValidation Loss: 5.865342\n",
      "Validation loss decreased (inf --> 5.86534).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.851993 \tValidation Loss: 5.612120\n",
      "Validation loss decreased (5.86534 --> 5.61212).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.403199 \tValidation Loss: 5.239155\n",
      "Validation loss decreased (5.61212 --> 5.23915).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.754879 \tValidation Loss: 4.815071\n",
      "Validation loss decreased (5.23915 --> 4.81507).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.010919 \tValidation Loss: 4.422242\n",
      "Validation loss decreased (4.81507 --> 4.42224).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.295008 \tValidation Loss: 4.093986\n",
      "Validation loss decreased (4.42224 --> 4.09399).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.674769 \tValidation Loss: 3.833879\n",
      "Validation loss decreased (4.09399 --> 3.83388).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.175303 \tValidation Loss: 3.637877\n",
      "Validation loss decreased (3.83388 --> 3.63788).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.790483 \tValidation Loss: 3.492969\n",
      "Validation loss decreased (3.63788 --> 3.49297).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.491768 \tValidation Loss: 3.391127\n",
      "Validation loss decreased (3.49297 --> 3.39113).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.260940 \tValidation Loss: 3.320622\n",
      "Validation loss decreased (3.39113 --> 3.32062).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.082424 \tValidation Loss: 3.273440\n",
      "Validation loss decreased (3.32062 --> 3.27344).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.940701 \tValidation Loss: 3.245532\n",
      "Validation loss decreased (3.27344 --> 3.24553).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.829157 \tValidation Loss: 3.231898\n",
      "Validation loss decreased (3.24553 --> 3.23190).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.734631 \tValidation Loss: 3.227183\n",
      "Validation loss decreased (3.23190 --> 3.22718).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.660630 \tValidation Loss: 3.235828\n",
      "Epoch: 17 \tTraining Loss: 0.601007 \tValidation Loss: 3.246363\n",
      "Epoch: 18 \tTraining Loss: 0.545452 \tValidation Loss: 3.264139\n",
      "Epoch: 19 \tTraining Loss: 0.502263 \tValidation Loss: 3.285566\n",
      "Epoch: 20 \tTraining Loss: 0.469331 \tValidation Loss: 3.309022\n",
      "Epoch: 1 \tTraining Loss: 6.461156 \tValidation Loss: 5.837883\n",
      "Validation loss decreased (inf --> 5.83788).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.842119 \tValidation Loss: 5.581905\n",
      "Validation loss decreased (5.83788 --> 5.58190).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.376654 \tValidation Loss: 5.199344\n",
      "Validation loss decreased (5.58190 --> 5.19934).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.723442 \tValidation Loss: 4.764578\n",
      "Validation loss decreased (5.19934 --> 4.76458).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.989557 \tValidation Loss: 4.358058\n",
      "Validation loss decreased (4.76458 --> 4.35806).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.280558 \tValidation Loss: 4.016010\n",
      "Validation loss decreased (4.35806 --> 4.01601).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.666258 \tValidation Loss: 3.744029\n",
      "Validation loss decreased (4.01601 --> 3.74403).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.169999 \tValidation Loss: 3.536546\n",
      "Validation loss decreased (3.74403 --> 3.53655).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.785939 \tValidation Loss: 3.384251\n",
      "Validation loss decreased (3.53655 --> 3.38425).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.489777 \tValidation Loss: 3.272623\n",
      "Validation loss decreased (3.38425 --> 3.27262).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.259980 \tValidation Loss: 3.195586\n",
      "Validation loss decreased (3.27262 --> 3.19559).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.079100 \tValidation Loss: 3.143382\n",
      "Validation loss decreased (3.19559 --> 3.14338).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.938878 \tValidation Loss: 3.109818\n",
      "Validation loss decreased (3.14338 --> 3.10982).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 \tTraining Loss: 0.827412 \tValidation Loss: 3.091155\n",
      "Validation loss decreased (3.10982 --> 3.09116).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.731793 \tValidation Loss: 3.083426\n",
      "Validation loss decreased (3.09116 --> 3.08343).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.658577 \tValidation Loss: 3.083965\n",
      "Epoch: 17 \tTraining Loss: 0.595615 \tValidation Loss: 3.093773\n",
      "Epoch: 18 \tTraining Loss: 0.544878 \tValidation Loss: 3.106896\n",
      "Epoch: 19 \tTraining Loss: 0.505275 \tValidation Loss: 3.127357\n",
      "Epoch: 20 \tTraining Loss: 0.465872 \tValidation Loss: 3.148586\n",
      "Epoch: 1 \tTraining Loss: 6.454552 \tValidation Loss: 5.865429\n",
      "Validation loss decreased (inf --> 5.86543).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.847193 \tValidation Loss: 5.608631\n",
      "Validation loss decreased (5.86543 --> 5.60863).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.383445 \tValidation Loss: 5.237844\n",
      "Validation loss decreased (5.60863 --> 5.23784).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.729511 \tValidation Loss: 4.816502\n",
      "Validation loss decreased (5.23784 --> 4.81650).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.989434 \tValidation Loss: 4.422602\n",
      "Validation loss decreased (4.81650 --> 4.42260).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.280349 \tValidation Loss: 4.087559\n",
      "Validation loss decreased (4.42260 --> 4.08756).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.667840 \tValidation Loss: 3.819268\n",
      "Validation loss decreased (4.08756 --> 3.81927).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.171334 \tValidation Loss: 3.612580\n",
      "Validation loss decreased (3.81927 --> 3.61258).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.787706 \tValidation Loss: 3.460197\n",
      "Validation loss decreased (3.61258 --> 3.46020).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.495045 \tValidation Loss: 3.348157\n",
      "Validation loss decreased (3.46020 --> 3.34816).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.265085 \tValidation Loss: 3.269527\n",
      "Validation loss decreased (3.34816 --> 3.26953).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.083091 \tValidation Loss: 3.214468\n",
      "Validation loss decreased (3.26953 --> 3.21447).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.940677 \tValidation Loss: 3.178612\n",
      "Validation loss decreased (3.21447 --> 3.17861).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.827811 \tValidation Loss: 3.160276\n",
      "Validation loss decreased (3.17861 --> 3.16028).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.733898 \tValidation Loss: 3.153761\n",
      "Validation loss decreased (3.16028 --> 3.15376).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.659644 \tValidation Loss: 3.157591\n",
      "Epoch: 17 \tTraining Loss: 0.596255 \tValidation Loss: 3.167730\n",
      "Epoch: 18 \tTraining Loss: 0.546202 \tValidation Loss: 3.186363\n",
      "Epoch: 19 \tTraining Loss: 0.502475 \tValidation Loss: 3.211504\n",
      "Epoch: 20 \tTraining Loss: 0.467223 \tValidation Loss: 3.236356\n",
      "Epoch: 1 \tTraining Loss: 6.454334 \tValidation Loss: 5.867792\n",
      "Validation loss decreased (inf --> 5.86779).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.843265 \tValidation Loss: 5.608109\n",
      "Validation loss decreased (5.86779 --> 5.60811).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.380639 \tValidation Loss: 5.228478\n",
      "Validation loss decreased (5.60811 --> 5.22848).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.728415 \tValidation Loss: 4.780545\n",
      "Validation loss decreased (5.22848 --> 4.78054).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.987811 \tValidation Loss: 4.362694\n",
      "Validation loss decreased (4.78054 --> 4.36269).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.277696 \tValidation Loss: 4.014553\n",
      "Validation loss decreased (4.36269 --> 4.01455).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.663979 \tValidation Loss: 3.737566\n",
      "Validation loss decreased (4.01455 --> 3.73757).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.166978 \tValidation Loss: 3.523709\n",
      "Validation loss decreased (3.73757 --> 3.52371).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.782366 \tValidation Loss: 3.366682\n",
      "Validation loss decreased (3.52371 --> 3.36668).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.490013 \tValidation Loss: 3.251802\n",
      "Validation loss decreased (3.36668 --> 3.25180).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.260502 \tValidation Loss: 3.171644\n",
      "Validation loss decreased (3.25180 --> 3.17164).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.080980 \tValidation Loss: 3.116967\n",
      "Validation loss decreased (3.17164 --> 3.11697).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.940016 \tValidation Loss: 3.084283\n",
      "Validation loss decreased (3.11697 --> 3.08428).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.824528 \tValidation Loss: 3.066247\n",
      "Validation loss decreased (3.08428 --> 3.06625).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.734940 \tValidation Loss: 3.060126\n",
      "Validation loss decreased (3.06625 --> 3.06013).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.659246 \tValidation Loss: 3.062248\n",
      "Epoch: 17 \tTraining Loss: 0.598678 \tValidation Loss: 3.072505\n",
      "Epoch: 18 \tTraining Loss: 0.547680 \tValidation Loss: 3.086992\n",
      "Epoch: 19 \tTraining Loss: 0.504571 \tValidation Loss: 3.106959\n",
      "Epoch: 20 \tTraining Loss: 0.468926 \tValidation Loss: 3.128407\n",
      "Epoch: 1 \tTraining Loss: 6.453738 \tValidation Loss: 5.899191\n",
      "Validation loss decreased (inf --> 5.89919).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.848295 \tValidation Loss: 5.642115\n",
      "Validation loss decreased (5.89919 --> 5.64212).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.388840 \tValidation Loss: 5.271760\n",
      "Validation loss decreased (5.64212 --> 5.27176).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.739064 \tValidation Loss: 4.839191\n",
      "Validation loss decreased (5.27176 --> 4.83919).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.001716 \tValidation Loss: 4.428215\n",
      "Validation loss decreased (4.83919 --> 4.42822).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.294638 \tValidation Loss: 4.080463\n",
      "Validation loss decreased (4.42822 --> 4.08046).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.679205 \tValidation Loss: 3.803811\n",
      "Validation loss decreased (4.08046 --> 3.80381).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.184901 \tValidation Loss: 3.593504\n",
      "Validation loss decreased (3.80381 --> 3.59350).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.799379 \tValidation Loss: 3.438148\n",
      "Validation loss decreased (3.59350 --> 3.43815).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.503052 \tValidation Loss: 3.325258\n",
      "Validation loss decreased (3.43815 --> 3.32526).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.273873 \tValidation Loss: 3.242706\n",
      "Validation loss decreased (3.32526 --> 3.24271).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.090333 \tValidation Loss: 3.185276\n",
      "Validation loss decreased (3.24271 --> 3.18528).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.948595 \tValidation Loss: 3.149261\n",
      "Validation loss decreased (3.18528 --> 3.14926).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.835389 \tValidation Loss: 3.128079\n",
      "Validation loss decreased (3.14926 --> 3.12808).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.744549 \tValidation Loss: 3.122261\n",
      "Validation loss decreased (3.12808 --> 3.12226).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.666312 \tValidation Loss: 3.124425\n",
      "Epoch: 17 \tTraining Loss: 0.603691 \tValidation Loss: 3.132517\n",
      "Epoch: 18 \tTraining Loss: 0.550051 \tValidation Loss: 3.149042\n",
      "Epoch: 19 \tTraining Loss: 0.510341 \tValidation Loss: 3.167443\n",
      "Epoch: 20 \tTraining Loss: 0.471836 \tValidation Loss: 3.196568\n",
      "bbc/sport\\199.txt  had a problem\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 6 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.455991 \tValidation Loss: 5.689966\n",
      "Validation loss decreased (inf --> 5.68997).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.782245 \tValidation Loss: 5.411355\n",
      "Validation loss decreased (5.68997 --> 5.41135).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.261951 \tValidation Loss: 5.019144\n",
      "Validation loss decreased (5.41135 --> 5.01914).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.546300 \tValidation Loss: 4.567148\n",
      "Validation loss decreased (5.01914 --> 4.56715).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.760257 \tValidation Loss: 4.146206\n",
      "Validation loss decreased (4.56715 --> 4.14621).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.026195 \tValidation Loss: 3.792436\n",
      "Validation loss decreased (4.14621 --> 3.79244).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.400456 \tValidation Loss: 3.512719\n",
      "Validation loss decreased (3.79244 --> 3.51272).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 \tTraining Loss: 1.910061 \tValidation Loss: 3.299191\n",
      "Validation loss decreased (3.51272 --> 3.29919).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.531151 \tValidation Loss: 3.137292\n",
      "Validation loss decreased (3.29919 --> 3.13729).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.244560 \tValidation Loss: 3.018254\n",
      "Validation loss decreased (3.13729 --> 3.01825).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.024925 \tValidation Loss: 2.930789\n",
      "Validation loss decreased (3.01825 --> 2.93079).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.853478 \tValidation Loss: 2.869036\n",
      "Validation loss decreased (2.93079 --> 2.86904).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.719869 \tValidation Loss: 2.827203\n",
      "Validation loss decreased (2.86904 --> 2.82720).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.613416 \tValidation Loss: 2.801508\n",
      "Validation loss decreased (2.82720 --> 2.80151).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.530304 \tValidation Loss: 2.790246\n",
      "Validation loss decreased (2.80151 --> 2.79025).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.467470 \tValidation Loss: 2.787561\n",
      "Validation loss decreased (2.79025 --> 2.78756).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.412084 \tValidation Loss: 2.792931\n",
      "Epoch: 18 \tTraining Loss: 0.369485 \tValidation Loss: 2.805559\n",
      "Epoch: 19 \tTraining Loss: 0.334154 \tValidation Loss: 2.821020\n",
      "Epoch: 20 \tTraining Loss: 0.304719 \tValidation Loss: 2.837965\n",
      "Epoch: 1 \tTraining Loss: 6.454440 \tValidation Loss: 5.611429\n",
      "Validation loss decreased (inf --> 5.61143).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.796779 \tValidation Loss: 5.325563\n",
      "Validation loss decreased (5.61143 --> 5.32556).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.280159 \tValidation Loss: 4.912100\n",
      "Validation loss decreased (5.32556 --> 4.91210).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.562049 \tValidation Loss: 4.457378\n",
      "Validation loss decreased (4.91210 --> 4.45738).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.776833 \tValidation Loss: 4.036903\n",
      "Validation loss decreased (4.45738 --> 4.03690).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.037133 \tValidation Loss: 3.681663\n",
      "Validation loss decreased (4.03690 --> 3.68166).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.409971 \tValidation Loss: 3.399889\n",
      "Validation loss decreased (3.68166 --> 3.39989).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.915480 \tValidation Loss: 3.185682\n",
      "Validation loss decreased (3.39989 --> 3.18568).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.536770 \tValidation Loss: 3.027467\n",
      "Validation loss decreased (3.18568 --> 3.02747).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.249255 \tValidation Loss: 2.915534\n",
      "Validation loss decreased (3.02747 --> 2.91553).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.030359 \tValidation Loss: 2.834243\n",
      "Validation loss decreased (2.91553 --> 2.83424).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.858252 \tValidation Loss: 2.779649\n",
      "Validation loss decreased (2.83424 --> 2.77965).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.722703 \tValidation Loss: 2.744911\n",
      "Validation loss decreased (2.77965 --> 2.74491).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.620270 \tValidation Loss: 2.723827\n",
      "Validation loss decreased (2.74491 --> 2.72383).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.535190 \tValidation Loss: 2.716146\n",
      "Validation loss decreased (2.72383 --> 2.71615).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.469248 \tValidation Loss: 2.716961\n",
      "Epoch: 17 \tTraining Loss: 0.412335 \tValidation Loss: 2.728974\n",
      "Epoch: 18 \tTraining Loss: 0.365297 \tValidation Loss: 2.741587\n",
      "Epoch: 19 \tTraining Loss: 0.333029 \tValidation Loss: 2.756316\n",
      "Epoch: 20 \tTraining Loss: 0.305398 \tValidation Loss: 2.776303\n",
      "Epoch: 1 \tTraining Loss: 6.459079 \tValidation Loss: 5.575287\n",
      "Validation loss decreased (inf --> 5.57529).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.797511 \tValidation Loss: 5.300558\n",
      "Validation loss decreased (5.57529 --> 5.30056).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.283837 \tValidation Loss: 4.898749\n",
      "Validation loss decreased (5.30056 --> 4.89875).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.563137 \tValidation Loss: 4.448142\n",
      "Validation loss decreased (4.89875 --> 4.44814).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.770183 \tValidation Loss: 4.026541\n",
      "Validation loss decreased (4.44814 --> 4.02654).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.027806 \tValidation Loss: 3.675904\n",
      "Validation loss decreased (4.02654 --> 3.67590).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.399733 \tValidation Loss: 3.405074\n",
      "Validation loss decreased (3.67590 --> 3.40507).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.901788 \tValidation Loss: 3.200738\n",
      "Validation loss decreased (3.40507 --> 3.20074).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.524343 \tValidation Loss: 3.050182\n",
      "Validation loss decreased (3.20074 --> 3.05018).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.241205 \tValidation Loss: 2.939270\n",
      "Validation loss decreased (3.05018 --> 2.93927).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.024355 \tValidation Loss: 2.860327\n",
      "Validation loss decreased (2.93927 --> 2.86033).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.853490 \tValidation Loss: 2.805404\n",
      "Validation loss decreased (2.86033 --> 2.80540).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.716128 \tValidation Loss: 2.769373\n",
      "Validation loss decreased (2.80540 --> 2.76937).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.611485 \tValidation Loss: 2.743817\n",
      "Validation loss decreased (2.76937 --> 2.74382).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.529778 \tValidation Loss: 2.732323\n",
      "Validation loss decreased (2.74382 --> 2.73232).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.462416 \tValidation Loss: 2.731060\n",
      "Validation loss decreased (2.73232 --> 2.73106).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.409056 \tValidation Loss: 2.734812\n",
      "Epoch: 18 \tTraining Loss: 0.365454 \tValidation Loss: 2.742604\n",
      "Epoch: 19 \tTraining Loss: 0.329665 \tValidation Loss: 2.760664\n",
      "Epoch: 20 \tTraining Loss: 0.301065 \tValidation Loss: 2.778546\n",
      "Epoch: 1 \tTraining Loss: 6.457841 \tValidation Loss: 5.649913\n",
      "Validation loss decreased (inf --> 5.64991).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.791530 \tValidation Loss: 5.356445\n",
      "Validation loss decreased (5.64991 --> 5.35644).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.269219 \tValidation Loss: 4.944907\n",
      "Validation loss decreased (5.35644 --> 4.94491).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.542665 \tValidation Loss: 4.487069\n",
      "Validation loss decreased (4.94491 --> 4.48707).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.747991 \tValidation Loss: 4.067094\n",
      "Validation loss decreased (4.48707 --> 4.06709).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.009877 \tValidation Loss: 3.712305\n",
      "Validation loss decreased (4.06709 --> 3.71231).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.386035 \tValidation Loss: 3.431401\n",
      "Validation loss decreased (3.71231 --> 3.43140).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.897599 \tValidation Loss: 3.217655\n",
      "Validation loss decreased (3.43140 --> 3.21766).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.525475 \tValidation Loss: 3.057379\n",
      "Validation loss decreased (3.21766 --> 3.05738).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.242455 \tValidation Loss: 2.939568\n",
      "Validation loss decreased (3.05738 --> 2.93957).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.025514 \tValidation Loss: 2.853577\n",
      "Validation loss decreased (2.93957 --> 2.85358).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.852513 \tValidation Loss: 2.792703\n",
      "Validation loss decreased (2.85358 --> 2.79270).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.720598 \tValidation Loss: 2.750626\n",
      "Validation loss decreased (2.79270 --> 2.75063).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.617895 \tValidation Loss: 2.723902\n",
      "Validation loss decreased (2.75063 --> 2.72390).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.531495 \tValidation Loss: 2.709344\n",
      "Validation loss decreased (2.72390 --> 2.70934).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.461198 \tValidation Loss: 2.706921\n",
      "Validation loss decreased (2.70934 --> 2.70692).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.408410 \tValidation Loss: 2.709364\n",
      "Epoch: 18 \tTraining Loss: 0.366359 \tValidation Loss: 2.716998\n",
      "Epoch: 19 \tTraining Loss: 0.330045 \tValidation Loss: 2.732488\n",
      "Epoch: 20 \tTraining Loss: 0.298009 \tValidation Loss: 2.751526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 6.460915 \tValidation Loss: 5.639141\n",
      "Validation loss decreased (inf --> 5.63914).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.790794 \tValidation Loss: 5.355423\n",
      "Validation loss decreased (5.63914 --> 5.35542).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.267561 \tValidation Loss: 4.952989\n",
      "Validation loss decreased (5.35542 --> 4.95299).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.546189 \tValidation Loss: 4.500021\n",
      "Validation loss decreased (4.95299 --> 4.50002).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.757408 \tValidation Loss: 4.081047\n",
      "Validation loss decreased (4.50002 --> 4.08105).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.015941 \tValidation Loss: 3.725468\n",
      "Validation loss decreased (4.08105 --> 3.72547).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.393564 \tValidation Loss: 3.445489\n",
      "Validation loss decreased (3.72547 --> 3.44549).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.904563 \tValidation Loss: 3.232523\n",
      "Validation loss decreased (3.44549 --> 3.23252).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.531718 \tValidation Loss: 3.075420\n",
      "Validation loss decreased (3.23252 --> 3.07542).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.241051 \tValidation Loss: 2.960062\n",
      "Validation loss decreased (3.07542 --> 2.96006).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.026268 \tValidation Loss: 2.876191\n",
      "Validation loss decreased (2.96006 --> 2.87619).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.855426 \tValidation Loss: 2.815730\n",
      "Validation loss decreased (2.87619 --> 2.81573).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.719850 \tValidation Loss: 2.777444\n",
      "Validation loss decreased (2.81573 --> 2.77744).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.614148 \tValidation Loss: 2.753801\n",
      "Validation loss decreased (2.77744 --> 2.75380).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.530094 \tValidation Loss: 2.742166\n",
      "Validation loss decreased (2.75380 --> 2.74217).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.464391 \tValidation Loss: 2.739470\n",
      "Validation loss decreased (2.74217 --> 2.73947).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.409023 \tValidation Loss: 2.742588\n",
      "Epoch: 18 \tTraining Loss: 0.367590 \tValidation Loss: 2.754618\n",
      "Epoch: 19 \tTraining Loss: 0.329810 \tValidation Loss: 2.768977\n",
      "Epoch: 20 \tTraining Loss: 0.298738 \tValidation Loss: 2.783787\n",
      "Epoch: 1 \tTraining Loss: 6.458232 \tValidation Loss: 5.599581\n",
      "Validation loss decreased (inf --> 5.59958).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.794139 \tValidation Loss: 5.329317\n",
      "Validation loss decreased (5.59958 --> 5.32932).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.281140 \tValidation Loss: 4.931491\n",
      "Validation loss decreased (5.32932 --> 4.93149).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.565121 \tValidation Loss: 4.481041\n",
      "Validation loss decreased (4.93149 --> 4.48104).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.777849 \tValidation Loss: 4.061177\n",
      "Validation loss decreased (4.48104 --> 4.06118).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.039493 \tValidation Loss: 3.703541\n",
      "Validation loss decreased (4.06118 --> 3.70354).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.414565 \tValidation Loss: 3.420017\n",
      "Validation loss decreased (3.70354 --> 3.42002).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.918086 \tValidation Loss: 3.204067\n",
      "Validation loss decreased (3.42002 --> 3.20407).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.537931 \tValidation Loss: 3.043636\n",
      "Validation loss decreased (3.20407 --> 3.04364).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.249540 \tValidation Loss: 2.922947\n",
      "Validation loss decreased (3.04364 --> 2.92295).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.029976 \tValidation Loss: 2.838027\n",
      "Validation loss decreased (2.92295 --> 2.83803).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.857700 \tValidation Loss: 2.777272\n",
      "Validation loss decreased (2.83803 --> 2.77727).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.724268 \tValidation Loss: 2.737436\n",
      "Validation loss decreased (2.77727 --> 2.73744).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.615885 \tValidation Loss: 2.711644\n",
      "Validation loss decreased (2.73744 --> 2.71164).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.531020 \tValidation Loss: 2.701256\n",
      "Validation loss decreased (2.71164 --> 2.70126).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.464097 \tValidation Loss: 2.695976\n",
      "Validation loss decreased (2.70126 --> 2.69598).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.411636 \tValidation Loss: 2.699519\n",
      "Epoch: 18 \tTraining Loss: 0.367014 \tValidation Loss: 2.711388\n",
      "Epoch: 19 \tTraining Loss: 0.331644 \tValidation Loss: 2.725124\n",
      "Epoch: 20 \tTraining Loss: 0.300845 \tValidation Loss: 2.741794\n",
      "Epoch: 1 \tTraining Loss: 6.456121 \tValidation Loss: 5.590796\n",
      "Validation loss decreased (inf --> 5.59080).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.786087 \tValidation Loss: 5.314790\n",
      "Validation loss decreased (5.59080 --> 5.31479).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.263533 \tValidation Loss: 4.909462\n",
      "Validation loss decreased (5.31479 --> 4.90946).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.548568 \tValidation Loss: 4.450028\n",
      "Validation loss decreased (4.90946 --> 4.45003).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.764063 \tValidation Loss: 4.025281\n",
      "Validation loss decreased (4.45003 --> 4.02528).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.023482 \tValidation Loss: 3.674539\n",
      "Validation loss decreased (4.02528 --> 3.67454).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.403810 \tValidation Loss: 3.401738\n",
      "Validation loss decreased (3.67454 --> 3.40174).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.913518 \tValidation Loss: 3.193219\n",
      "Validation loss decreased (3.40174 --> 3.19322).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.539397 \tValidation Loss: 3.037092\n",
      "Validation loss decreased (3.19322 --> 3.03709).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.253947 \tValidation Loss: 2.921265\n",
      "Validation loss decreased (3.03709 --> 2.92127).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.031108 \tValidation Loss: 2.841145\n",
      "Validation loss decreased (2.92127 --> 2.84115).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.862531 \tValidation Loss: 2.783599\n",
      "Validation loss decreased (2.84115 --> 2.78360).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.726020 \tValidation Loss: 2.747573\n",
      "Validation loss decreased (2.78360 --> 2.74757).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.618959 \tValidation Loss: 2.725211\n",
      "Validation loss decreased (2.74757 --> 2.72521).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.535625 \tValidation Loss: 2.713947\n",
      "Validation loss decreased (2.72521 --> 2.71395).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.468504 \tValidation Loss: 2.712160\n",
      "Validation loss decreased (2.71395 --> 2.71216).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.414708 \tValidation Loss: 2.718366\n",
      "Epoch: 18 \tTraining Loss: 0.369740 \tValidation Loss: 2.729267\n",
      "Epoch: 19 \tTraining Loss: 0.332612 \tValidation Loss: 2.742515\n",
      "Epoch: 20 \tTraining Loss: 0.303561 \tValidation Loss: 2.759665\n",
      "Epoch: 1 \tTraining Loss: 6.467456 \tValidation Loss: 5.625841\n",
      "Validation loss decreased (inf --> 5.62584).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.795131 \tValidation Loss: 5.336399\n",
      "Validation loss decreased (5.62584 --> 5.33640).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.275410 \tValidation Loss: 4.932283\n",
      "Validation loss decreased (5.33640 --> 4.93228).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.555611 \tValidation Loss: 4.487677\n",
      "Validation loss decreased (4.93228 --> 4.48768).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.768863 \tValidation Loss: 4.085281\n",
      "Validation loss decreased (4.48768 --> 4.08528).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.031220 \tValidation Loss: 3.740488\n",
      "Validation loss decreased (4.08528 --> 3.74049).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.409003 \tValidation Loss: 3.467114\n",
      "Validation loss decreased (3.74049 --> 3.46711).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.915086 \tValidation Loss: 3.261035\n",
      "Validation loss decreased (3.46711 --> 3.26103).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.535278 \tValidation Loss: 3.110266\n",
      "Validation loss decreased (3.26103 --> 3.11027).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.251317 \tValidation Loss: 3.002707\n",
      "Validation loss decreased (3.11027 --> 3.00271).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.032115 \tValidation Loss: 2.925240\n",
      "Validation loss decreased (3.00271 --> 2.92524).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 \tTraining Loss: 0.858617 \tValidation Loss: 2.871954\n",
      "Validation loss decreased (2.92524 --> 2.87195).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.727980 \tValidation Loss: 2.835788\n",
      "Validation loss decreased (2.87195 --> 2.83579).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.618722 \tValidation Loss: 2.814146\n",
      "Validation loss decreased (2.83579 --> 2.81415).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.534813 \tValidation Loss: 2.805604\n",
      "Validation loss decreased (2.81415 --> 2.80560).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.467554 \tValidation Loss: 2.808500\n",
      "Epoch: 17 \tTraining Loss: 0.414040 \tValidation Loss: 2.816114\n",
      "Epoch: 18 \tTraining Loss: 0.370183 \tValidation Loss: 2.825634\n",
      "Epoch: 19 \tTraining Loss: 0.335474 \tValidation Loss: 2.839133\n",
      "Epoch: 20 \tTraining Loss: 0.305969 \tValidation Loss: 2.858071\n",
      "Epoch: 1 \tTraining Loss: 6.455269 \tValidation Loss: 5.658926\n",
      "Validation loss decreased (inf --> 5.65893).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.792471 \tValidation Loss: 5.369134\n",
      "Validation loss decreased (5.65893 --> 5.36913).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.275893 \tValidation Loss: 4.965345\n",
      "Validation loss decreased (5.36913 --> 4.96534).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.547653 \tValidation Loss: 4.513865\n",
      "Validation loss decreased (4.96534 --> 4.51387).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.749024 \tValidation Loss: 4.096937\n",
      "Validation loss decreased (4.51387 --> 4.09694).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.009654 \tValidation Loss: 3.742791\n",
      "Validation loss decreased (4.09694 --> 3.74279).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.385291 \tValidation Loss: 3.462850\n",
      "Validation loss decreased (3.74279 --> 3.46285).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.893774 \tValidation Loss: 3.247818\n",
      "Validation loss decreased (3.46285 --> 3.24782).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.520573 \tValidation Loss: 3.085591\n",
      "Validation loss decreased (3.24782 --> 3.08559).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.236868 \tValidation Loss: 2.966520\n",
      "Validation loss decreased (3.08559 --> 2.96652).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.018621 \tValidation Loss: 2.883571\n",
      "Validation loss decreased (2.96652 --> 2.88357).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.846122 \tValidation Loss: 2.824628\n",
      "Validation loss decreased (2.88357 --> 2.82463).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.715065 \tValidation Loss: 2.784683\n",
      "Validation loss decreased (2.82463 --> 2.78468).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.607383 \tValidation Loss: 2.763772\n",
      "Validation loss decreased (2.78468 --> 2.76377).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.522751 \tValidation Loss: 2.755562\n",
      "Validation loss decreased (2.76377 --> 2.75556).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.458820 \tValidation Loss: 2.755326\n",
      "Validation loss decreased (2.75556 --> 2.75533).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.405005 \tValidation Loss: 2.759692\n",
      "Epoch: 18 \tTraining Loss: 0.359893 \tValidation Loss: 2.771381\n",
      "Epoch: 19 \tTraining Loss: 0.324863 \tValidation Loss: 2.787015\n",
      "Epoch: 20 \tTraining Loss: 0.295409 \tValidation Loss: 2.804108\n",
      "Epoch: 1 \tTraining Loss: 6.462095 \tValidation Loss: 5.606352\n",
      "Validation loss decreased (inf --> 5.60635).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.795888 \tValidation Loss: 5.333886\n",
      "Validation loss decreased (5.60635 --> 5.33389).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.286110 \tValidation Loss: 4.923306\n",
      "Validation loss decreased (5.33389 --> 4.92331).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.569976 \tValidation Loss: 4.458207\n",
      "Validation loss decreased (4.92331 --> 4.45821).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.779918 \tValidation Loss: 4.035549\n",
      "Validation loss decreased (4.45821 --> 4.03555).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.038148 \tValidation Loss: 3.681096\n",
      "Validation loss decreased (4.03555 --> 3.68110).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.413199 \tValidation Loss: 3.399572\n",
      "Validation loss decreased (3.68110 --> 3.39957).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.923221 \tValidation Loss: 3.183855\n",
      "Validation loss decreased (3.39957 --> 3.18385).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.549306 \tValidation Loss: 3.019718\n",
      "Validation loss decreased (3.18385 --> 3.01972).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.260136 \tValidation Loss: 2.897687\n",
      "Validation loss decreased (3.01972 --> 2.89769).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.040791 \tValidation Loss: 2.807346\n",
      "Validation loss decreased (2.89769 --> 2.80735).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.865594 \tValidation Loss: 2.743710\n",
      "Validation loss decreased (2.80735 --> 2.74371).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.728728 \tValidation Loss: 2.703692\n",
      "Validation loss decreased (2.74371 --> 2.70369).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.622083 \tValidation Loss: 2.675470\n",
      "Validation loss decreased (2.70369 --> 2.67547).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.538208 \tValidation Loss: 2.661155\n",
      "Validation loss decreased (2.67547 --> 2.66116).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.468763 \tValidation Loss: 2.659167\n",
      "Validation loss decreased (2.66116 --> 2.65917).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.413690 \tValidation Loss: 2.662557\n",
      "Epoch: 18 \tTraining Loss: 0.370061 \tValidation Loss: 2.670800\n",
      "Epoch: 19 \tTraining Loss: 0.334341 \tValidation Loss: 2.687652\n",
      "Epoch: 20 \tTraining Loss: 0.302045 \tValidation Loss: 2.702728\n",
      "bbc/sport\\199.txt  had a problem\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 7 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.471767 \tValidation Loss: 5.414747\n",
      "Validation loss decreased (inf --> 5.41475).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.749750 \tValidation Loss: 5.129349\n",
      "Validation loss decreased (5.41475 --> 5.12935).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.219834 \tValidation Loss: 4.725991\n",
      "Validation loss decreased (5.12935 --> 4.72599).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.486127 \tValidation Loss: 4.271296\n",
      "Validation loss decreased (4.72599 --> 4.27130).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.680209 \tValidation Loss: 3.860153\n",
      "Validation loss decreased (4.27130 --> 3.86015).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.935323 \tValidation Loss: 3.515390\n",
      "Validation loss decreased (3.86015 --> 3.51539).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.309395 \tValidation Loss: 3.239541\n",
      "Validation loss decreased (3.51539 --> 3.23954).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.818046 \tValidation Loss: 3.026253\n",
      "Validation loss decreased (3.23954 --> 3.02625).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.442896 \tValidation Loss: 2.868145\n",
      "Validation loss decreased (3.02625 --> 2.86814).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.154569 \tValidation Loss: 2.752797\n",
      "Validation loss decreased (2.86814 --> 2.75280).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.932411 \tValidation Loss: 2.666744\n",
      "Validation loss decreased (2.75280 --> 2.66674).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.760542 \tValidation Loss: 2.605437\n",
      "Validation loss decreased (2.66674 --> 2.60544).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.627066 \tValidation Loss: 2.563488\n",
      "Validation loss decreased (2.60544 --> 2.56349).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.520507 \tValidation Loss: 2.540157\n",
      "Validation loss decreased (2.56349 --> 2.54016).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.440763 \tValidation Loss: 2.526676\n",
      "Validation loss decreased (2.54016 --> 2.52668).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.373112 \tValidation Loss: 2.522101\n",
      "Validation loss decreased (2.52668 --> 2.52210).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.322315 \tValidation Loss: 2.526637\n",
      "Epoch: 18 \tTraining Loss: 0.280243 \tValidation Loss: 2.535573\n",
      "Epoch: 19 \tTraining Loss: 0.249560 \tValidation Loss: 2.547240\n",
      "Epoch: 20 \tTraining Loss: 0.223289 \tValidation Loss: 2.558839\n",
      "Epoch: 1 \tTraining Loss: 6.468854 \tValidation Loss: 5.426722\n",
      "Validation loss decreased (inf --> 5.42672).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.742025 \tValidation Loss: 5.159116\n",
      "Validation loss decreased (5.42672 --> 5.15912).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.205140 \tValidation Loss: 4.772561\n",
      "Validation loss decreased (5.15912 --> 4.77256).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.465040 \tValidation Loss: 4.326907\n",
      "Validation loss decreased (4.77256 --> 4.32691).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \tTraining Loss: 3.657350 \tValidation Loss: 3.914835\n",
      "Validation loss decreased (4.32691 --> 3.91484).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.913390 \tValidation Loss: 3.571374\n",
      "Validation loss decreased (3.91484 --> 3.57137).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.296404 \tValidation Loss: 3.299683\n",
      "Validation loss decreased (3.57137 --> 3.29968).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.807706 \tValidation Loss: 3.091966\n",
      "Validation loss decreased (3.29968 --> 3.09197).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.440210 \tValidation Loss: 2.934983\n",
      "Validation loss decreased (3.09197 --> 2.93498).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.155153 \tValidation Loss: 2.818309\n",
      "Validation loss decreased (2.93498 --> 2.81831).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.934397 \tValidation Loss: 2.732123\n",
      "Validation loss decreased (2.81831 --> 2.73212).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.763136 \tValidation Loss: 2.668009\n",
      "Validation loss decreased (2.73212 --> 2.66801).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.629710 \tValidation Loss: 2.626446\n",
      "Validation loss decreased (2.66801 --> 2.62645).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.523493 \tValidation Loss: 2.599989\n",
      "Validation loss decreased (2.62645 --> 2.59999).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.439357 \tValidation Loss: 2.586773\n",
      "Validation loss decreased (2.59999 --> 2.58677).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.375479 \tValidation Loss: 2.583067\n",
      "Validation loss decreased (2.58677 --> 2.58307).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.324975 \tValidation Loss: 2.585846\n",
      "Epoch: 18 \tTraining Loss: 0.285034 \tValidation Loss: 2.592080\n",
      "Epoch: 19 \tTraining Loss: 0.250818 \tValidation Loss: 2.605738\n",
      "Epoch: 20 \tTraining Loss: 0.225035 \tValidation Loss: 2.620815\n",
      "Epoch: 1 \tTraining Loss: 6.464308 \tValidation Loss: 5.404684\n",
      "Validation loss decreased (inf --> 5.40468).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.750967 \tValidation Loss: 5.121184\n",
      "Validation loss decreased (5.40468 --> 5.12118).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.224470 \tValidation Loss: 4.726870\n",
      "Validation loss decreased (5.12118 --> 4.72687).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.491705 \tValidation Loss: 4.272795\n",
      "Validation loss decreased (4.72687 --> 4.27280).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.684221 \tValidation Loss: 3.857745\n",
      "Validation loss decreased (4.27280 --> 3.85775).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.937604 \tValidation Loss: 3.501743\n",
      "Validation loss decreased (3.85775 --> 3.50174).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.313360 \tValidation Loss: 3.213558\n",
      "Validation loss decreased (3.50174 --> 3.21356).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.822836 \tValidation Loss: 2.987522\n",
      "Validation loss decreased (3.21356 --> 2.98752).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.447514 \tValidation Loss: 2.814985\n",
      "Validation loss decreased (2.98752 --> 2.81499).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.157258 \tValidation Loss: 2.687490\n",
      "Validation loss decreased (2.81499 --> 2.68749).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.935725 \tValidation Loss: 2.592978\n",
      "Validation loss decreased (2.68749 --> 2.59298).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.762441 \tValidation Loss: 2.524101\n",
      "Validation loss decreased (2.59298 --> 2.52410).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.628322 \tValidation Loss: 2.475676\n",
      "Validation loss decreased (2.52410 --> 2.47568).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.517619 \tValidation Loss: 2.444734\n",
      "Validation loss decreased (2.47568 --> 2.44473).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.439008 \tValidation Loss: 2.424381\n",
      "Validation loss decreased (2.44473 --> 2.42438).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.372577 \tValidation Loss: 2.416880\n",
      "Validation loss decreased (2.42438 --> 2.41688).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.321384 \tValidation Loss: 2.416989\n",
      "Epoch: 18 \tTraining Loss: 0.284443 \tValidation Loss: 2.418656\n",
      "Epoch: 19 \tTraining Loss: 0.248943 \tValidation Loss: 2.427211\n",
      "Epoch: 20 \tTraining Loss: 0.222611 \tValidation Loss: 2.437222\n",
      "Epoch: 1 \tTraining Loss: 6.457389 \tValidation Loss: 5.407259\n",
      "Validation loss decreased (inf --> 5.40726).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.753948 \tValidation Loss: 5.132377\n",
      "Validation loss decreased (5.40726 --> 5.13238).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.234983 \tValidation Loss: 4.744427\n",
      "Validation loss decreased (5.13238 --> 4.74443).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.503228 \tValidation Loss: 4.288509\n",
      "Validation loss decreased (4.74443 --> 4.28851).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.692912 \tValidation Loss: 3.879663\n",
      "Validation loss decreased (4.28851 --> 3.87966).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.937726 \tValidation Loss: 3.543855\n",
      "Validation loss decreased (3.87966 --> 3.54386).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.309726 \tValidation Loss: 3.281509\n",
      "Validation loss decreased (3.54386 --> 3.28151).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.816655 \tValidation Loss: 3.085531\n",
      "Validation loss decreased (3.28151 --> 3.08553).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.443204 \tValidation Loss: 2.938751\n",
      "Validation loss decreased (3.08553 --> 2.93875).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.156547 \tValidation Loss: 2.828728\n",
      "Validation loss decreased (2.93875 --> 2.82873).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.930256 \tValidation Loss: 2.749179\n",
      "Validation loss decreased (2.82873 --> 2.74918).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.760754 \tValidation Loss: 2.693508\n",
      "Validation loss decreased (2.74918 --> 2.69351).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.624124 \tValidation Loss: 2.654467\n",
      "Validation loss decreased (2.69351 --> 2.65447).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.517189 \tValidation Loss: 2.629414\n",
      "Validation loss decreased (2.65447 --> 2.62941).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.435032 \tValidation Loss: 2.620397\n",
      "Validation loss decreased (2.62941 --> 2.62040).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.368320 \tValidation Loss: 2.619525\n",
      "Validation loss decreased (2.62040 --> 2.61952).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.321780 \tValidation Loss: 2.622510\n",
      "Epoch: 18 \tTraining Loss: 0.279858 \tValidation Loss: 2.631882\n",
      "Epoch: 19 \tTraining Loss: 0.245894 \tValidation Loss: 2.649299\n",
      "Epoch: 20 \tTraining Loss: 0.221161 \tValidation Loss: 2.664999\n",
      "Epoch: 1 \tTraining Loss: 6.460928 \tValidation Loss: 5.384880\n",
      "Validation loss decreased (inf --> 5.38488).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.746470 \tValidation Loss: 5.103408\n",
      "Validation loss decreased (5.38488 --> 5.10341).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.216409 \tValidation Loss: 4.710840\n",
      "Validation loss decreased (5.10341 --> 4.71084).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.485687 \tValidation Loss: 4.263452\n",
      "Validation loss decreased (4.71084 --> 4.26345).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.680484 \tValidation Loss: 3.845343\n",
      "Validation loss decreased (4.26345 --> 3.84534).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.932628 \tValidation Loss: 3.489747\n",
      "Validation loss decreased (3.84534 --> 3.48975).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.305578 \tValidation Loss: 3.209589\n",
      "Validation loss decreased (3.48975 --> 3.20959).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.818493 \tValidation Loss: 3.002076\n",
      "Validation loss decreased (3.20959 --> 3.00208).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.444774 \tValidation Loss: 2.846646\n",
      "Validation loss decreased (3.00208 --> 2.84665).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.156158 \tValidation Loss: 2.732332\n",
      "Validation loss decreased (2.84665 --> 2.73233).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.933400 \tValidation Loss: 2.647253\n",
      "Validation loss decreased (2.73233 --> 2.64725).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.765259 \tValidation Loss: 2.585475\n",
      "Validation loss decreased (2.64725 --> 2.58548).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.626910 \tValidation Loss: 2.543842\n",
      "Validation loss decreased (2.58548 --> 2.54384).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.522248 \tValidation Loss: 2.516353\n",
      "Validation loss decreased (2.54384 --> 2.51635).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.440817 \tValidation Loss: 2.500369\n",
      "Validation loss decreased (2.51635 --> 2.50037).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 \tTraining Loss: 0.374900 \tValidation Loss: 2.493122\n",
      "Validation loss decreased (2.50037 --> 2.49312).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.323954 \tValidation Loss: 2.496399\n",
      "Epoch: 18 \tTraining Loss: 0.284510 \tValidation Loss: 2.503604\n",
      "Epoch: 19 \tTraining Loss: 0.252737 \tValidation Loss: 2.510576\n",
      "Epoch: 20 \tTraining Loss: 0.224946 \tValidation Loss: 2.524743\n",
      "Epoch: 1 \tTraining Loss: 6.462119 \tValidation Loss: 5.431684\n",
      "Validation loss decreased (inf --> 5.43168).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.747196 \tValidation Loss: 5.139624\n",
      "Validation loss decreased (5.43168 --> 5.13962).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.218508 \tValidation Loss: 4.743335\n",
      "Validation loss decreased (5.13962 --> 4.74333).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.486617 \tValidation Loss: 4.290581\n",
      "Validation loss decreased (4.74333 --> 4.29058).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.684397 \tValidation Loss: 3.872865\n",
      "Validation loss decreased (4.29058 --> 3.87286).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.937567 \tValidation Loss: 3.523738\n",
      "Validation loss decreased (3.87286 --> 3.52374).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.310994 \tValidation Loss: 3.246969\n",
      "Validation loss decreased (3.52374 --> 3.24697).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.819024 \tValidation Loss: 3.031427\n",
      "Validation loss decreased (3.24697 --> 3.03143).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.440454 \tValidation Loss: 2.866001\n",
      "Validation loss decreased (3.03143 --> 2.86600).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.156759 \tValidation Loss: 2.742063\n",
      "Validation loss decreased (2.86600 --> 2.74206).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.932056 \tValidation Loss: 2.650580\n",
      "Validation loss decreased (2.74206 --> 2.65058).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.759561 \tValidation Loss: 2.587044\n",
      "Validation loss decreased (2.65058 --> 2.58704).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.625035 \tValidation Loss: 2.544727\n",
      "Validation loss decreased (2.58704 --> 2.54473).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.519935 \tValidation Loss: 2.518163\n",
      "Validation loss decreased (2.54473 --> 2.51816).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.437789 \tValidation Loss: 2.505583\n",
      "Validation loss decreased (2.51816 --> 2.50558).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.375244 \tValidation Loss: 2.498789\n",
      "Validation loss decreased (2.50558 --> 2.49879).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.322206 \tValidation Loss: 2.500554\n",
      "Epoch: 18 \tTraining Loss: 0.281524 \tValidation Loss: 2.508187\n",
      "Epoch: 19 \tTraining Loss: 0.248218 \tValidation Loss: 2.519250\n",
      "Epoch: 20 \tTraining Loss: 0.225171 \tValidation Loss: 2.532624\n",
      "Epoch: 1 \tTraining Loss: 6.466992 \tValidation Loss: 5.410771\n",
      "Validation loss decreased (inf --> 5.41077).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.746871 \tValidation Loss: 5.125093\n",
      "Validation loss decreased (5.41077 --> 5.12509).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.216013 \tValidation Loss: 4.726960\n",
      "Validation loss decreased (5.12509 --> 4.72696).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.483483 \tValidation Loss: 4.269527\n",
      "Validation loss decreased (4.72696 --> 4.26953).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.674795 \tValidation Loss: 3.846619\n",
      "Validation loss decreased (4.26953 --> 3.84662).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.921404 \tValidation Loss: 3.492388\n",
      "Validation loss decreased (3.84662 --> 3.49239).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.292858 \tValidation Loss: 3.218961\n",
      "Validation loss decreased (3.49239 --> 3.21896).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.801395 \tValidation Loss: 3.012534\n",
      "Validation loss decreased (3.21896 --> 3.01253).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.427661 \tValidation Loss: 2.857234\n",
      "Validation loss decreased (3.01253 --> 2.85723).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.143930 \tValidation Loss: 2.740333\n",
      "Validation loss decreased (2.85723 --> 2.74033).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.925713 \tValidation Loss: 2.653977\n",
      "Validation loss decreased (2.74033 --> 2.65398).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.752123 \tValidation Loss: 2.593647\n",
      "Validation loss decreased (2.65398 --> 2.59365).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.619695 \tValidation Loss: 2.555078\n",
      "Validation loss decreased (2.59365 --> 2.55508).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.512587 \tValidation Loss: 2.531918\n",
      "Validation loss decreased (2.55508 --> 2.53192).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.434669 \tValidation Loss: 2.520411\n",
      "Validation loss decreased (2.53192 --> 2.52041).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.368407 \tValidation Loss: 2.517130\n",
      "Validation loss decreased (2.52041 --> 2.51713).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.319289 \tValidation Loss: 2.520455\n",
      "Epoch: 18 \tTraining Loss: 0.278345 \tValidation Loss: 2.529399\n",
      "Epoch: 19 \tTraining Loss: 0.247196 \tValidation Loss: 2.544650\n",
      "Epoch: 20 \tTraining Loss: 0.221373 \tValidation Loss: 2.561856\n",
      "Epoch: 1 \tTraining Loss: 6.465244 \tValidation Loss: 5.401829\n",
      "Validation loss decreased (inf --> 5.40183).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.753601 \tValidation Loss: 5.116190\n",
      "Validation loss decreased (5.40183 --> 5.11619).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.237506 \tValidation Loss: 4.715210\n",
      "Validation loss decreased (5.11619 --> 4.71521).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.510688 \tValidation Loss: 4.254474\n",
      "Validation loss decreased (4.71521 --> 4.25447).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.703022 \tValidation Loss: 3.824681\n",
      "Validation loss decreased (4.25447 --> 3.82468).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.952802 \tValidation Loss: 3.460483\n",
      "Validation loss decreased (3.82468 --> 3.46048).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.322455 \tValidation Loss: 3.174347\n",
      "Validation loss decreased (3.46048 --> 3.17435).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.831906 \tValidation Loss: 2.961649\n",
      "Validation loss decreased (3.17435 --> 2.96165).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.449441 \tValidation Loss: 2.803216\n",
      "Validation loss decreased (2.96165 --> 2.80322).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.162571 \tValidation Loss: 2.687710\n",
      "Validation loss decreased (2.80322 --> 2.68771).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.942435 \tValidation Loss: 2.603279\n",
      "Validation loss decreased (2.68771 --> 2.60328).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.765701 \tValidation Loss: 2.544401\n",
      "Validation loss decreased (2.60328 --> 2.54440).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.632442 \tValidation Loss: 2.504638\n",
      "Validation loss decreased (2.54440 --> 2.50464).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.526297 \tValidation Loss: 2.480118\n",
      "Validation loss decreased (2.50464 --> 2.48012).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.444152 \tValidation Loss: 2.464839\n",
      "Validation loss decreased (2.48012 --> 2.46484).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.379027 \tValidation Loss: 2.459284\n",
      "Validation loss decreased (2.46484 --> 2.45928).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.325356 \tValidation Loss: 2.463315\n",
      "Epoch: 18 \tTraining Loss: 0.283932 \tValidation Loss: 2.471479\n",
      "Epoch: 19 \tTraining Loss: 0.251577 \tValidation Loss: 2.484606\n",
      "Epoch: 20 \tTraining Loss: 0.224111 \tValidation Loss: 2.496638\n",
      "Epoch: 1 \tTraining Loss: 6.470598 \tValidation Loss: 5.390479\n",
      "Validation loss decreased (inf --> 5.39048).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.758944 \tValidation Loss: 5.108230\n",
      "Validation loss decreased (5.39048 --> 5.10823).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.229685 \tValidation Loss: 4.712150\n",
      "Validation loss decreased (5.10823 --> 4.71215).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.492719 \tValidation Loss: 4.252327\n",
      "Validation loss decreased (4.71215 --> 4.25233).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.678594 \tValidation Loss: 3.827609\n",
      "Validation loss decreased (4.25233 --> 3.82761).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.925924 \tValidation Loss: 3.475436\n",
      "Validation loss decreased (3.82761 --> 3.47544).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.299487 \tValidation Loss: 3.199225\n",
      "Validation loss decreased (3.47544 --> 3.19923).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.809499 \tValidation Loss: 2.993609\n",
      "Validation loss decreased (3.19923 --> 2.99361).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 \tTraining Loss: 1.433815 \tValidation Loss: 2.841066\n",
      "Validation loss decreased (2.99361 --> 2.84107).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.148861 \tValidation Loss: 2.730547\n",
      "Validation loss decreased (2.84107 --> 2.73055).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.927159 \tValidation Loss: 2.651030\n",
      "Validation loss decreased (2.73055 --> 2.65103).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.755043 \tValidation Loss: 2.594709\n",
      "Validation loss decreased (2.65103 --> 2.59471).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.624355 \tValidation Loss: 2.557165\n",
      "Validation loss decreased (2.59471 --> 2.55716).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.517846 \tValidation Loss: 2.531275\n",
      "Validation loss decreased (2.55716 --> 2.53128).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.436537 \tValidation Loss: 2.517516\n",
      "Validation loss decreased (2.53128 --> 2.51752).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.373775 \tValidation Loss: 2.514071\n",
      "Validation loss decreased (2.51752 --> 2.51407).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.318412 \tValidation Loss: 2.516454\n",
      "Epoch: 18 \tTraining Loss: 0.280821 \tValidation Loss: 2.527175\n",
      "Epoch: 19 \tTraining Loss: 0.247473 \tValidation Loss: 2.537333\n",
      "Epoch: 20 \tTraining Loss: 0.222679 \tValidation Loss: 2.551657\n",
      "Epoch: 1 \tTraining Loss: 6.473563 \tValidation Loss: 5.404533\n",
      "Validation loss decreased (inf --> 5.40453).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.750989 \tValidation Loss: 5.134560\n",
      "Validation loss decreased (5.40453 --> 5.13456).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.217590 \tValidation Loss: 4.747323\n",
      "Validation loss decreased (5.13456 --> 4.74732).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.488101 \tValidation Loss: 4.302581\n",
      "Validation loss decreased (4.74732 --> 4.30258).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.687816 \tValidation Loss: 3.888044\n",
      "Validation loss decreased (4.30258 --> 3.88804).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.939716 \tValidation Loss: 3.538320\n",
      "Validation loss decreased (3.88804 --> 3.53832).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.312508 \tValidation Loss: 3.259188\n",
      "Validation loss decreased (3.53832 --> 3.25919).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.819227 \tValidation Loss: 3.046614\n",
      "Validation loss decreased (3.25919 --> 3.04661).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.445034 \tValidation Loss: 2.885674\n",
      "Validation loss decreased (3.04661 --> 2.88567).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.159184 \tValidation Loss: 2.769561\n",
      "Validation loss decreased (2.88567 --> 2.76956).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.940084 \tValidation Loss: 2.682803\n",
      "Validation loss decreased (2.76956 --> 2.68280).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.768092 \tValidation Loss: 2.619138\n",
      "Validation loss decreased (2.68280 --> 2.61914).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.632554 \tValidation Loss: 2.575617\n",
      "Validation loss decreased (2.61914 --> 2.57562).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.528166 \tValidation Loss: 2.547979\n",
      "Validation loss decreased (2.57562 --> 2.54798).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.444598 \tValidation Loss: 2.532356\n",
      "Validation loss decreased (2.54798 --> 2.53236).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.379374 \tValidation Loss: 2.525379\n",
      "Validation loss decreased (2.53236 --> 2.52538).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.329072 \tValidation Loss: 2.526898\n",
      "Epoch: 18 \tTraining Loss: 0.286662 \tValidation Loss: 2.531069\n",
      "Epoch: 19 \tTraining Loss: 0.252439 \tValidation Loss: 2.540684\n",
      "Epoch: 20 \tTraining Loss: 0.227787 \tValidation Loss: 2.554678\n",
      "bbc/sport\\199.txt  had a problem\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 8 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.514576 \tValidation Loss: 5.149205\n",
      "Validation loss decreased (inf --> 5.14920).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.739895 \tValidation Loss: 4.914248\n",
      "Validation loss decreased (5.14920 --> 4.91425).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.230843 \tValidation Loss: 4.577748\n",
      "Validation loss decreased (4.91425 --> 4.57775).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.539187 \tValidation Loss: 4.170108\n",
      "Validation loss decreased (4.57775 --> 4.17011).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.754274 \tValidation Loss: 3.770333\n",
      "Validation loss decreased (4.17011 --> 3.77033).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.005959 \tValidation Loss: 3.428125\n",
      "Validation loss decreased (3.77033 --> 3.42812).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.367244 \tValidation Loss: 3.154315\n",
      "Validation loss decreased (3.42812 --> 3.15432).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.858077 \tValidation Loss: 2.943863\n",
      "Validation loss decreased (3.15432 --> 2.94386).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.464582 \tValidation Loss: 2.783721\n",
      "Validation loss decreased (2.94386 --> 2.78372).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.163319 \tValidation Loss: 2.661620\n",
      "Validation loss decreased (2.78372 --> 2.66162).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.927936 \tValidation Loss: 2.570029\n",
      "Validation loss decreased (2.66162 --> 2.57003).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.740099 \tValidation Loss: 2.500367\n",
      "Validation loss decreased (2.57003 --> 2.50037).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.600027 \tValidation Loss: 2.453969\n",
      "Validation loss decreased (2.50037 --> 2.45397).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.484795 \tValidation Loss: 2.420806\n",
      "Validation loss decreased (2.45397 --> 2.42081).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.401739 \tValidation Loss: 2.401337\n",
      "Validation loss decreased (2.42081 --> 2.40134).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.334439 \tValidation Loss: 2.388183\n",
      "Validation loss decreased (2.40134 --> 2.38818).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.281925 \tValidation Loss: 2.386988\n",
      "Validation loss decreased (2.38818 --> 2.38699).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.240912 \tValidation Loss: 2.389717\n",
      "Epoch: 19 \tTraining Loss: 0.210870 \tValidation Loss: 2.395516\n",
      "Epoch: 20 \tTraining Loss: 0.186211 \tValidation Loss: 2.402987\n",
      "Epoch: 1 \tTraining Loss: 6.513571 \tValidation Loss: 5.146678\n",
      "Validation loss decreased (inf --> 5.14668).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.741756 \tValidation Loss: 4.912181\n",
      "Validation loss decreased (5.14668 --> 4.91218).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.232441 \tValidation Loss: 4.562433\n",
      "Validation loss decreased (4.91218 --> 4.56243).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.534966 \tValidation Loss: 4.137703\n",
      "Validation loss decreased (4.56243 --> 4.13770).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.745094 \tValidation Loss: 3.732550\n",
      "Validation loss decreased (4.13770 --> 3.73255).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.990411 \tValidation Loss: 3.395081\n",
      "Validation loss decreased (3.73255 --> 3.39508).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.349573 \tValidation Loss: 3.131823\n",
      "Validation loss decreased (3.39508 --> 3.13182).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.839881 \tValidation Loss: 2.932345\n",
      "Validation loss decreased (3.13182 --> 2.93235).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.449679 \tValidation Loss: 2.782020\n",
      "Validation loss decreased (2.93235 --> 2.78202).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.145253 \tValidation Loss: 2.670239\n",
      "Validation loss decreased (2.78202 --> 2.67024).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.912345 \tValidation Loss: 2.588684\n",
      "Validation loss decreased (2.67024 --> 2.58868).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.731693 \tValidation Loss: 2.531951\n",
      "Validation loss decreased (2.58868 --> 2.53195).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.589127 \tValidation Loss: 2.492451\n",
      "Validation loss decreased (2.53195 --> 2.49245).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.479131 \tValidation Loss: 2.466386\n",
      "Validation loss decreased (2.49245 --> 2.46639).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.394388 \tValidation Loss: 2.456914\n",
      "Validation loss decreased (2.46639 --> 2.45691).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.327736 \tValidation Loss: 2.450161\n",
      "Validation loss decreased (2.45691 --> 2.45016).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.278003 \tValidation Loss: 2.451130\n",
      "Epoch: 18 \tTraining Loss: 0.238543 \tValidation Loss: 2.457326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 \tTraining Loss: 0.208400 \tValidation Loss: 2.467890\n",
      "Epoch: 20 \tTraining Loss: 0.184935 \tValidation Loss: 2.477647\n",
      "Epoch: 1 \tTraining Loss: 6.519658 \tValidation Loss: 5.139216\n",
      "Validation loss decreased (inf --> 5.13922).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.741544 \tValidation Loss: 4.919875\n",
      "Validation loss decreased (5.13922 --> 4.91987).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.229636 \tValidation Loss: 4.569670\n",
      "Validation loss decreased (4.91987 --> 4.56967).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.531727 \tValidation Loss: 4.155285\n",
      "Validation loss decreased (4.56967 --> 4.15528).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.743031 \tValidation Loss: 3.765284\n",
      "Validation loss decreased (4.15528 --> 3.76528).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.993300 \tValidation Loss: 3.433711\n",
      "Validation loss decreased (3.76528 --> 3.43371).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.354661 \tValidation Loss: 3.166128\n",
      "Validation loss decreased (3.43371 --> 3.16613).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.851035 \tValidation Loss: 2.958328\n",
      "Validation loss decreased (3.16613 --> 2.95833).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.460661 \tValidation Loss: 2.799794\n",
      "Validation loss decreased (2.95833 --> 2.79979).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.157366 \tValidation Loss: 2.680861\n",
      "Validation loss decreased (2.79979 --> 2.68086).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.922092 \tValidation Loss: 2.593228\n",
      "Validation loss decreased (2.68086 --> 2.59323).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.736766 \tValidation Loss: 2.532689\n",
      "Validation loss decreased (2.59323 --> 2.53269).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.595828 \tValidation Loss: 2.491733\n",
      "Validation loss decreased (2.53269 --> 2.49173).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.485686 \tValidation Loss: 2.466476\n",
      "Validation loss decreased (2.49173 --> 2.46648).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.397301 \tValidation Loss: 2.448181\n",
      "Validation loss decreased (2.46648 --> 2.44818).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.333415 \tValidation Loss: 2.444475\n",
      "Validation loss decreased (2.44818 --> 2.44447).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.280353 \tValidation Loss: 2.444479\n",
      "Epoch: 18 \tTraining Loss: 0.240905 \tValidation Loss: 2.450245\n",
      "Epoch: 19 \tTraining Loss: 0.210449 \tValidation Loss: 2.459613\n",
      "Epoch: 20 \tTraining Loss: 0.183850 \tValidation Loss: 2.470940\n",
      "Epoch: 1 \tTraining Loss: 6.517914 \tValidation Loss: 5.145970\n",
      "Validation loss decreased (inf --> 5.14597).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.737191 \tValidation Loss: 4.918809\n",
      "Validation loss decreased (5.14597 --> 4.91881).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.226604 \tValidation Loss: 4.589008\n",
      "Validation loss decreased (4.91881 --> 4.58901).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.524366 \tValidation Loss: 4.187504\n",
      "Validation loss decreased (4.58901 --> 4.18750).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.735178 \tValidation Loss: 3.798489\n",
      "Validation loss decreased (4.18750 --> 3.79849).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.984227 \tValidation Loss: 3.469071\n",
      "Validation loss decreased (3.79849 --> 3.46907).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.345451 \tValidation Loss: 3.212304\n",
      "Validation loss decreased (3.46907 --> 3.21230).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.840708 \tValidation Loss: 3.017990\n",
      "Validation loss decreased (3.21230 --> 3.01799).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.448459 \tValidation Loss: 2.872907\n",
      "Validation loss decreased (3.01799 --> 2.87291).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.145885 \tValidation Loss: 2.769231\n",
      "Validation loss decreased (2.87291 --> 2.76923).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.912668 \tValidation Loss: 2.693198\n",
      "Validation loss decreased (2.76923 --> 2.69320).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.732639 \tValidation Loss: 2.639064\n",
      "Validation loss decreased (2.69320 --> 2.63906).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.588108 \tValidation Loss: 2.605510\n",
      "Validation loss decreased (2.63906 --> 2.60551).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.480673 \tValidation Loss: 2.584815\n",
      "Validation loss decreased (2.60551 --> 2.58482).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.394914 \tValidation Loss: 2.575553\n",
      "Validation loss decreased (2.58482 --> 2.57555).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.328275 \tValidation Loss: 2.573965\n",
      "Validation loss decreased (2.57555 --> 2.57397).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.280601 \tValidation Loss: 2.577963\n",
      "Epoch: 18 \tTraining Loss: 0.239401 \tValidation Loss: 2.586138\n",
      "Epoch: 19 \tTraining Loss: 0.209510 \tValidation Loss: 2.597563\n",
      "Epoch: 20 \tTraining Loss: 0.184173 \tValidation Loss: 2.611168\n",
      "Epoch: 1 \tTraining Loss: 6.515435 \tValidation Loss: 5.099919\n",
      "Validation loss decreased (inf --> 5.09992).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.742254 \tValidation Loss: 4.873979\n",
      "Validation loss decreased (5.09992 --> 4.87398).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.230185 \tValidation Loss: 4.520819\n",
      "Validation loss decreased (4.87398 --> 4.52082).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.528189 \tValidation Loss: 4.111360\n",
      "Validation loss decreased (4.52082 --> 4.11136).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.740450 \tValidation Loss: 3.724227\n",
      "Validation loss decreased (4.11136 --> 3.72423).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.993405 \tValidation Loss: 3.397930\n",
      "Validation loss decreased (3.72423 --> 3.39793).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.355038 \tValidation Loss: 3.146277\n",
      "Validation loss decreased (3.39793 --> 3.14628).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.847200 \tValidation Loss: 2.956451\n",
      "Validation loss decreased (3.14628 --> 2.95645).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.455524 \tValidation Loss: 2.811412\n",
      "Validation loss decreased (2.95645 --> 2.81141).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.152629 \tValidation Loss: 2.702074\n",
      "Validation loss decreased (2.81141 --> 2.70207).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.920102 \tValidation Loss: 2.620021\n",
      "Validation loss decreased (2.70207 --> 2.62002).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.737737 \tValidation Loss: 2.560808\n",
      "Validation loss decreased (2.62002 --> 2.56081).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.593392 \tValidation Loss: 2.520054\n",
      "Validation loss decreased (2.56081 --> 2.52005).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.480841 \tValidation Loss: 2.496370\n",
      "Validation loss decreased (2.52005 --> 2.49637).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.398016 \tValidation Loss: 2.479782\n",
      "Validation loss decreased (2.49637 --> 2.47978).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.328937 \tValidation Loss: 2.473586\n",
      "Validation loss decreased (2.47978 --> 2.47359).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.280254 \tValidation Loss: 2.474406\n",
      "Epoch: 18 \tTraining Loss: 0.243247 \tValidation Loss: 2.479454\n",
      "Epoch: 19 \tTraining Loss: 0.209515 \tValidation Loss: 2.491723\n",
      "Epoch: 20 \tTraining Loss: 0.186574 \tValidation Loss: 2.503339\n",
      "Epoch: 1 \tTraining Loss: 6.523061 \tValidation Loss: 5.165975\n",
      "Validation loss decreased (inf --> 5.16597).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.736993 \tValidation Loss: 4.927759\n",
      "Validation loss decreased (5.16597 --> 4.92776).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.217730 \tValidation Loss: 4.576403\n",
      "Validation loss decreased (4.92776 --> 4.57640).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.513940 \tValidation Loss: 4.165979\n",
      "Validation loss decreased (4.57640 --> 4.16598).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.727823 \tValidation Loss: 3.776403\n",
      "Validation loss decreased (4.16598 --> 3.77640).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.976878 \tValidation Loss: 3.440558\n",
      "Validation loss decreased (3.77640 --> 3.44056).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.343530 \tValidation Loss: 3.175311\n",
      "Validation loss decreased (3.44056 --> 3.17531).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.840790 \tValidation Loss: 2.974926\n",
      "Validation loss decreased (3.17531 --> 2.97493).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.447859 \tValidation Loss: 2.821391\n",
      "Validation loss decreased (2.97493 --> 2.82139).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.152557 \tValidation Loss: 2.704777\n",
      "Validation loss decreased (2.82139 --> 2.70478).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 \tTraining Loss: 0.916469 \tValidation Loss: 2.618477\n",
      "Validation loss decreased (2.70478 --> 2.61848).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.736865 \tValidation Loss: 2.554312\n",
      "Validation loss decreased (2.61848 --> 2.55431).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.592115 \tValidation Loss: 2.512040\n",
      "Validation loss decreased (2.55431 --> 2.51204).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.485384 \tValidation Loss: 2.483289\n",
      "Validation loss decreased (2.51204 --> 2.48329).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.398221 \tValidation Loss: 2.467697\n",
      "Validation loss decreased (2.48329 --> 2.46770).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.332900 \tValidation Loss: 2.461909\n",
      "Validation loss decreased (2.46770 --> 2.46191).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.282058 \tValidation Loss: 2.462740\n",
      "Epoch: 18 \tTraining Loss: 0.243984 \tValidation Loss: 2.465099\n",
      "Epoch: 19 \tTraining Loss: 0.211629 \tValidation Loss: 2.474130\n",
      "Epoch: 20 \tTraining Loss: 0.185571 \tValidation Loss: 2.485312\n",
      "Epoch: 1 \tTraining Loss: 6.521805 \tValidation Loss: 5.092919\n",
      "Validation loss decreased (inf --> 5.09292).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.747166 \tValidation Loss: 4.859118\n",
      "Validation loss decreased (5.09292 --> 4.85912).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.240907 \tValidation Loss: 4.525721\n",
      "Validation loss decreased (4.85912 --> 4.52572).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.542419 \tValidation Loss: 4.122636\n",
      "Validation loss decreased (4.52572 --> 4.12264).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.755500 \tValidation Loss: 3.732392\n",
      "Validation loss decreased (4.12264 --> 3.73239).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.001365 \tValidation Loss: 3.400342\n",
      "Validation loss decreased (3.73239 --> 3.40034).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.362047 \tValidation Loss: 3.137896\n",
      "Validation loss decreased (3.40034 --> 3.13790).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.850487 \tValidation Loss: 2.937963\n",
      "Validation loss decreased (3.13790 --> 2.93796).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.459158 \tValidation Loss: 2.789184\n",
      "Validation loss decreased (2.93796 --> 2.78918).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.154996 \tValidation Loss: 2.679284\n",
      "Validation loss decreased (2.78918 --> 2.67928).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.922087 \tValidation Loss: 2.598857\n",
      "Validation loss decreased (2.67928 --> 2.59886).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.741301 \tValidation Loss: 2.539504\n",
      "Validation loss decreased (2.59886 --> 2.53950).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.596384 \tValidation Loss: 2.497654\n",
      "Validation loss decreased (2.53950 --> 2.49765).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.487272 \tValidation Loss: 2.470047\n",
      "Validation loss decreased (2.49765 --> 2.47005).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.398915 \tValidation Loss: 2.453945\n",
      "Validation loss decreased (2.47005 --> 2.45394).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.333834 \tValidation Loss: 2.444735\n",
      "Validation loss decreased (2.45394 --> 2.44473).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.282146 \tValidation Loss: 2.442548\n",
      "Validation loss decreased (2.44473 --> 2.44255).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.240488 \tValidation Loss: 2.447693\n",
      "Epoch: 19 \tTraining Loss: 0.208190 \tValidation Loss: 2.455108\n",
      "Epoch: 20 \tTraining Loss: 0.186088 \tValidation Loss: 2.464985\n",
      "Epoch: 1 \tTraining Loss: 6.508103 \tValidation Loss: 5.114182\n",
      "Validation loss decreased (inf --> 5.11418).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.741311 \tValidation Loss: 4.879778\n",
      "Validation loss decreased (5.11418 --> 4.87978).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.238089 \tValidation Loss: 4.542117\n",
      "Validation loss decreased (4.87978 --> 4.54212).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.542634 \tValidation Loss: 4.145272\n",
      "Validation loss decreased (4.54212 --> 4.14527).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.750311 \tValidation Loss: 3.768953\n",
      "Validation loss decreased (4.14527 --> 3.76895).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.998482 \tValidation Loss: 3.447962\n",
      "Validation loss decreased (3.76895 --> 3.44796).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.356051 \tValidation Loss: 3.185342\n",
      "Validation loss decreased (3.44796 --> 3.18534).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.847431 \tValidation Loss: 2.980313\n",
      "Validation loss decreased (3.18534 --> 2.98031).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.456073 \tValidation Loss: 2.825643\n",
      "Validation loss decreased (2.98031 --> 2.82564).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.153402 \tValidation Loss: 2.707217\n",
      "Validation loss decreased (2.82564 --> 2.70722).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.922968 \tValidation Loss: 2.615220\n",
      "Validation loss decreased (2.70722 --> 2.61522).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.738489 \tValidation Loss: 2.548149\n",
      "Validation loss decreased (2.61522 --> 2.54815).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.597151 \tValidation Loss: 2.499323\n",
      "Validation loss decreased (2.54815 --> 2.49932).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.487022 \tValidation Loss: 2.465441\n",
      "Validation loss decreased (2.49932 --> 2.46544).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.401770 \tValidation Loss: 2.446188\n",
      "Validation loss decreased (2.46544 --> 2.44619).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.333172 \tValidation Loss: 2.435231\n",
      "Validation loss decreased (2.44619 --> 2.43523).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.283748 \tValidation Loss: 2.428086\n",
      "Validation loss decreased (2.43523 --> 2.42809).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.242232 \tValidation Loss: 2.434979\n",
      "Epoch: 19 \tTraining Loss: 0.213749 \tValidation Loss: 2.439708\n",
      "Epoch: 20 \tTraining Loss: 0.187138 \tValidation Loss: 2.448190\n",
      "Epoch: 1 \tTraining Loss: 6.522587 \tValidation Loss: 5.138276\n",
      "Validation loss decreased (inf --> 5.13828).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.735248 \tValidation Loss: 4.904235\n",
      "Validation loss decreased (5.13828 --> 4.90423).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.215757 \tValidation Loss: 4.561785\n",
      "Validation loss decreased (4.90423 --> 4.56178).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.511538 \tValidation Loss: 4.158903\n",
      "Validation loss decreased (4.56178 --> 4.15890).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.723656 \tValidation Loss: 3.777274\n",
      "Validation loss decreased (4.15890 --> 3.77727).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.977435 \tValidation Loss: 3.448973\n",
      "Validation loss decreased (3.77727 --> 3.44897).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.345135 \tValidation Loss: 3.186808\n",
      "Validation loss decreased (3.44897 --> 3.18681).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.842373 \tValidation Loss: 2.985126\n",
      "Validation loss decreased (3.18681 --> 2.98513).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.453217 \tValidation Loss: 2.830825\n",
      "Validation loss decreased (2.98513 --> 2.83083).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.150548 \tValidation Loss: 2.712045\n",
      "Validation loss decreased (2.83083 --> 2.71205).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.919909 \tValidation Loss: 2.622657\n",
      "Validation loss decreased (2.71205 --> 2.62266).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.738949 \tValidation Loss: 2.556772\n",
      "Validation loss decreased (2.62266 --> 2.55677).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.597043 \tValidation Loss: 2.510392\n",
      "Validation loss decreased (2.55677 --> 2.51039).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.486224 \tValidation Loss: 2.479018\n",
      "Validation loss decreased (2.51039 --> 2.47902).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.400841 \tValidation Loss: 2.461036\n",
      "Validation loss decreased (2.47902 --> 2.46104).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.332532 \tValidation Loss: 2.451213\n",
      "Validation loss decreased (2.46104 --> 2.45121).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.284220 \tValidation Loss: 2.450105\n",
      "Validation loss decreased (2.45121 --> 2.45011).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.244780 \tValidation Loss: 2.455404\n",
      "Epoch: 19 \tTraining Loss: 0.211163 \tValidation Loss: 2.462457\n",
      "Epoch: 20 \tTraining Loss: 0.185899 \tValidation Loss: 2.471563\n",
      "Epoch: 1 \tTraining Loss: 6.519495 \tValidation Loss: 5.107097\n",
      "Validation loss decreased (inf --> 5.10710).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 5.741150 \tValidation Loss: 4.860895\n",
      "Validation loss decreased (5.10710 --> 4.86089).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.223167 \tValidation Loss: 4.511276\n",
      "Validation loss decreased (4.86089 --> 4.51128).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.516828 \tValidation Loss: 4.113803\n",
      "Validation loss decreased (4.51128 --> 4.11380).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.729296 \tValidation Loss: 3.740189\n",
      "Validation loss decreased (4.11380 --> 3.74019).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.982326 \tValidation Loss: 3.426904\n",
      "Validation loss decreased (3.74019 --> 3.42690).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.343187 \tValidation Loss: 3.177796\n",
      "Validation loss decreased (3.42690 --> 3.17780).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.838731 \tValidation Loss: 2.986793\n",
      "Validation loss decreased (3.17780 --> 2.98679).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.448903 \tValidation Loss: 2.843496\n",
      "Validation loss decreased (2.98679 --> 2.84350).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.150203 \tValidation Loss: 2.738107\n",
      "Validation loss decreased (2.84350 --> 2.73811).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.919784 \tValidation Loss: 2.660274\n",
      "Validation loss decreased (2.73811 --> 2.66027).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.736098 \tValidation Loss: 2.604869\n",
      "Validation loss decreased (2.66027 --> 2.60487).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.594143 \tValidation Loss: 2.566848\n",
      "Validation loss decreased (2.60487 --> 2.56685).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.486791 \tValidation Loss: 2.542680\n",
      "Validation loss decreased (2.56685 --> 2.54268).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.399413 \tValidation Loss: 2.529157\n",
      "Validation loss decreased (2.54268 --> 2.52916).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.331055 \tValidation Loss: 2.527033\n",
      "Validation loss decreased (2.52916 --> 2.52703).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.281949 \tValidation Loss: 2.526031\n",
      "Validation loss decreased (2.52703 --> 2.52603).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.241611 \tValidation Loss: 2.533568\n",
      "Epoch: 19 \tTraining Loss: 0.209630 \tValidation Loss: 2.545749\n",
      "Epoch: 20 \tTraining Loss: 0.185219 \tValidation Loss: 2.554637\n",
      "bbc/sport\\199.txt  had a problem\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 9 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.532990 \tValidation Loss: 4.733102\n",
      "Validation loss decreased (inf --> 4.73310).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.692293 \tValidation Loss: 4.500445\n",
      "Validation loss decreased (4.73310 --> 4.50044).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.224670 \tValidation Loss: 4.236482\n",
      "Validation loss decreased (4.50044 --> 4.23648).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.597319 \tValidation Loss: 3.905153\n",
      "Validation loss decreased (4.23648 --> 3.90515).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.863133 \tValidation Loss: 3.575911\n",
      "Validation loss decreased (3.90515 --> 3.57591).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.131536 \tValidation Loss: 3.285376\n",
      "Validation loss decreased (3.57591 --> 3.28538).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.493535 \tValidation Loss: 3.048644\n",
      "Validation loss decreased (3.28538 --> 3.04864).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.967594 \tValidation Loss: 2.869050\n",
      "Validation loss decreased (3.04864 --> 2.86905).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.552042 \tValidation Loss: 2.733782\n",
      "Validation loss decreased (2.86905 --> 2.73378).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.230577 \tValidation Loss: 2.632181\n",
      "Validation loss decreased (2.73378 --> 2.63218).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.978131 \tValidation Loss: 2.557697\n",
      "Validation loss decreased (2.63218 --> 2.55770).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.782084 \tValidation Loss: 2.502672\n",
      "Validation loss decreased (2.55770 --> 2.50267).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.624706 \tValidation Loss: 2.464309\n",
      "Validation loss decreased (2.50267 --> 2.46431).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.501960 \tValidation Loss: 2.441320\n",
      "Validation loss decreased (2.46431 --> 2.44132).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.408310 \tValidation Loss: 2.431190\n",
      "Validation loss decreased (2.44132 --> 2.43119).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.334570 \tValidation Loss: 2.427835\n",
      "Validation loss decreased (2.43119 --> 2.42783).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.280124 \tValidation Loss: 2.429900\n",
      "Epoch: 18 \tTraining Loss: 0.237642 \tValidation Loss: 2.436257\n",
      "Epoch: 19 \tTraining Loss: 0.205058 \tValidation Loss: 2.448068\n",
      "Epoch: 20 \tTraining Loss: 0.176356 \tValidation Loss: 2.460830\n",
      "Epoch: 1 \tTraining Loss: 6.540307 \tValidation Loss: 4.754111\n",
      "Validation loss decreased (inf --> 4.75411).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.688374 \tValidation Loss: 4.527036\n",
      "Validation loss decreased (4.75411 --> 4.52704).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.218250 \tValidation Loss: 4.256037\n",
      "Validation loss decreased (4.52704 --> 4.25604).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.590646 \tValidation Loss: 3.918316\n",
      "Validation loss decreased (4.25604 --> 3.91832).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.850892 \tValidation Loss: 3.584643\n",
      "Validation loss decreased (3.91832 --> 3.58464).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.113693 \tValidation Loss: 3.294483\n",
      "Validation loss decreased (3.58464 --> 3.29448).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.469367 \tValidation Loss: 3.065008\n",
      "Validation loss decreased (3.29448 --> 3.06501).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.948357 \tValidation Loss: 2.890955\n",
      "Validation loss decreased (3.06501 --> 2.89095).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.538202 \tValidation Loss: 2.762032\n",
      "Validation loss decreased (2.89095 --> 2.76203).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.218434 \tValidation Loss: 2.667142\n",
      "Validation loss decreased (2.76203 --> 2.66714).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.972404 \tValidation Loss: 2.596959\n",
      "Validation loss decreased (2.66714 --> 2.59696).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.774227 \tValidation Loss: 2.545111\n",
      "Validation loss decreased (2.59696 --> 2.54511).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.620420 \tValidation Loss: 2.511088\n",
      "Validation loss decreased (2.54511 --> 2.51109).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.503450 \tValidation Loss: 2.488467\n",
      "Validation loss decreased (2.51109 --> 2.48847).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.408482 \tValidation Loss: 2.477669\n",
      "Validation loss decreased (2.48847 --> 2.47767).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.335680 \tValidation Loss: 2.473269\n",
      "Validation loss decreased (2.47767 --> 2.47327).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.279961 \tValidation Loss: 2.473835\n",
      "Epoch: 18 \tTraining Loss: 0.239544 \tValidation Loss: 2.478872\n",
      "Epoch: 19 \tTraining Loss: 0.203817 \tValidation Loss: 2.486691\n",
      "Epoch: 20 \tTraining Loss: 0.177864 \tValidation Loss: 2.497625\n",
      "Epoch: 1 \tTraining Loss: 6.533809 \tValidation Loss: 4.771553\n",
      "Validation loss decreased (inf --> 4.77155).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.687816 \tValidation Loss: 4.536246\n",
      "Validation loss decreased (4.77155 --> 4.53625).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.219161 \tValidation Loss: 4.257927\n",
      "Validation loss decreased (4.53625 --> 4.25793).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.592437 \tValidation Loss: 3.907558\n",
      "Validation loss decreased (4.25793 --> 3.90756).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.859896 \tValidation Loss: 3.553049\n",
      "Validation loss decreased (3.90756 --> 3.55305).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.130149 \tValidation Loss: 3.234104\n",
      "Validation loss decreased (3.55305 --> 3.23410).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.482086 \tValidation Loss: 2.982811\n",
      "Validation loss decreased (3.23410 --> 2.98281).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.961899 \tValidation Loss: 2.793902\n",
      "Validation loss decreased (2.98281 --> 2.79390).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.555122 \tValidation Loss: 2.649667\n",
      "Validation loss decreased (2.79390 --> 2.64967).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.231388 \tValidation Loss: 2.537236\n",
      "Validation loss decreased (2.64967 --> 2.53724).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 \tTraining Loss: 0.979020 \tValidation Loss: 2.451844\n",
      "Validation loss decreased (2.53724 --> 2.45184).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.783044 \tValidation Loss: 2.389499\n",
      "Validation loss decreased (2.45184 --> 2.38950).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.622622 \tValidation Loss: 2.346522\n",
      "Validation loss decreased (2.38950 --> 2.34652).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.503355 \tValidation Loss: 2.318092\n",
      "Validation loss decreased (2.34652 --> 2.31809).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.409588 \tValidation Loss: 2.301095\n",
      "Validation loss decreased (2.31809 --> 2.30110).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.334232 \tValidation Loss: 2.292099\n",
      "Validation loss decreased (2.30110 --> 2.29210).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.278688 \tValidation Loss: 2.290279\n",
      "Validation loss decreased (2.29210 --> 2.29028).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.233566 \tValidation Loss: 2.293099\n",
      "Epoch: 19 \tTraining Loss: 0.201155 \tValidation Loss: 2.302246\n",
      "Epoch: 20 \tTraining Loss: 0.174542 \tValidation Loss: 2.312184\n",
      "Epoch: 1 \tTraining Loss: 6.544713 \tValidation Loss: 4.725442\n",
      "Validation loss decreased (inf --> 4.72544).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.698628 \tValidation Loss: 4.461403\n",
      "Validation loss decreased (4.72544 --> 4.46140).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.227684 \tValidation Loss: 4.167749\n",
      "Validation loss decreased (4.46140 --> 4.16775).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.591689 \tValidation Loss: 3.825456\n",
      "Validation loss decreased (4.16775 --> 3.82546).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.846741 \tValidation Loss: 3.486571\n",
      "Validation loss decreased (3.82546 --> 3.48657).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.117144 \tValidation Loss: 3.186974\n",
      "Validation loss decreased (3.48657 --> 3.18697).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.477594 \tValidation Loss: 2.943427\n",
      "Validation loss decreased (3.18697 --> 2.94343).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.956236 \tValidation Loss: 2.759167\n",
      "Validation loss decreased (2.94343 --> 2.75917).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.549373 \tValidation Loss: 2.623745\n",
      "Validation loss decreased (2.75917 --> 2.62374).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.231499 \tValidation Loss: 2.521085\n",
      "Validation loss decreased (2.62374 --> 2.52109).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.979287 \tValidation Loss: 2.442261\n",
      "Validation loss decreased (2.52109 --> 2.44226).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.780685 \tValidation Loss: 2.386231\n",
      "Validation loss decreased (2.44226 --> 2.38623).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.623187 \tValidation Loss: 2.347615\n",
      "Validation loss decreased (2.38623 --> 2.34761).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.502543 \tValidation Loss: 2.324005\n",
      "Validation loss decreased (2.34761 --> 2.32400).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.407554 \tValidation Loss: 2.309684\n",
      "Validation loss decreased (2.32400 --> 2.30968).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.336910 \tValidation Loss: 2.304078\n",
      "Validation loss decreased (2.30968 --> 2.30408).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.279978 \tValidation Loss: 2.303047\n",
      "Validation loss decreased (2.30408 --> 2.30305).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.236004 \tValidation Loss: 2.306127\n",
      "Epoch: 19 \tTraining Loss: 0.203718 \tValidation Loss: 2.313691\n",
      "Epoch: 20 \tTraining Loss: 0.177285 \tValidation Loss: 2.322537\n",
      "Epoch: 1 \tTraining Loss: 6.543374 \tValidation Loss: 4.768347\n",
      "Validation loss decreased (inf --> 4.76835).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.687033 \tValidation Loss: 4.534829\n",
      "Validation loss decreased (4.76835 --> 4.53483).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.215540 \tValidation Loss: 4.259070\n",
      "Validation loss decreased (4.53483 --> 4.25907).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.579907 \tValidation Loss: 3.915778\n",
      "Validation loss decreased (4.25907 --> 3.91578).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.830714 \tValidation Loss: 3.573213\n",
      "Validation loss decreased (3.91578 --> 3.57321).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.094844 \tValidation Loss: 3.274882\n",
      "Validation loss decreased (3.57321 --> 3.27488).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.448834 \tValidation Loss: 3.029228\n",
      "Validation loss decreased (3.27488 --> 3.02923).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.934892 \tValidation Loss: 2.838679\n",
      "Validation loss decreased (3.02923 --> 2.83868).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.529761 \tValidation Loss: 2.695173\n",
      "Validation loss decreased (2.83868 --> 2.69517).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.211518 \tValidation Loss: 2.585765\n",
      "Validation loss decreased (2.69517 --> 2.58576).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.964127 \tValidation Loss: 2.503422\n",
      "Validation loss decreased (2.58576 --> 2.50342).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.768928 \tValidation Loss: 2.440888\n",
      "Validation loss decreased (2.50342 --> 2.44089).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.616888 \tValidation Loss: 2.395637\n",
      "Validation loss decreased (2.44089 --> 2.39564).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.497992 \tValidation Loss: 2.366690\n",
      "Validation loss decreased (2.39564 --> 2.36669).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.402847 \tValidation Loss: 2.347958\n",
      "Validation loss decreased (2.36669 --> 2.34796).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.330276 \tValidation Loss: 2.338546\n",
      "Validation loss decreased (2.34796 --> 2.33855).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.276590 \tValidation Loss: 2.339646\n",
      "Epoch: 18 \tTraining Loss: 0.234827 \tValidation Loss: 2.339962\n",
      "Epoch: 19 \tTraining Loss: 0.201190 \tValidation Loss: 2.345138\n",
      "Epoch: 20 \tTraining Loss: 0.176001 \tValidation Loss: 2.350545\n",
      "Epoch: 1 \tTraining Loss: 6.539622 \tValidation Loss: 4.747952\n",
      "Validation loss decreased (inf --> 4.74795).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.684774 \tValidation Loss: 4.502722\n",
      "Validation loss decreased (4.74795 --> 4.50272).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.216524 \tValidation Loss: 4.212970\n",
      "Validation loss decreased (4.50272 --> 4.21297).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.590552 \tValidation Loss: 3.856352\n",
      "Validation loss decreased (4.21297 --> 3.85635).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.849163 \tValidation Loss: 3.503993\n",
      "Validation loss decreased (3.85635 --> 3.50399).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.113145 \tValidation Loss: 3.201976\n",
      "Validation loss decreased (3.50399 --> 3.20198).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.471772 \tValidation Loss: 2.959612\n",
      "Validation loss decreased (3.20198 --> 2.95961).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.955888 \tValidation Loss: 2.770660\n",
      "Validation loss decreased (2.95961 --> 2.77066).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.541226 \tValidation Loss: 2.624822\n",
      "Validation loss decreased (2.77066 --> 2.62482).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.220818 \tValidation Loss: 2.512036\n",
      "Validation loss decreased (2.62482 --> 2.51204).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.970317 \tValidation Loss: 2.425586\n",
      "Validation loss decreased (2.51204 --> 2.42559).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.774885 \tValidation Loss: 2.362411\n",
      "Validation loss decreased (2.42559 --> 2.36241).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.620388 \tValidation Loss: 2.318614\n",
      "Validation loss decreased (2.36241 --> 2.31861).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.496538 \tValidation Loss: 2.289444\n",
      "Validation loss decreased (2.31861 --> 2.28944).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.404087 \tValidation Loss: 2.272002\n",
      "Validation loss decreased (2.28944 --> 2.27200).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.329380 \tValidation Loss: 2.266744\n",
      "Validation loss decreased (2.27200 --> 2.26674).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.275269 \tValidation Loss: 2.262822\n",
      "Validation loss decreased (2.26674 --> 2.26282).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.232906 \tValidation Loss: 2.266359\n",
      "Epoch: 19 \tTraining Loss: 0.200447 \tValidation Loss: 2.275905\n",
      "Epoch: 20 \tTraining Loss: 0.176198 \tValidation Loss: 2.283352\n",
      "Epoch: 1 \tTraining Loss: 6.532962 \tValidation Loss: 4.756818\n",
      "Validation loss decreased (inf --> 4.75682).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 5.693372 \tValidation Loss: 4.523219\n",
      "Validation loss decreased (4.75682 --> 4.52322).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.227467 \tValidation Loss: 4.241883\n",
      "Validation loss decreased (4.52322 --> 4.24188).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.603871 \tValidation Loss: 3.891556\n",
      "Validation loss decreased (4.24188 --> 3.89156).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.864427 \tValidation Loss: 3.542470\n",
      "Validation loss decreased (3.89156 --> 3.54247).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.132224 \tValidation Loss: 3.235028\n",
      "Validation loss decreased (3.54247 --> 3.23503).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.489215 \tValidation Loss: 2.988498\n",
      "Validation loss decreased (3.23503 --> 2.98850).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.969902 \tValidation Loss: 2.798986\n",
      "Validation loss decreased (2.98850 --> 2.79899).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.559226 \tValidation Loss: 2.658202\n",
      "Validation loss decreased (2.79899 --> 2.65820).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.234833 \tValidation Loss: 2.553994\n",
      "Validation loss decreased (2.65820 --> 2.55399).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.989050 \tValidation Loss: 2.476047\n",
      "Validation loss decreased (2.55399 --> 2.47605).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.786287 \tValidation Loss: 2.423170\n",
      "Validation loss decreased (2.47605 --> 2.42317).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.632463 \tValidation Loss: 2.385607\n",
      "Validation loss decreased (2.42317 --> 2.38561).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.507784 \tValidation Loss: 2.360087\n",
      "Validation loss decreased (2.38561 --> 2.36009).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.411005 \tValidation Loss: 2.347294\n",
      "Validation loss decreased (2.36009 --> 2.34729).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.341320 \tValidation Loss: 2.341308\n",
      "Validation loss decreased (2.34729 --> 2.34131).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.282066 \tValidation Loss: 2.341401\n",
      "Epoch: 18 \tTraining Loss: 0.238817 \tValidation Loss: 2.346883\n",
      "Epoch: 19 \tTraining Loss: 0.205264 \tValidation Loss: 2.356866\n",
      "Epoch: 20 \tTraining Loss: 0.180162 \tValidation Loss: 2.365237\n",
      "Epoch: 1 \tTraining Loss: 6.543431 \tValidation Loss: 4.712888\n",
      "Validation loss decreased (inf --> 4.71289).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.697357 \tValidation Loss: 4.466417\n",
      "Validation loss decreased (4.71289 --> 4.46642).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.223929 \tValidation Loss: 4.186835\n",
      "Validation loss decreased (4.46642 --> 4.18684).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.599165 \tValidation Loss: 3.861487\n",
      "Validation loss decreased (4.18684 --> 3.86149).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.860801 \tValidation Loss: 3.536413\n",
      "Validation loss decreased (3.86149 --> 3.53641).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.131296 \tValidation Loss: 3.248413\n",
      "Validation loss decreased (3.53641 --> 3.24841).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.489199 \tValidation Loss: 3.011638\n",
      "Validation loss decreased (3.24841 --> 3.01164).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.965956 \tValidation Loss: 2.827181\n",
      "Validation loss decreased (3.01164 --> 2.82718).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.557574 \tValidation Loss: 2.686253\n",
      "Validation loss decreased (2.82718 --> 2.68625).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.236433 \tValidation Loss: 2.580085\n",
      "Validation loss decreased (2.68625 --> 2.58008).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.983402 \tValidation Loss: 2.499994\n",
      "Validation loss decreased (2.58008 --> 2.49999).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.785035 \tValidation Loss: 2.444686\n",
      "Validation loss decreased (2.49999 --> 2.44469).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.631644 \tValidation Loss: 2.406073\n",
      "Validation loss decreased (2.44469 --> 2.40607).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.507783 \tValidation Loss: 2.381855\n",
      "Validation loss decreased (2.40607 --> 2.38185).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.411261 \tValidation Loss: 2.368455\n",
      "Validation loss decreased (2.38185 --> 2.36845).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.338985 \tValidation Loss: 2.364282\n",
      "Validation loss decreased (2.36845 --> 2.36428).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.283016 \tValidation Loss: 2.366182\n",
      "Epoch: 18 \tTraining Loss: 0.237899 \tValidation Loss: 2.372956\n",
      "Epoch: 19 \tTraining Loss: 0.205109 \tValidation Loss: 2.379301\n",
      "Epoch: 20 \tTraining Loss: 0.178639 \tValidation Loss: 2.388153\n",
      "Epoch: 1 \tTraining Loss: 6.545839 \tValidation Loss: 4.744317\n",
      "Validation loss decreased (inf --> 4.74432).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.688868 \tValidation Loss: 4.500637\n",
      "Validation loss decreased (4.74432 --> 4.50064).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.213925 \tValidation Loss: 4.213518\n",
      "Validation loss decreased (4.50064 --> 4.21352).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.581586 \tValidation Loss: 3.860672\n",
      "Validation loss decreased (4.21352 --> 3.86067).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.836928 \tValidation Loss: 3.512052\n",
      "Validation loss decreased (3.86067 --> 3.51205).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.105772 \tValidation Loss: 3.206649\n",
      "Validation loss decreased (3.51205 --> 3.20665).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.460973 \tValidation Loss: 2.962683\n",
      "Validation loss decreased (3.20665 --> 2.96268).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.942464 \tValidation Loss: 2.777070\n",
      "Validation loss decreased (2.96268 --> 2.77707).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.531508 \tValidation Loss: 2.639322\n",
      "Validation loss decreased (2.77707 --> 2.63932).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.210260 \tValidation Loss: 2.534414\n",
      "Validation loss decreased (2.63932 --> 2.53441).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.962810 \tValidation Loss: 2.452331\n",
      "Validation loss decreased (2.53441 --> 2.45233).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.764314 \tValidation Loss: 2.393257\n",
      "Validation loss decreased (2.45233 --> 2.39326).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.614436 \tValidation Loss: 2.353950\n",
      "Validation loss decreased (2.39326 --> 2.35395).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.492792 \tValidation Loss: 2.330498\n",
      "Validation loss decreased (2.35395 --> 2.33050).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.398547 \tValidation Loss: 2.315341\n",
      "Validation loss decreased (2.33050 --> 2.31534).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.326734 \tValidation Loss: 2.307845\n",
      "Validation loss decreased (2.31534 --> 2.30784).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.272004 \tValidation Loss: 2.310094\n",
      "Epoch: 18 \tTraining Loss: 0.230880 \tValidation Loss: 2.316280\n",
      "Epoch: 19 \tTraining Loss: 0.197765 \tValidation Loss: 2.326079\n",
      "Epoch: 20 \tTraining Loss: 0.170393 \tValidation Loss: 2.335489\n",
      "Epoch: 1 \tTraining Loss: 6.542998 \tValidation Loss: 4.763802\n",
      "Validation loss decreased (inf --> 4.76380).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.684659 \tValidation Loss: 4.511373\n",
      "Validation loss decreased (4.76380 --> 4.51137).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.204406 \tValidation Loss: 4.224600\n",
      "Validation loss decreased (4.51137 --> 4.22460).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.566604 \tValidation Loss: 3.875371\n",
      "Validation loss decreased (4.22460 --> 3.87537).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.820689 \tValidation Loss: 3.532322\n",
      "Validation loss decreased (3.87537 --> 3.53232).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.095124 \tValidation Loss: 3.232984\n",
      "Validation loss decreased (3.53232 --> 3.23298).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.461391 \tValidation Loss: 2.987888\n",
      "Validation loss decreased (3.23298 --> 2.98789).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.945778 \tValidation Loss: 2.794862\n",
      "Validation loss decreased (2.98789 --> 2.79486).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.539946 \tValidation Loss: 2.646994\n",
      "Validation loss decreased (2.79486 --> 2.64699).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.223379 \tValidation Loss: 2.533920\n",
      "Validation loss decreased (2.64699 --> 2.53392).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.971835 \tValidation Loss: 2.448443\n",
      "Validation loss decreased (2.53392 --> 2.44844).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.777593 \tValidation Loss: 2.385894\n",
      "Validation loss decreased (2.44844 --> 2.38589).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 \tTraining Loss: 0.622569 \tValidation Loss: 2.341192\n",
      "Validation loss decreased (2.38589 --> 2.34119).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.498858 \tValidation Loss: 2.312750\n",
      "Validation loss decreased (2.34119 --> 2.31275).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.407004 \tValidation Loss: 2.296348\n",
      "Validation loss decreased (2.31275 --> 2.29635).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.334557 \tValidation Loss: 2.287573\n",
      "Validation loss decreased (2.29635 --> 2.28757).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.279795 \tValidation Loss: 2.286217\n",
      "Validation loss decreased (2.28757 --> 2.28622).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.235640 \tValidation Loss: 2.288130\n",
      "Epoch: 19 \tTraining Loss: 0.202911 \tValidation Loss: 2.295160\n",
      "Epoch: 20 \tTraining Loss: 0.176715 \tValidation Loss: 2.303378\n",
      "bbc/sport\\199.txt  had a problem\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 10 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.604856 \tValidation Loss: 6.113382\n",
      "Validation loss decreased (inf --> 6.11338).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.717429 \tValidation Loss: 5.641434\n",
      "Validation loss decreased (6.11338 --> 5.64143).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.247826 \tValidation Loss: 5.341259\n",
      "Validation loss decreased (5.64143 --> 5.34126).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.699485 \tValidation Loss: 4.963153\n",
      "Validation loss decreased (5.34126 --> 4.96315).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.021038 \tValidation Loss: 4.554375\n",
      "Validation loss decreased (4.96315 --> 4.55437).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.316434 \tValidation Loss: 4.184375\n",
      "Validation loss decreased (4.55437 --> 4.18438).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.672982 \tValidation Loss: 3.881177\n",
      "Validation loss decreased (4.18438 --> 3.88118).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.132916 \tValidation Loss: 3.646487\n",
      "Validation loss decreased (3.88118 --> 3.64649).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.701314 \tValidation Loss: 3.466631\n",
      "Validation loss decreased (3.64649 --> 3.46663).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.360020 \tValidation Loss: 3.331685\n",
      "Validation loss decreased (3.46663 --> 3.33169).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.088055 \tValidation Loss: 3.229183\n",
      "Validation loss decreased (3.33169 --> 3.22918).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.872715 \tValidation Loss: 3.151489\n",
      "Validation loss decreased (3.22918 --> 3.15149).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.699949 \tValidation Loss: 3.093865\n",
      "Validation loss decreased (3.15149 --> 3.09387).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.561979 \tValidation Loss: 3.052596\n",
      "Validation loss decreased (3.09387 --> 3.05260).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.454081 \tValidation Loss: 3.028017\n",
      "Validation loss decreased (3.05260 --> 3.02802).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.370068 \tValidation Loss: 3.015850\n",
      "Validation loss decreased (3.02802 --> 3.01585).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.304830 \tValidation Loss: 3.013360\n",
      "Validation loss decreased (3.01585 --> 3.01336).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.256878 \tValidation Loss: 3.017691\n",
      "Epoch: 19 \tTraining Loss: 0.219957 \tValidation Loss: 3.021992\n",
      "Epoch: 20 \tTraining Loss: 0.189117 \tValidation Loss: 3.032288\n",
      "Epoch: 1 \tTraining Loss: 6.606348 \tValidation Loss: 6.113326\n",
      "Validation loss decreased (inf --> 6.11333).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.698377 \tValidation Loss: 5.590923\n",
      "Validation loss decreased (6.11333 --> 5.59092).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.233381 \tValidation Loss: 5.289702\n",
      "Validation loss decreased (5.59092 --> 5.28970).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.683006 \tValidation Loss: 4.913774\n",
      "Validation loss decreased (5.28970 --> 4.91377).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.010868 \tValidation Loss: 4.509869\n",
      "Validation loss decreased (4.91377 --> 4.50987).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.310213 \tValidation Loss: 4.144035\n",
      "Validation loss decreased (4.50987 --> 4.14404).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.673264 \tValidation Loss: 3.847197\n",
      "Validation loss decreased (4.14404 --> 3.84720).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.143921 \tValidation Loss: 3.614808\n",
      "Validation loss decreased (3.84720 --> 3.61481).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.716073 \tValidation Loss: 3.434003\n",
      "Validation loss decreased (3.61481 --> 3.43400).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.374389 \tValidation Loss: 3.293195\n",
      "Validation loss decreased (3.43400 --> 3.29319).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.100651 \tValidation Loss: 3.186196\n",
      "Validation loss decreased (3.29319 --> 3.18620).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.878547 \tValidation Loss: 3.106304\n",
      "Validation loss decreased (3.18620 --> 3.10630).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.702821 \tValidation Loss: 3.051041\n",
      "Validation loss decreased (3.10630 --> 3.05104).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.564833 \tValidation Loss: 3.013492\n",
      "Validation loss decreased (3.05104 --> 3.01349).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.454841 \tValidation Loss: 2.992831\n",
      "Validation loss decreased (3.01349 --> 2.99283).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.372023 \tValidation Loss: 2.982747\n",
      "Validation loss decreased (2.99283 --> 2.98275).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.307543 \tValidation Loss: 2.980356\n",
      "Validation loss decreased (2.98275 --> 2.98036).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.260451 \tValidation Loss: 2.982920\n",
      "Epoch: 19 \tTraining Loss: 0.219937 \tValidation Loss: 2.990552\n",
      "Epoch: 20 \tTraining Loss: 0.190262 \tValidation Loss: 3.001063\n",
      "Epoch: 1 \tTraining Loss: 6.601167 \tValidation Loss: 6.095022\n",
      "Validation loss decreased (inf --> 6.09502).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.706283 \tValidation Loss: 5.607174\n",
      "Validation loss decreased (6.09502 --> 5.60717).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.249126 \tValidation Loss: 5.304245\n",
      "Validation loss decreased (5.60717 --> 5.30425).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.712271 \tValidation Loss: 4.924676\n",
      "Validation loss decreased (5.30425 --> 4.92468).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.040665 \tValidation Loss: 4.520049\n",
      "Validation loss decreased (4.92468 --> 4.52005).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.339340 \tValidation Loss: 4.150127\n",
      "Validation loss decreased (4.52005 --> 4.15013).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.699356 \tValidation Loss: 3.847334\n",
      "Validation loss decreased (4.15013 --> 3.84733).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.160151 \tValidation Loss: 3.616963\n",
      "Validation loss decreased (3.84733 --> 3.61696).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.727996 \tValidation Loss: 3.446127\n",
      "Validation loss decreased (3.61696 --> 3.44613).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.384656 \tValidation Loss: 3.319353\n",
      "Validation loss decreased (3.44613 --> 3.31935).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.110490 \tValidation Loss: 3.224544\n",
      "Validation loss decreased (3.31935 --> 3.22454).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.891922 \tValidation Loss: 3.151247\n",
      "Validation loss decreased (3.22454 --> 3.15125).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.714517 \tValidation Loss: 3.102651\n",
      "Validation loss decreased (3.15125 --> 3.10265).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.573805 \tValidation Loss: 3.071303\n",
      "Validation loss decreased (3.10265 --> 3.07130).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.464296 \tValidation Loss: 3.055055\n",
      "Validation loss decreased (3.07130 --> 3.05505).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.378343 \tValidation Loss: 3.047430\n",
      "Validation loss decreased (3.05505 --> 3.04743).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.313087 \tValidation Loss: 3.047751\n",
      "Epoch: 18 \tTraining Loss: 0.263831 \tValidation Loss: 3.054555\n",
      "Epoch: 19 \tTraining Loss: 0.224641 \tValidation Loss: 3.065994\n",
      "Epoch: 20 \tTraining Loss: 0.194634 \tValidation Loss: 3.078840\n",
      "Epoch: 1 \tTraining Loss: 6.605406 \tValidation Loss: 6.111529\n",
      "Validation loss decreased (inf --> 6.11153).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.707203 \tValidation Loss: 5.620132\n",
      "Validation loss decreased (6.11153 --> 5.62013).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \tTraining Loss: 5.244941 \tValidation Loss: 5.316234\n",
      "Validation loss decreased (5.62013 --> 5.31623).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.698579 \tValidation Loss: 4.946980\n",
      "Validation loss decreased (5.31623 --> 4.94698).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.020538 \tValidation Loss: 4.562455\n",
      "Validation loss decreased (4.94698 --> 4.56245).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.309772 \tValidation Loss: 4.214953\n",
      "Validation loss decreased (4.56245 --> 4.21495).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.661794 \tValidation Loss: 3.923831\n",
      "Validation loss decreased (4.21495 --> 3.92383).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.123695 \tValidation Loss: 3.690761\n",
      "Validation loss decreased (3.92383 --> 3.69076).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.694334 \tValidation Loss: 3.510303\n",
      "Validation loss decreased (3.69076 --> 3.51030).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.354221 \tValidation Loss: 3.369512\n",
      "Validation loss decreased (3.51030 --> 3.36951).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.082752 \tValidation Loss: 3.261578\n",
      "Validation loss decreased (3.36951 --> 3.26158).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.867069 \tValidation Loss: 3.180468\n",
      "Validation loss decreased (3.26158 --> 3.18047).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.696054 \tValidation Loss: 3.122187\n",
      "Validation loss decreased (3.18047 --> 3.12219).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.557515 \tValidation Loss: 3.085428\n",
      "Validation loss decreased (3.12219 --> 3.08543).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.447545 \tValidation Loss: 3.062931\n",
      "Validation loss decreased (3.08543 --> 3.06293).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.366392 \tValidation Loss: 3.051062\n",
      "Validation loss decreased (3.06293 --> 3.05106).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.305102 \tValidation Loss: 3.047395\n",
      "Validation loss decreased (3.05106 --> 3.04739).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.254616 \tValidation Loss: 3.052197\n",
      "Epoch: 19 \tTraining Loss: 0.215526 \tValidation Loss: 3.058245\n",
      "Epoch: 20 \tTraining Loss: 0.185900 \tValidation Loss: 3.067588\n",
      "Epoch: 1 \tTraining Loss: 6.599162 \tValidation Loss: 6.088522\n",
      "Validation loss decreased (inf --> 6.08852).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.704688 \tValidation Loss: 5.604398\n",
      "Validation loss decreased (6.08852 --> 5.60440).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.246890 \tValidation Loss: 5.298728\n",
      "Validation loss decreased (5.60440 --> 5.29873).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.700717 \tValidation Loss: 4.931678\n",
      "Validation loss decreased (5.29873 --> 4.93168).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.028133 \tValidation Loss: 4.545453\n",
      "Validation loss decreased (4.93168 --> 4.54545).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.322660 \tValidation Loss: 4.195171\n",
      "Validation loss decreased (4.54545 --> 4.19517).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.680957 \tValidation Loss: 3.909197\n",
      "Validation loss decreased (4.19517 --> 3.90920).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.145496 \tValidation Loss: 3.684343\n",
      "Validation loss decreased (3.90920 --> 3.68434).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.712000 \tValidation Loss: 3.510189\n",
      "Validation loss decreased (3.68434 --> 3.51019).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.369755 \tValidation Loss: 3.376974\n",
      "Validation loss decreased (3.51019 --> 3.37697).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.095435 \tValidation Loss: 3.276946\n",
      "Validation loss decreased (3.37697 --> 3.27695).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.875373 \tValidation Loss: 3.204872\n",
      "Validation loss decreased (3.27695 --> 3.20487).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.702453 \tValidation Loss: 3.154903\n",
      "Validation loss decreased (3.20487 --> 3.15490).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.564446 \tValidation Loss: 3.119575\n",
      "Validation loss decreased (3.15490 --> 3.11957).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.455150 \tValidation Loss: 3.102138\n",
      "Validation loss decreased (3.11957 --> 3.10214).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.370515 \tValidation Loss: 3.093519\n",
      "Validation loss decreased (3.10214 --> 3.09352).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.307996 \tValidation Loss: 3.095956\n",
      "Epoch: 18 \tTraining Loss: 0.256805 \tValidation Loss: 3.101219\n",
      "Epoch: 19 \tTraining Loss: 0.220630 \tValidation Loss: 3.110465\n",
      "Epoch: 20 \tTraining Loss: 0.190069 \tValidation Loss: 3.120349\n",
      "Epoch: 1 \tTraining Loss: 6.602446 \tValidation Loss: 6.137577\n",
      "Validation loss decreased (inf --> 6.13758).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.691327 \tValidation Loss: 5.696067\n",
      "Validation loss decreased (6.13758 --> 5.69607).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.227324 \tValidation Loss: 5.394859\n",
      "Validation loss decreased (5.69607 --> 5.39486).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.675626 \tValidation Loss: 5.040769\n",
      "Validation loss decreased (5.39486 --> 5.04077).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.000398 \tValidation Loss: 4.667031\n",
      "Validation loss decreased (5.04077 --> 4.66703).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.296382 \tValidation Loss: 4.323369\n",
      "Validation loss decreased (4.66703 --> 4.32337).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.656210 \tValidation Loss: 4.036243\n",
      "Validation loss decreased (4.32337 --> 4.03624).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.122988 \tValidation Loss: 3.811056\n",
      "Validation loss decreased (4.03624 --> 3.81106).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.695980 \tValidation Loss: 3.637926\n",
      "Validation loss decreased (3.81106 --> 3.63793).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.356708 \tValidation Loss: 3.505175\n",
      "Validation loss decreased (3.63793 --> 3.50518).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.087149 \tValidation Loss: 3.404606\n",
      "Validation loss decreased (3.50518 --> 3.40461).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.869075 \tValidation Loss: 3.331073\n",
      "Validation loss decreased (3.40461 --> 3.33107).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.697811 \tValidation Loss: 3.277878\n",
      "Validation loss decreased (3.33107 --> 3.27788).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.559146 \tValidation Loss: 3.244404\n",
      "Validation loss decreased (3.27788 --> 3.24440).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.452386 \tValidation Loss: 3.225100\n",
      "Validation loss decreased (3.24440 --> 3.22510).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.368840 \tValidation Loss: 3.215737\n",
      "Validation loss decreased (3.22510 --> 3.21574).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.304777 \tValidation Loss: 3.215184\n",
      "Validation loss decreased (3.21574 --> 3.21518).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.256010 \tValidation Loss: 3.222851\n",
      "Epoch: 19 \tTraining Loss: 0.215442 \tValidation Loss: 3.233773\n",
      "Epoch: 20 \tTraining Loss: 0.188194 \tValidation Loss: 3.247006\n",
      "Epoch: 1 \tTraining Loss: 6.603539 \tValidation Loss: 6.113814\n",
      "Validation loss decreased (inf --> 6.11381).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.705851 \tValidation Loss: 5.639031\n",
      "Validation loss decreased (6.11381 --> 5.63903).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.241991 \tValidation Loss: 5.338561\n",
      "Validation loss decreased (5.63903 --> 5.33856).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.700335 \tValidation Loss: 4.968625\n",
      "Validation loss decreased (5.33856 --> 4.96863).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.032165 \tValidation Loss: 4.570109\n",
      "Validation loss decreased (4.96863 --> 4.57011).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.329578 \tValidation Loss: 4.201165\n",
      "Validation loss decreased (4.57011 --> 4.20116).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.688922 \tValidation Loss: 3.901078\n",
      "Validation loss decreased (4.20116 --> 3.90108).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.147832 \tValidation Loss: 3.672773\n",
      "Validation loss decreased (3.90108 --> 3.67277).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.715108 \tValidation Loss: 3.496948\n",
      "Validation loss decreased (3.67277 --> 3.49695).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.371401 \tValidation Loss: 3.362888\n",
      "Validation loss decreased (3.49695 --> 3.36289).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.099624 \tValidation Loss: 3.261269\n",
      "Validation loss decreased (3.36289 --> 3.26127).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.882253 \tValidation Loss: 3.186002\n",
      "Validation loss decreased (3.26127 --> 3.18600).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 \tTraining Loss: 0.706092 \tValidation Loss: 3.134873\n",
      "Validation loss decreased (3.18600 --> 3.13487).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.567484 \tValidation Loss: 3.101090\n",
      "Validation loss decreased (3.13487 --> 3.10109).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.461015 \tValidation Loss: 3.078410\n",
      "Validation loss decreased (3.10109 --> 3.07841).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.375400 \tValidation Loss: 3.066487\n",
      "Validation loss decreased (3.07841 --> 3.06649).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.309393 \tValidation Loss: 3.061759\n",
      "Validation loss decreased (3.06649 --> 3.06176).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.261904 \tValidation Loss: 3.061663\n",
      "Validation loss decreased (3.06176 --> 3.06166).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.221627 \tValidation Loss: 3.068084\n",
      "Epoch: 20 \tTraining Loss: 0.191398 \tValidation Loss: 3.077478\n",
      "Epoch: 1 \tTraining Loss: 6.603248 \tValidation Loss: 6.101928\n",
      "Validation loss decreased (inf --> 6.10193).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.707922 \tValidation Loss: 5.588491\n",
      "Validation loss decreased (6.10193 --> 5.58849).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.231163 \tValidation Loss: 5.281807\n",
      "Validation loss decreased (5.58849 --> 5.28181).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.673538 \tValidation Loss: 4.908035\n",
      "Validation loss decreased (5.28181 --> 4.90804).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.995850 \tValidation Loss: 4.510966\n",
      "Validation loss decreased (4.90804 --> 4.51097).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.288541 \tValidation Loss: 4.152914\n",
      "Validation loss decreased (4.51097 --> 4.15291).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.647847 \tValidation Loss: 3.863839\n",
      "Validation loss decreased (4.15291 --> 3.86384).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.115200 \tValidation Loss: 3.641136\n",
      "Validation loss decreased (3.86384 --> 3.64114).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.689557 \tValidation Loss: 3.470288\n",
      "Validation loss decreased (3.64114 --> 3.47029).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.349204 \tValidation Loss: 3.339944\n",
      "Validation loss decreased (3.47029 --> 3.33994).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.082681 \tValidation Loss: 3.239013\n",
      "Validation loss decreased (3.33994 --> 3.23901).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.864704 \tValidation Loss: 3.163653\n",
      "Validation loss decreased (3.23901 --> 3.16365).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.692544 \tValidation Loss: 3.110583\n",
      "Validation loss decreased (3.16365 --> 3.11058).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.559118 \tValidation Loss: 3.076332\n",
      "Validation loss decreased (3.11058 --> 3.07633).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.451216 \tValidation Loss: 3.054492\n",
      "Validation loss decreased (3.07633 --> 3.05449).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.367978 \tValidation Loss: 3.046668\n",
      "Validation loss decreased (3.05449 --> 3.04667).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.305037 \tValidation Loss: 3.048711\n",
      "Epoch: 18 \tTraining Loss: 0.255945 \tValidation Loss: 3.054584\n",
      "Epoch: 19 \tTraining Loss: 0.217756 \tValidation Loss: 3.062330\n",
      "Epoch: 20 \tTraining Loss: 0.189702 \tValidation Loss: 3.071796\n",
      "Epoch: 1 \tTraining Loss: 6.594323 \tValidation Loss: 6.083896\n",
      "Validation loss decreased (inf --> 6.08390).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.695694 \tValidation Loss: 5.608990\n",
      "Validation loss decreased (6.08390 --> 5.60899).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.237755 \tValidation Loss: 5.305798\n",
      "Validation loss decreased (5.60899 --> 5.30580).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.701594 \tValidation Loss: 4.941882\n",
      "Validation loss decreased (5.30580 --> 4.94188).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.038765 \tValidation Loss: 4.545244\n",
      "Validation loss decreased (4.94188 --> 4.54524).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.341537 \tValidation Loss: 4.180066\n",
      "Validation loss decreased (4.54524 --> 4.18007).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.701915 \tValidation Loss: 3.876344\n",
      "Validation loss decreased (4.18007 --> 3.87634).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.164975 \tValidation Loss: 3.636805\n",
      "Validation loss decreased (3.87634 --> 3.63680).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.728407 \tValidation Loss: 3.452910\n",
      "Validation loss decreased (3.63680 --> 3.45291).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.380159 \tValidation Loss: 3.308804\n",
      "Validation loss decreased (3.45291 --> 3.30880).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.105450 \tValidation Loss: 3.197258\n",
      "Validation loss decreased (3.30880 --> 3.19726).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.886193 \tValidation Loss: 3.113624\n",
      "Validation loss decreased (3.19726 --> 3.11362).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.707903 \tValidation Loss: 3.052563\n",
      "Validation loss decreased (3.11362 --> 3.05256).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.567146 \tValidation Loss: 3.010976\n",
      "Validation loss decreased (3.05256 --> 3.01098).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.459675 \tValidation Loss: 2.988568\n",
      "Validation loss decreased (3.01098 --> 2.98857).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.374497 \tValidation Loss: 2.973114\n",
      "Validation loss decreased (2.98857 --> 2.97311).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.310291 \tValidation Loss: 2.968458\n",
      "Validation loss decreased (2.97311 --> 2.96846).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.260667 \tValidation Loss: 2.969139\n",
      "Epoch: 19 \tTraining Loss: 0.222194 \tValidation Loss: 2.974553\n",
      "Epoch: 20 \tTraining Loss: 0.193685 \tValidation Loss: 2.981890\n",
      "Epoch: 1 \tTraining Loss: 6.593422 \tValidation Loss: 6.111082\n",
      "Validation loss decreased (inf --> 6.11108).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.690410 \tValidation Loss: 5.675930\n",
      "Validation loss decreased (6.11108 --> 5.67593).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.231796 \tValidation Loss: 5.365678\n",
      "Validation loss decreased (5.67593 --> 5.36568).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.687898 \tValidation Loss: 4.998828\n",
      "Validation loss decreased (5.36568 --> 4.99883).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.014887 \tValidation Loss: 4.603161\n",
      "Validation loss decreased (4.99883 --> 4.60316).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.314152 \tValidation Loss: 4.235204\n",
      "Validation loss decreased (4.60316 --> 4.23520).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.673974 \tValidation Loss: 3.920317\n",
      "Validation loss decreased (4.23520 --> 3.92032).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.139980 \tValidation Loss: 3.666861\n",
      "Validation loss decreased (3.92032 --> 3.66686).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.712359 \tValidation Loss: 3.470346\n",
      "Validation loss decreased (3.66686 --> 3.47035).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.371083 \tValidation Loss: 3.315437\n",
      "Validation loss decreased (3.47035 --> 3.31544).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.098034 \tValidation Loss: 3.199153\n",
      "Validation loss decreased (3.31544 --> 3.19915).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.879303 \tValidation Loss: 3.111226\n",
      "Validation loss decreased (3.19915 --> 3.11123).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.703547 \tValidation Loss: 3.048133\n",
      "Validation loss decreased (3.11123 --> 3.04813).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.564589 \tValidation Loss: 3.004700\n",
      "Validation loss decreased (3.04813 --> 3.00470).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.456531 \tValidation Loss: 2.978916\n",
      "Validation loss decreased (3.00470 --> 2.97892).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.375542 \tValidation Loss: 2.967846\n",
      "Validation loss decreased (2.97892 --> 2.96785).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.310520 \tValidation Loss: 2.963160\n",
      "Validation loss decreased (2.96785 --> 2.96316).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.258733 \tValidation Loss: 2.964889\n",
      "Epoch: 19 \tTraining Loss: 0.220488 \tValidation Loss: 2.970240\n",
      "Epoch: 20 \tTraining Loss: 0.193459 \tValidation Loss: 2.978842\n",
      "bbc/sport\\199.txt  had a problem\n",
      "bbc/sport\\199.txt  had a problem\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 3 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 5.999537 \tValidation Loss: 5.247406\n",
      "Validation loss decreased (inf --> 5.24741).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.493076 \tValidation Loss: 5.117290\n",
      "Validation loss decreased (5.24741 --> 5.11729).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \tTraining Loss: 5.256970 \tValidation Loss: 4.946089\n",
      "Validation loss decreased (5.11729 --> 4.94609).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.944638 \tValidation Loss: 4.765890\n",
      "Validation loss decreased (4.94609 --> 4.76589).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.587656 \tValidation Loss: 4.602444\n",
      "Validation loss decreased (4.76589 --> 4.60244).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.217857 \tValidation Loss: 4.467250\n",
      "Validation loss decreased (4.60244 --> 4.46725).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.858443 \tValidation Loss: 4.361822\n",
      "Validation loss decreased (4.46725 --> 4.36182).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.531312 \tValidation Loss: 4.286480\n",
      "Validation loss decreased (4.36182 --> 4.28648).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.244499 \tValidation Loss: 4.237528\n",
      "Validation loss decreased (4.28648 --> 4.23753).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.998856 \tValidation Loss: 4.208037\n",
      "Validation loss decreased (4.23753 --> 4.20804).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.790222 \tValidation Loss: 4.195418\n",
      "Validation loss decreased (4.20804 --> 4.19542).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.616876 \tValidation Loss: 4.196517\n",
      "Epoch: 13 \tTraining Loss: 2.476664 \tValidation Loss: 4.205085\n",
      "Epoch: 14 \tTraining Loss: 2.358138 \tValidation Loss: 4.221912\n",
      "Epoch: 15 \tTraining Loss: 2.256126 \tValidation Loss: 4.242716\n",
      "Epoch: 16 \tTraining Loss: 2.173105 \tValidation Loss: 4.269752\n",
      "Epoch: 17 \tTraining Loss: 2.101158 \tValidation Loss: 4.298373\n",
      "Epoch: 18 \tTraining Loss: 2.043172 \tValidation Loss: 4.328363\n",
      "Epoch: 19 \tTraining Loss: 1.989521 \tValidation Loss: 4.359997\n",
      "Epoch: 20 \tTraining Loss: 1.947109 \tValidation Loss: 4.392139\n",
      "Epoch: 1 \tTraining Loss: 6.001841 \tValidation Loss: 5.248607\n",
      "Validation loss decreased (inf --> 5.24861).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.498808 \tValidation Loss: 5.126876\n",
      "Validation loss decreased (5.24861 --> 5.12688).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.258465 \tValidation Loss: 4.951067\n",
      "Validation loss decreased (5.12688 --> 4.95107).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.942038 \tValidation Loss: 4.770128\n",
      "Validation loss decreased (4.95107 --> 4.77013).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.580724 \tValidation Loss: 4.611735\n",
      "Validation loss decreased (4.77013 --> 4.61174).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.207748 \tValidation Loss: 4.482283\n",
      "Validation loss decreased (4.61174 --> 4.48228).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.850633 \tValidation Loss: 4.386739\n",
      "Validation loss decreased (4.48228 --> 4.38674).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.526151 \tValidation Loss: 4.321794\n",
      "Validation loss decreased (4.38674 --> 4.32179).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.238839 \tValidation Loss: 4.281956\n",
      "Validation loss decreased (4.32179 --> 4.28196).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.996076 \tValidation Loss: 4.261938\n",
      "Validation loss decreased (4.28196 --> 4.26194).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.789678 \tValidation Loss: 4.256654\n",
      "Validation loss decreased (4.26194 --> 4.25665).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.617536 \tValidation Loss: 4.260844\n",
      "Epoch: 13 \tTraining Loss: 2.476494 \tValidation Loss: 4.274889\n",
      "Epoch: 14 \tTraining Loss: 2.357706 \tValidation Loss: 4.294998\n",
      "Epoch: 15 \tTraining Loss: 2.257833 \tValidation Loss: 4.320265\n",
      "Epoch: 16 \tTraining Loss: 2.175298 \tValidation Loss: 4.349549\n",
      "Epoch: 17 \tTraining Loss: 2.105502 \tValidation Loss: 4.379280\n",
      "Epoch: 18 \tTraining Loss: 2.043317 \tValidation Loss: 4.413659\n",
      "Epoch: 19 \tTraining Loss: 1.993413 \tValidation Loss: 4.447312\n",
      "Epoch: 20 \tTraining Loss: 1.946747 \tValidation Loss: 4.482158\n",
      "Epoch: 1 \tTraining Loss: 6.004845 \tValidation Loss: 5.211887\n",
      "Validation loss decreased (inf --> 5.21189).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.493167 \tValidation Loss: 5.083429\n",
      "Validation loss decreased (5.21189 --> 5.08343).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.255598 \tValidation Loss: 4.907103\n",
      "Validation loss decreased (5.08343 --> 4.90710).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.940108 \tValidation Loss: 4.721382\n",
      "Validation loss decreased (4.90710 --> 4.72138).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.583358 \tValidation Loss: 4.553328\n",
      "Validation loss decreased (4.72138 --> 4.55333).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.212248 \tValidation Loss: 4.417157\n",
      "Validation loss decreased (4.55333 --> 4.41716).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.855171 \tValidation Loss: 4.315456\n",
      "Validation loss decreased (4.41716 --> 4.31546).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.525002 \tValidation Loss: 4.245670\n",
      "Validation loss decreased (4.31546 --> 4.24567).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.238997 \tValidation Loss: 4.200876\n",
      "Validation loss decreased (4.24567 --> 4.20088).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.993692 \tValidation Loss: 4.176835\n",
      "Validation loss decreased (4.20088 --> 4.17684).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.788815 \tValidation Loss: 4.166661\n",
      "Validation loss decreased (4.17684 --> 4.16666).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.615882 \tValidation Loss: 4.167003\n",
      "Epoch: 13 \tTraining Loss: 2.472713 \tValidation Loss: 4.176011\n",
      "Epoch: 14 \tTraining Loss: 2.353306 \tValidation Loss: 4.192257\n",
      "Epoch: 15 \tTraining Loss: 2.255925 \tValidation Loss: 4.214384\n",
      "Epoch: 16 \tTraining Loss: 2.168925 \tValidation Loss: 4.240833\n",
      "Epoch: 17 \tTraining Loss: 2.100240 \tValidation Loss: 4.268110\n",
      "Epoch: 18 \tTraining Loss: 2.040545 \tValidation Loss: 4.297697\n",
      "Epoch: 19 \tTraining Loss: 1.988340 \tValidation Loss: 4.329488\n",
      "Epoch: 20 \tTraining Loss: 1.944253 \tValidation Loss: 4.364210\n",
      "Epoch: 1 \tTraining Loss: 6.000749 \tValidation Loss: 5.214407\n",
      "Validation loss decreased (inf --> 5.21441).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.495203 \tValidation Loss: 5.099267\n",
      "Validation loss decreased (5.21441 --> 5.09927).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.260159 \tValidation Loss: 4.927179\n",
      "Validation loss decreased (5.09927 --> 4.92718).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.947882 \tValidation Loss: 4.742612\n",
      "Validation loss decreased (4.92718 --> 4.74261).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.589093 \tValidation Loss: 4.574200\n",
      "Validation loss decreased (4.74261 --> 4.57420).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.215589 \tValidation Loss: 4.436840\n",
      "Validation loss decreased (4.57420 --> 4.43684).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.853661 \tValidation Loss: 4.334223\n",
      "Validation loss decreased (4.43684 --> 4.33422).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.522231 \tValidation Loss: 4.262890\n",
      "Validation loss decreased (4.33422 --> 4.26289).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.234334 \tValidation Loss: 4.218492\n",
      "Validation loss decreased (4.26289 --> 4.21849).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.985917 \tValidation Loss: 4.193966\n",
      "Validation loss decreased (4.21849 --> 4.19397).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.778756 \tValidation Loss: 4.186345\n",
      "Validation loss decreased (4.19397 --> 4.18634).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.606803 \tValidation Loss: 4.191747\n",
      "Epoch: 13 \tTraining Loss: 2.464002 \tValidation Loss: 4.206445\n",
      "Epoch: 14 \tTraining Loss: 2.344487 \tValidation Loss: 4.225858\n",
      "Epoch: 15 \tTraining Loss: 2.247173 \tValidation Loss: 4.250915\n",
      "Epoch: 16 \tTraining Loss: 2.160915 \tValidation Loss: 4.281256\n",
      "Epoch: 17 \tTraining Loss: 2.090162 \tValidation Loss: 4.311655\n",
      "Epoch: 18 \tTraining Loss: 2.036189 \tValidation Loss: 4.344170\n",
      "Epoch: 19 \tTraining Loss: 1.979616 \tValidation Loss: 4.379608\n",
      "Epoch: 20 \tTraining Loss: 1.938604 \tValidation Loss: 4.414018\n",
      "Epoch: 1 \tTraining Loss: 6.000023 \tValidation Loss: 5.251842\n",
      "Validation loss decreased (inf --> 5.25184).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.496226 \tValidation Loss: 5.134994\n",
      "Validation loss decreased (5.25184 --> 5.13499).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.255676 \tValidation Loss: 4.979632\n",
      "Validation loss decreased (5.13499 --> 4.97963).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.935794 \tValidation Loss: 4.814223\n",
      "Validation loss decreased (4.97963 --> 4.81422).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.574594 \tValidation Loss: 4.661760\n",
      "Validation loss decreased (4.81422 --> 4.66176).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 \tTraining Loss: 4.202901 \tValidation Loss: 4.534891\n",
      "Validation loss decreased (4.66176 --> 4.53489).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.844943 \tValidation Loss: 4.439104\n",
      "Validation loss decreased (4.53489 --> 4.43910).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.519146 \tValidation Loss: 4.372946\n",
      "Validation loss decreased (4.43910 --> 4.37295).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.232898 \tValidation Loss: 4.329975\n",
      "Validation loss decreased (4.37295 --> 4.32997).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.988252 \tValidation Loss: 4.305043\n",
      "Validation loss decreased (4.32997 --> 4.30504).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.782247 \tValidation Loss: 4.295214\n",
      "Validation loss decreased (4.30504 --> 4.29521).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.609728 \tValidation Loss: 4.297770\n",
      "Epoch: 13 \tTraining Loss: 2.467988 \tValidation Loss: 4.307483\n",
      "Epoch: 14 \tTraining Loss: 2.346289 \tValidation Loss: 4.326659\n",
      "Epoch: 15 \tTraining Loss: 2.247563 \tValidation Loss: 4.349977\n",
      "Epoch: 16 \tTraining Loss: 2.162987 \tValidation Loss: 4.377667\n",
      "Epoch: 17 \tTraining Loss: 2.093955 \tValidation Loss: 4.408607\n",
      "Epoch: 18 \tTraining Loss: 2.036267 \tValidation Loss: 4.440973\n",
      "Epoch: 19 \tTraining Loss: 1.984152 \tValidation Loss: 4.472096\n",
      "Epoch: 20 \tTraining Loss: 1.940700 \tValidation Loss: 4.506978\n",
      "Epoch: 1 \tTraining Loss: 5.996654 \tValidation Loss: 5.237925\n",
      "Validation loss decreased (inf --> 5.23793).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.490233 \tValidation Loss: 5.121948\n",
      "Validation loss decreased (5.23793 --> 5.12195).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.253407 \tValidation Loss: 4.957544\n",
      "Validation loss decreased (5.12195 --> 4.95754).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.938731 \tValidation Loss: 4.784785\n",
      "Validation loss decreased (4.95754 --> 4.78479).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.583316 \tValidation Loss: 4.627769\n",
      "Validation loss decreased (4.78479 --> 4.62777).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.211429 \tValidation Loss: 4.493346\n",
      "Validation loss decreased (4.62777 --> 4.49335).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.849914 \tValidation Loss: 4.390588\n",
      "Validation loss decreased (4.49335 --> 4.39059).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.522081 \tValidation Loss: 4.318783\n",
      "Validation loss decreased (4.39059 --> 4.31878).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.237493 \tValidation Loss: 4.272913\n",
      "Validation loss decreased (4.31878 --> 4.27291).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.990594 \tValidation Loss: 4.247485\n",
      "Validation loss decreased (4.27291 --> 4.24748).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.787998 \tValidation Loss: 4.237259\n",
      "Validation loss decreased (4.24748 --> 4.23726).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.618505 \tValidation Loss: 4.236497\n",
      "Validation loss decreased (4.23726 --> 4.23650).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.473479 \tValidation Loss: 4.246654\n",
      "Epoch: 14 \tTraining Loss: 2.353961 \tValidation Loss: 4.263105\n",
      "Epoch: 15 \tTraining Loss: 2.253374 \tValidation Loss: 4.284192\n",
      "Epoch: 16 \tTraining Loss: 2.170380 \tValidation Loss: 4.307782\n",
      "Epoch: 17 \tTraining Loss: 2.101314 \tValidation Loss: 4.332989\n",
      "Epoch: 18 \tTraining Loss: 2.039857 \tValidation Loss: 4.362336\n",
      "Epoch: 19 \tTraining Loss: 1.989106 \tValidation Loss: 4.391530\n",
      "Epoch: 20 \tTraining Loss: 1.946077 \tValidation Loss: 4.422735\n",
      "Epoch: 1 \tTraining Loss: 6.002966 \tValidation Loss: 5.227284\n",
      "Validation loss decreased (inf --> 5.22728).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.493718 \tValidation Loss: 5.099109\n",
      "Validation loss decreased (5.22728 --> 5.09911).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.252789 \tValidation Loss: 4.913185\n",
      "Validation loss decreased (5.09911 --> 4.91318).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.933812 \tValidation Loss: 4.724886\n",
      "Validation loss decreased (4.91318 --> 4.72489).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.572663 \tValidation Loss: 4.559494\n",
      "Validation loss decreased (4.72489 --> 4.55949).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.198556 \tValidation Loss: 4.427696\n",
      "Validation loss decreased (4.55949 --> 4.42770).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.839214 \tValidation Loss: 4.328607\n",
      "Validation loss decreased (4.42770 --> 4.32861).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.514604 \tValidation Loss: 4.258037\n",
      "Validation loss decreased (4.32861 --> 4.25804).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.232103 \tValidation Loss: 4.211640\n",
      "Validation loss decreased (4.25804 --> 4.21164).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.988349 \tValidation Loss: 4.185509\n",
      "Validation loss decreased (4.21164 --> 4.18551).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.784824 \tValidation Loss: 4.173476\n",
      "Validation loss decreased (4.18551 --> 4.17348).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.614519 \tValidation Loss: 4.174975\n",
      "Epoch: 13 \tTraining Loss: 2.470880 \tValidation Loss: 4.185911\n",
      "Epoch: 14 \tTraining Loss: 2.353877 \tValidation Loss: 4.203134\n",
      "Epoch: 15 \tTraining Loss: 2.252032 \tValidation Loss: 4.225756\n",
      "Epoch: 16 \tTraining Loss: 2.170759 \tValidation Loss: 4.251248\n",
      "Epoch: 17 \tTraining Loss: 2.098516 \tValidation Loss: 4.281208\n",
      "Epoch: 18 \tTraining Loss: 2.037792 \tValidation Loss: 4.312008\n",
      "Epoch: 19 \tTraining Loss: 1.989649 \tValidation Loss: 4.345830\n",
      "Epoch: 20 \tTraining Loss: 1.944646 \tValidation Loss: 4.378583\n",
      "Epoch: 1 \tTraining Loss: 5.994651 \tValidation Loss: 5.272669\n",
      "Validation loss decreased (inf --> 5.27267).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.490624 \tValidation Loss: 5.152716\n",
      "Validation loss decreased (5.27267 --> 5.15272).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.254085 \tValidation Loss: 4.980091\n",
      "Validation loss decreased (5.15272 --> 4.98009).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.935666 \tValidation Loss: 4.800676\n",
      "Validation loss decreased (4.98009 --> 4.80068).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.571919 \tValidation Loss: 4.641580\n",
      "Validation loss decreased (4.80068 --> 4.64158).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.194970 \tValidation Loss: 4.512851\n",
      "Validation loss decreased (4.64158 --> 4.51285).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.833252 \tValidation Loss: 4.416129\n",
      "Validation loss decreased (4.51285 --> 4.41613).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.506271 \tValidation Loss: 4.349161\n",
      "Validation loss decreased (4.41613 --> 4.34916).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.218683 \tValidation Loss: 4.305534\n",
      "Validation loss decreased (4.34916 --> 4.30553).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.972930 \tValidation Loss: 4.283584\n",
      "Validation loss decreased (4.30553 --> 4.28358).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.771742 \tValidation Loss: 4.275240\n",
      "Validation loss decreased (4.28358 --> 4.27524).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.599114 \tValidation Loss: 4.280257\n",
      "Epoch: 13 \tTraining Loss: 2.460524 \tValidation Loss: 4.293775\n",
      "Epoch: 14 \tTraining Loss: 2.342693 \tValidation Loss: 4.314561\n",
      "Epoch: 15 \tTraining Loss: 2.243562 \tValidation Loss: 4.338136\n",
      "Epoch: 16 \tTraining Loss: 2.159985 \tValidation Loss: 4.366602\n",
      "Epoch: 17 \tTraining Loss: 2.088338 \tValidation Loss: 4.395877\n",
      "Epoch: 18 \tTraining Loss: 2.030066 \tValidation Loss: 4.428660\n",
      "Epoch: 19 \tTraining Loss: 1.978511 \tValidation Loss: 4.461472\n",
      "Epoch: 20 \tTraining Loss: 1.934930 \tValidation Loss: 4.495503\n",
      "Epoch: 1 \tTraining Loss: 5.996876 \tValidation Loss: 5.252841\n",
      "Validation loss decreased (inf --> 5.25284).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.487722 \tValidation Loss: 5.129355\n",
      "Validation loss decreased (5.25284 --> 5.12935).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.245295 \tValidation Loss: 4.963369\n",
      "Validation loss decreased (5.12935 --> 4.96337).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.924884 \tValidation Loss: 4.791440\n",
      "Validation loss decreased (4.96337 --> 4.79144).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.563387 \tValidation Loss: 4.636534\n",
      "Validation loss decreased (4.79144 --> 4.63653).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.194475 \tValidation Loss: 4.506686\n",
      "Validation loss decreased (4.63653 --> 4.50669).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.838926 \tValidation Loss: 4.405178\n",
      "Validation loss decreased (4.50669 --> 4.40518).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.517676 \tValidation Loss: 4.333149\n",
      "Validation loss decreased (4.40518 --> 4.33315).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 \tTraining Loss: 3.231143 \tValidation Loss: 4.286022\n",
      "Validation loss decreased (4.33315 --> 4.28602).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.988980 \tValidation Loss: 4.259462\n",
      "Validation loss decreased (4.28602 --> 4.25946).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.785321 \tValidation Loss: 4.247502\n",
      "Validation loss decreased (4.25946 --> 4.24750).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.612397 \tValidation Loss: 4.247616\n",
      "Epoch: 13 \tTraining Loss: 2.472537 \tValidation Loss: 4.257021\n",
      "Epoch: 14 \tTraining Loss: 2.350774 \tValidation Loss: 4.272950\n",
      "Epoch: 15 \tTraining Loss: 2.253447 \tValidation Loss: 4.295088\n",
      "Epoch: 16 \tTraining Loss: 2.166253 \tValidation Loss: 4.321525\n",
      "Epoch: 17 \tTraining Loss: 2.096023 \tValidation Loss: 4.350220\n",
      "Epoch: 18 \tTraining Loss: 2.037104 \tValidation Loss: 4.380496\n",
      "Epoch: 19 \tTraining Loss: 1.982454 \tValidation Loss: 4.412919\n",
      "Epoch: 20 \tTraining Loss: 1.939725 \tValidation Loss: 4.445690\n",
      "Epoch: 1 \tTraining Loss: 6.002889 \tValidation Loss: 5.232266\n",
      "Validation loss decreased (inf --> 5.23227).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.497322 \tValidation Loss: 5.105389\n",
      "Validation loss decreased (5.23227 --> 5.10539).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.255933 \tValidation Loss: 4.933203\n",
      "Validation loss decreased (5.10539 --> 4.93320).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.935490 \tValidation Loss: 4.757600\n",
      "Validation loss decreased (4.93320 --> 4.75760).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.570949 \tValidation Loss: 4.599631\n",
      "Validation loss decreased (4.75760 --> 4.59963).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.197552 \tValidation Loss: 4.468811\n",
      "Validation loss decreased (4.59963 --> 4.46881).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.842041 \tValidation Loss: 4.367386\n",
      "Validation loss decreased (4.46881 --> 4.36739).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.516427 \tValidation Loss: 4.293826\n",
      "Validation loss decreased (4.36739 --> 4.29383).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 3.232666 \tValidation Loss: 4.246440\n",
      "Validation loss decreased (4.29383 --> 4.24644).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.989742 \tValidation Loss: 4.218682\n",
      "Validation loss decreased (4.24644 --> 4.21868).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.781899 \tValidation Loss: 4.206259\n",
      "Validation loss decreased (4.21868 --> 4.20626).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.610003 \tValidation Loss: 4.205892\n",
      "Validation loss decreased (4.20626 --> 4.20589).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.469873 \tValidation Loss: 4.214582\n",
      "Epoch: 14 \tTraining Loss: 2.352245 \tValidation Loss: 4.229648\n",
      "Epoch: 15 \tTraining Loss: 2.248414 \tValidation Loss: 4.249483\n",
      "Epoch: 16 \tTraining Loss: 2.167765 \tValidation Loss: 4.274119\n",
      "Epoch: 17 \tTraining Loss: 2.097168 \tValidation Loss: 4.300626\n",
      "Epoch: 18 \tTraining Loss: 2.039147 \tValidation Loss: 4.329383\n",
      "Epoch: 19 \tTraining Loss: 1.984967 \tValidation Loss: 4.360483\n",
      "Epoch: 20 \tTraining Loss: 1.939452 \tValidation Loss: 4.393378\n",
      "bbc/sport\\199.txt  had a problem\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 4 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 5.992569 \tValidation Loss: 5.291163\n",
      "Validation loss decreased (inf --> 5.29116).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.434452 \tValidation Loss: 5.083301\n",
      "Validation loss decreased (5.29116 --> 5.08330).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.059144 \tValidation Loss: 4.805247\n",
      "Validation loss decreased (5.08330 --> 4.80525).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.587020 \tValidation Loss: 4.534845\n",
      "Validation loss decreased (4.80525 --> 4.53484).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.079535 \tValidation Loss: 4.300066\n",
      "Validation loss decreased (4.53484 --> 4.30007).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.596023 \tValidation Loss: 4.108073\n",
      "Validation loss decreased (4.30007 --> 4.10807).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.160635 \tValidation Loss: 3.956138\n",
      "Validation loss decreased (4.10807 --> 3.95614).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.790555 \tValidation Loss: 3.841172\n",
      "Validation loss decreased (3.95614 --> 3.84117).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.483984 \tValidation Loss: 3.756354\n",
      "Validation loss decreased (3.84117 --> 3.75635).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.240464 \tValidation Loss: 3.696085\n",
      "Validation loss decreased (3.75635 --> 3.69609).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.034873 \tValidation Loss: 3.658359\n",
      "Validation loss decreased (3.69609 --> 3.65836).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.866398 \tValidation Loss: 3.635068\n",
      "Validation loss decreased (3.65836 --> 3.63507).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.731823 \tValidation Loss: 3.623319\n",
      "Validation loss decreased (3.63507 --> 3.62332).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.620982 \tValidation Loss: 3.623930\n",
      "Epoch: 15 \tTraining Loss: 1.526146 \tValidation Loss: 3.633475\n",
      "Epoch: 16 \tTraining Loss: 1.447682 \tValidation Loss: 3.648573\n",
      "Epoch: 17 \tTraining Loss: 1.377377 \tValidation Loss: 3.667716\n",
      "Epoch: 18 \tTraining Loss: 1.320676 \tValidation Loss: 3.691739\n",
      "Epoch: 19 \tTraining Loss: 1.266548 \tValidation Loss: 3.719659\n",
      "Epoch: 20 \tTraining Loss: 1.223322 \tValidation Loss: 3.747378\n",
      "Epoch: 1 \tTraining Loss: 5.997078 \tValidation Loss: 5.282254\n",
      "Validation loss decreased (inf --> 5.28225).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.437361 \tValidation Loss: 5.071581\n",
      "Validation loss decreased (5.28225 --> 5.07158).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.059906 \tValidation Loss: 4.791800\n",
      "Validation loss decreased (5.07158 --> 4.79180).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.584641 \tValidation Loss: 4.514502\n",
      "Validation loss decreased (4.79180 --> 4.51450).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.076641 \tValidation Loss: 4.270333\n",
      "Validation loss decreased (4.51450 --> 4.27033).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.588816 \tValidation Loss: 4.075117\n",
      "Validation loss decreased (4.27033 --> 4.07512).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.155111 \tValidation Loss: 3.924973\n",
      "Validation loss decreased (4.07512 --> 3.92497).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.785500 \tValidation Loss: 3.814056\n",
      "Validation loss decreased (3.92497 --> 3.81406).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.476316 \tValidation Loss: 3.734306\n",
      "Validation loss decreased (3.81406 --> 3.73431).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.225780 \tValidation Loss: 3.679402\n",
      "Validation loss decreased (3.73431 --> 3.67940).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.024856 \tValidation Loss: 3.644804\n",
      "Validation loss decreased (3.67940 --> 3.64480).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.857688 \tValidation Loss: 3.627210\n",
      "Validation loss decreased (3.64480 --> 3.62721).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.722715 \tValidation Loss: 3.621820\n",
      "Validation loss decreased (3.62721 --> 3.62182).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.611870 \tValidation Loss: 3.625487\n",
      "Epoch: 15 \tTraining Loss: 1.515691 \tValidation Loss: 3.636497\n",
      "Epoch: 16 \tTraining Loss: 1.438277 \tValidation Loss: 3.653898\n",
      "Epoch: 17 \tTraining Loss: 1.372323 \tValidation Loss: 3.676607\n",
      "Epoch: 18 \tTraining Loss: 1.310421 \tValidation Loss: 3.701399\n",
      "Epoch: 19 \tTraining Loss: 1.262139 \tValidation Loss: 3.729052\n",
      "Epoch: 20 \tTraining Loss: 1.221756 \tValidation Loss: 3.758867\n",
      "Epoch: 1 \tTraining Loss: 5.998349 \tValidation Loss: 5.291019\n",
      "Validation loss decreased (inf --> 5.29102).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.441249 \tValidation Loss: 5.100928\n",
      "Validation loss decreased (5.29102 --> 5.10093).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.070379 \tValidation Loss: 4.838549\n",
      "Validation loss decreased (5.10093 --> 4.83855).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.600229 \tValidation Loss: 4.569241\n",
      "Validation loss decreased (4.83855 --> 4.56924).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.094691 \tValidation Loss: 4.331597\n",
      "Validation loss decreased (4.56924 --> 4.33160).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.609465 \tValidation Loss: 4.138074\n",
      "Validation loss decreased (4.33160 --> 4.13807).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.171181 \tValidation Loss: 3.987394\n",
      "Validation loss decreased (4.13807 --> 3.98739).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.800702 \tValidation Loss: 3.874556\n",
      "Validation loss decreased (3.98739 --> 3.87456).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 \tTraining Loss: 2.493616 \tValidation Loss: 3.793958\n",
      "Validation loss decreased (3.87456 --> 3.79396).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.240672 \tValidation Loss: 3.738437\n",
      "Validation loss decreased (3.79396 --> 3.73844).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.034881 \tValidation Loss: 3.701205\n",
      "Validation loss decreased (3.73844 --> 3.70121).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.868510 \tValidation Loss: 3.679905\n",
      "Validation loss decreased (3.70121 --> 3.67990).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.732878 \tValidation Loss: 3.670077\n",
      "Validation loss decreased (3.67990 --> 3.67008).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.619403 \tValidation Loss: 3.671987\n",
      "Epoch: 15 \tTraining Loss: 1.527015 \tValidation Loss: 3.679527\n",
      "Epoch: 16 \tTraining Loss: 1.449670 \tValidation Loss: 3.694178\n",
      "Epoch: 17 \tTraining Loss: 1.379515 \tValidation Loss: 3.714801\n",
      "Epoch: 18 \tTraining Loss: 1.318982 \tValidation Loss: 3.738132\n",
      "Epoch: 19 \tTraining Loss: 1.267050 \tValidation Loss: 3.763958\n",
      "Epoch: 20 \tTraining Loss: 1.226081 \tValidation Loss: 3.793056\n",
      "Epoch: 1 \tTraining Loss: 6.001847 \tValidation Loss: 5.296000\n",
      "Validation loss decreased (inf --> 5.29600).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.434645 \tValidation Loss: 5.072110\n",
      "Validation loss decreased (5.29600 --> 5.07211).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.057062 \tValidation Loss: 4.787387\n",
      "Validation loss decreased (5.07211 --> 4.78739).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.585325 \tValidation Loss: 4.508124\n",
      "Validation loss decreased (4.78739 --> 4.50812).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.078186 \tValidation Loss: 4.263501\n",
      "Validation loss decreased (4.50812 --> 4.26350).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.592609 \tValidation Loss: 4.068335\n",
      "Validation loss decreased (4.26350 --> 4.06834).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.159380 \tValidation Loss: 3.919661\n",
      "Validation loss decreased (4.06834 --> 3.91966).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.791479 \tValidation Loss: 3.808105\n",
      "Validation loss decreased (3.91966 --> 3.80811).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.485916 \tValidation Loss: 3.725700\n",
      "Validation loss decreased (3.80811 --> 3.72570).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.237139 \tValidation Loss: 3.667109\n",
      "Validation loss decreased (3.72570 --> 3.66711).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.031529 \tValidation Loss: 3.627792\n",
      "Validation loss decreased (3.66711 --> 3.62779).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.868490 \tValidation Loss: 3.603694\n",
      "Validation loss decreased (3.62779 --> 3.60369).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.733227 \tValidation Loss: 3.592927\n",
      "Validation loss decreased (3.60369 --> 3.59293).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.615656 \tValidation Loss: 3.592046\n",
      "Validation loss decreased (3.59293 --> 3.59205).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.524517 \tValidation Loss: 3.598998\n",
      "Epoch: 16 \tTraining Loss: 1.443764 \tValidation Loss: 3.614078\n",
      "Epoch: 17 \tTraining Loss: 1.376039 \tValidation Loss: 3.632939\n",
      "Epoch: 18 \tTraining Loss: 1.319560 \tValidation Loss: 3.653578\n",
      "Epoch: 19 \tTraining Loss: 1.269347 \tValidation Loss: 3.678502\n",
      "Epoch: 20 \tTraining Loss: 1.227030 \tValidation Loss: 3.708776\n",
      "Epoch: 1 \tTraining Loss: 5.999224 \tValidation Loss: 5.283673\n",
      "Validation loss decreased (inf --> 5.28367).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.433031 \tValidation Loss: 5.068181\n",
      "Validation loss decreased (5.28367 --> 5.06818).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.057259 \tValidation Loss: 4.783132\n",
      "Validation loss decreased (5.06818 --> 4.78313).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.586162 \tValidation Loss: 4.500604\n",
      "Validation loss decreased (4.78313 --> 4.50060).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.081321 \tValidation Loss: 4.255009\n",
      "Validation loss decreased (4.50060 --> 4.25501).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.598391 \tValidation Loss: 4.057287\n",
      "Validation loss decreased (4.25501 --> 4.05729).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.166045 \tValidation Loss: 3.905097\n",
      "Validation loss decreased (4.05729 --> 3.90510).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.797488 \tValidation Loss: 3.792666\n",
      "Validation loss decreased (3.90510 --> 3.79267).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.489491 \tValidation Loss: 3.711864\n",
      "Validation loss decreased (3.79267 --> 3.71186).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.240237 \tValidation Loss: 3.657100\n",
      "Validation loss decreased (3.71186 --> 3.65710).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.037609 \tValidation Loss: 3.623487\n",
      "Validation loss decreased (3.65710 --> 3.62349).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.872654 \tValidation Loss: 3.604924\n",
      "Validation loss decreased (3.62349 --> 3.60492).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.736347 \tValidation Loss: 3.597904\n",
      "Validation loss decreased (3.60492 --> 3.59790).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.625873 \tValidation Loss: 3.599699\n",
      "Epoch: 15 \tTraining Loss: 1.528191 \tValidation Loss: 3.608980\n",
      "Epoch: 16 \tTraining Loss: 1.450717 \tValidation Loss: 3.623278\n",
      "Epoch: 17 \tTraining Loss: 1.382550 \tValidation Loss: 3.644032\n",
      "Epoch: 18 \tTraining Loss: 1.323878 \tValidation Loss: 3.667018\n",
      "Epoch: 19 \tTraining Loss: 1.271727 \tValidation Loss: 3.693880\n",
      "Epoch: 20 \tTraining Loss: 1.232217 \tValidation Loss: 3.722368\n",
      "Epoch: 1 \tTraining Loss: 5.998479 \tValidation Loss: 5.274913\n",
      "Validation loss decreased (inf --> 5.27491).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.438411 \tValidation Loss: 5.072761\n",
      "Validation loss decreased (5.27491 --> 5.07276).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.063938 \tValidation Loss: 4.789927\n",
      "Validation loss decreased (5.07276 --> 4.78993).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.587203 \tValidation Loss: 4.506278\n",
      "Validation loss decreased (4.78993 --> 4.50628).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.077973 \tValidation Loss: 4.258763\n",
      "Validation loss decreased (4.50628 --> 4.25876).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.593815 \tValidation Loss: 4.056574\n",
      "Validation loss decreased (4.25876 --> 4.05657).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.160165 \tValidation Loss: 3.902781\n",
      "Validation loss decreased (4.05657 --> 3.90278).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.792609 \tValidation Loss: 3.790578\n",
      "Validation loss decreased (3.90278 --> 3.79058).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.484140 \tValidation Loss: 3.708922\n",
      "Validation loss decreased (3.79058 --> 3.70892).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.237574 \tValidation Loss: 3.654148\n",
      "Validation loss decreased (3.70892 --> 3.65415).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.037161 \tValidation Loss: 3.618654\n",
      "Validation loss decreased (3.65415 --> 3.61865).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.869097 \tValidation Loss: 3.596107\n",
      "Validation loss decreased (3.61865 --> 3.59611).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.734395 \tValidation Loss: 3.589334\n",
      "Validation loss decreased (3.59611 --> 3.58933).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.622139 \tValidation Loss: 3.589754\n",
      "Epoch: 15 \tTraining Loss: 1.527858 \tValidation Loss: 3.598291\n",
      "Epoch: 16 \tTraining Loss: 1.448323 \tValidation Loss: 3.614388\n",
      "Epoch: 17 \tTraining Loss: 1.379867 \tValidation Loss: 3.635413\n",
      "Epoch: 18 \tTraining Loss: 1.325143 \tValidation Loss: 3.659308\n",
      "Epoch: 19 \tTraining Loss: 1.271370 \tValidation Loss: 3.684818\n",
      "Epoch: 20 \tTraining Loss: 1.226986 \tValidation Loss: 3.715710\n",
      "Epoch: 1 \tTraining Loss: 5.995095 \tValidation Loss: 5.314432\n",
      "Validation loss decreased (inf --> 5.31443).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.437994 \tValidation Loss: 5.112567\n",
      "Validation loss decreased (5.31443 --> 5.11257).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.069029 \tValidation Loss: 4.829004\n",
      "Validation loss decreased (5.11257 --> 4.82900).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.595134 \tValidation Loss: 4.542308\n",
      "Validation loss decreased (4.82900 --> 4.54231).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.085095 \tValidation Loss: 4.292779\n",
      "Validation loss decreased (4.54231 --> 4.29278).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.596479 \tValidation Loss: 4.091267\n",
      "Validation loss decreased (4.29278 --> 4.09127).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 \tTraining Loss: 3.159916 \tValidation Loss: 3.939985\n",
      "Validation loss decreased (4.09127 --> 3.93999).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.793884 \tValidation Loss: 3.829669\n",
      "Validation loss decreased (3.93999 --> 3.82967).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.487112 \tValidation Loss: 3.753668\n",
      "Validation loss decreased (3.82967 --> 3.75367).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.235905 \tValidation Loss: 3.703962\n",
      "Validation loss decreased (3.75367 --> 3.70396).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.034694 \tValidation Loss: 3.674612\n",
      "Validation loss decreased (3.70396 --> 3.67461).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.868790 \tValidation Loss: 3.659693\n",
      "Validation loss decreased (3.67461 --> 3.65969).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.732502 \tValidation Loss: 3.657755\n",
      "Validation loss decreased (3.65969 --> 3.65775).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.621261 \tValidation Loss: 3.663772\n",
      "Epoch: 15 \tTraining Loss: 1.524275 \tValidation Loss: 3.680850\n",
      "Epoch: 16 \tTraining Loss: 1.446780 \tValidation Loss: 3.702351\n",
      "Epoch: 17 \tTraining Loss: 1.378023 \tValidation Loss: 3.726370\n",
      "Epoch: 18 \tTraining Loss: 1.321733 \tValidation Loss: 3.755318\n",
      "Epoch: 19 \tTraining Loss: 1.269767 \tValidation Loss: 3.786413\n",
      "Epoch: 20 \tTraining Loss: 1.227307 \tValidation Loss: 3.818705\n",
      "Epoch: 1 \tTraining Loss: 5.995062 \tValidation Loss: 5.303906\n",
      "Validation loss decreased (inf --> 5.30391).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.435801 \tValidation Loss: 5.096718\n",
      "Validation loss decreased (5.30391 --> 5.09672).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.066472 \tValidation Loss: 4.821217\n",
      "Validation loss decreased (5.09672 --> 4.82122).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.596687 \tValidation Loss: 4.551948\n",
      "Validation loss decreased (4.82122 --> 4.55195).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.090973 \tValidation Loss: 4.310914\n",
      "Validation loss decreased (4.55195 --> 4.31091).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.600237 \tValidation Loss: 4.115253\n",
      "Validation loss decreased (4.31091 --> 4.11525).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.163254 \tValidation Loss: 3.967969\n",
      "Validation loss decreased (4.11525 --> 3.96797).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.798681 \tValidation Loss: 3.857459\n",
      "Validation loss decreased (3.96797 --> 3.85746).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.493387 \tValidation Loss: 3.777204\n",
      "Validation loss decreased (3.85746 --> 3.77720).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.246058 \tValidation Loss: 3.719537\n",
      "Validation loss decreased (3.77720 --> 3.71954).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.041334 \tValidation Loss: 3.681042\n",
      "Validation loss decreased (3.71954 --> 3.68104).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.876578 \tValidation Loss: 3.655171\n",
      "Validation loss decreased (3.68104 --> 3.65517).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.740290 \tValidation Loss: 3.642750\n",
      "Validation loss decreased (3.65517 --> 3.64275).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.624148 \tValidation Loss: 3.640113\n",
      "Validation loss decreased (3.64275 --> 3.64011).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.532578 \tValidation Loss: 3.645440\n",
      "Epoch: 16 \tTraining Loss: 1.451416 \tValidation Loss: 3.655219\n",
      "Epoch: 17 \tTraining Loss: 1.384270 \tValidation Loss: 3.672205\n",
      "Epoch: 18 \tTraining Loss: 1.324704 \tValidation Loss: 3.693624\n",
      "Epoch: 19 \tTraining Loss: 1.274809 \tValidation Loss: 3.718484\n",
      "Epoch: 20 \tTraining Loss: 1.232804 \tValidation Loss: 3.748073\n",
      "Epoch: 1 \tTraining Loss: 5.997433 \tValidation Loss: 5.268615\n",
      "Validation loss decreased (inf --> 5.26861).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.432239 \tValidation Loss: 5.070154\n",
      "Validation loss decreased (5.26861 --> 5.07015).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.054886 \tValidation Loss: 4.796554\n",
      "Validation loss decreased (5.07015 --> 4.79655).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.580062 \tValidation Loss: 4.522182\n",
      "Validation loss decreased (4.79655 --> 4.52218).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.072723 \tValidation Loss: 4.283751\n",
      "Validation loss decreased (4.52218 --> 4.28375).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.587196 \tValidation Loss: 4.089060\n",
      "Validation loss decreased (4.28375 --> 4.08906).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.151517 \tValidation Loss: 3.938858\n",
      "Validation loss decreased (4.08906 --> 3.93886).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.781982 \tValidation Loss: 3.828370\n",
      "Validation loss decreased (3.93886 --> 3.82837).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.475257 \tValidation Loss: 3.750206\n",
      "Validation loss decreased (3.82837 --> 3.75021).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.224119 \tValidation Loss: 3.698774\n",
      "Validation loss decreased (3.75021 --> 3.69877).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.023792 \tValidation Loss: 3.668351\n",
      "Validation loss decreased (3.69877 --> 3.66835).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.856031 \tValidation Loss: 3.653064\n",
      "Validation loss decreased (3.66835 --> 3.65306).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.722295 \tValidation Loss: 3.650547\n",
      "Validation loss decreased (3.65306 --> 3.65055).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.610155 \tValidation Loss: 3.657246\n",
      "Epoch: 15 \tTraining Loss: 1.517803 \tValidation Loss: 3.673674\n",
      "Epoch: 16 \tTraining Loss: 1.441547 \tValidation Loss: 3.693467\n",
      "Epoch: 17 \tTraining Loss: 1.376180 \tValidation Loss: 3.717890\n",
      "Epoch: 18 \tTraining Loss: 1.314163 \tValidation Loss: 3.743151\n",
      "Epoch: 19 \tTraining Loss: 1.264298 \tValidation Loss: 3.773373\n",
      "Epoch: 20 \tTraining Loss: 1.219017 \tValidation Loss: 3.805162\n",
      "Epoch: 1 \tTraining Loss: 5.995341 \tValidation Loss: 5.312368\n",
      "Validation loss decreased (inf --> 5.31237).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.436550 \tValidation Loss: 5.107632\n",
      "Validation loss decreased (5.31237 --> 5.10763).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.060612 \tValidation Loss: 4.832487\n",
      "Validation loss decreased (5.10763 --> 4.83249).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.589735 \tValidation Loss: 4.553195\n",
      "Validation loss decreased (4.83249 --> 4.55319).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.083579 \tValidation Loss: 4.304873\n",
      "Validation loss decreased (4.55319 --> 4.30487).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.595135 \tValidation Loss: 4.103966\n",
      "Validation loss decreased (4.30487 --> 4.10397).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.160659 \tValidation Loss: 3.948222\n",
      "Validation loss decreased (4.10397 --> 3.94822).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.792182 \tValidation Loss: 3.834184\n",
      "Validation loss decreased (3.94822 --> 3.83418).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.486761 \tValidation Loss: 3.751307\n",
      "Validation loss decreased (3.83418 --> 3.75131).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.236960 \tValidation Loss: 3.692808\n",
      "Validation loss decreased (3.75131 --> 3.69281).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.033839 \tValidation Loss: 3.656088\n",
      "Validation loss decreased (3.69281 --> 3.65609).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.866313 \tValidation Loss: 3.634732\n",
      "Validation loss decreased (3.65609 --> 3.63473).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.733334 \tValidation Loss: 3.626298\n",
      "Validation loss decreased (3.63473 --> 3.62630).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.618646 \tValidation Loss: 3.628793\n",
      "Epoch: 15 \tTraining Loss: 1.523581 \tValidation Loss: 3.639643\n",
      "Epoch: 16 \tTraining Loss: 1.442996 \tValidation Loss: 3.654716\n",
      "Epoch: 17 \tTraining Loss: 1.380067 \tValidation Loss: 3.674992\n",
      "Epoch: 18 \tTraining Loss: 1.322794 \tValidation Loss: 3.699954\n",
      "Epoch: 19 \tTraining Loss: 1.270965 \tValidation Loss: 3.728440\n",
      "Epoch: 20 \tTraining Loss: 1.225595 \tValidation Loss: 3.758653\n",
      "bbc/sport\\199.txt  had a problem\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 5 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 5.995193 \tValidation Loss: 5.032185\n",
      "Validation loss decreased (inf --> 5.03218).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.370697 \tValidation Loss: 4.798431\n",
      "Validation loss decreased (5.03218 --> 4.79843).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.914633 \tValidation Loss: 4.485236\n",
      "Validation loss decreased (4.79843 --> 4.48524).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.350904 \tValidation Loss: 4.167766\n",
      "Validation loss decreased (4.48524 --> 4.16777).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \tTraining Loss: 3.758568 \tValidation Loss: 3.888090\n",
      "Validation loss decreased (4.16777 --> 3.88809).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.207488 \tValidation Loss: 3.662826\n",
      "Validation loss decreased (3.88809 --> 3.66283).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.735337 \tValidation Loss: 3.489115\n",
      "Validation loss decreased (3.66283 --> 3.48911).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.348824 \tValidation Loss: 3.360408\n",
      "Validation loss decreased (3.48911 --> 3.36041).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.037718 \tValidation Loss: 3.267888\n",
      "Validation loss decreased (3.36041 --> 3.26789).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.788056 \tValidation Loss: 3.200892\n",
      "Validation loss decreased (3.26789 --> 3.20089).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.590284 \tValidation Loss: 3.157093\n",
      "Validation loss decreased (3.20089 --> 3.15709).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.424706 \tValidation Loss: 3.131962\n",
      "Validation loss decreased (3.15709 --> 3.13196).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.295859 \tValidation Loss: 3.120072\n",
      "Validation loss decreased (3.13196 --> 3.12007).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.184481 \tValidation Loss: 3.117398\n",
      "Validation loss decreased (3.12007 --> 3.11740).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.091187 \tValidation Loss: 3.123961\n",
      "Epoch: 16 \tTraining Loss: 1.015910 \tValidation Loss: 3.137932\n",
      "Epoch: 17 \tTraining Loss: 0.950837 \tValidation Loss: 3.157538\n",
      "Epoch: 18 \tTraining Loss: 0.897880 \tValidation Loss: 3.178442\n",
      "Epoch: 19 \tTraining Loss: 0.848836 \tValidation Loss: 3.206994\n",
      "Epoch: 20 \tTraining Loss: 0.807497 \tValidation Loss: 3.234712\n",
      "Epoch: 1 \tTraining Loss: 5.990996 \tValidation Loss: 4.996822\n",
      "Validation loss decreased (inf --> 4.99682).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.375011 \tValidation Loss: 4.754156\n",
      "Validation loss decreased (4.99682 --> 4.75416).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.915955 \tValidation Loss: 4.433687\n",
      "Validation loss decreased (4.75416 --> 4.43369).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.343475 \tValidation Loss: 4.113597\n",
      "Validation loss decreased (4.43369 --> 4.11360).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.752764 \tValidation Loss: 3.834086\n",
      "Validation loss decreased (4.11360 --> 3.83409).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.205638 \tValidation Loss: 3.611248\n",
      "Validation loss decreased (3.83409 --> 3.61125).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.733035 \tValidation Loss: 3.442174\n",
      "Validation loss decreased (3.61125 --> 3.44217).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.346144 \tValidation Loss: 3.315609\n",
      "Validation loss decreased (3.44217 --> 3.31561).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.036241 \tValidation Loss: 3.221983\n",
      "Validation loss decreased (3.31561 --> 3.22198).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.786078 \tValidation Loss: 3.152945\n",
      "Validation loss decreased (3.22198 --> 3.15295).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.586035 \tValidation Loss: 3.104465\n",
      "Validation loss decreased (3.15295 --> 3.10446).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.426268 \tValidation Loss: 3.075206\n",
      "Validation loss decreased (3.10446 --> 3.07521).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.289296 \tValidation Loss: 3.059586\n",
      "Validation loss decreased (3.07521 --> 3.05959).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.184748 \tValidation Loss: 3.056784\n",
      "Validation loss decreased (3.05959 --> 3.05678).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.097543 \tValidation Loss: 3.060256\n",
      "Epoch: 16 \tTraining Loss: 1.015214 \tValidation Loss: 3.073290\n",
      "Epoch: 17 \tTraining Loss: 0.951180 \tValidation Loss: 3.086962\n",
      "Epoch: 18 \tTraining Loss: 0.897378 \tValidation Loss: 3.108082\n",
      "Epoch: 19 \tTraining Loss: 0.846486 \tValidation Loss: 3.131785\n",
      "Epoch: 20 \tTraining Loss: 0.808721 \tValidation Loss: 3.160041\n",
      "Epoch: 1 \tTraining Loss: 5.992058 \tValidation Loss: 5.033049\n",
      "Validation loss decreased (inf --> 5.03305).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.370036 \tValidation Loss: 4.780496\n",
      "Validation loss decreased (5.03305 --> 4.78050).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.909762 \tValidation Loss: 4.448862\n",
      "Validation loss decreased (4.78050 --> 4.44886).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.342440 \tValidation Loss: 4.120291\n",
      "Validation loss decreased (4.44886 --> 4.12029).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.754374 \tValidation Loss: 3.836234\n",
      "Validation loss decreased (4.12029 --> 3.83623).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.212610 \tValidation Loss: 3.605067\n",
      "Validation loss decreased (3.83623 --> 3.60507).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.739763 \tValidation Loss: 3.424519\n",
      "Validation loss decreased (3.60507 --> 3.42452).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.356973 \tValidation Loss: 3.287813\n",
      "Validation loss decreased (3.42452 --> 3.28781).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.043059 \tValidation Loss: 3.185443\n",
      "Validation loss decreased (3.28781 --> 3.18544).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.790915 \tValidation Loss: 3.111538\n",
      "Validation loss decreased (3.18544 --> 3.11154).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.591156 \tValidation Loss: 3.060442\n",
      "Validation loss decreased (3.11154 --> 3.06044).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.432057 \tValidation Loss: 3.026714\n",
      "Validation loss decreased (3.06044 --> 3.02671).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.297354 \tValidation Loss: 3.006689\n",
      "Validation loss decreased (3.02671 --> 3.00669).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.188431 \tValidation Loss: 2.997729\n",
      "Validation loss decreased (3.00669 --> 2.99773).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.097301 \tValidation Loss: 2.998101\n",
      "Epoch: 16 \tTraining Loss: 1.017535 \tValidation Loss: 3.006457\n",
      "Epoch: 17 \tTraining Loss: 0.956746 \tValidation Loss: 3.019221\n",
      "Epoch: 18 \tTraining Loss: 0.899159 \tValidation Loss: 3.036697\n",
      "Epoch: 19 \tTraining Loss: 0.853358 \tValidation Loss: 3.056394\n",
      "Epoch: 20 \tTraining Loss: 0.810055 \tValidation Loss: 3.084023\n",
      "Epoch: 1 \tTraining Loss: 5.990919 \tValidation Loss: 5.037395\n",
      "Validation loss decreased (inf --> 5.03740).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.366990 \tValidation Loss: 4.780634\n",
      "Validation loss decreased (5.03740 --> 4.78063).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.904855 \tValidation Loss: 4.458657\n",
      "Validation loss decreased (4.78063 --> 4.45866).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.339858 \tValidation Loss: 4.141211\n",
      "Validation loss decreased (4.45866 --> 4.14121).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.759047 \tValidation Loss: 3.860863\n",
      "Validation loss decreased (4.14121 --> 3.86086).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.215669 \tValidation Loss: 3.629199\n",
      "Validation loss decreased (3.86086 --> 3.62920).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.749838 \tValidation Loss: 3.449098\n",
      "Validation loss decreased (3.62920 --> 3.44910).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.357967 \tValidation Loss: 3.315588\n",
      "Validation loss decreased (3.44910 --> 3.31559).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.046917 \tValidation Loss: 3.215618\n",
      "Validation loss decreased (3.31559 --> 3.21562).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.793489 \tValidation Loss: 3.147608\n",
      "Validation loss decreased (3.21562 --> 3.14761).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.596298 \tValidation Loss: 3.102900\n",
      "Validation loss decreased (3.14761 --> 3.10290).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.431734 \tValidation Loss: 3.076020\n",
      "Validation loss decreased (3.10290 --> 3.07602).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.298641 \tValidation Loss: 3.061842\n",
      "Validation loss decreased (3.07602 --> 3.06184).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.190777 \tValidation Loss: 3.060928\n",
      "Validation loss decreased (3.06184 --> 3.06093).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.095265 \tValidation Loss: 3.065680\n",
      "Epoch: 16 \tTraining Loss: 1.021489 \tValidation Loss: 3.080612\n",
      "Epoch: 17 \tTraining Loss: 0.958437 \tValidation Loss: 3.100896\n",
      "Epoch: 18 \tTraining Loss: 0.899753 \tValidation Loss: 3.128022\n",
      "Epoch: 19 \tTraining Loss: 0.853077 \tValidation Loss: 3.154701\n",
      "Epoch: 20 \tTraining Loss: 0.808397 \tValidation Loss: 3.185527\n",
      "Epoch: 1 \tTraining Loss: 5.992782 \tValidation Loss: 5.026643\n",
      "Validation loss decreased (inf --> 5.02664).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 5.372407 \tValidation Loss: 4.773937\n",
      "Validation loss decreased (5.02664 --> 4.77394).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.917941 \tValidation Loss: 4.447305\n",
      "Validation loss decreased (4.77394 --> 4.44730).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.350327 \tValidation Loss: 4.128978\n",
      "Validation loss decreased (4.44730 --> 4.12898).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.755800 \tValidation Loss: 3.856283\n",
      "Validation loss decreased (4.12898 --> 3.85628).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.208712 \tValidation Loss: 3.639169\n",
      "Validation loss decreased (3.85628 --> 3.63917).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.733935 \tValidation Loss: 3.471020\n",
      "Validation loss decreased (3.63917 --> 3.47102).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.347266 \tValidation Loss: 3.344056\n",
      "Validation loss decreased (3.47102 --> 3.34406).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.036685 \tValidation Loss: 3.249551\n",
      "Validation loss decreased (3.34406 --> 3.24955).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.786334 \tValidation Loss: 3.182442\n",
      "Validation loss decreased (3.24955 --> 3.18244).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.584137 \tValidation Loss: 3.135267\n",
      "Validation loss decreased (3.18244 --> 3.13527).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.422730 \tValidation Loss: 3.108614\n",
      "Validation loss decreased (3.13527 --> 3.10861).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.294291 \tValidation Loss: 3.092699\n",
      "Validation loss decreased (3.10861 --> 3.09270).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.185200 \tValidation Loss: 3.088464\n",
      "Validation loss decreased (3.09270 --> 3.08846).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.094530 \tValidation Loss: 3.093370\n",
      "Epoch: 16 \tTraining Loss: 1.018832 \tValidation Loss: 3.103903\n",
      "Epoch: 17 \tTraining Loss: 0.957244 \tValidation Loss: 3.119397\n",
      "Epoch: 18 \tTraining Loss: 0.900092 \tValidation Loss: 3.138837\n",
      "Epoch: 19 \tTraining Loss: 0.851810 \tValidation Loss: 3.162067\n",
      "Epoch: 20 \tTraining Loss: 0.812471 \tValidation Loss: 3.184244\n",
      "Epoch: 1 \tTraining Loss: 5.984986 \tValidation Loss: 5.020666\n",
      "Validation loss decreased (inf --> 5.02067).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.371559 \tValidation Loss: 4.762063\n",
      "Validation loss decreased (5.02067 --> 4.76206).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.914212 \tValidation Loss: 4.431106\n",
      "Validation loss decreased (4.76206 --> 4.43111).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.348252 \tValidation Loss: 4.102955\n",
      "Validation loss decreased (4.43111 --> 4.10295).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.755543 \tValidation Loss: 3.817453\n",
      "Validation loss decreased (4.10295 --> 3.81745).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.206587 \tValidation Loss: 3.586435\n",
      "Validation loss decreased (3.81745 --> 3.58643).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.736642 \tValidation Loss: 3.407667\n",
      "Validation loss decreased (3.58643 --> 3.40767).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.347237 \tValidation Loss: 3.275736\n",
      "Validation loss decreased (3.40767 --> 3.27574).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.037888 \tValidation Loss: 3.177512\n",
      "Validation loss decreased (3.27574 --> 3.17751).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.790267 \tValidation Loss: 3.106447\n",
      "Validation loss decreased (3.17751 --> 3.10645).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.589214 \tValidation Loss: 3.058928\n",
      "Validation loss decreased (3.10645 --> 3.05893).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.427777 \tValidation Loss: 3.026651\n",
      "Validation loss decreased (3.05893 --> 3.02665).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.294812 \tValidation Loss: 3.013032\n",
      "Validation loss decreased (3.02665 --> 3.01303).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.184312 \tValidation Loss: 3.006165\n",
      "Validation loss decreased (3.01303 --> 3.00616).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.092739 \tValidation Loss: 3.010137\n",
      "Epoch: 16 \tTraining Loss: 1.019238 \tValidation Loss: 3.018438\n",
      "Epoch: 17 \tTraining Loss: 0.952468 \tValidation Loss: 3.033243\n",
      "Epoch: 18 \tTraining Loss: 0.895512 \tValidation Loss: 3.051617\n",
      "Epoch: 19 \tTraining Loss: 0.850845 \tValidation Loss: 3.073817\n",
      "Epoch: 20 \tTraining Loss: 0.806770 \tValidation Loss: 3.101315\n",
      "Epoch: 1 \tTraining Loss: 5.991041 \tValidation Loss: 5.003150\n",
      "Validation loss decreased (inf --> 5.00315).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.380759 \tValidation Loss: 4.757610\n",
      "Validation loss decreased (5.00315 --> 4.75761).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.927184 \tValidation Loss: 4.428211\n",
      "Validation loss decreased (4.75761 --> 4.42821).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.356151 \tValidation Loss: 4.098176\n",
      "Validation loss decreased (4.42821 --> 4.09818).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.762022 \tValidation Loss: 3.812704\n",
      "Validation loss decreased (4.09818 --> 3.81270).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.215392 \tValidation Loss: 3.584241\n",
      "Validation loss decreased (3.81270 --> 3.58424).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.745468 \tValidation Loss: 3.408248\n",
      "Validation loss decreased (3.58424 --> 3.40825).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.355442 \tValidation Loss: 3.277763\n",
      "Validation loss decreased (3.40825 --> 3.27776).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.042386 \tValidation Loss: 3.181643\n",
      "Validation loss decreased (3.27776 --> 3.18164).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.796744 \tValidation Loss: 3.114261\n",
      "Validation loss decreased (3.18164 --> 3.11426).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.595943 \tValidation Loss: 3.066446\n",
      "Validation loss decreased (3.11426 --> 3.06645).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.438727 \tValidation Loss: 3.039300\n",
      "Validation loss decreased (3.06645 --> 3.03930).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.304044 \tValidation Loss: 3.023490\n",
      "Validation loss decreased (3.03930 --> 3.02349).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.193727 \tValidation Loss: 3.018689\n",
      "Validation loss decreased (3.02349 --> 3.01869).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.108110 \tValidation Loss: 3.024940\n",
      "Epoch: 16 \tTraining Loss: 1.026986 \tValidation Loss: 3.036312\n",
      "Epoch: 17 \tTraining Loss: 0.962732 \tValidation Loss: 3.053629\n",
      "Epoch: 18 \tTraining Loss: 0.906902 \tValidation Loss: 3.076059\n",
      "Epoch: 19 \tTraining Loss: 0.861163 \tValidation Loss: 3.101180\n",
      "Epoch: 20 \tTraining Loss: 0.815878 \tValidation Loss: 3.130215\n",
      "Epoch: 1 \tTraining Loss: 5.988752 \tValidation Loss: 5.025828\n",
      "Validation loss decreased (inf --> 5.02583).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.366839 \tValidation Loss: 4.779829\n",
      "Validation loss decreased (5.02583 --> 4.77983).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.908478 \tValidation Loss: 4.462860\n",
      "Validation loss decreased (4.77983 --> 4.46286).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.337961 \tValidation Loss: 4.146171\n",
      "Validation loss decreased (4.46286 --> 4.14617).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.745441 \tValidation Loss: 3.870514\n",
      "Validation loss decreased (4.14617 --> 3.87051).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.197982 \tValidation Loss: 3.650864\n",
      "Validation loss decreased (3.87051 --> 3.65086).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.726507 \tValidation Loss: 3.481445\n",
      "Validation loss decreased (3.65086 --> 3.48145).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.341818 \tValidation Loss: 3.352894\n",
      "Validation loss decreased (3.48145 --> 3.35289).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.030865 \tValidation Loss: 3.256111\n",
      "Validation loss decreased (3.35289 --> 3.25611).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.781845 \tValidation Loss: 3.188342\n",
      "Validation loss decreased (3.25611 --> 3.18834).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.581186 \tValidation Loss: 3.139806\n",
      "Validation loss decreased (3.18834 --> 3.13981).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.422323 \tValidation Loss: 3.107888\n",
      "Validation loss decreased (3.13981 --> 3.10789).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.289045 \tValidation Loss: 3.088603\n",
      "Validation loss decreased (3.10789 --> 3.08860).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.181004 \tValidation Loss: 3.082636\n",
      "Validation loss decreased (3.08860 --> 3.08264).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.088722 \tValidation Loss: 3.087197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 \tTraining Loss: 1.013543 \tValidation Loss: 3.097513\n",
      "Epoch: 17 \tTraining Loss: 0.949574 \tValidation Loss: 3.112675\n",
      "Epoch: 18 \tTraining Loss: 0.892250 \tValidation Loss: 3.131166\n",
      "Epoch: 19 \tTraining Loss: 0.845544 \tValidation Loss: 3.153795\n",
      "Epoch: 20 \tTraining Loss: 0.806041 \tValidation Loss: 3.182770\n",
      "Epoch: 1 \tTraining Loss: 5.986230 \tValidation Loss: 5.023346\n",
      "Validation loss decreased (inf --> 5.02335).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.374396 \tValidation Loss: 4.770537\n",
      "Validation loss decreased (5.02335 --> 4.77054).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.918686 \tValidation Loss: 4.444520\n",
      "Validation loss decreased (4.77054 --> 4.44452).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.350631 \tValidation Loss: 4.124001\n",
      "Validation loss decreased (4.44452 --> 4.12400).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.760990 \tValidation Loss: 3.849081\n",
      "Validation loss decreased (4.12400 --> 3.84908).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.212498 \tValidation Loss: 3.625576\n",
      "Validation loss decreased (3.84908 --> 3.62558).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.740644 \tValidation Loss: 3.451082\n",
      "Validation loss decreased (3.62558 --> 3.45108).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.353735 \tValidation Loss: 3.317986\n",
      "Validation loss decreased (3.45108 --> 3.31799).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.043521 \tValidation Loss: 3.219690\n",
      "Validation loss decreased (3.31799 --> 3.21969).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.793318 \tValidation Loss: 3.148473\n",
      "Validation loss decreased (3.21969 --> 3.14847).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.595151 \tValidation Loss: 3.096756\n",
      "Validation loss decreased (3.14847 --> 3.09676).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.436096 \tValidation Loss: 3.063909\n",
      "Validation loss decreased (3.09676 --> 3.06391).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.302274 \tValidation Loss: 3.042851\n",
      "Validation loss decreased (3.06391 --> 3.04285).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.193471 \tValidation Loss: 3.035051\n",
      "Validation loss decreased (3.04285 --> 3.03505).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.103517 \tValidation Loss: 3.035066\n",
      "Epoch: 16 \tTraining Loss: 1.025325 \tValidation Loss: 3.041680\n",
      "Epoch: 17 \tTraining Loss: 0.962785 \tValidation Loss: 3.058173\n",
      "Epoch: 18 \tTraining Loss: 0.906237 \tValidation Loss: 3.075099\n",
      "Epoch: 19 \tTraining Loss: 0.857150 \tValidation Loss: 3.097611\n",
      "Epoch: 20 \tTraining Loss: 0.816452 \tValidation Loss: 3.125442\n",
      "Epoch: 1 \tTraining Loss: 5.994582 \tValidation Loss: 5.016518\n",
      "Validation loss decreased (inf --> 5.01652).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.371649 \tValidation Loss: 4.778308\n",
      "Validation loss decreased (5.01652 --> 4.77831).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.912162 \tValidation Loss: 4.456314\n",
      "Validation loss decreased (4.77831 --> 4.45631).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.343546 \tValidation Loss: 4.132125\n",
      "Validation loss decreased (4.45631 --> 4.13212).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.749432 \tValidation Loss: 3.851024\n",
      "Validation loss decreased (4.13212 --> 3.85102).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.196580 \tValidation Loss: 3.627975\n",
      "Validation loss decreased (3.85102 --> 3.62797).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.726831 \tValidation Loss: 3.460046\n",
      "Validation loss decreased (3.62797 --> 3.46005).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.337823 \tValidation Loss: 3.333128\n",
      "Validation loss decreased (3.46005 --> 3.33313).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.029257 \tValidation Loss: 3.239712\n",
      "Validation loss decreased (3.33313 --> 3.23971).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.783478 \tValidation Loss: 3.171266\n",
      "Validation loss decreased (3.23971 --> 3.17127).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.584426 \tValidation Loss: 3.124336\n",
      "Validation loss decreased (3.17127 --> 3.12434).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.428508 \tValidation Loss: 3.095095\n",
      "Validation loss decreased (3.12434 --> 3.09510).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.291848 \tValidation Loss: 3.077685\n",
      "Validation loss decreased (3.09510 --> 3.07769).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.187874 \tValidation Loss: 3.070910\n",
      "Validation loss decreased (3.07769 --> 3.07091).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.095612 \tValidation Loss: 3.075261\n",
      "Epoch: 16 \tTraining Loss: 1.020611 \tValidation Loss: 3.087390\n",
      "Epoch: 17 \tTraining Loss: 0.956429 \tValidation Loss: 3.100649\n",
      "Epoch: 18 \tTraining Loss: 0.902516 \tValidation Loss: 3.119113\n",
      "Epoch: 19 \tTraining Loss: 0.855171 \tValidation Loss: 3.140368\n",
      "Epoch: 20 \tTraining Loss: 0.811556 \tValidation Loss: 3.164116\n",
      "bbc/sport\\199.txt  had a problem\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 6 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.018083 \tValidation Loss: 4.870655\n",
      "Validation loss decreased (inf --> 4.87065).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.356791 \tValidation Loss: 4.622918\n",
      "Validation loss decreased (4.87065 --> 4.62292).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.864556 \tValidation Loss: 4.282640\n",
      "Validation loss decreased (4.62292 --> 4.28264).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.241848 \tValidation Loss: 3.938917\n",
      "Validation loss decreased (4.28264 --> 3.93892).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.593960 \tValidation Loss: 3.636423\n",
      "Validation loss decreased (3.93892 --> 3.63642).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.004860 \tValidation Loss: 3.393173\n",
      "Validation loss decreased (3.63642 --> 3.39317).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.502212 \tValidation Loss: 3.208092\n",
      "Validation loss decreased (3.39317 --> 3.20809).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.099536 \tValidation Loss: 3.069546\n",
      "Validation loss decreased (3.20809 --> 3.06955).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.778160 \tValidation Loss: 2.966377\n",
      "Validation loss decreased (3.06955 --> 2.96638).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.524128 \tValidation Loss: 2.892320\n",
      "Validation loss decreased (2.96638 --> 2.89232).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.319941 \tValidation Loss: 2.841075\n",
      "Validation loss decreased (2.89232 --> 2.84108).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.154657 \tValidation Loss: 2.808424\n",
      "Validation loss decreased (2.84108 --> 2.80842).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.024039 \tValidation Loss: 2.789073\n",
      "Validation loss decreased (2.80842 --> 2.78907).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.914407 \tValidation Loss: 2.781000\n",
      "Validation loss decreased (2.78907 --> 2.78100).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.824000 \tValidation Loss: 2.781166\n",
      "Epoch: 16 \tTraining Loss: 0.750216 \tValidation Loss: 2.789013\n",
      "Epoch: 17 \tTraining Loss: 0.687112 \tValidation Loss: 2.804537\n",
      "Epoch: 18 \tTraining Loss: 0.631325 \tValidation Loss: 2.819581\n",
      "Epoch: 19 \tTraining Loss: 0.586764 \tValidation Loss: 2.839613\n",
      "Epoch: 20 \tTraining Loss: 0.551507 \tValidation Loss: 2.864155\n",
      "Epoch: 1 \tTraining Loss: 6.021429 \tValidation Loss: 4.856741\n",
      "Validation loss decreased (inf --> 4.85674).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.364700 \tValidation Loss: 4.596286\n",
      "Validation loss decreased (4.85674 --> 4.59629).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.874098 \tValidation Loss: 4.246190\n",
      "Validation loss decreased (4.59629 --> 4.24619).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.257395 \tValidation Loss: 3.893005\n",
      "Validation loss decreased (4.24619 --> 3.89301).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.614713 \tValidation Loss: 3.592224\n",
      "Validation loss decreased (3.89301 --> 3.59222).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.025889 \tValidation Loss: 3.353207\n",
      "Validation loss decreased (3.59222 --> 3.35321).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.527218 \tValidation Loss: 3.166325\n",
      "Validation loss decreased (3.35321 --> 3.16632).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.122701 \tValidation Loss: 3.024457\n",
      "Validation loss decreased (3.16632 --> 3.02446).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.800295 \tValidation Loss: 2.919748\n",
      "Validation loss decreased (3.02446 --> 2.91975).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.542156 \tValidation Loss: 2.846857\n",
      "Validation loss decreased (2.91975 --> 2.84686).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.338319 \tValidation Loss: 2.798161\n",
      "Validation loss decreased (2.84686 --> 2.79816).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 \tTraining Loss: 1.174067 \tValidation Loss: 2.766791\n",
      "Validation loss decreased (2.79816 --> 2.76679).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.036085 \tValidation Loss: 2.749151\n",
      "Validation loss decreased (2.76679 --> 2.74915).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.924232 \tValidation Loss: 2.742492\n",
      "Validation loss decreased (2.74915 --> 2.74249).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.834928 \tValidation Loss: 2.745995\n",
      "Epoch: 16 \tTraining Loss: 0.754859 \tValidation Loss: 2.755636\n",
      "Epoch: 17 \tTraining Loss: 0.691530 \tValidation Loss: 2.769942\n",
      "Epoch: 18 \tTraining Loss: 0.636113 \tValidation Loss: 2.791759\n",
      "Epoch: 19 \tTraining Loss: 0.593195 \tValidation Loss: 2.816701\n",
      "Epoch: 20 \tTraining Loss: 0.551885 \tValidation Loss: 2.844930\n",
      "Epoch: 1 \tTraining Loss: 6.021990 \tValidation Loss: 4.833145\n",
      "Validation loss decreased (inf --> 4.83314).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.369523 \tValidation Loss: 4.587304\n",
      "Validation loss decreased (4.83314 --> 4.58730).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.880074 \tValidation Loss: 4.246347\n",
      "Validation loss decreased (4.58730 --> 4.24635).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.258339 \tValidation Loss: 3.900349\n",
      "Validation loss decreased (4.24635 --> 3.90035).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.610531 \tValidation Loss: 3.597507\n",
      "Validation loss decreased (3.90035 --> 3.59751).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.019352 \tValidation Loss: 3.355217\n",
      "Validation loss decreased (3.59751 --> 3.35522).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.520762 \tValidation Loss: 3.169513\n",
      "Validation loss decreased (3.35522 --> 3.16951).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.116435 \tValidation Loss: 3.027597\n",
      "Validation loss decreased (3.16951 --> 3.02760).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.793235 \tValidation Loss: 2.922550\n",
      "Validation loss decreased (3.02760 --> 2.92255).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.538082 \tValidation Loss: 2.847059\n",
      "Validation loss decreased (2.92255 --> 2.84706).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.333373 \tValidation Loss: 2.791549\n",
      "Validation loss decreased (2.84706 --> 2.79155).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.166549 \tValidation Loss: 2.755535\n",
      "Validation loss decreased (2.79155 --> 2.75554).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.034852 \tValidation Loss: 2.733545\n",
      "Validation loss decreased (2.75554 --> 2.73355).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.921118 \tValidation Loss: 2.722254\n",
      "Validation loss decreased (2.73355 --> 2.72225).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.834055 \tValidation Loss: 2.720115\n",
      "Validation loss decreased (2.72225 --> 2.72012).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.756736 \tValidation Loss: 2.720772\n",
      "Epoch: 17 \tTraining Loss: 0.691726 \tValidation Loss: 2.735628\n",
      "Epoch: 18 \tTraining Loss: 0.638692 \tValidation Loss: 2.753022\n",
      "Epoch: 19 \tTraining Loss: 0.591354 \tValidation Loss: 2.770161\n",
      "Epoch: 20 \tTraining Loss: 0.549870 \tValidation Loss: 2.796320\n",
      "Epoch: 1 \tTraining Loss: 6.014491 \tValidation Loss: 4.864491\n",
      "Validation loss decreased (inf --> 4.86449).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.360170 \tValidation Loss: 4.626507\n",
      "Validation loss decreased (4.86449 --> 4.62651).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.874713 \tValidation Loss: 4.288697\n",
      "Validation loss decreased (4.62651 --> 4.28870).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.255478 \tValidation Loss: 3.939455\n",
      "Validation loss decreased (4.28870 --> 3.93945).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.607251 \tValidation Loss: 3.633044\n",
      "Validation loss decreased (3.93945 --> 3.63304).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.015220 \tValidation Loss: 3.385059\n",
      "Validation loss decreased (3.63304 --> 3.38506).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.517125 \tValidation Loss: 3.191508\n",
      "Validation loss decreased (3.38506 --> 3.19151).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.114070 \tValidation Loss: 3.044412\n",
      "Validation loss decreased (3.19151 --> 3.04441).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.792157 \tValidation Loss: 2.931537\n",
      "Validation loss decreased (3.04441 --> 2.93154).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.538040 \tValidation Loss: 2.851019\n",
      "Validation loss decreased (2.93154 --> 2.85102).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.332560 \tValidation Loss: 2.793394\n",
      "Validation loss decreased (2.85102 --> 2.79339).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.169919 \tValidation Loss: 2.753942\n",
      "Validation loss decreased (2.79339 --> 2.75394).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.034513 \tValidation Loss: 2.729289\n",
      "Validation loss decreased (2.75394 --> 2.72929).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.925503 \tValidation Loss: 2.718576\n",
      "Validation loss decreased (2.72929 --> 2.71858).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.830320 \tValidation Loss: 2.718478\n",
      "Validation loss decreased (2.71858 --> 2.71848).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.758994 \tValidation Loss: 2.724070\n",
      "Epoch: 17 \tTraining Loss: 0.696323 \tValidation Loss: 2.731083\n",
      "Epoch: 18 \tTraining Loss: 0.638477 \tValidation Loss: 2.749426\n",
      "Epoch: 19 \tTraining Loss: 0.597415 \tValidation Loss: 2.770043\n",
      "Epoch: 20 \tTraining Loss: 0.555324 \tValidation Loss: 2.791002\n",
      "Epoch: 1 \tTraining Loss: 6.025193 \tValidation Loss: 4.848209\n",
      "Validation loss decreased (inf --> 4.84821).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.359666 \tValidation Loss: 4.604532\n",
      "Validation loss decreased (4.84821 --> 4.60453).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.866256 \tValidation Loss: 4.270536\n",
      "Validation loss decreased (4.60453 --> 4.27054).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.244421 \tValidation Loss: 3.938039\n",
      "Validation loss decreased (4.27054 --> 3.93804).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.602626 \tValidation Loss: 3.648427\n",
      "Validation loss decreased (3.93804 --> 3.64843).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.014727 \tValidation Loss: 3.412960\n",
      "Validation loss decreased (3.64843 --> 3.41296).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.517508 \tValidation Loss: 3.233437\n",
      "Validation loss decreased (3.41296 --> 3.23344).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.114980 \tValidation Loss: 3.097528\n",
      "Validation loss decreased (3.23344 --> 3.09753).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.794357 \tValidation Loss: 2.996227\n",
      "Validation loss decreased (3.09753 --> 2.99623).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.537075 \tValidation Loss: 2.921167\n",
      "Validation loss decreased (2.99623 --> 2.92117).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.334743 \tValidation Loss: 2.868678\n",
      "Validation loss decreased (2.92117 --> 2.86868).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.168268 \tValidation Loss: 2.832990\n",
      "Validation loss decreased (2.86868 --> 2.83299).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.032563 \tValidation Loss: 2.814631\n",
      "Validation loss decreased (2.83299 --> 2.81463).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.919781 \tValidation Loss: 2.807558\n",
      "Validation loss decreased (2.81463 --> 2.80756).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.834371 \tValidation Loss: 2.809386\n",
      "Epoch: 16 \tTraining Loss: 0.755884 \tValidation Loss: 2.815862\n",
      "Epoch: 17 \tTraining Loss: 0.690044 \tValidation Loss: 2.832518\n",
      "Epoch: 18 \tTraining Loss: 0.635114 \tValidation Loss: 2.852824\n",
      "Epoch: 19 \tTraining Loss: 0.593266 \tValidation Loss: 2.876252\n",
      "Epoch: 20 \tTraining Loss: 0.552464 \tValidation Loss: 2.899222\n",
      "Epoch: 1 \tTraining Loss: 6.017622 \tValidation Loss: 4.912099\n",
      "Validation loss decreased (inf --> 4.91210).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.353815 \tValidation Loss: 4.665990\n",
      "Validation loss decreased (4.91210 --> 4.66599).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.861446 \tValidation Loss: 4.326652\n",
      "Validation loss decreased (4.66599 --> 4.32665).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.240072 \tValidation Loss: 3.984732\n",
      "Validation loss decreased (4.32665 --> 3.98473).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.596717 \tValidation Loss: 3.688688\n",
      "Validation loss decreased (3.98473 --> 3.68869).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.007286 \tValidation Loss: 3.453377\n",
      "Validation loss decreased (3.68869 --> 3.45338).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.513081 \tValidation Loss: 3.270332\n",
      "Validation loss decreased (3.45338 --> 3.27033).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 \tTraining Loss: 2.111317 \tValidation Loss: 3.129518\n",
      "Validation loss decreased (3.27033 --> 3.12952).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.791412 \tValidation Loss: 3.021992\n",
      "Validation loss decreased (3.12952 --> 3.02199).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.535560 \tValidation Loss: 2.943100\n",
      "Validation loss decreased (3.02199 --> 2.94310).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.335253 \tValidation Loss: 2.887101\n",
      "Validation loss decreased (2.94310 --> 2.88710).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.166826 \tValidation Loss: 2.848291\n",
      "Validation loss decreased (2.88710 --> 2.84829).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.036566 \tValidation Loss: 2.827548\n",
      "Validation loss decreased (2.84829 --> 2.82755).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.924785 \tValidation Loss: 2.817529\n",
      "Validation loss decreased (2.82755 --> 2.81753).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.834484 \tValidation Loss: 2.816028\n",
      "Validation loss decreased (2.81753 --> 2.81603).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.757700 \tValidation Loss: 2.820919\n",
      "Epoch: 17 \tTraining Loss: 0.693812 \tValidation Loss: 2.833381\n",
      "Epoch: 18 \tTraining Loss: 0.641503 \tValidation Loss: 2.851127\n",
      "Epoch: 19 \tTraining Loss: 0.595849 \tValidation Loss: 2.871523\n",
      "Epoch: 20 \tTraining Loss: 0.559695 \tValidation Loss: 2.896621\n",
      "Epoch: 1 \tTraining Loss: 6.023108 \tValidation Loss: 4.878745\n",
      "Validation loss decreased (inf --> 4.87874).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.346787 \tValidation Loss: 4.627560\n",
      "Validation loss decreased (4.87874 --> 4.62756).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.852649 \tValidation Loss: 4.293665\n",
      "Validation loss decreased (4.62756 --> 4.29366).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.227678 \tValidation Loss: 3.962029\n",
      "Validation loss decreased (4.29366 --> 3.96203).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.583697 \tValidation Loss: 3.671887\n",
      "Validation loss decreased (3.96203 --> 3.67189).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.999085 \tValidation Loss: 3.434419\n",
      "Validation loss decreased (3.67189 --> 3.43442).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.505701 \tValidation Loss: 3.249273\n",
      "Validation loss decreased (3.43442 --> 3.24927).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.106423 \tValidation Loss: 3.109245\n",
      "Validation loss decreased (3.24927 --> 3.10925).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.787111 \tValidation Loss: 3.003970\n",
      "Validation loss decreased (3.10925 --> 3.00397).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.536945 \tValidation Loss: 2.922799\n",
      "Validation loss decreased (3.00397 --> 2.92280).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.333527 \tValidation Loss: 2.865496\n",
      "Validation loss decreased (2.92280 --> 2.86550).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.167851 \tValidation Loss: 2.828943\n",
      "Validation loss decreased (2.86550 --> 2.82894).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.037718 \tValidation Loss: 2.806108\n",
      "Validation loss decreased (2.82894 --> 2.80611).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.928189 \tValidation Loss: 2.797218\n",
      "Validation loss decreased (2.80611 --> 2.79722).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.835949 \tValidation Loss: 2.795872\n",
      "Validation loss decreased (2.79722 --> 2.79587).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.761346 \tValidation Loss: 2.803037\n",
      "Epoch: 17 \tTraining Loss: 0.696217 \tValidation Loss: 2.815587\n",
      "Epoch: 18 \tTraining Loss: 0.642846 \tValidation Loss: 2.833404\n",
      "Epoch: 19 \tTraining Loss: 0.597400 \tValidation Loss: 2.854027\n",
      "Epoch: 20 \tTraining Loss: 0.557430 \tValidation Loss: 2.878067\n",
      "Epoch: 1 \tTraining Loss: 6.031719 \tValidation Loss: 4.835716\n",
      "Validation loss decreased (inf --> 4.83572).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.367094 \tValidation Loss: 4.583806\n",
      "Validation loss decreased (4.83572 --> 4.58381).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.877847 \tValidation Loss: 4.227425\n",
      "Validation loss decreased (4.58381 --> 4.22742).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.257246 \tValidation Loss: 3.869844\n",
      "Validation loss decreased (4.22742 --> 3.86984).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.611045 \tValidation Loss: 3.564610\n",
      "Validation loss decreased (3.86984 --> 3.56461).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.016901 \tValidation Loss: 3.320784\n",
      "Validation loss decreased (3.56461 --> 3.32078).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.516248 \tValidation Loss: 3.134365\n",
      "Validation loss decreased (3.32078 --> 3.13436).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.108807 \tValidation Loss: 2.996675\n",
      "Validation loss decreased (3.13436 --> 2.99668).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.789107 \tValidation Loss: 2.893082\n",
      "Validation loss decreased (2.99668 --> 2.89308).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.531476 \tValidation Loss: 2.820821\n",
      "Validation loss decreased (2.89308 --> 2.82082).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.329063 \tValidation Loss: 2.768373\n",
      "Validation loss decreased (2.82082 --> 2.76837).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.164619 \tValidation Loss: 2.733788\n",
      "Validation loss decreased (2.76837 --> 2.73379).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.030735 \tValidation Loss: 2.714459\n",
      "Validation loss decreased (2.73379 --> 2.71446).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.921019 \tValidation Loss: 2.705563\n",
      "Validation loss decreased (2.71446 --> 2.70556).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.828443 \tValidation Loss: 2.706404\n",
      "Epoch: 16 \tTraining Loss: 0.752453 \tValidation Loss: 2.713944\n",
      "Epoch: 17 \tTraining Loss: 0.690076 \tValidation Loss: 2.728691\n",
      "Epoch: 18 \tTraining Loss: 0.634100 \tValidation Loss: 2.746558\n",
      "Epoch: 19 \tTraining Loss: 0.590542 \tValidation Loss: 2.769193\n",
      "Epoch: 20 \tTraining Loss: 0.553696 \tValidation Loss: 2.792804\n",
      "Epoch: 1 \tTraining Loss: 6.024555 \tValidation Loss: 4.860703\n",
      "Validation loss decreased (inf --> 4.86070).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.365506 \tValidation Loss: 4.609162\n",
      "Validation loss decreased (4.86070 --> 4.60916).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.877347 \tValidation Loss: 4.266416\n",
      "Validation loss decreased (4.60916 --> 4.26642).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.259603 \tValidation Loss: 3.926436\n",
      "Validation loss decreased (4.26642 --> 3.92644).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.618344 \tValidation Loss: 3.632274\n",
      "Validation loss decreased (3.92644 --> 3.63227).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.025069 \tValidation Loss: 3.391439\n",
      "Validation loss decreased (3.63227 --> 3.39144).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.527836 \tValidation Loss: 3.204694\n",
      "Validation loss decreased (3.39144 --> 3.20469).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.120072 \tValidation Loss: 3.062192\n",
      "Validation loss decreased (3.20469 --> 3.06219).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.794994 \tValidation Loss: 2.957034\n",
      "Validation loss decreased (3.06219 --> 2.95703).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.537044 \tValidation Loss: 2.878872\n",
      "Validation loss decreased (2.95703 --> 2.87887).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.333245 \tValidation Loss: 2.824317\n",
      "Validation loss decreased (2.87887 --> 2.82432).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.167971 \tValidation Loss: 2.786969\n",
      "Validation loss decreased (2.82432 --> 2.78697).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.034074 \tValidation Loss: 2.761938\n",
      "Validation loss decreased (2.78697 --> 2.76194).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.921430 \tValidation Loss: 2.749607\n",
      "Validation loss decreased (2.76194 --> 2.74961).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.829585 \tValidation Loss: 2.747418\n",
      "Validation loss decreased (2.74961 --> 2.74742).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.754430 \tValidation Loss: 2.754159\n",
      "Epoch: 17 \tTraining Loss: 0.689363 \tValidation Loss: 2.764217\n",
      "Epoch: 18 \tTraining Loss: 0.635916 \tValidation Loss: 2.780758\n",
      "Epoch: 19 \tTraining Loss: 0.592512 \tValidation Loss: 2.799309\n",
      "Epoch: 20 \tTraining Loss: 0.547099 \tValidation Loss: 2.822474\n",
      "Epoch: 1 \tTraining Loss: 6.023022 \tValidation Loss: 4.859276\n",
      "Validation loss decreased (inf --> 4.85928).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.360335 \tValidation Loss: 4.614239\n",
      "Validation loss decreased (4.85928 --> 4.61424).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \tTraining Loss: 4.870169 \tValidation Loss: 4.278560\n",
      "Validation loss decreased (4.61424 --> 4.27856).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.246864 \tValidation Loss: 3.944060\n",
      "Validation loss decreased (4.27856 --> 3.94406).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.599515 \tValidation Loss: 3.654764\n",
      "Validation loss decreased (3.94406 --> 3.65476).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.009467 \tValidation Loss: 3.423724\n",
      "Validation loss decreased (3.65476 --> 3.42372).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.511801 \tValidation Loss: 3.248092\n",
      "Validation loss decreased (3.42372 --> 3.24809).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.106558 \tValidation Loss: 3.117896\n",
      "Validation loss decreased (3.24809 --> 3.11790).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.790198 \tValidation Loss: 3.023763\n",
      "Validation loss decreased (3.11790 --> 3.02376).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.534398 \tValidation Loss: 2.956215\n",
      "Validation loss decreased (3.02376 --> 2.95622).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.332328 \tValidation Loss: 2.908409\n",
      "Validation loss decreased (2.95622 --> 2.90841).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.165014 \tValidation Loss: 2.879103\n",
      "Validation loss decreased (2.90841 --> 2.87910).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.029336 \tValidation Loss: 2.859501\n",
      "Validation loss decreased (2.87910 --> 2.85950).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.920637 \tValidation Loss: 2.852303\n",
      "Validation loss decreased (2.85950 --> 2.85230).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.833081 \tValidation Loss: 2.855124\n",
      "Epoch: 16 \tTraining Loss: 0.750074 \tValidation Loss: 2.867011\n",
      "Epoch: 17 \tTraining Loss: 0.687585 \tValidation Loss: 2.881291\n",
      "Epoch: 18 \tTraining Loss: 0.635804 \tValidation Loss: 2.902738\n",
      "Epoch: 19 \tTraining Loss: 0.589608 \tValidation Loss: 2.924768\n",
      "Epoch: 20 \tTraining Loss: 0.548514 \tValidation Loss: 2.952368\n",
      "bbc/sport\\199.txt  had a problem\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 7 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.042611 \tValidation Loss: 4.740775\n",
      "Validation loss decreased (inf --> 4.74077).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.347977 \tValidation Loss: 4.484875\n",
      "Validation loss decreased (4.74077 --> 4.48487).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.862924 \tValidation Loss: 4.151632\n",
      "Validation loss decreased (4.48487 --> 4.15163).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.231042 \tValidation Loss: 3.814858\n",
      "Validation loss decreased (4.15163 --> 3.81486).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.568768 \tValidation Loss: 3.513721\n",
      "Validation loss decreased (3.81486 --> 3.51372).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.956555 \tValidation Loss: 3.264541\n",
      "Validation loss decreased (3.51372 --> 3.26454).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.441143 \tValidation Loss: 3.067232\n",
      "Validation loss decreased (3.26454 --> 3.06723).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.026651 \tValidation Loss: 2.914947\n",
      "Validation loss decreased (3.06723 --> 2.91495).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.690899 \tValidation Loss: 2.796904\n",
      "Validation loss decreased (2.91495 --> 2.79690).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.421752 \tValidation Loss: 2.708177\n",
      "Validation loss decreased (2.79690 --> 2.70818).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.208519 \tValidation Loss: 2.642491\n",
      "Validation loss decreased (2.70818 --> 2.64249).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.038878 \tValidation Loss: 2.599254\n",
      "Validation loss decreased (2.64249 --> 2.59925).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.890969 \tValidation Loss: 2.569700\n",
      "Validation loss decreased (2.59925 --> 2.56970).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.778451 \tValidation Loss: 2.552390\n",
      "Validation loss decreased (2.56970 --> 2.55239).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.683897 \tValidation Loss: 2.545344\n",
      "Validation loss decreased (2.55239 --> 2.54534).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.607151 \tValidation Loss: 2.546513\n",
      "Epoch: 17 \tTraining Loss: 0.543649 \tValidation Loss: 2.554045\n",
      "Epoch: 18 \tTraining Loss: 0.486963 \tValidation Loss: 2.568203\n",
      "Epoch: 19 \tTraining Loss: 0.445615 \tValidation Loss: 2.585258\n",
      "Epoch: 20 \tTraining Loss: 0.405369 \tValidation Loss: 2.605541\n",
      "Epoch: 1 \tTraining Loss: 6.044749 \tValidation Loss: 4.702597\n",
      "Validation loss decreased (inf --> 4.70260).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.354541 \tValidation Loss: 4.455446\n",
      "Validation loss decreased (4.70260 --> 4.45545).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.868623 \tValidation Loss: 4.119726\n",
      "Validation loss decreased (4.45545 --> 4.11973).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.234063 \tValidation Loss: 3.772948\n",
      "Validation loss decreased (4.11973 --> 3.77295).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.565056 \tValidation Loss: 3.465958\n",
      "Validation loss decreased (3.77295 --> 3.46596).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.952902 \tValidation Loss: 3.213272\n",
      "Validation loss decreased (3.46596 --> 3.21327).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.434758 \tValidation Loss: 3.015576\n",
      "Validation loss decreased (3.21327 --> 3.01558).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.015535 \tValidation Loss: 2.865399\n",
      "Validation loss decreased (3.01558 --> 2.86540).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.677187 \tValidation Loss: 2.754572\n",
      "Validation loss decreased (2.86540 --> 2.75457).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.406777 \tValidation Loss: 2.674521\n",
      "Validation loss decreased (2.75457 --> 2.67452).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.193272 \tValidation Loss: 2.615193\n",
      "Validation loss decreased (2.67452 --> 2.61519).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.019856 \tValidation Loss: 2.574026\n",
      "Validation loss decreased (2.61519 --> 2.57403).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.883607 \tValidation Loss: 2.547299\n",
      "Validation loss decreased (2.57403 --> 2.54730).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.768108 \tValidation Loss: 2.532653\n",
      "Validation loss decreased (2.54730 --> 2.53265).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.674468 \tValidation Loss: 2.524361\n",
      "Validation loss decreased (2.53265 --> 2.52436).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.596804 \tValidation Loss: 2.525123\n",
      "Epoch: 17 \tTraining Loss: 0.534159 \tValidation Loss: 2.532741\n",
      "Epoch: 18 \tTraining Loss: 0.480198 \tValidation Loss: 2.544412\n",
      "Epoch: 19 \tTraining Loss: 0.437441 \tValidation Loss: 2.561273\n",
      "Epoch: 20 \tTraining Loss: 0.399322 \tValidation Loss: 2.578482\n",
      "Epoch: 1 \tTraining Loss: 6.056324 \tValidation Loss: 4.739719\n",
      "Validation loss decreased (inf --> 4.73972).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.348279 \tValidation Loss: 4.503687\n",
      "Validation loss decreased (4.73972 --> 4.50369).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.863957 \tValidation Loss: 4.185386\n",
      "Validation loss decreased (4.50369 --> 4.18539).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.238101 \tValidation Loss: 3.848851\n",
      "Validation loss decreased (4.18539 --> 3.84885).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.573160 \tValidation Loss: 3.547893\n",
      "Validation loss decreased (3.84885 --> 3.54789).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.958196 \tValidation Loss: 3.303603\n",
      "Validation loss decreased (3.54789 --> 3.30360).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.435114 \tValidation Loss: 3.114211\n",
      "Validation loss decreased (3.30360 --> 3.11421).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.015312 \tValidation Loss: 2.971360\n",
      "Validation loss decreased (3.11421 --> 2.97136).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.678006 \tValidation Loss: 2.867542\n",
      "Validation loss decreased (2.97136 --> 2.86754).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.411404 \tValidation Loss: 2.791751\n",
      "Validation loss decreased (2.86754 --> 2.79175).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.195974 \tValidation Loss: 2.739562\n",
      "Validation loss decreased (2.79175 --> 2.73956).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.022142 \tValidation Loss: 2.704396\n",
      "Validation loss decreased (2.73956 --> 2.70440).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.882145 \tValidation Loss: 2.682721\n",
      "Validation loss decreased (2.70440 --> 2.68272).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.769383 \tValidation Loss: 2.672072\n",
      "Validation loss decreased (2.68272 --> 2.67207).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 \tTraining Loss: 0.673508 \tValidation Loss: 2.670257\n",
      "Validation loss decreased (2.67207 --> 2.67026).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.597573 \tValidation Loss: 2.674218\n",
      "Epoch: 17 \tTraining Loss: 0.532916 \tValidation Loss: 2.684753\n",
      "Epoch: 18 \tTraining Loss: 0.479779 \tValidation Loss: 2.701281\n",
      "Epoch: 19 \tTraining Loss: 0.437141 \tValidation Loss: 2.720815\n",
      "Epoch: 20 \tTraining Loss: 0.400543 \tValidation Loss: 2.747072\n",
      "Epoch: 1 \tTraining Loss: 6.045451 \tValidation Loss: 4.736615\n",
      "Validation loss decreased (inf --> 4.73662).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.346203 \tValidation Loss: 4.486630\n",
      "Validation loss decreased (4.73662 --> 4.48663).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.863417 \tValidation Loss: 4.152717\n",
      "Validation loss decreased (4.48663 --> 4.15272).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.237607 \tValidation Loss: 3.809256\n",
      "Validation loss decreased (4.15272 --> 3.80926).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.574979 \tValidation Loss: 3.506517\n",
      "Validation loss decreased (3.80926 --> 3.50652).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.960647 \tValidation Loss: 3.258358\n",
      "Validation loss decreased (3.50652 --> 3.25836).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.443887 \tValidation Loss: 3.062621\n",
      "Validation loss decreased (3.25836 --> 3.06262).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.020625 \tValidation Loss: 2.908809\n",
      "Validation loss decreased (3.06262 --> 2.90881).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.684732 \tValidation Loss: 2.790586\n",
      "Validation loss decreased (2.90881 --> 2.79059).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.414860 \tValidation Loss: 2.699904\n",
      "Validation loss decreased (2.79059 --> 2.69990).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.198867 \tValidation Loss: 2.633214\n",
      "Validation loss decreased (2.69990 --> 2.63321).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.023896 \tValidation Loss: 2.588631\n",
      "Validation loss decreased (2.63321 --> 2.58863).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.878116 \tValidation Loss: 2.557332\n",
      "Validation loss decreased (2.58863 --> 2.55733).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.765178 \tValidation Loss: 2.539679\n",
      "Validation loss decreased (2.55733 --> 2.53968).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.672825 \tValidation Loss: 2.532603\n",
      "Validation loss decreased (2.53968 --> 2.53260).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.594851 \tValidation Loss: 2.531894\n",
      "Validation loss decreased (2.53260 --> 2.53189).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.530602 \tValidation Loss: 2.539097\n",
      "Epoch: 18 \tTraining Loss: 0.481617 \tValidation Loss: 2.550300\n",
      "Epoch: 19 \tTraining Loss: 0.435116 \tValidation Loss: 2.568971\n",
      "Epoch: 20 \tTraining Loss: 0.395210 \tValidation Loss: 2.587118\n",
      "Epoch: 1 \tTraining Loss: 6.036036 \tValidation Loss: 4.763925\n",
      "Validation loss decreased (inf --> 4.76392).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.344611 \tValidation Loss: 4.522459\n",
      "Validation loss decreased (4.76392 --> 4.52246).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.860311 \tValidation Loss: 4.199552\n",
      "Validation loss decreased (4.52246 --> 4.19955).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.228474 \tValidation Loss: 3.865183\n",
      "Validation loss decreased (4.19955 --> 3.86518).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.565948 \tValidation Loss: 3.565681\n",
      "Validation loss decreased (3.86518 --> 3.56568).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.956924 \tValidation Loss: 3.319650\n",
      "Validation loss decreased (3.56568 --> 3.31965).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.439953 \tValidation Loss: 3.127511\n",
      "Validation loss decreased (3.31965 --> 3.12751).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.017643 \tValidation Loss: 2.980763\n",
      "Validation loss decreased (3.12751 --> 2.98076).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.681819 \tValidation Loss: 2.873307\n",
      "Validation loss decreased (2.98076 --> 2.87331).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.413820 \tValidation Loss: 2.791849\n",
      "Validation loss decreased (2.87331 --> 2.79185).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.199329 \tValidation Loss: 2.730693\n",
      "Validation loss decreased (2.79185 --> 2.73069).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.025951 \tValidation Loss: 2.688152\n",
      "Validation loss decreased (2.73069 --> 2.68815).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.883452 \tValidation Loss: 2.661784\n",
      "Validation loss decreased (2.68815 --> 2.66178).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.770898 \tValidation Loss: 2.648288\n",
      "Validation loss decreased (2.66178 --> 2.64829).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.673265 \tValidation Loss: 2.641035\n",
      "Validation loss decreased (2.64829 --> 2.64104).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.595471 \tValidation Loss: 2.643112\n",
      "Epoch: 17 \tTraining Loss: 0.534548 \tValidation Loss: 2.650349\n",
      "Epoch: 18 \tTraining Loss: 0.481241 \tValidation Loss: 2.665489\n",
      "Epoch: 19 \tTraining Loss: 0.436717 \tValidation Loss: 2.682275\n",
      "Epoch: 20 \tTraining Loss: 0.399803 \tValidation Loss: 2.707013\n",
      "Epoch: 1 \tTraining Loss: 6.039168 \tValidation Loss: 4.728913\n",
      "Validation loss decreased (inf --> 4.72891).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.349110 \tValidation Loss: 4.492943\n",
      "Validation loss decreased (4.72891 --> 4.49294).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.866081 \tValidation Loss: 4.171653\n",
      "Validation loss decreased (4.49294 --> 4.17165).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.237954 \tValidation Loss: 3.836329\n",
      "Validation loss decreased (4.17165 --> 3.83633).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.573883 \tValidation Loss: 3.536951\n",
      "Validation loss decreased (3.83633 --> 3.53695).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.958909 \tValidation Loss: 3.293965\n",
      "Validation loss decreased (3.53695 --> 3.29397).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.441023 \tValidation Loss: 3.108258\n",
      "Validation loss decreased (3.29397 --> 3.10826).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.021178 \tValidation Loss: 2.966180\n",
      "Validation loss decreased (3.10826 --> 2.96618).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.683631 \tValidation Loss: 2.858772\n",
      "Validation loss decreased (2.96618 --> 2.85877).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.413378 \tValidation Loss: 2.779378\n",
      "Validation loss decreased (2.85877 --> 2.77938).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.200772 \tValidation Loss: 2.720341\n",
      "Validation loss decreased (2.77938 --> 2.72034).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.027221 \tValidation Loss: 2.677000\n",
      "Validation loss decreased (2.72034 --> 2.67700).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.887980 \tValidation Loss: 2.648145\n",
      "Validation loss decreased (2.67700 --> 2.64815).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.770549 \tValidation Loss: 2.633020\n",
      "Validation loss decreased (2.64815 --> 2.63302).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.677159 \tValidation Loss: 2.626923\n",
      "Validation loss decreased (2.63302 --> 2.62692).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.599520 \tValidation Loss: 2.631023\n",
      "Epoch: 17 \tTraining Loss: 0.534592 \tValidation Loss: 2.636846\n",
      "Epoch: 18 \tTraining Loss: 0.483371 \tValidation Loss: 2.649838\n",
      "Epoch: 19 \tTraining Loss: 0.439116 \tValidation Loss: 2.665922\n",
      "Epoch: 20 \tTraining Loss: 0.397401 \tValidation Loss: 2.685163\n",
      "Epoch: 1 \tTraining Loss: 6.040360 \tValidation Loss: 4.748189\n",
      "Validation loss decreased (inf --> 4.74819).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.339393 \tValidation Loss: 4.484192\n",
      "Validation loss decreased (4.74819 --> 4.48419).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.849947 \tValidation Loss: 4.138524\n",
      "Validation loss decreased (4.48419 --> 4.13852).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.221973 \tValidation Loss: 3.779141\n",
      "Validation loss decreased (4.13852 --> 3.77914).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.558274 \tValidation Loss: 3.465114\n",
      "Validation loss decreased (3.77914 --> 3.46511).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.948079 \tValidation Loss: 3.210361\n",
      "Validation loss decreased (3.46511 --> 3.21036).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.433133 \tValidation Loss: 3.010485\n",
      "Validation loss decreased (3.21036 --> 3.01049).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.019736 \tValidation Loss: 2.857144\n",
      "Validation loss decreased (3.01049 --> 2.85714).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 \tTraining Loss: 1.679640 \tValidation Loss: 2.744631\n",
      "Validation loss decreased (2.85714 --> 2.74463).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.416429 \tValidation Loss: 2.660397\n",
      "Validation loss decreased (2.74463 --> 2.66040).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.202289 \tValidation Loss: 2.600037\n",
      "Validation loss decreased (2.66040 --> 2.60004).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.026403 \tValidation Loss: 2.558103\n",
      "Validation loss decreased (2.60004 --> 2.55810).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.888475 \tValidation Loss: 2.528913\n",
      "Validation loss decreased (2.55810 --> 2.52891).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.779192 \tValidation Loss: 2.510447\n",
      "Validation loss decreased (2.52891 --> 2.51045).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.683227 \tValidation Loss: 2.502495\n",
      "Validation loss decreased (2.51045 --> 2.50249).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.606907 \tValidation Loss: 2.499334\n",
      "Validation loss decreased (2.50249 --> 2.49933).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.540561 \tValidation Loss: 2.503753\n",
      "Epoch: 18 \tTraining Loss: 0.488045 \tValidation Loss: 2.517844\n",
      "Epoch: 19 \tTraining Loss: 0.443039 \tValidation Loss: 2.531172\n",
      "Epoch: 20 \tTraining Loss: 0.406255 \tValidation Loss: 2.548034\n",
      "Epoch: 1 \tTraining Loss: 6.043019 \tValidation Loss: 4.740119\n",
      "Validation loss decreased (inf --> 4.74012).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.342564 \tValidation Loss: 4.489356\n",
      "Validation loss decreased (4.74012 --> 4.48936).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.855252 \tValidation Loss: 4.152505\n",
      "Validation loss decreased (4.48936 --> 4.15250).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.223313 \tValidation Loss: 3.808459\n",
      "Validation loss decreased (4.15250 --> 3.80846).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.562949 \tValidation Loss: 3.511912\n",
      "Validation loss decreased (3.80846 --> 3.51191).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.957402 \tValidation Loss: 3.271535\n",
      "Validation loss decreased (3.51191 --> 3.27154).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.446935 \tValidation Loss: 3.084622\n",
      "Validation loss decreased (3.27154 --> 3.08462).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.029921 \tValidation Loss: 2.943533\n",
      "Validation loss decreased (3.08462 --> 2.94353).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.693655 \tValidation Loss: 2.837108\n",
      "Validation loss decreased (2.94353 --> 2.83711).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.427911 \tValidation Loss: 2.759262\n",
      "Validation loss decreased (2.83711 --> 2.75926).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.211539 \tValidation Loss: 2.705867\n",
      "Validation loss decreased (2.75926 --> 2.70587).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.035565 \tValidation Loss: 2.670400\n",
      "Validation loss decreased (2.70587 --> 2.67040).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.897871 \tValidation Loss: 2.650183\n",
      "Validation loss decreased (2.67040 --> 2.65018).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.778986 \tValidation Loss: 2.639019\n",
      "Validation loss decreased (2.65018 --> 2.63902).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.682847 \tValidation Loss: 2.641657\n",
      "Epoch: 16 \tTraining Loss: 0.606381 \tValidation Loss: 2.647386\n",
      "Epoch: 17 \tTraining Loss: 0.541213 \tValidation Loss: 2.660538\n",
      "Epoch: 18 \tTraining Loss: 0.488205 \tValidation Loss: 2.681553\n",
      "Epoch: 19 \tTraining Loss: 0.444293 \tValidation Loss: 2.701780\n",
      "Epoch: 20 \tTraining Loss: 0.404752 \tValidation Loss: 2.724073\n",
      "Epoch: 1 \tTraining Loss: 6.047270 \tValidation Loss: 4.730241\n",
      "Validation loss decreased (inf --> 4.73024).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.350015 \tValidation Loss: 4.477753\n",
      "Validation loss decreased (4.73024 --> 4.47775).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.862175 \tValidation Loss: 4.140763\n",
      "Validation loss decreased (4.47775 --> 4.14076).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.234343 \tValidation Loss: 3.793907\n",
      "Validation loss decreased (4.14076 --> 3.79391).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.571467 \tValidation Loss: 3.489262\n",
      "Validation loss decreased (3.79391 --> 3.48926).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.961322 \tValidation Loss: 3.238562\n",
      "Validation loss decreased (3.48926 --> 3.23856).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.444342 \tValidation Loss: 3.040487\n",
      "Validation loss decreased (3.23856 --> 3.04049).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.026392 \tValidation Loss: 2.887320\n",
      "Validation loss decreased (3.04049 --> 2.88732).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.690172 \tValidation Loss: 2.767946\n",
      "Validation loss decreased (2.88732 --> 2.76795).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.422951 \tValidation Loss: 2.678703\n",
      "Validation loss decreased (2.76795 --> 2.67870).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.210489 \tValidation Loss: 2.613524\n",
      "Validation loss decreased (2.67870 --> 2.61352).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.037711 \tValidation Loss: 2.566716\n",
      "Validation loss decreased (2.61352 --> 2.56672).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.894630 \tValidation Loss: 2.536218\n",
      "Validation loss decreased (2.56672 --> 2.53622).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.783675 \tValidation Loss: 2.516533\n",
      "Validation loss decreased (2.53622 --> 2.51653).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.684712 \tValidation Loss: 2.508455\n",
      "Validation loss decreased (2.51653 --> 2.50846).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.603815 \tValidation Loss: 2.507645\n",
      "Validation loss decreased (2.50846 --> 2.50764).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.541193 \tValidation Loss: 2.513638\n",
      "Epoch: 18 \tTraining Loss: 0.486783 \tValidation Loss: 2.523249\n",
      "Epoch: 19 \tTraining Loss: 0.441006 \tValidation Loss: 2.537472\n",
      "Epoch: 20 \tTraining Loss: 0.407536 \tValidation Loss: 2.553815\n",
      "Epoch: 1 \tTraining Loss: 6.044000 \tValidation Loss: 4.727570\n",
      "Validation loss decreased (inf --> 4.72757).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.345803 \tValidation Loss: 4.471356\n",
      "Validation loss decreased (4.72757 --> 4.47136).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.849365 \tValidation Loss: 4.130683\n",
      "Validation loss decreased (4.47136 --> 4.13068).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.210000 \tValidation Loss: 3.781130\n",
      "Validation loss decreased (4.13068 --> 3.78113).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.545002 \tValidation Loss: 3.478321\n",
      "Validation loss decreased (3.78113 --> 3.47832).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.933775 \tValidation Loss: 3.233921\n",
      "Validation loss decreased (3.47832 --> 3.23392).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.420030 \tValidation Loss: 3.045233\n",
      "Validation loss decreased (3.23392 --> 3.04523).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.001793 \tValidation Loss: 2.898949\n",
      "Validation loss decreased (3.04523 --> 2.89895).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.666982 \tValidation Loss: 2.787682\n",
      "Validation loss decreased (2.89895 --> 2.78768).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.402685 \tValidation Loss: 2.701802\n",
      "Validation loss decreased (2.78768 --> 2.70180).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.190972 \tValidation Loss: 2.642280\n",
      "Validation loss decreased (2.70180 --> 2.64228).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.015345 \tValidation Loss: 2.600091\n",
      "Validation loss decreased (2.64228 --> 2.60009).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.879160 \tValidation Loss: 2.574515\n",
      "Validation loss decreased (2.60009 --> 2.57451).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.761783 \tValidation Loss: 2.559302\n",
      "Validation loss decreased (2.57451 --> 2.55930).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.670502 \tValidation Loss: 2.553480\n",
      "Validation loss decreased (2.55930 --> 2.55348).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.592998 \tValidation Loss: 2.556262\n",
      "Epoch: 17 \tTraining Loss: 0.529561 \tValidation Loss: 2.564830\n",
      "Epoch: 18 \tTraining Loss: 0.477054 \tValidation Loss: 2.579238\n",
      "Epoch: 19 \tTraining Loss: 0.432485 \tValidation Loss: 2.598816\n",
      "Epoch: 20 \tTraining Loss: 0.398057 \tValidation Loss: 2.616893\n",
      "bbc/sport\\199.txt  had a problem\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 8 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.064258 \tValidation Loss: 4.537757\n",
      "Validation loss decreased (inf --> 4.53776).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.328247 \tValidation Loss: 4.316116\n",
      "Validation loss decreased (4.53776 --> 4.31612).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \tTraining Loss: 4.874517 \tValidation Loss: 4.010052\n",
      "Validation loss decreased (4.31612 --> 4.01005).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.268906 \tValidation Loss: 3.681772\n",
      "Validation loss decreased (4.01005 --> 3.68177).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.611373 \tValidation Loss: 3.392557\n",
      "Validation loss decreased (3.68177 --> 3.39256).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.994625 \tValidation Loss: 3.152022\n",
      "Validation loss decreased (3.39256 --> 3.15202).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.463176 \tValidation Loss: 2.961836\n",
      "Validation loss decreased (3.15202 --> 2.96184).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.026650 \tValidation Loss: 2.816846\n",
      "Validation loss decreased (2.96184 --> 2.81685).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.673442 \tValidation Loss: 2.705786\n",
      "Validation loss decreased (2.81685 --> 2.70579).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.387917 \tValidation Loss: 2.620613\n",
      "Validation loss decreased (2.70579 --> 2.62061).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.159101 \tValidation Loss: 2.554656\n",
      "Validation loss decreased (2.62061 --> 2.55466).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.971931 \tValidation Loss: 2.509888\n",
      "Validation loss decreased (2.55466 --> 2.50989).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.820425 \tValidation Loss: 2.478723\n",
      "Validation loss decreased (2.50989 --> 2.47872).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.698778 \tValidation Loss: 2.460293\n",
      "Validation loss decreased (2.47872 --> 2.46029).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.596511 \tValidation Loss: 2.453359\n",
      "Validation loss decreased (2.46029 --> 2.45336).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.514302 \tValidation Loss: 2.449002\n",
      "Validation loss decreased (2.45336 --> 2.44900).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.448139 \tValidation Loss: 2.455556\n",
      "Epoch: 18 \tTraining Loss: 0.392739 \tValidation Loss: 2.466510\n",
      "Epoch: 19 \tTraining Loss: 0.350939 \tValidation Loss: 2.477827\n",
      "Epoch: 20 \tTraining Loss: 0.313474 \tValidation Loss: 2.496661\n",
      "Epoch: 1 \tTraining Loss: 6.067416 \tValidation Loss: 4.560887\n",
      "Validation loss decreased (inf --> 4.56089).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.321795 \tValidation Loss: 4.341992\n",
      "Validation loss decreased (4.56089 --> 4.34199).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.862583 \tValidation Loss: 4.058629\n",
      "Validation loss decreased (4.34199 --> 4.05863).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.259354 \tValidation Loss: 3.747667\n",
      "Validation loss decreased (4.05863 --> 3.74767).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.608465 \tValidation Loss: 3.464437\n",
      "Validation loss decreased (3.74767 --> 3.46444).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.997475 \tValidation Loss: 3.224546\n",
      "Validation loss decreased (3.46444 --> 3.22455).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.467232 \tValidation Loss: 3.031955\n",
      "Validation loss decreased (3.22455 --> 3.03196).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.028041 \tValidation Loss: 2.880472\n",
      "Validation loss decreased (3.03196 --> 2.88047).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.678012 \tValidation Loss: 2.761825\n",
      "Validation loss decreased (2.88047 --> 2.76183).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.393741 \tValidation Loss: 2.669363\n",
      "Validation loss decreased (2.76183 --> 2.66936).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.163732 \tValidation Loss: 2.598235\n",
      "Validation loss decreased (2.66936 --> 2.59824).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.978213 \tValidation Loss: 2.545284\n",
      "Validation loss decreased (2.59824 --> 2.54528).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.825089 \tValidation Loss: 2.510475\n",
      "Validation loss decreased (2.54528 --> 2.51048).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.702176 \tValidation Loss: 2.487877\n",
      "Validation loss decreased (2.51048 --> 2.48788).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.600785 \tValidation Loss: 2.473819\n",
      "Validation loss decreased (2.48788 --> 2.47382).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.517840 \tValidation Loss: 2.470158\n",
      "Validation loss decreased (2.47382 --> 2.47016).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.452307 \tValidation Loss: 2.473064\n",
      "Epoch: 18 \tTraining Loss: 0.398155 \tValidation Loss: 2.479130\n",
      "Epoch: 19 \tTraining Loss: 0.352231 \tValidation Loss: 2.488606\n",
      "Epoch: 20 \tTraining Loss: 0.316089 \tValidation Loss: 2.504015\n",
      "Epoch: 1 \tTraining Loss: 6.068779 \tValidation Loss: 4.539757\n",
      "Validation loss decreased (inf --> 4.53976).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.318027 \tValidation Loss: 4.323932\n",
      "Validation loss decreased (4.53976 --> 4.32393).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.862122 \tValidation Loss: 4.034484\n",
      "Validation loss decreased (4.32393 --> 4.03448).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.259248 \tValidation Loss: 3.722066\n",
      "Validation loss decreased (4.03448 --> 3.72207).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.605600 \tValidation Loss: 3.436573\n",
      "Validation loss decreased (3.72207 --> 3.43657).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.992566 \tValidation Loss: 3.198218\n",
      "Validation loss decreased (3.43657 --> 3.19822).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.466357 \tValidation Loss: 3.005554\n",
      "Validation loss decreased (3.19822 --> 3.00555).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.029847 \tValidation Loss: 2.856538\n",
      "Validation loss decreased (3.00555 --> 2.85654).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.678234 \tValidation Loss: 2.742132\n",
      "Validation loss decreased (2.85654 --> 2.74213).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.392581 \tValidation Loss: 2.654971\n",
      "Validation loss decreased (2.74213 --> 2.65497).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.162098 \tValidation Loss: 2.589159\n",
      "Validation loss decreased (2.65497 --> 2.58916).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.977699 \tValidation Loss: 2.541999\n",
      "Validation loss decreased (2.58916 --> 2.54200).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.827242 \tValidation Loss: 2.509119\n",
      "Validation loss decreased (2.54200 --> 2.50912).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.703584 \tValidation Loss: 2.488751\n",
      "Validation loss decreased (2.50912 --> 2.48875).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.601112 \tValidation Loss: 2.481099\n",
      "Validation loss decreased (2.48875 --> 2.48110).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.520792 \tValidation Loss: 2.479643\n",
      "Validation loss decreased (2.48110 --> 2.47964).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.452907 \tValidation Loss: 2.482201\n",
      "Epoch: 18 \tTraining Loss: 0.401014 \tValidation Loss: 2.489921\n",
      "Epoch: 19 \tTraining Loss: 0.353269 \tValidation Loss: 2.504976\n",
      "Epoch: 20 \tTraining Loss: 0.318072 \tValidation Loss: 2.522488\n",
      "Epoch: 1 \tTraining Loss: 6.064120 \tValidation Loss: 4.541655\n",
      "Validation loss decreased (inf --> 4.54165).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.323312 \tValidation Loss: 4.311641\n",
      "Validation loss decreased (4.54165 --> 4.31164).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.868223 \tValidation Loss: 4.013174\n",
      "Validation loss decreased (4.31164 --> 4.01317).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.269194 \tValidation Loss: 3.694450\n",
      "Validation loss decreased (4.01317 --> 3.69445).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.622335 \tValidation Loss: 3.409901\n",
      "Validation loss decreased (3.69445 --> 3.40990).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.011188 \tValidation Loss: 3.168943\n",
      "Validation loss decreased (3.40990 --> 3.16894).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.479940 \tValidation Loss: 2.974718\n",
      "Validation loss decreased (3.16894 --> 2.97472).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.043031 \tValidation Loss: 2.822773\n",
      "Validation loss decreased (2.97472 --> 2.82277).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.687723 \tValidation Loss: 2.705991\n",
      "Validation loss decreased (2.82277 --> 2.70599).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.401858 \tValidation Loss: 2.618720\n",
      "Validation loss decreased (2.70599 --> 2.61872).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.170802 \tValidation Loss: 2.554313\n",
      "Validation loss decreased (2.61872 --> 2.55431).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.982618 \tValidation Loss: 2.508524\n",
      "Validation loss decreased (2.55431 --> 2.50852).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.827116 \tValidation Loss: 2.478607\n",
      "Validation loss decreased (2.50852 --> 2.47861).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 \tTraining Loss: 0.700899 \tValidation Loss: 2.460691\n",
      "Validation loss decreased (2.47861 --> 2.46069).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.600464 \tValidation Loss: 2.451608\n",
      "Validation loss decreased (2.46069 --> 2.45161).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.520428 \tValidation Loss: 2.449141\n",
      "Validation loss decreased (2.45161 --> 2.44914).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.449625 \tValidation Loss: 2.455558\n",
      "Epoch: 18 \tTraining Loss: 0.397344 \tValidation Loss: 2.468873\n",
      "Epoch: 19 \tTraining Loss: 0.350396 \tValidation Loss: 2.482347\n",
      "Epoch: 20 \tTraining Loss: 0.314092 \tValidation Loss: 2.497388\n",
      "Epoch: 1 \tTraining Loss: 6.070656 \tValidation Loss: 4.555329\n",
      "Validation loss decreased (inf --> 4.55533).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.320828 \tValidation Loss: 4.327368\n",
      "Validation loss decreased (4.55533 --> 4.32737).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.863227 \tValidation Loss: 4.041484\n",
      "Validation loss decreased (4.32737 --> 4.04148).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.260922 \tValidation Loss: 3.735011\n",
      "Validation loss decreased (4.04148 --> 3.73501).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.612123 \tValidation Loss: 3.460417\n",
      "Validation loss decreased (3.73501 --> 3.46042).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.999359 \tValidation Loss: 3.232503\n",
      "Validation loss decreased (3.46042 --> 3.23250).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.469379 \tValidation Loss: 3.050598\n",
      "Validation loss decreased (3.23250 --> 3.05060).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.034588 \tValidation Loss: 2.909532\n",
      "Validation loss decreased (3.05060 --> 2.90953).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.678622 \tValidation Loss: 2.803315\n",
      "Validation loss decreased (2.90953 --> 2.80332).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.395386 \tValidation Loss: 2.726142\n",
      "Validation loss decreased (2.80332 --> 2.72614).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.167454 \tValidation Loss: 2.669403\n",
      "Validation loss decreased (2.72614 --> 2.66940).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.980451 \tValidation Loss: 2.629363\n",
      "Validation loss decreased (2.66940 --> 2.62936).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.827770 \tValidation Loss: 2.604346\n",
      "Validation loss decreased (2.62936 --> 2.60435).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.705315 \tValidation Loss: 2.588371\n",
      "Validation loss decreased (2.60435 --> 2.58837).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.600875 \tValidation Loss: 2.584695\n",
      "Validation loss decreased (2.58837 --> 2.58469).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.521793 \tValidation Loss: 2.586742\n",
      "Epoch: 17 \tTraining Loss: 0.455466 \tValidation Loss: 2.595615\n",
      "Epoch: 18 \tTraining Loss: 0.397800 \tValidation Loss: 2.608538\n",
      "Epoch: 19 \tTraining Loss: 0.351224 \tValidation Loss: 2.623066\n",
      "Epoch: 20 \tTraining Loss: 0.313190 \tValidation Loss: 2.640209\n",
      "Epoch: 1 \tTraining Loss: 6.065717 \tValidation Loss: 4.558742\n",
      "Validation loss decreased (inf --> 4.55874).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.331236 \tValidation Loss: 4.331814\n",
      "Validation loss decreased (4.55874 --> 4.33181).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.872777 \tValidation Loss: 4.042051\n",
      "Validation loss decreased (4.33181 --> 4.04205).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.268147 \tValidation Loss: 3.724249\n",
      "Validation loss decreased (4.04205 --> 3.72425).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.614098 \tValidation Loss: 3.432184\n",
      "Validation loss decreased (3.72425 --> 3.43218).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.003070 \tValidation Loss: 3.185404\n",
      "Validation loss decreased (3.43218 --> 3.18540).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.472820 \tValidation Loss: 2.986568\n",
      "Validation loss decreased (3.18540 --> 2.98657).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.033737 \tValidation Loss: 2.832553\n",
      "Validation loss decreased (2.98657 --> 2.83255).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.680045 \tValidation Loss: 2.714940\n",
      "Validation loss decreased (2.83255 --> 2.71494).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.394268 \tValidation Loss: 2.628325\n",
      "Validation loss decreased (2.71494 --> 2.62833).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.164056 \tValidation Loss: 2.564176\n",
      "Validation loss decreased (2.62833 --> 2.56418).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.975608 \tValidation Loss: 2.515511\n",
      "Validation loss decreased (2.56418 --> 2.51551).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.824656 \tValidation Loss: 2.483503\n",
      "Validation loss decreased (2.51551 --> 2.48350).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.701804 \tValidation Loss: 2.463038\n",
      "Validation loss decreased (2.48350 --> 2.46304).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.602502 \tValidation Loss: 2.451936\n",
      "Validation loss decreased (2.46304 --> 2.45194).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.519174 \tValidation Loss: 2.449386\n",
      "Validation loss decreased (2.45194 --> 2.44939).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.448198 \tValidation Loss: 2.454251\n",
      "Epoch: 18 \tTraining Loss: 0.397054 \tValidation Loss: 2.461513\n",
      "Epoch: 19 \tTraining Loss: 0.353437 \tValidation Loss: 2.477773\n",
      "Epoch: 20 \tTraining Loss: 0.314559 \tValidation Loss: 2.494453\n",
      "Epoch: 1 \tTraining Loss: 6.068264 \tValidation Loss: 4.568211\n",
      "Validation loss decreased (inf --> 4.56821).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.325378 \tValidation Loss: 4.330695\n",
      "Validation loss decreased (4.56821 --> 4.33070).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.868353 \tValidation Loss: 4.032754\n",
      "Validation loss decreased (4.33070 --> 4.03275).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.263946 \tValidation Loss: 3.709853\n",
      "Validation loss decreased (4.03275 --> 3.70985).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.610896 \tValidation Loss: 3.424447\n",
      "Validation loss decreased (3.70985 --> 3.42445).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.001971 \tValidation Loss: 3.190605\n",
      "Validation loss decreased (3.42445 --> 3.19061).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.474369 \tValidation Loss: 3.004225\n",
      "Validation loss decreased (3.19061 --> 3.00422).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.037916 \tValidation Loss: 2.857804\n",
      "Validation loss decreased (3.00422 --> 2.85780).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.686070 \tValidation Loss: 2.742897\n",
      "Validation loss decreased (2.85780 --> 2.74290).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.397717 \tValidation Loss: 2.654109\n",
      "Validation loss decreased (2.74290 --> 2.65411).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.166702 \tValidation Loss: 2.588790\n",
      "Validation loss decreased (2.65411 --> 2.58879).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.977732 \tValidation Loss: 2.541870\n",
      "Validation loss decreased (2.58879 --> 2.54187).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.827418 \tValidation Loss: 2.511385\n",
      "Validation loss decreased (2.54187 --> 2.51138).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.701359 \tValidation Loss: 2.493279\n",
      "Validation loss decreased (2.51138 --> 2.49328).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.600383 \tValidation Loss: 2.482268\n",
      "Validation loss decreased (2.49328 --> 2.48227).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.517545 \tValidation Loss: 2.483135\n",
      "Epoch: 17 \tTraining Loss: 0.450637 \tValidation Loss: 2.488007\n",
      "Epoch: 18 \tTraining Loss: 0.397011 \tValidation Loss: 2.501484\n",
      "Epoch: 19 \tTraining Loss: 0.351756 \tValidation Loss: 2.513678\n",
      "Epoch: 20 \tTraining Loss: 0.313693 \tValidation Loss: 2.532121\n",
      "Epoch: 1 \tTraining Loss: 6.059504 \tValidation Loss: 4.556472\n",
      "Validation loss decreased (inf --> 4.55647).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.329010 \tValidation Loss: 4.319719\n",
      "Validation loss decreased (4.55647 --> 4.31972).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.869289 \tValidation Loss: 4.029348\n",
      "Validation loss decreased (4.31972 --> 4.02935).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.264915 \tValidation Loss: 3.706884\n",
      "Validation loss decreased (4.02935 --> 3.70688).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.611258 \tValidation Loss: 3.410003\n",
      "Validation loss decreased (3.70688 --> 3.41000).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.993988 \tValidation Loss: 3.166602\n",
      "Validation loss decreased (3.41000 --> 3.16660).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.466296 \tValidation Loss: 2.977561\n",
      "Validation loss decreased (3.16660 --> 2.97756).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 \tTraining Loss: 2.027750 \tValidation Loss: 2.832918\n",
      "Validation loss decreased (2.97756 --> 2.83292).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.674980 \tValidation Loss: 2.721602\n",
      "Validation loss decreased (2.83292 --> 2.72160).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.387511 \tValidation Loss: 2.636933\n",
      "Validation loss decreased (2.72160 --> 2.63693).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.159559 \tValidation Loss: 2.572290\n",
      "Validation loss decreased (2.63693 --> 2.57229).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.971375 \tValidation Loss: 2.525837\n",
      "Validation loss decreased (2.57229 --> 2.52584).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.821154 \tValidation Loss: 2.492163\n",
      "Validation loss decreased (2.52584 --> 2.49216).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.697556 \tValidation Loss: 2.472903\n",
      "Validation loss decreased (2.49216 --> 2.47290).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.597368 \tValidation Loss: 2.464613\n",
      "Validation loss decreased (2.47290 --> 2.46461).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.515520 \tValidation Loss: 2.464897\n",
      "Epoch: 17 \tTraining Loss: 0.450191 \tValidation Loss: 2.471480\n",
      "Epoch: 18 \tTraining Loss: 0.393227 \tValidation Loss: 2.484786\n",
      "Epoch: 19 \tTraining Loss: 0.350712 \tValidation Loss: 2.498732\n",
      "Epoch: 20 \tTraining Loss: 0.312397 \tValidation Loss: 2.516571\n",
      "Epoch: 1 \tTraining Loss: 6.064335 \tValidation Loss: 4.529048\n",
      "Validation loss decreased (inf --> 4.52905).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.324528 \tValidation Loss: 4.311456\n",
      "Validation loss decreased (4.52905 --> 4.31146).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.862862 \tValidation Loss: 4.020941\n",
      "Validation loss decreased (4.31146 --> 4.02094).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.260397 \tValidation Loss: 3.708023\n",
      "Validation loss decreased (4.02094 --> 3.70802).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.611827 \tValidation Loss: 3.424767\n",
      "Validation loss decreased (3.70802 --> 3.42477).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.002662 \tValidation Loss: 3.187026\n",
      "Validation loss decreased (3.42477 --> 3.18703).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.472330 \tValidation Loss: 2.994154\n",
      "Validation loss decreased (3.18703 --> 2.99415).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.031518 \tValidation Loss: 2.840491\n",
      "Validation loss decreased (2.99415 --> 2.84049).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.677330 \tValidation Loss: 2.719167\n",
      "Validation loss decreased (2.84049 --> 2.71917).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.386567 \tValidation Loss: 2.624419\n",
      "Validation loss decreased (2.71917 --> 2.62442).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.160049 \tValidation Loss: 2.553013\n",
      "Validation loss decreased (2.62442 --> 2.55301).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.973151 \tValidation Loss: 2.499409\n",
      "Validation loss decreased (2.55301 --> 2.49941).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.818968 \tValidation Loss: 2.459925\n",
      "Validation loss decreased (2.49941 --> 2.45993).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.700437 \tValidation Loss: 2.432819\n",
      "Validation loss decreased (2.45993 --> 2.43282).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.596880 \tValidation Loss: 2.420161\n",
      "Validation loss decreased (2.43282 --> 2.42016).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.514738 \tValidation Loss: 2.412894\n",
      "Validation loss decreased (2.42016 --> 2.41289).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.449791 \tValidation Loss: 2.411701\n",
      "Validation loss decreased (2.41289 --> 2.41170).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.394175 \tValidation Loss: 2.418056\n",
      "Epoch: 19 \tTraining Loss: 0.349858 \tValidation Loss: 2.428009\n",
      "Epoch: 20 \tTraining Loss: 0.312095 \tValidation Loss: 2.445184\n",
      "Epoch: 1 \tTraining Loss: 6.068193 \tValidation Loss: 4.568035\n",
      "Validation loss decreased (inf --> 4.56803).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.315578 \tValidation Loss: 4.338141\n",
      "Validation loss decreased (4.56803 --> 4.33814).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.851082 \tValidation Loss: 4.047984\n",
      "Validation loss decreased (4.33814 --> 4.04798).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.245176 \tValidation Loss: 3.738011\n",
      "Validation loss decreased (4.04798 --> 3.73801).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.596494 \tValidation Loss: 3.452738\n",
      "Validation loss decreased (3.73801 --> 3.45274).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.990510 \tValidation Loss: 3.210713\n",
      "Validation loss decreased (3.45274 --> 3.21071).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.463831 \tValidation Loss: 3.018986\n",
      "Validation loss decreased (3.21071 --> 3.01899).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.030587 \tValidation Loss: 2.868837\n",
      "Validation loss decreased (3.01899 --> 2.86884).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.676465 \tValidation Loss: 2.752537\n",
      "Validation loss decreased (2.86884 --> 2.75254).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.391503 \tValidation Loss: 2.665373\n",
      "Validation loss decreased (2.75254 --> 2.66537).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.161486 \tValidation Loss: 2.598845\n",
      "Validation loss decreased (2.66537 --> 2.59884).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.976901 \tValidation Loss: 2.552895\n",
      "Validation loss decreased (2.59884 --> 2.55289).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.819373 \tValidation Loss: 2.519666\n",
      "Validation loss decreased (2.55289 --> 2.51967).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.697369 \tValidation Loss: 2.500073\n",
      "Validation loss decreased (2.51967 --> 2.50007).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.596253 \tValidation Loss: 2.492324\n",
      "Validation loss decreased (2.50007 --> 2.49232).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.511472 \tValidation Loss: 2.493016\n",
      "Epoch: 17 \tTraining Loss: 0.448877 \tValidation Loss: 2.501930\n",
      "Epoch: 18 \tTraining Loss: 0.391264 \tValidation Loss: 2.513298\n",
      "Epoch: 19 \tTraining Loss: 0.345797 \tValidation Loss: 2.526842\n",
      "Epoch: 20 \tTraining Loss: 0.308701 \tValidation Loss: 2.547559\n",
      "bbc/sport\\199.txt  had a problem\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 9 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.188084 \tValidation Loss: 5.586399\n",
      "Validation loss decreased (inf --> 5.58640).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.366952 \tValidation Loss: 5.349487\n",
      "Validation loss decreased (5.58640 --> 5.34949).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.940452 \tValidation Loss: 5.020726\n",
      "Validation loss decreased (5.34949 --> 5.02073).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.374224 \tValidation Loss: 4.638413\n",
      "Validation loss decreased (5.02073 --> 4.63841).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.730549 \tValidation Loss: 4.289672\n",
      "Validation loss decreased (4.63841 --> 4.28967).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.111024 \tValidation Loss: 4.000696\n",
      "Validation loss decreased (4.28967 --> 4.00070).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.564832 \tValidation Loss: 3.768525\n",
      "Validation loss decreased (4.00070 --> 3.76853).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.105503 \tValidation Loss: 3.583688\n",
      "Validation loss decreased (3.76853 --> 3.58369).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.734655 \tValidation Loss: 3.439320\n",
      "Validation loss decreased (3.58369 --> 3.43932).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.429247 \tValidation Loss: 3.326157\n",
      "Validation loss decreased (3.43932 --> 3.32616).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.183483 \tValidation Loss: 3.242526\n",
      "Validation loss decreased (3.32616 --> 3.24253).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.982375 \tValidation Loss: 3.182942\n",
      "Validation loss decreased (3.24253 --> 3.18294).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.816168 \tValidation Loss: 3.139422\n",
      "Validation loss decreased (3.18294 --> 3.13942).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.685564 \tValidation Loss: 3.113577\n",
      "Validation loss decreased (3.13942 --> 3.11358).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.574434 \tValidation Loss: 3.099480\n",
      "Validation loss decreased (3.11358 --> 3.09948).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.486573 \tValidation Loss: 3.094138\n",
      "Validation loss decreased (3.09948 --> 3.09414).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.416013 \tValidation Loss: 3.098119\n",
      "Epoch: 18 \tTraining Loss: 0.359254 \tValidation Loss: 3.109205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 \tTraining Loss: 0.310541 \tValidation Loss: 3.122805\n",
      "Epoch: 20 \tTraining Loss: 0.275559 \tValidation Loss: 3.139167\n",
      "Epoch: 1 \tTraining Loss: 6.184161 \tValidation Loss: 5.583597\n",
      "Validation loss decreased (inf --> 5.58360).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.362643 \tValidation Loss: 5.355526\n",
      "Validation loss decreased (5.58360 --> 5.35553).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.933907 \tValidation Loss: 5.038745\n",
      "Validation loss decreased (5.35553 --> 5.03874).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.366661 \tValidation Loss: 4.671698\n",
      "Validation loss decreased (5.03874 --> 4.67170).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.727989 \tValidation Loss: 4.330175\n",
      "Validation loss decreased (4.67170 --> 4.33017).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.110896 \tValidation Loss: 4.042498\n",
      "Validation loss decreased (4.33017 --> 4.04250).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.568037 \tValidation Loss: 3.809109\n",
      "Validation loss decreased (4.04250 --> 3.80911).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.108650 \tValidation Loss: 3.625898\n",
      "Validation loss decreased (3.80911 --> 3.62590).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.730023 \tValidation Loss: 3.485476\n",
      "Validation loss decreased (3.62590 --> 3.48548).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.423535 \tValidation Loss: 3.381026\n",
      "Validation loss decreased (3.48548 --> 3.38103).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.177039 \tValidation Loss: 3.303219\n",
      "Validation loss decreased (3.38103 --> 3.30322).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.974349 \tValidation Loss: 3.252360\n",
      "Validation loss decreased (3.30322 --> 3.25236).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.810729 \tValidation Loss: 3.218791\n",
      "Validation loss decreased (3.25236 --> 3.21879).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.679323 \tValidation Loss: 3.201470\n",
      "Validation loss decreased (3.21879 --> 3.20147).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.572783 \tValidation Loss: 3.194597\n",
      "Validation loss decreased (3.20147 --> 3.19460).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.484567 \tValidation Loss: 3.197105\n",
      "Epoch: 17 \tTraining Loss: 0.414822 \tValidation Loss: 3.204491\n",
      "Epoch: 18 \tTraining Loss: 0.357827 \tValidation Loss: 3.220386\n",
      "Epoch: 19 \tTraining Loss: 0.310903 \tValidation Loss: 3.242839\n",
      "Epoch: 20 \tTraining Loss: 0.273956 \tValidation Loss: 3.259796\n",
      "Epoch: 1 \tTraining Loss: 6.186103 \tValidation Loss: 5.581817\n",
      "Validation loss decreased (inf --> 5.58182).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.369659 \tValidation Loss: 5.356182\n",
      "Validation loss decreased (5.58182 --> 5.35618).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.954638 \tValidation Loss: 5.039856\n",
      "Validation loss decreased (5.35618 --> 5.03986).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.396728 \tValidation Loss: 4.660928\n",
      "Validation loss decreased (5.03986 --> 4.66093).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.754480 \tValidation Loss: 4.310434\n",
      "Validation loss decreased (4.66093 --> 4.31043).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.137814 \tValidation Loss: 4.016018\n",
      "Validation loss decreased (4.31043 --> 4.01602).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.596305 \tValidation Loss: 3.775701\n",
      "Validation loss decreased (4.01602 --> 3.77570).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.135886 \tValidation Loss: 3.582698\n",
      "Validation loss decreased (3.77570 --> 3.58270).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.758204 \tValidation Loss: 3.428098\n",
      "Validation loss decreased (3.58270 --> 3.42810).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.448937 \tValidation Loss: 3.310836\n",
      "Validation loss decreased (3.42810 --> 3.31084).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.197597 \tValidation Loss: 3.224049\n",
      "Validation loss decreased (3.31084 --> 3.22405).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.995780 \tValidation Loss: 3.157185\n",
      "Validation loss decreased (3.22405 --> 3.15719).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.827641 \tValidation Loss: 3.109684\n",
      "Validation loss decreased (3.15719 --> 3.10968).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.694022 \tValidation Loss: 3.081388\n",
      "Validation loss decreased (3.10968 --> 3.08139).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.586868 \tValidation Loss: 3.062144\n",
      "Validation loss decreased (3.08139 --> 3.06214).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.494394 \tValidation Loss: 3.052025\n",
      "Validation loss decreased (3.06214 --> 3.05202).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.422040 \tValidation Loss: 3.054938\n",
      "Epoch: 18 \tTraining Loss: 0.361880 \tValidation Loss: 3.062003\n",
      "Epoch: 19 \tTraining Loss: 0.319358 \tValidation Loss: 3.075281\n",
      "Epoch: 20 \tTraining Loss: 0.279441 \tValidation Loss: 3.090091\n",
      "Epoch: 1 \tTraining Loss: 6.178388 \tValidation Loss: 5.585138\n",
      "Validation loss decreased (inf --> 5.58514).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.366671 \tValidation Loss: 5.358657\n",
      "Validation loss decreased (5.58514 --> 5.35866).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.946646 \tValidation Loss: 5.038219\n",
      "Validation loss decreased (5.35866 --> 5.03822).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.383511 \tValidation Loss: 4.666991\n",
      "Validation loss decreased (5.03822 --> 4.66699).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.746261 \tValidation Loss: 4.323844\n",
      "Validation loss decreased (4.66699 --> 4.32384).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.127759 \tValidation Loss: 4.039091\n",
      "Validation loss decreased (4.32384 --> 4.03909).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.583407 \tValidation Loss: 3.801891\n",
      "Validation loss decreased (4.03909 --> 3.80189).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.122220 \tValidation Loss: 3.612391\n",
      "Validation loss decreased (3.80189 --> 3.61239).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.742877 \tValidation Loss: 3.465018\n",
      "Validation loss decreased (3.61239 --> 3.46502).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.436333 \tValidation Loss: 3.354347\n",
      "Validation loss decreased (3.46502 --> 3.35435).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.189768 \tValidation Loss: 3.272966\n",
      "Validation loss decreased (3.35435 --> 3.27297).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.985426 \tValidation Loss: 3.211713\n",
      "Validation loss decreased (3.27297 --> 3.21171).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.821846 \tValidation Loss: 3.170660\n",
      "Validation loss decreased (3.21171 --> 3.17066).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.686090 \tValidation Loss: 3.146731\n",
      "Validation loss decreased (3.17066 --> 3.14673).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.575544 \tValidation Loss: 3.132042\n",
      "Validation loss decreased (3.14673 --> 3.13204).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.491594 \tValidation Loss: 3.128622\n",
      "Validation loss decreased (3.13204 --> 3.12862).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.414906 \tValidation Loss: 3.132205\n",
      "Epoch: 18 \tTraining Loss: 0.358161 \tValidation Loss: 3.142720\n",
      "Epoch: 19 \tTraining Loss: 0.313227 \tValidation Loss: 3.156773\n",
      "Epoch: 20 \tTraining Loss: 0.274321 \tValidation Loss: 3.175328\n",
      "Epoch: 1 \tTraining Loss: 6.180173 \tValidation Loss: 5.546452\n",
      "Validation loss decreased (inf --> 5.54645).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.361544 \tValidation Loss: 5.312131\n",
      "Validation loss decreased (5.54645 --> 5.31213).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.937033 \tValidation Loss: 4.989345\n",
      "Validation loss decreased (5.31213 --> 4.98934).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.376902 \tValidation Loss: 4.622706\n",
      "Validation loss decreased (4.98934 --> 4.62271).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.745855 \tValidation Loss: 4.279952\n",
      "Validation loss decreased (4.62271 --> 4.27995).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.127198 \tValidation Loss: 3.992544\n",
      "Validation loss decreased (4.27995 --> 3.99254).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.584209 \tValidation Loss: 3.760099\n",
      "Validation loss decreased (3.99254 --> 3.76010).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.128403 \tValidation Loss: 3.575136\n",
      "Validation loss decreased (3.76010 --> 3.57514).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.755253 \tValidation Loss: 3.430545\n",
      "Validation loss decreased (3.57514 --> 3.43055).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.449488 \tValidation Loss: 3.317313\n",
      "Validation loss decreased (3.43055 --> 3.31731).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 \tTraining Loss: 1.202543 \tValidation Loss: 3.231198\n",
      "Validation loss decreased (3.31731 --> 3.23120).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.993534 \tValidation Loss: 3.165440\n",
      "Validation loss decreased (3.23120 --> 3.16544).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.829651 \tValidation Loss: 3.118982\n",
      "Validation loss decreased (3.16544 --> 3.11898).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.694945 \tValidation Loss: 3.088699\n",
      "Validation loss decreased (3.11898 --> 3.08870).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.583176 \tValidation Loss: 3.071663\n",
      "Validation loss decreased (3.08870 --> 3.07166).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.490450 \tValidation Loss: 3.064512\n",
      "Validation loss decreased (3.07166 --> 3.06451).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.422523 \tValidation Loss: 3.067922\n",
      "Epoch: 18 \tTraining Loss: 0.363046 \tValidation Loss: 3.077213\n",
      "Epoch: 19 \tTraining Loss: 0.318299 \tValidation Loss: 3.089483\n",
      "Epoch: 20 \tTraining Loss: 0.280101 \tValidation Loss: 3.106575\n",
      "Epoch: 1 \tTraining Loss: 6.186380 \tValidation Loss: 5.520326\n",
      "Validation loss decreased (inf --> 5.52033).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.373442 \tValidation Loss: 5.276250\n",
      "Validation loss decreased (5.52033 --> 5.27625).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.948148 \tValidation Loss: 4.958103\n",
      "Validation loss decreased (5.27625 --> 4.95810).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.383943 \tValidation Loss: 4.588823\n",
      "Validation loss decreased (4.95810 --> 4.58882).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.747199 \tValidation Loss: 4.247056\n",
      "Validation loss decreased (4.58882 --> 4.24706).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.131379 \tValidation Loss: 3.961703\n",
      "Validation loss decreased (4.24706 --> 3.96170).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.586996 \tValidation Loss: 3.730951\n",
      "Validation loss decreased (3.96170 --> 3.73095).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.125734 \tValidation Loss: 3.547920\n",
      "Validation loss decreased (3.73095 --> 3.54792).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.746772 \tValidation Loss: 3.405535\n",
      "Validation loss decreased (3.54792 --> 3.40553).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.439025 \tValidation Loss: 3.298768\n",
      "Validation loss decreased (3.40553 --> 3.29877).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.188703 \tValidation Loss: 3.219794\n",
      "Validation loss decreased (3.29877 --> 3.21979).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.986231 \tValidation Loss: 3.160582\n",
      "Validation loss decreased (3.21979 --> 3.16058).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.821914 \tValidation Loss: 3.120678\n",
      "Validation loss decreased (3.16058 --> 3.12068).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.690732 \tValidation Loss: 3.095846\n",
      "Validation loss decreased (3.12068 --> 3.09585).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.580596 \tValidation Loss: 3.084262\n",
      "Validation loss decreased (3.09585 --> 3.08426).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.492675 \tValidation Loss: 3.080282\n",
      "Validation loss decreased (3.08426 --> 3.08028).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.422092 \tValidation Loss: 3.084147\n",
      "Epoch: 18 \tTraining Loss: 0.363863 \tValidation Loss: 3.094099\n",
      "Epoch: 19 \tTraining Loss: 0.320944 \tValidation Loss: 3.109949\n",
      "Epoch: 20 \tTraining Loss: 0.281403 \tValidation Loss: 3.124330\n",
      "Epoch: 1 \tTraining Loss: 6.177336 \tValidation Loss: 5.601981\n",
      "Validation loss decreased (inf --> 5.60198).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.367031 \tValidation Loss: 5.350017\n",
      "Validation loss decreased (5.60198 --> 5.35002).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.943911 \tValidation Loss: 5.024395\n",
      "Validation loss decreased (5.35002 --> 5.02439).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.379777 \tValidation Loss: 4.651298\n",
      "Validation loss decreased (5.02439 --> 4.65130).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.737397 \tValidation Loss: 4.306718\n",
      "Validation loss decreased (4.65130 --> 4.30672).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.121574 \tValidation Loss: 4.012253\n",
      "Validation loss decreased (4.30672 --> 4.01225).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.576852 \tValidation Loss: 3.772520\n",
      "Validation loss decreased (4.01225 --> 3.77252).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.118597 \tValidation Loss: 3.584157\n",
      "Validation loss decreased (3.77252 --> 3.58416).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.743806 \tValidation Loss: 3.436413\n",
      "Validation loss decreased (3.58416 --> 3.43641).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.439907 \tValidation Loss: 3.321753\n",
      "Validation loss decreased (3.43641 --> 3.32175).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.195342 \tValidation Loss: 3.232483\n",
      "Validation loss decreased (3.32175 --> 3.23248).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.988984 \tValidation Loss: 3.166448\n",
      "Validation loss decreased (3.23248 --> 3.16645).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.823474 \tValidation Loss: 3.119993\n",
      "Validation loss decreased (3.16645 --> 3.11999).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.688074 \tValidation Loss: 3.086677\n",
      "Validation loss decreased (3.11999 --> 3.08668).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.580234 \tValidation Loss: 3.070507\n",
      "Validation loss decreased (3.08668 --> 3.07051).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.491769 \tValidation Loss: 3.062865\n",
      "Validation loss decreased (3.07051 --> 3.06286).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.419606 \tValidation Loss: 3.065514\n",
      "Epoch: 18 \tTraining Loss: 0.358946 \tValidation Loss: 3.073751\n",
      "Epoch: 19 \tTraining Loss: 0.311989 \tValidation Loss: 3.084132\n",
      "Epoch: 20 \tTraining Loss: 0.275874 \tValidation Loss: 3.102795\n",
      "Epoch: 1 \tTraining Loss: 6.178722 \tValidation Loss: 5.554243\n",
      "Validation loss decreased (inf --> 5.55424).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.370173 \tValidation Loss: 5.309898\n",
      "Validation loss decreased (5.55424 --> 5.30990).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.944189 \tValidation Loss: 4.977296\n",
      "Validation loss decreased (5.30990 --> 4.97730).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.377574 \tValidation Loss: 4.594036\n",
      "Validation loss decreased (4.97730 --> 4.59404).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.738797 \tValidation Loss: 4.235585\n",
      "Validation loss decreased (4.59404 --> 4.23559).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.117034 \tValidation Loss: 3.938763\n",
      "Validation loss decreased (4.23559 --> 3.93876).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.571048 \tValidation Loss: 3.702339\n",
      "Validation loss decreased (3.93876 --> 3.70234).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.111190 \tValidation Loss: 3.517235\n",
      "Validation loss decreased (3.70234 --> 3.51724).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.734050 \tValidation Loss: 3.374261\n",
      "Validation loss decreased (3.51724 --> 3.37426).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.431294 \tValidation Loss: 3.263993\n",
      "Validation loss decreased (3.37426 --> 3.26399).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.183684 \tValidation Loss: 3.180169\n",
      "Validation loss decreased (3.26399 --> 3.18017).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.980815 \tValidation Loss: 3.116296\n",
      "Validation loss decreased (3.18017 --> 3.11630).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.815337 \tValidation Loss: 3.068784\n",
      "Validation loss decreased (3.11630 --> 3.06878).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.681635 \tValidation Loss: 3.037418\n",
      "Validation loss decreased (3.06878 --> 3.03742).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.573808 \tValidation Loss: 3.019169\n",
      "Validation loss decreased (3.03742 --> 3.01917).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.485329 \tValidation Loss: 3.014030\n",
      "Validation loss decreased (3.01917 --> 3.01403).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.413713 \tValidation Loss: 3.019359\n",
      "Epoch: 18 \tTraining Loss: 0.357336 \tValidation Loss: 3.027394\n",
      "Epoch: 19 \tTraining Loss: 0.308642 \tValidation Loss: 3.039558\n",
      "Epoch: 20 \tTraining Loss: 0.274834 \tValidation Loss: 3.054574\n",
      "Epoch: 1 \tTraining Loss: 6.183232 \tValidation Loss: 5.583719\n",
      "Validation loss decreased (inf --> 5.58372).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.368737 \tValidation Loss: 5.345151\n",
      "Validation loss decreased (5.58372 --> 5.34515).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.952842 \tValidation Loss: 5.026549\n",
      "Validation loss decreased (5.34515 --> 5.02655).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 \tTraining Loss: 4.393508 \tValidation Loss: 4.652626\n",
      "Validation loss decreased (5.02655 --> 4.65263).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.760054 \tValidation Loss: 4.300855\n",
      "Validation loss decreased (4.65263 --> 4.30085).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.136308 \tValidation Loss: 4.010343\n",
      "Validation loss decreased (4.30085 --> 4.01034).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.589710 \tValidation Loss: 3.786212\n",
      "Validation loss decreased (4.01034 --> 3.78621).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.129689 \tValidation Loss: 3.611602\n",
      "Validation loss decreased (3.78621 --> 3.61160).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.753080 \tValidation Loss: 3.477135\n",
      "Validation loss decreased (3.61160 --> 3.47713).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.447175 \tValidation Loss: 3.373353\n",
      "Validation loss decreased (3.47713 --> 3.37335).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.198475 \tValidation Loss: 3.294381\n",
      "Validation loss decreased (3.37335 --> 3.29438).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.995946 \tValidation Loss: 3.234281\n",
      "Validation loss decreased (3.29438 --> 3.23428).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.827382 \tValidation Loss: 3.194819\n",
      "Validation loss decreased (3.23428 --> 3.19482).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.690032 \tValidation Loss: 3.168656\n",
      "Validation loss decreased (3.19482 --> 3.16866).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.581622 \tValidation Loss: 3.155022\n",
      "Validation loss decreased (3.16866 --> 3.15502).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.492636 \tValidation Loss: 3.151291\n",
      "Validation loss decreased (3.15502 --> 3.15129).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.418200 \tValidation Loss: 3.156713\n",
      "Epoch: 18 \tTraining Loss: 0.361016 \tValidation Loss: 3.168682\n",
      "Epoch: 19 \tTraining Loss: 0.317435 \tValidation Loss: 3.180770\n",
      "Epoch: 20 \tTraining Loss: 0.276773 \tValidation Loss: 3.201908\n",
      "Epoch: 1 \tTraining Loss: 6.186881 \tValidation Loss: 5.580013\n",
      "Validation loss decreased (inf --> 5.58001).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.364191 \tValidation Loss: 5.344301\n",
      "Validation loss decreased (5.58001 --> 5.34430).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.939203 \tValidation Loss: 5.015385\n",
      "Validation loss decreased (5.34430 --> 5.01538).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.372348 \tValidation Loss: 4.630041\n",
      "Validation loss decreased (5.01538 --> 4.63004).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.736472 \tValidation Loss: 4.275425\n",
      "Validation loss decreased (4.63004 --> 4.27542).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.120149 \tValidation Loss: 3.983865\n",
      "Validation loss decreased (4.27542 --> 3.98386).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.578769 \tValidation Loss: 3.753786\n",
      "Validation loss decreased (3.98386 --> 3.75379).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.118516 \tValidation Loss: 3.573701\n",
      "Validation loss decreased (3.75379 --> 3.57370).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.743424 \tValidation Loss: 3.433882\n",
      "Validation loss decreased (3.57370 --> 3.43388).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.437588 \tValidation Loss: 3.325760\n",
      "Validation loss decreased (3.43388 --> 3.32576).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.187415 \tValidation Loss: 3.242317\n",
      "Validation loss decreased (3.32576 --> 3.24232).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.987499 \tValidation Loss: 3.180336\n",
      "Validation loss decreased (3.24232 --> 3.18034).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.822898 \tValidation Loss: 3.138903\n",
      "Validation loss decreased (3.18034 --> 3.13890).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.688088 \tValidation Loss: 3.110620\n",
      "Validation loss decreased (3.13890 --> 3.11062).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.573411 \tValidation Loss: 3.093419\n",
      "Validation loss decreased (3.11062 --> 3.09342).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.486996 \tValidation Loss: 3.090052\n",
      "Validation loss decreased (3.09342 --> 3.09005).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.415917 \tValidation Loss: 3.096876\n",
      "Epoch: 18 \tTraining Loss: 0.356395 \tValidation Loss: 3.111079\n",
      "Epoch: 19 \tTraining Loss: 0.311193 \tValidation Loss: 3.122388\n",
      "Epoch: 20 \tTraining Loss: 0.273702 \tValidation Loss: 3.140156\n",
      "bbc/sport\\199.txt  had a problem\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 10 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.186338 \tValidation Loss: 5.404878\n",
      "Validation loss decreased (inf --> 5.40488).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.306977 \tValidation Loss: 5.075907\n",
      "Validation loss decreased (5.40488 --> 5.07591).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.927971 \tValidation Loss: 4.834177\n",
      "Validation loss decreased (5.07591 --> 4.83418).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.460201 \tValidation Loss: 4.533321\n",
      "Validation loss decreased (4.83418 --> 4.53332).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.898556 \tValidation Loss: 4.227032\n",
      "Validation loss decreased (4.53332 --> 4.22703).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.318178 \tValidation Loss: 3.956874\n",
      "Validation loss decreased (4.22703 --> 3.95687).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.782756 \tValidation Loss: 3.736187\n",
      "Validation loss decreased (3.95687 --> 3.73619).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.314551 \tValidation Loss: 3.558541\n",
      "Validation loss decreased (3.73619 --> 3.55854).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.918797 \tValidation Loss: 3.419248\n",
      "Validation loss decreased (3.55854 --> 3.41925).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.588287 \tValidation Loss: 3.309577\n",
      "Validation loss decreased (3.41925 --> 3.30958).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.315203 \tValidation Loss: 3.224334\n",
      "Validation loss decreased (3.30958 --> 3.22433).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.090729 \tValidation Loss: 3.157353\n",
      "Validation loss decreased (3.22433 --> 3.15735).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.906215 \tValidation Loss: 3.106686\n",
      "Validation loss decreased (3.15735 --> 3.10669).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.749355 \tValidation Loss: 3.072994\n",
      "Validation loss decreased (3.10669 --> 3.07299).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.624744 \tValidation Loss: 3.048470\n",
      "Validation loss decreased (3.07299 --> 3.04847).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.525438 \tValidation Loss: 3.033281\n",
      "Validation loss decreased (3.04847 --> 3.03328).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.443108 \tValidation Loss: 3.028002\n",
      "Validation loss decreased (3.03328 --> 3.02800).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.373120 \tValidation Loss: 3.031117\n",
      "Epoch: 19 \tTraining Loss: 0.321029 \tValidation Loss: 3.037262\n",
      "Epoch: 20 \tTraining Loss: 0.277453 \tValidation Loss: 3.045543\n",
      "Epoch: 1 \tTraining Loss: 6.193030 \tValidation Loss: 5.392508\n",
      "Validation loss decreased (inf --> 5.39251).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.315450 \tValidation Loss: 5.039605\n",
      "Validation loss decreased (5.39251 --> 5.03961).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.932508 \tValidation Loss: 4.784160\n",
      "Validation loss decreased (5.03961 --> 4.78416).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.460102 \tValidation Loss: 4.471827\n",
      "Validation loss decreased (4.78416 --> 4.47183).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.888564 \tValidation Loss: 4.156012\n",
      "Validation loss decreased (4.47183 --> 4.15601).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.300016 \tValidation Loss: 3.885098\n",
      "Validation loss decreased (4.15601 --> 3.88510).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.755715 \tValidation Loss: 3.661363\n",
      "Validation loss decreased (3.88510 --> 3.66136).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.287461 \tValidation Loss: 3.477764\n",
      "Validation loss decreased (3.66136 --> 3.47776).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.895139 \tValidation Loss: 3.329869\n",
      "Validation loss decreased (3.47776 --> 3.32987).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.568063 \tValidation Loss: 3.212746\n",
      "Validation loss decreased (3.32987 --> 3.21275).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.297495 \tValidation Loss: 3.119515\n",
      "Validation loss decreased (3.21275 --> 3.11951).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.069583 \tValidation Loss: 3.045872\n",
      "Validation loss decreased (3.11951 --> 3.04587).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 \tTraining Loss: 0.886998 \tValidation Loss: 2.992669\n",
      "Validation loss decreased (3.04587 --> 2.99267).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.735420 \tValidation Loss: 2.953522\n",
      "Validation loss decreased (2.99267 --> 2.95352).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.612392 \tValidation Loss: 2.928502\n",
      "Validation loss decreased (2.95352 --> 2.92850).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.510799 \tValidation Loss: 2.915258\n",
      "Validation loss decreased (2.92850 --> 2.91526).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.430296 \tValidation Loss: 2.912248\n",
      "Validation loss decreased (2.91526 --> 2.91225).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.365340 \tValidation Loss: 2.914680\n",
      "Epoch: 19 \tTraining Loss: 0.310662 \tValidation Loss: 2.923606\n",
      "Epoch: 20 \tTraining Loss: 0.272110 \tValidation Loss: 2.934123\n",
      "Epoch: 1 \tTraining Loss: 6.184147 \tValidation Loss: 5.392899\n",
      "Validation loss decreased (inf --> 5.39290).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.304416 \tValidation Loss: 5.046655\n",
      "Validation loss decreased (5.39290 --> 5.04665).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.925010 \tValidation Loss: 4.788011\n",
      "Validation loss decreased (5.04665 --> 4.78801).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.453500 \tValidation Loss: 4.463527\n",
      "Validation loss decreased (4.78801 --> 4.46353).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.888248 \tValidation Loss: 4.142108\n",
      "Validation loss decreased (4.46353 --> 4.14211).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.311455 \tValidation Loss: 3.863023\n",
      "Validation loss decreased (4.14211 --> 3.86302).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.776897 \tValidation Loss: 3.635431\n",
      "Validation loss decreased (3.86302 --> 3.63543).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.313585 \tValidation Loss: 3.456784\n",
      "Validation loss decreased (3.63543 --> 3.45678).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.916043 \tValidation Loss: 3.317851\n",
      "Validation loss decreased (3.45678 --> 3.31785).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.587088 \tValidation Loss: 3.208413\n",
      "Validation loss decreased (3.31785 --> 3.20841).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.310704 \tValidation Loss: 3.121443\n",
      "Validation loss decreased (3.20841 --> 3.12144).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.086777 \tValidation Loss: 3.053175\n",
      "Validation loss decreased (3.12144 --> 3.05318).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.902616 \tValidation Loss: 3.002209\n",
      "Validation loss decreased (3.05318 --> 3.00221).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.746772 \tValidation Loss: 2.966807\n",
      "Validation loss decreased (3.00221 --> 2.96681).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.620617 \tValidation Loss: 2.943180\n",
      "Validation loss decreased (2.96681 --> 2.94318).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.518539 \tValidation Loss: 2.930817\n",
      "Validation loss decreased (2.94318 --> 2.93082).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.434427 \tValidation Loss: 2.927263\n",
      "Validation loss decreased (2.93082 --> 2.92726).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.370130 \tValidation Loss: 2.929727\n",
      "Epoch: 19 \tTraining Loss: 0.316814 \tValidation Loss: 2.938387\n",
      "Epoch: 20 \tTraining Loss: 0.273879 \tValidation Loss: 2.946884\n",
      "Epoch: 1 \tTraining Loss: 6.191239 \tValidation Loss: 5.419303\n",
      "Validation loss decreased (inf --> 5.41930).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.312218 \tValidation Loss: 5.107755\n",
      "Validation loss decreased (5.41930 --> 5.10775).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.924655 \tValidation Loss: 4.854682\n",
      "Validation loss decreased (5.10775 --> 4.85468).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.447893 \tValidation Loss: 4.545534\n",
      "Validation loss decreased (4.85468 --> 4.54553).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.876618 \tValidation Loss: 4.232362\n",
      "Validation loss decreased (4.54553 --> 4.23236).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.292007 \tValidation Loss: 3.956542\n",
      "Validation loss decreased (4.23236 --> 3.95654).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.750753 \tValidation Loss: 3.730614\n",
      "Validation loss decreased (3.95654 --> 3.73061).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.278146 \tValidation Loss: 3.549457\n",
      "Validation loss decreased (3.73061 --> 3.54946).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.883950 \tValidation Loss: 3.407560\n",
      "Validation loss decreased (3.54946 --> 3.40756).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.556710 \tValidation Loss: 3.298807\n",
      "Validation loss decreased (3.40756 --> 3.29881).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.283893 \tValidation Loss: 3.215393\n",
      "Validation loss decreased (3.29881 --> 3.21539).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.066456 \tValidation Loss: 3.154625\n",
      "Validation loss decreased (3.21539 --> 3.15463).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.880119 \tValidation Loss: 3.109239\n",
      "Validation loss decreased (3.15463 --> 3.10924).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.729485 \tValidation Loss: 3.079306\n",
      "Validation loss decreased (3.10924 --> 3.07931).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.605838 \tValidation Loss: 3.062665\n",
      "Validation loss decreased (3.07931 --> 3.06266).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.505808 \tValidation Loss: 3.057728\n",
      "Validation loss decreased (3.06266 --> 3.05773).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.425337 \tValidation Loss: 3.060219\n",
      "Epoch: 18 \tTraining Loss: 0.361767 \tValidation Loss: 3.069066\n",
      "Epoch: 19 \tTraining Loss: 0.310566 \tValidation Loss: 3.083543\n",
      "Epoch: 20 \tTraining Loss: 0.267759 \tValidation Loss: 3.102311\n",
      "Epoch: 1 \tTraining Loss: 6.190771 \tValidation Loss: 5.390303\n",
      "Validation loss decreased (inf --> 5.39030).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.319855 \tValidation Loss: 5.041349\n",
      "Validation loss decreased (5.39030 --> 5.04135).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.933006 \tValidation Loss: 4.797376\n",
      "Validation loss decreased (5.04135 --> 4.79738).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.464369 \tValidation Loss: 4.502475\n",
      "Validation loss decreased (4.79738 --> 4.50248).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.901150 \tValidation Loss: 4.201336\n",
      "Validation loss decreased (4.50248 --> 4.20134).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.323242 \tValidation Loss: 3.929178\n",
      "Validation loss decreased (4.20134 --> 3.92918).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.785174 \tValidation Loss: 3.702856\n",
      "Validation loss decreased (3.92918 --> 3.70286).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.313391 \tValidation Loss: 3.522722\n",
      "Validation loss decreased (3.70286 --> 3.52272).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.910710 \tValidation Loss: 3.377064\n",
      "Validation loss decreased (3.52272 --> 3.37706).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.578668 \tValidation Loss: 3.262376\n",
      "Validation loss decreased (3.37706 --> 3.26238).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.301812 \tValidation Loss: 3.171907\n",
      "Validation loss decreased (3.26238 --> 3.17191).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.075673 \tValidation Loss: 3.103551\n",
      "Validation loss decreased (3.17191 --> 3.10355).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.887519 \tValidation Loss: 3.053148\n",
      "Validation loss decreased (3.10355 --> 3.05315).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.738570 \tValidation Loss: 3.016468\n",
      "Validation loss decreased (3.05315 --> 3.01647).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.609780 \tValidation Loss: 2.994822\n",
      "Validation loss decreased (3.01647 --> 2.99482).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.507860 \tValidation Loss: 2.987936\n",
      "Validation loss decreased (2.99482 --> 2.98794).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.427377 \tValidation Loss: 2.988553\n",
      "Epoch: 18 \tTraining Loss: 0.365652 \tValidation Loss: 2.996609\n",
      "Epoch: 19 \tTraining Loss: 0.310630 \tValidation Loss: 3.009785\n",
      "Epoch: 20 \tTraining Loss: 0.269389 \tValidation Loss: 3.023952\n",
      "Epoch: 1 \tTraining Loss: 6.189036 \tValidation Loss: 5.413734\n",
      "Validation loss decreased (inf --> 5.41373).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.308088 \tValidation Loss: 5.073014\n",
      "Validation loss decreased (5.41373 --> 5.07301).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.918969 \tValidation Loss: 4.826683\n",
      "Validation loss decreased (5.07301 --> 4.82668).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.448400 \tValidation Loss: 4.525307\n",
      "Validation loss decreased (4.82668 --> 4.52531).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \tTraining Loss: 3.886342 \tValidation Loss: 4.220918\n",
      "Validation loss decreased (4.52531 --> 4.22092).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.310578 \tValidation Loss: 3.950811\n",
      "Validation loss decreased (4.22092 --> 3.95081).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.779906 \tValidation Loss: 3.721363\n",
      "Validation loss decreased (3.95081 --> 3.72136).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.312368 \tValidation Loss: 3.531555\n",
      "Validation loss decreased (3.72136 --> 3.53156).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.913924 \tValidation Loss: 3.377899\n",
      "Validation loss decreased (3.53156 --> 3.37790).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.586075 \tValidation Loss: 3.255025\n",
      "Validation loss decreased (3.37790 --> 3.25503).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.311039 \tValidation Loss: 3.158044\n",
      "Validation loss decreased (3.25503 --> 3.15804).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.086452 \tValidation Loss: 3.079821\n",
      "Validation loss decreased (3.15804 --> 3.07982).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.898641 \tValidation Loss: 3.020133\n",
      "Validation loss decreased (3.07982 --> 3.02013).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.747528 \tValidation Loss: 2.976115\n",
      "Validation loss decreased (3.02013 --> 2.97611).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.621510 \tValidation Loss: 2.948070\n",
      "Validation loss decreased (2.97611 --> 2.94807).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.519570 \tValidation Loss: 2.933163\n",
      "Validation loss decreased (2.94807 --> 2.93316).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.438305 \tValidation Loss: 2.922284\n",
      "Validation loss decreased (2.93316 --> 2.92228).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.370352 \tValidation Loss: 2.920059\n",
      "Validation loss decreased (2.92228 --> 2.92006).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.317901 \tValidation Loss: 2.925283\n",
      "Epoch: 20 \tTraining Loss: 0.276741 \tValidation Loss: 2.931081\n",
      "Epoch: 1 \tTraining Loss: 6.187631 \tValidation Loss: 5.380659\n",
      "Validation loss decreased (inf --> 5.38066).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.310317 \tValidation Loss: 5.041538\n",
      "Validation loss decreased (5.38066 --> 5.04154).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.920710 \tValidation Loss: 4.802974\n",
      "Validation loss decreased (5.04154 --> 4.80297).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.443005 \tValidation Loss: 4.507729\n",
      "Validation loss decreased (4.80297 --> 4.50773).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.870753 \tValidation Loss: 4.205118\n",
      "Validation loss decreased (4.50773 --> 4.20512).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.290072 \tValidation Loss: 3.938837\n",
      "Validation loss decreased (4.20512 --> 3.93884).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.752131 \tValidation Loss: 3.717780\n",
      "Validation loss decreased (3.93884 --> 3.71778).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.288783 \tValidation Loss: 3.535892\n",
      "Validation loss decreased (3.71778 --> 3.53589).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.896293 \tValidation Loss: 3.386481\n",
      "Validation loss decreased (3.53589 --> 3.38648).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.568968 \tValidation Loss: 3.268446\n",
      "Validation loss decreased (3.38648 --> 3.26845).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.293933 \tValidation Loss: 3.175600\n",
      "Validation loss decreased (3.26845 --> 3.17560).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.073358 \tValidation Loss: 3.104937\n",
      "Validation loss decreased (3.17560 --> 3.10494).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.889330 \tValidation Loss: 3.052379\n",
      "Validation loss decreased (3.10494 --> 3.05238).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.734403 \tValidation Loss: 3.015246\n",
      "Validation loss decreased (3.05238 --> 3.01525).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.613151 \tValidation Loss: 2.989616\n",
      "Validation loss decreased (3.01525 --> 2.98962).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.512865 \tValidation Loss: 2.975872\n",
      "Validation loss decreased (2.98962 --> 2.97587).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.429994 \tValidation Loss: 2.973493\n",
      "Validation loss decreased (2.97587 --> 2.97349).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.364120 \tValidation Loss: 2.980059\n",
      "Epoch: 19 \tTraining Loss: 0.312678 \tValidation Loss: 2.990922\n",
      "Epoch: 20 \tTraining Loss: 0.271357 \tValidation Loss: 3.000783\n",
      "Epoch: 1 \tTraining Loss: 6.196871 \tValidation Loss: 5.427908\n",
      "Validation loss decreased (inf --> 5.42791).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.312157 \tValidation Loss: 5.081343\n",
      "Validation loss decreased (5.42791 --> 5.08134).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.924334 \tValidation Loss: 4.823056\n",
      "Validation loss decreased (5.08134 --> 4.82306).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.446099 \tValidation Loss: 4.509048\n",
      "Validation loss decreased (4.82306 --> 4.50905).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.875231 \tValidation Loss: 4.183338\n",
      "Validation loss decreased (4.50905 --> 4.18334).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.294359 \tValidation Loss: 3.887837\n",
      "Validation loss decreased (4.18334 --> 3.88784).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.758989 \tValidation Loss: 3.639480\n",
      "Validation loss decreased (3.88784 --> 3.63948).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.291014 \tValidation Loss: 3.435701\n",
      "Validation loss decreased (3.63948 --> 3.43570).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.895668 \tValidation Loss: 3.268916\n",
      "Validation loss decreased (3.43570 --> 3.26892).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.564542 \tValidation Loss: 3.132921\n",
      "Validation loss decreased (3.26892 --> 3.13292).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.290576 \tValidation Loss: 3.024272\n",
      "Validation loss decreased (3.13292 --> 3.02427).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.065760 \tValidation Loss: 2.939442\n",
      "Validation loss decreased (3.02427 --> 2.93944).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.876934 \tValidation Loss: 2.875888\n",
      "Validation loss decreased (2.93944 --> 2.87589).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.728969 \tValidation Loss: 2.828433\n",
      "Validation loss decreased (2.87589 --> 2.82843).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.601571 \tValidation Loss: 2.794152\n",
      "Validation loss decreased (2.82843 --> 2.79415).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.505132 \tValidation Loss: 2.774162\n",
      "Validation loss decreased (2.79415 --> 2.77416).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.423206 \tValidation Loss: 2.761491\n",
      "Validation loss decreased (2.77416 --> 2.76149).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.357793 \tValidation Loss: 2.758564\n",
      "Validation loss decreased (2.76149 --> 2.75856).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.309179 \tValidation Loss: 2.762774\n",
      "Epoch: 20 \tTraining Loss: 0.266072 \tValidation Loss: 2.768015\n",
      "Epoch: 1 \tTraining Loss: 6.193847 \tValidation Loss: 5.405278\n",
      "Validation loss decreased (inf --> 5.40528).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.312022 \tValidation Loss: 5.052602\n",
      "Validation loss decreased (5.40528 --> 5.05260).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.927090 \tValidation Loss: 4.789658\n",
      "Validation loss decreased (5.05260 --> 4.78966).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.451082 \tValidation Loss: 4.475301\n",
      "Validation loss decreased (4.78966 --> 4.47530).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.884897 \tValidation Loss: 4.158304\n",
      "Validation loss decreased (4.47530 --> 4.15830).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.305057 \tValidation Loss: 3.873484\n",
      "Validation loss decreased (4.15830 --> 3.87348).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.768570 \tValidation Loss: 3.631398\n",
      "Validation loss decreased (3.87348 --> 3.63140).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.298408 \tValidation Loss: 3.431515\n",
      "Validation loss decreased (3.63140 --> 3.43152).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.902125 \tValidation Loss: 3.269372\n",
      "Validation loss decreased (3.43152 --> 3.26937).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.572828 \tValidation Loss: 3.144720\n",
      "Validation loss decreased (3.26937 --> 3.14472).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.302048 \tValidation Loss: 3.046340\n",
      "Validation loss decreased (3.14472 --> 3.04634).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.071379 \tValidation Loss: 2.973325\n",
      "Validation loss decreased (3.04634 --> 2.97332).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 \tTraining Loss: 0.886525 \tValidation Loss: 2.920218\n",
      "Validation loss decreased (2.97332 --> 2.92022).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.737882 \tValidation Loss: 2.885025\n",
      "Validation loss decreased (2.92022 --> 2.88502).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.611527 \tValidation Loss: 2.863125\n",
      "Validation loss decreased (2.88502 --> 2.86312).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.510969 \tValidation Loss: 2.849190\n",
      "Validation loss decreased (2.86312 --> 2.84919).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.430096 \tValidation Loss: 2.848928\n",
      "Validation loss decreased (2.84919 --> 2.84893).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.364303 \tValidation Loss: 2.856066\n",
      "Epoch: 19 \tTraining Loss: 0.309928 \tValidation Loss: 2.864598\n",
      "Epoch: 20 \tTraining Loss: 0.271679 \tValidation Loss: 2.874780\n",
      "Epoch: 1 \tTraining Loss: 6.179847 \tValidation Loss: 5.423988\n",
      "Validation loss decreased (inf --> 5.42399).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.306017 \tValidation Loss: 5.119703\n",
      "Validation loss decreased (5.42399 --> 5.11970).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.926086 \tValidation Loss: 4.870311\n",
      "Validation loss decreased (5.11970 --> 4.87031).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.461425 \tValidation Loss: 4.578782\n",
      "Validation loss decreased (4.87031 --> 4.57878).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.901081 \tValidation Loss: 4.277610\n",
      "Validation loss decreased (4.57878 --> 4.27761).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.323166 \tValidation Loss: 4.000158\n",
      "Validation loss decreased (4.27761 --> 4.00016).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.785598 \tValidation Loss: 3.765949\n",
      "Validation loss decreased (4.00016 --> 3.76595).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.316332 \tValidation Loss: 3.574211\n",
      "Validation loss decreased (3.76595 --> 3.57421).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.915712 \tValidation Loss: 3.418273\n",
      "Validation loss decreased (3.57421 --> 3.41827).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.583255 \tValidation Loss: 3.294410\n",
      "Validation loss decreased (3.41827 --> 3.29441).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.306465 \tValidation Loss: 3.195946\n",
      "Validation loss decreased (3.29441 --> 3.19595).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.079644 \tValidation Loss: 3.119865\n",
      "Validation loss decreased (3.19595 --> 3.11986).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.891696 \tValidation Loss: 3.061297\n",
      "Validation loss decreased (3.11986 --> 3.06130).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.741182 \tValidation Loss: 3.022231\n",
      "Validation loss decreased (3.06130 --> 3.02223).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.616159 \tValidation Loss: 2.997113\n",
      "Validation loss decreased (3.02223 --> 2.99711).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.512141 \tValidation Loss: 2.981764\n",
      "Validation loss decreased (2.99711 --> 2.98176).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.431592 \tValidation Loss: 2.979737\n",
      "Validation loss decreased (2.98176 --> 2.97974).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.365781 \tValidation Loss: 2.983992\n",
      "Epoch: 19 \tTraining Loss: 0.313752 \tValidation Loss: 2.992876\n",
      "Epoch: 20 \tTraining Loss: 0.271645 \tValidation Loss: 3.004274\n"
     ]
    }
   ],
   "source": [
    "# Preparing the results dataframes:\n",
    "windows = list(range(3,11))\n",
    "columns = ['Predicted_top5_mean', 'Predicted_top5_std', 'Predicted_top10_mean', 'Predicted_top10_std']\n",
    "Results_Nolemmatize = pd.DataFrame(index=index, columns=columns)\n",
    "Results_lemmatize = pd.DataFrame(index=index, columns=columns)\n",
    "\n",
    "# Getting some results:\n",
    "for lemmatize in [False , True]:\n",
    "    \n",
    "    # Building the corpus\n",
    "    corpus = Corpus(meta = 'Corpus BBC '+category+' News, only verbs as target, no stopwords.')\n",
    "    import_bbc_folder(category,corpus , lemmatize = lemmatize)\n",
    "    \n",
    "    for window in windows:\n",
    "                \n",
    "        # Building the dataset:\n",
    "        sentences , verbs = Build_Dataset([category], corpus, window, one_hot=True , lemmatize=lemmatize)\n",
    "        \n",
    "        print('\\n Starting:...-> Lemmatize =',lemmatize,', window =', window , '\\n')\n",
    "        \n",
    "        lr=0.001\n",
    "        batch_size = 512\n",
    "        n_epochs = 20\n",
    "        file_name = 'CBOW_BBC_'+category+'_lemmatize='+str(lemmatize)+'_window='+str(window)+'_crossval.pt'\n",
    "        random_state = 123\n",
    "        K = 10\n",
    "        \n",
    "        # Cross validating the model:\n",
    "        training_losses, validation_losses, predicted_intop5, predicted_intop10 = K_fold_Cross_validate(K , sentences , verbs,\n",
    "                                                                                                corpus, lr,batch_size ,n_epochs,\n",
    "                                                                                                file_name, random_state)\n",
    "        \n",
    "        # Getting the prediction measures mean and standard deviation:\n",
    "        predicted_intop5_mean , predicted_intop5_std  = np.mean(predicted_intop5) , np.std(predicted_intop5)\n",
    "        predicted_intop10_mean , predicted_intop10_std  = np.mean(predicted_intop10) , np.std(predicted_intop10)\n",
    "        \n",
    "        # Adding the measures to the corresponding dataframe:\n",
    "        if lemmatize:\n",
    "            Results_lemmatize.loc[window , 'Predicted_top5_mean'] = predicted_intop5_mean\n",
    "            Results_lemmatize.loc[window , 'Predicted_top5_std'] = predicted_intop5_std\n",
    "            Results_lemmatize.loc[window , 'Predicted_top10_mean'] = predicted_intop10_mean\n",
    "            Results_lemmatize.loc[window , 'Predicted_top10_std'] = predicted_intop10_std\n",
    "        else:\n",
    "            Results_Nolemmatize.loc[window , 'Predicted_top5_mean'] = predicted_intop5_mean\n",
    "            Results_Nolemmatize.loc[window , 'Predicted_top5_std'] = predicted_intop5_std\n",
    "            Results_Nolemmatize.loc[window , 'Predicted_top10_mean'] = predicted_intop10_mean\n",
    "            Results_Nolemmatize.loc[window , 'Predicted_top10_std'] = predicted_intop10_std\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(category+'results.pkl', 'wb') as f:\n",
    "    pickle.dump((Results_lemmatize , Results_Nolemmatize),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(category+'results.pkl', 'rb') as f:\n",
    "    Results_lemmatize , Results_Nolemmatize = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_top5_mean</th>\n",
       "      <th>Predicted_top5_std</th>\n",
       "      <th>Predicted_top10_mean</th>\n",
       "      <th>Predicted_top10_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.365799</td>\n",
       "      <td>0.00998085</td>\n",
       "      <td>0.470095</td>\n",
       "      <td>0.00858114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.505035</td>\n",
       "      <td>0.00905122</td>\n",
       "      <td>0.609093</td>\n",
       "      <td>0.00805589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.600122</td>\n",
       "      <td>0.00576343</td>\n",
       "      <td>0.6854</td>\n",
       "      <td>0.00680115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.652902</td>\n",
       "      <td>0.0053423</td>\n",
       "      <td>0.724972</td>\n",
       "      <td>0.00417978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.670573</td>\n",
       "      <td>0.00444428</td>\n",
       "      <td>0.731934</td>\n",
       "      <td>0.0071292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.675117</td>\n",
       "      <td>0.0101308</td>\n",
       "      <td>0.729336</td>\n",
       "      <td>0.00864941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.673291</td>\n",
       "      <td>0.00724386</td>\n",
       "      <td>0.721924</td>\n",
       "      <td>0.00773968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.652669</td>\n",
       "      <td>0.0143266</td>\n",
       "      <td>0.697331</td>\n",
       "      <td>0.0145561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted_top5_mean Predicted_top5_std Predicted_top10_mean  \\\n",
       "3             0.365799         0.00998085             0.470095   \n",
       "4             0.505035         0.00905122             0.609093   \n",
       "5             0.600122         0.00576343               0.6854   \n",
       "6             0.652902          0.0053423             0.724972   \n",
       "7             0.670573         0.00444428             0.731934   \n",
       "8             0.675117          0.0101308             0.729336   \n",
       "9             0.673291         0.00724386             0.721924   \n",
       "10            0.652669          0.0143266             0.697331   \n",
       "\n",
       "   Predicted_top10_std  \n",
       "3           0.00858114  \n",
       "4           0.00805589  \n",
       "5           0.00680115  \n",
       "6           0.00417978  \n",
       "7            0.0071292  \n",
       "8           0.00864941  \n",
       "9           0.00773968  \n",
       "10           0.0145561  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Results_lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_top5_mean</th>\n",
       "      <th>Predicted_top5_std</th>\n",
       "      <th>Predicted_top10_mean</th>\n",
       "      <th>Predicted_top10_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.366016</td>\n",
       "      <td>0.00534194</td>\n",
       "      <td>0.46167</td>\n",
       "      <td>0.005423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.533203</td>\n",
       "      <td>0.00536776</td>\n",
       "      <td>0.627441</td>\n",
       "      <td>0.00594521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.647998</td>\n",
       "      <td>0.0094213</td>\n",
       "      <td>0.719604</td>\n",
       "      <td>0.00635258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.704464</td>\n",
       "      <td>0.00715592</td>\n",
       "      <td>0.758482</td>\n",
       "      <td>0.00817118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.720898</td>\n",
       "      <td>0.00879171</td>\n",
       "      <td>0.763249</td>\n",
       "      <td>0.0078383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.715313</td>\n",
       "      <td>0.00482165</td>\n",
       "      <td>0.751914</td>\n",
       "      <td>0.00609287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.706787</td>\n",
       "      <td>0.0118165</td>\n",
       "      <td>0.737891</td>\n",
       "      <td>0.0125191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.683268</td>\n",
       "      <td>0.0137222</td>\n",
       "      <td>0.715495</td>\n",
       "      <td>0.0117476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted_top5_mean Predicted_top5_std Predicted_top10_mean  \\\n",
       "3             0.366016         0.00534194              0.46167   \n",
       "4             0.533203         0.00536776             0.627441   \n",
       "5             0.647998          0.0094213             0.719604   \n",
       "6             0.704464         0.00715592             0.758482   \n",
       "7             0.720898         0.00879171             0.763249   \n",
       "8             0.715313         0.00482165             0.751914   \n",
       "9             0.706787          0.0118165             0.737891   \n",
       "10            0.683268          0.0137222             0.715495   \n",
       "\n",
       "   Predicted_top10_std  \n",
       "3             0.005423  \n",
       "4           0.00594521  \n",
       "5           0.00635258  \n",
       "6           0.00817118  \n",
       "7            0.0078383  \n",
       "8           0.00609287  \n",
       "9            0.0125191  \n",
       "10           0.0117476  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Results_Nolemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.bar(Results_lemmatize.index.values, Results_lemmatize['Predicted_top10_mean'].values, yerr=Results_lemmatize['Predicted_top10_std'].values, width=-0.4, align='edge', alpha=0.8, ecolor='black', capsize=4,  label='Top 10 +L')\n",
    "ax.bar(Results_lemmatize.index.values, Results_lemmatize['Predicted_top5_mean'].values, yerr=Results_lemmatize['Predicted_top5_std'].values, color='green', width=-0.4, align='edge', alpha=0.7, ecolor='black', capsize=4, label='Top 5 +L')\n",
    "ax.bar(Results_Nolemmatize.index.values, Results_Nolemmatize['Predicted_top10_mean'].values, yerr=Results_Nolemmatize['Predicted_top10_std'].values, width=0.4, align='edge', alpha=0.8, ecolor='black', capsize=4,  label='Top 10')\n",
    "ax.bar(Results_Nolemmatize.index.values, Results_Nolemmatize['Predicted_top5_mean'].values, yerr=Results_Nolemmatize['Predicted_top5_std'].values, color='purple', width=0.4, align='edge', alpha=0.7, ecolor='black', capsize=4, label='Top 5')\n",
    "ax.set_ylabel('Accuracy of Prediction')\n",
    "ax.set_xlabel('Window Size')\n",
    "ax.set_xticks(Results_lemmatize.index.values)\n",
    "ax.set_yticks(np.arange(0,1.1,0.1))\n",
    "ax.yaxis.grid(True)\n",
    "ax.legend()\n",
    "plt.savefig(category+'-bars.pdf', dpi=500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking a look at the predicted probabilities of the best setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbc/sport\\199.txt  had a problem\n",
      "bbc/sport\\199.txt  had a problem\n",
      "Epoch: 1 \tTraining Loss: 6.459275 \tValidation Loss: 5.405391\n",
      "Validation loss decreased (inf --> 5.40539).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.749724 \tValidation Loss: 5.136132\n",
      "Validation loss decreased (5.40539 --> 5.13613).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.226538 \tValidation Loss: 4.757624\n",
      "Validation loss decreased (5.13613 --> 4.75762).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.502225 \tValidation Loss: 4.316479\n",
      "Validation loss decreased (4.75762 --> 4.31648).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.703577 \tValidation Loss: 3.903156\n",
      "Validation loss decreased (4.31648 --> 3.90316).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.950408 \tValidation Loss: 3.550335\n",
      "Validation loss decreased (3.90316 --> 3.55033).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.316395 \tValidation Loss: 3.269647\n",
      "Validation loss decreased (3.55033 --> 3.26965).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.820173 \tValidation Loss: 3.052382\n",
      "Validation loss decreased (3.26965 --> 3.05238).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.444334 \tValidation Loss: 2.887480\n",
      "Validation loss decreased (3.05238 --> 2.88748).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.156371 \tValidation Loss: 2.764626\n",
      "Validation loss decreased (2.88748 --> 2.76463).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.934197 \tValidation Loss: 2.673078\n",
      "Validation loss decreased (2.76463 --> 2.67308).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.763038 \tValidation Loss: 2.610512\n",
      "Validation loss decreased (2.67308 --> 2.61051).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.627907 \tValidation Loss: 2.563841\n",
      "Validation loss decreased (2.61051 --> 2.56384).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.519755 \tValidation Loss: 2.535170\n",
      "Validation loss decreased (2.56384 --> 2.53517).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.436091 \tValidation Loss: 2.517015\n",
      "Validation loss decreased (2.53517 --> 2.51701).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.372976 \tValidation Loss: 2.512600\n",
      "Validation loss decreased (2.51701 --> 2.51260).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.320808 \tValidation Loss: 2.509961\n",
      "Validation loss decreased (2.51260 --> 2.50996).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.281594 \tValidation Loss: 2.514736\n",
      "Epoch: 19 \tTraining Loss: 0.250088 \tValidation Loss: 2.524192\n",
      "Epoch: 20 \tTraining Loss: 0.223445 \tValidation Loss: 2.535378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize = False\n",
    "window = 7\n",
    "\n",
    "# Building the corpus\n",
    "corpus = Corpus(meta = 'Corpus BBC '+category+' News, only verbs as target, no stopwords.')\n",
    "import_bbc_folder(category,corpus , lemmatize = lemmatize)\n",
    "\n",
    "# Building the dataset\n",
    "sentences , verbs = Build_Dataset([category], corpus, window, one_hot=True , lemmatize=lemmatize)\n",
    "\n",
    "# Getting the train_valid_test data:\n",
    "x_train, x_test, y_train, y_test = train_test_split(sentences, verbs, test_size=0.1, random_state=123)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.1, random_state=123)\n",
    "\n",
    "# Building the model\n",
    "vocab_size = len(corpus.get_vocabs_to_learn())\n",
    "verbs_size = len(corpus.get_verbs_to_learn())\n",
    "hidden_dim = 500\n",
    "\n",
    "model = CBOW(vocab_size, hidden_dim, verbs_size)\n",
    "model.cuda()\n",
    "\n",
    "# Training the model\n",
    "lr=0.001\n",
    "batch_size = 512\n",
    "n_epochs = 20\n",
    "file_name = 'CBOW_BBC'+category+'_window='+str(window)+'_forevaluation.pt'\n",
    "\n",
    "train_losses, valid_losses = Train_model(model, lr, batch_size, n_epochs, file_name, x_train, y_train, x_valid, y_valid)\n",
    "\n",
    "# Loading the best model parameters\n",
    "model.load_state_dict(torch.load(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1dc0fd8fa08>"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd3hUVf7H8feZ9N4JNXSEJIQQIgRBKbosoIggSrVgQeyu666sXdeCyiKi/hRUsKGgIopIsSFFpZfQCb2nAAkJ6cn5/XEnMYSUIZmW5Pt6nnnmZm77chk+nJx777lKa40QQgjnZXJ0AUIIIaomQS2EEE5OgloIIZycBLUQQjg5CWohhHByrrbYaGhoqG7VqpUtNi2EEPXSxo0b07TWYRXNs0lQt2rVig0bNthi00IIUS8ppQ5XNk+6PoQQwslJUAshhJOToBZCCCcnQS2EEE5OgloIIZycBLUQQjg5CWohhHByThPURcWad5bvY+vRdEeXIoQQTsVpgjorr5A5aw7zyLwtnM8rdHQ5QggLnT59mtjYWGJjY2ncuDHNmjUr/Tk/P9+ibYwfP549e/ZUucw777zDnDlzrFEyvXv3ZsuWLVbZlj3Y5M7EmgjwcmPqyFhGv7+G/y7ayeQbYxxdkhDCAiEhIaWh99xzz+Hr68tjjz12wTJaa7TWmEwVtw1nz55d7X7uv//+2hdbRzlNixogoU0I9/Zpy9z1R1my7aSjyxFC1MK+ffuIjo5m4sSJxMXFcfLkSSZMmEB8fDxRUVG88MILpcuWtHALCwsJDAxk0qRJdOnShZ49e5KSkgLAU089xbRp00qXnzRpEt27d+eyyy7jjz/+AOD8+fPceOONdOnShdGjRxMfH19ty/mzzz6jc+fOREdH88QTTwBQWFjILbfcUvr59OnTAXjjjTeIjIykS5cujBs3zurHrDJO06Iu8cg1HVi9L41J32wjNiKQJgFeji5JiDrl+e93sPPEOatuM7KpP88Oibrk9Xbu3Mns2bN57733AJg8eTLBwcEUFhbSr18/RowYQWRk5AXrZGRk0KdPHyZPnsyjjz7KrFmzmDRp0kXb1lqzbt06Fi5cyAsvvMDSpUt56623aNy4MfPnz2fr1q3ExcVVWd+xY8d46qmn2LBhAwEBAVxzzTUsWrSIsLAw0tLS2LZtGwDp6ca5s9dee43Dhw/j7u5e+pk9OFWLGsDd1cSbo7qSX1jMP7/cSnGxPNNRiLqqbdu2XH755aU/f/HFF8TFxREXF8euXbvYuXPnRet4eXkxaNAgALp168ahQ4cq3Pbw4cMvWmb16tWMGjUKgC5duhAVVfV/LmvXrqV///6Ehobi5ubGmDFjWLlyJe3atWPPnj08/PDDLFu2jICAAACioqIYN24cc+bMwc3N7ZKORW04XYsaoHWoD89dH8nj87fx/qoD3NOnraNLEqLOqEnL11Z8fHxKp5OSknjzzTdZt24dgYGBjBs3jtzc3IvWcXd3L512cXGhsLDiiws8PDwuWuZSH9Zd2fIhISEkJiayZMkSpk+fzvz585k5cybLli1jxYoVfPfdd7z44ots374dFxeXS9pnTThdi7rEzfEtGBjVmCk/7mH78QxHlyOEqKVz587h5+eHv78/J0+eZNmyZVbfR+/evfnyyy8B2LZtW4Ut9rISEhJYvnw5p0+fprCwkLlz59KnTx9SU1PRWnPTTTfx/PPPs2nTJoqKijh27Bj9+/fn9ddfJzU1lezsbKv/GSrilC1qAKUUk2/szMBp6Tw0dzM/PHglXu62/59LCGEbcXFxREZGEh0dTZs2bejVq5fV9/Hggw9y6623EhMTQ1xcHNHR0aXdFhVp3rw5L7zwAn379kVrzZAhQ7j22mvZtGkTd955J1prlFK8+uqrFBYWMmbMGDIzMykuLubxxx/Hz8/P6n+GiqhL/VXBEvHx8dpaDw74Y18aYz9cy+juEbw8rLNVtimEqJ8KCwspLCzE09OTpKQkBgwYQFJSEq6uTtsmLaWU2qi1jq9ontNXf0W7UCZc2YYZKw/Qt0MYA6IaO7okIYSTysrK4uqrr6awsBCtNTNmzKgTIV2dOvEn+OeAy/h9fxqPz08ktkUgjfw9HV2SEMIJBQYGsnHjRkeXYXVOezKxLHdXE9NGdiWnoIh/fiWX7AkhGhaLglopFaiU+loptVsptUsp1dPWhZXXrpEvT18XyaqkNGb9ftDeuxdCCIextEX9JrBUa90R6ALssl1JlRvTPYK/RYbz2tI9Vr/zSgghnFW1Qa2U8geuAj4E0Frna60dMhapUopXb4whwNuNh+duJregyBFlCCGEXVnSom4DpAKzlVKblVIfKKV8yi+klJqglNqglNqQmppq9UJLBPu4M/XmLiSlZPHyYoc07IUQ5fTt2/eiG1imTZvGfffdV+V6vr6+AJw4cYIRI0ZUuu3qLvedNm3aBTefDB482CpjcTz33HNMmTKl1tupLUuC2hWIA97VWncFzgMXjZCitZ6ptY7XWseHhYVZucwLXdk+jLt6t+aTPw/zy65km+5LCFG90aNHM3fu3As+mzt3LqNHj7Zo/aZNm/L111/XeP/lg3rx4sUEBgbWeHvOxpKgPgYc01qvNf/8NUZwO9S/Bl5Gx8Z+/PvrRFIyLx4vQAhhPyNGjGDRokXk5eUBcOjQIU6cOEHv3r1Lr22Oi4ujc+fOfPfddxetf+jQIaKjowHIyclh1KhRxMTEMHLkSHJyckqXu/fee0uHSX322WcBmD59OidOnKBfv37069cPgFatWpGWlgbA1KlTiY6OJjo6unSY1EOHDtGpUyfuvvtuoqKiGDBgwAX7qciWLVtISEggJiaGYcOGcfbs2dL9R0ZGEhMTUzog1IoVK0ofntC1a1cyMzNrfGzBguuotdanlFJHlVKXaa33AFcDVd9Abwceri68Nbor1721mn99lchH4y9HKeXosoRwvCWT4NQ2626zcWcYNLnS2SEhIXTv3p2lS5cydOhQ5s6dy8iRI1FK4enpyYIFC/D39yctLY2EhASuv/76Sv+9vvvuu3h7e5OYmEhiYuIFQ5W+9NJLBAcHU1RUxNVXX01iYiIPPfQQU6dOZfny5YSGhl6wrY0bNzJ79mzWrl2L1poePXrQp08fgoKCSEpK4osvvuD999/n5ptvZv78+VWOMX3rrbfy1ltv0adPH5555hmef/55pk2bxuTJkzl48CAeHh6l3S1TpkzhnXfeoVevXmRlZeHpWbt7Pyy96uNBYI5SKhGIBV6u1V6tpH24H09d24kVe1P56I9Dji5HiAatbPdH2W4PrTVPPPEEMTExXHPNNRw/fpzk5Mq7LFeuXFkamDExMcTE/PW0py+//JK4uDi6du3Kjh07qh10afXq1QwbNgwfHx98fX0ZPnw4q1atAqB169bExsYCVQ+nCsYY2enp6fTp0weA2267jZUrV5bWOHbsWD777LPSuyB79erFo48+yvTp00lPT6/13ZEWra213gJUeA+6o41LaMnyPam8smQ3PduG0LGxv6NLEsKxqmj52tINN9zAo48+yqZNm8jJySltCc+ZM4fU1FQ2btyIm5sbrVq1qnB407Iqam0fPHiQKVOmsH79eoKCgrj99tur3U5VYxmVDJMKxlCp1XV9VOaHH35g5cqVLFy4kP/+97/s2LGDSZMmce2117J48WISEhL4+eef6dixY422D3XkzsSqKKV4bUQM/p5uPPzFFrlkTwgH8fX1pW/fvtxxxx0XnETMyMigUaNGuLm5sXz5cg4fPlzldq666qrSh9hu376dxMREwBgm1cfHh4CAAJKTk1myZEnpOn5+fhX2A1911VV8++23ZGdnc/78eRYsWMCVV155yX+2gIAAgoKCSlvjn376KX369KG4uJijR4/Sr18/XnvtNdLT08nKymL//v107tyZxx9/nPj4eHbv3n3J+yyrToz1UZ1QXw+m3BTD7bPX88Q325hyUxdMJumvFsLeRo8ezfDhwy+4AmTs2LEMGTKE+Ph4YmNjq21Z3nvvvYwfP56YmBhiY2Pp3r07YDyxpWvXrkRFRV00TOqECRMYNGgQTZo0Yfny5aWfx8XFcfvtt5du46677qJr165VdnNU5uOPP2bixIlkZ2fTpk0bZs+eTVFREePGjSMjIwOtNf/4xz8IDAzk6aefZvny5bi4uBAZGVn6xJqacvphTi/F9F+SmPrTXsb2iODFG6Ll5KIQos6o08OcXooH+7cjO7+I91bsx8PVhaev6yRhLYSo8+pVUCuleHzgZeQWFDHr94N4uJn4998vk7AWQtRp9SqowQjrZ4dEkl9UzLu/7cfT1YWHr2nv6LKEEKLG6l1QgxHWLw6NJq+gmDd+3ounm0meZC6EqLPqZVADmEzGZXt5hUW8smQ3Hq4mbu/V2tFlCSHEJau3QQ3gYlK8MTKW/MJinvt+Jx5uLozuHuHosoQQ4pLU+RtequPmYuKtMV3pe1kYTyzYxjebjjm6JCGEuCT1PqjBGMDpvXHd6NkmhMe+2sqixBOOLkkIISzmXEGdlgTFxTbZtKebCx/cFk+3lkE8MncLP+44ZZP9CCGEtTlPUOeegw//BjOuhL3LwAZ3THq7uzLr9suJahbAA59v5rc9KVbfhxBCWJvzBLW7LwyeAvlZ8PnNMHswHFlb/XqXyM/TjU/Gd6ddI1/u+XQjf+xLs/o+hBDCmpwnqE0m6DwC7l8P1/4PzuyHWQPgi9GQbN3nFAR4u/HZXT1oGeLNnR9vYMOhM1bdvhBCWJPzBHUJV3e4/C54aDP0fxoOrYZ3r4AFEyH9iNV2E+zjzmd39aBJgCe3z17P1qMOebC6EEJUy/mCuoS7D1z1GDy8Fa54ALZ/A291Mx4zdN463RWN/DyZc3cPgnzcuHXWOnacyLDKdoUQwpqcN6hLeAfDgBeNFnbMSFg3A97sAr9NhrzaPTASoEmAF5/flYCPuwu3fLiOpOTab1MIIazJ+YO6REAzGPo23LcW2vaH316BN2NhzXtQmFerTbcI9mbO3QmYlOLeOZvkKTFCCKdSd4K6RFgHGPkp3PUrhEfC0sfhrXjY8gUU1zxgW4f68MbILuxLyWLykto9NkcIIayp7gV1iebd4NaFcMsC8A6CbyfCe72Nk481dGX7MG6/ohUf/XGIVUmpVixWCCFqru4GNYBSRjfI3b/BiNlQkA0fD4EVr9W4dT1pUEfaNfLlsa+2kp6db916hRCiBiwKaqXUIaXUNqXUFqWU/R+GWB2TCaKHw8TfofNNsPwl+Gw4ZF36nYeebi5MGxnL6ax8nlywvcrHzQshhD1cSou6n9Y6trKHLzoFD18YNgOufwuOrDG6Qg6uvOTNRDcL4B9/68AP207y7ZbjNihUCCEsV7e7PiqiFMTdCnf/Cp4B8MlQ+O3VS+4KmdinLfEtg3jm2x0cT8+xUbFCCFE9S4NaAz8qpTYqpSbYsiCrCY+Cu5cbXSG/vQyfDrukrpCShw4Ua80/v9xCcbF0gQghHMPSoO6ltY4DBgH3K6WuKr+AUmqCUmqDUmpDaqqTXDFR2hXyNhxda3SFHFhh8eotgr159voo1hw4wwerD9iwUCGEqJxFQa21PmF+TwEWAN0rWGam1jpeax0fFhZm3SprQymIu6VcV8hki7tCburWnAGR4UxZtpddJ8/ZuFghhLhYtUGtlPJRSvmVTAMDgO22LszqSrpCYkYadzV+egNkJle7mlKKV4Z3xt/LjX/M2yJ3LQoh7M6SFnU4sFoptRVYB/ygtV5q27JsxMMXhr0HQ9+Bo+st7goJ8fXg9REx7D6VydSf9tqhUCGE+Eu1Qa21PqC17mJ+RWmtX7JHYTajFHQdZ3SFeAUaXSHLX6m2K6Rfx0aM7RHB+6sO8Of+03YqVggh6uPleZYKjzS6QrqMghWTjcCupivkyWs70SrEh39+uYWMnAI7FSqEaOgablBDma6Q/4NjG+C9XnBwVaWLe7u78sbIWJIz83hu4Q47FiqEaMgadlCX6DoWJiwHryDjeuut8ypdNLZFIA/2b8eCzcdZlHjCjkUKIRoqCeoSjTrBnT9BRAIsmAArXq/0SegP9GtHlxaBPLlgO6cycu1cqBCioZGgLssrEMbNNy7hW/4iLHwQii7ui3Z1MTFtZCz5hcX86+utcteiEMKmJKjLc/Uw7ma86l+w+VP4fCTkXnyjS+tQH566rhOrktL4+M9Ddi9TCNFwSFBXRCno/5QxCt+B32D2YDh3cX/0mO4R9O/YiMlLdsuzFoUQNiNBXZW4W2Hsl3D2IHxwDSRfeKWHUorJN3bGx8OVR+ZtIb+w2EGFCiHqMwnq6rS7BsYvAV0MswbC/uUXzG7k58nk4Z3ZceIc036WuxaFENYnQW2JJjFw188Q0ALmjIDNcy6YPSCqMSPjW/Deiv2sP3TGQUUKIeorCWpLBTSHO5ZAq97w3X3GCHxlLt97ekgkzYK8ePzrRBm4SQhhVRLUl8IzAMZ8BbFjjRH4vrsfCo0H4Pp6uPLysM4cSDvP/y3f5+BChRD1iQT1pXJ1N0bf6/sEbJljdIXkZgBwZfswhndtxrsr9rNXrgIRQliJBHVNKAV9H4cb3oXDvxsnGTOOAcbATb4ervznm21yI4wQwiokqGsjdgyM/doI6Q+ugZOJhPh68NS1kWw8fJbP1x1xdIVCiHpAgrq22vaDO5aCMsHsQZD0E8PjmtGrXQivLtlN8jkZC0QIUTsS1NYQHmVcvhfcGj6/GfXHW7w0NJr8omIZDlUIUWsS1Nbi3xTuWAadhsBPT9Nq1aM82i+CJdtP8eOOU46uTghRh0lQW5O7D9z0MfR7EhLncff+B7miUT7PfLeDzFx5IowQomYkqK1NKejzbxj5GabU3Xxc8G+aZG3nfz/K7eVCiJqRoLaVTkPgrp9w8/DiK48XyVz7CZuPnHV0VUKIOkiC2pbCo4wH6EZ0539u77F/ziMUFEgXiBDi0khQ25pPCK63fsuRdmMZkfctJ969HnLSHV2VEKIOsTiolVIuSqnNSqlFtiyoXnJxI2Lc/zEn7FGanl5LwYx+kJbk6KqEEHXEpbSoHwZ22aqQhuCaWx7nLp4h+9xp9Pv9IeknR5ckhKgDLApqpVRz4FrgA9uWU7+F+3tyzaBhDM5+gQyPpjDnJvj9zUqfdi6EEGB5i3oa8G+g0mdNKaUmKKU2KKU2pKamWqW4+mhs9wgat+zAoMwnyeswBH56BhbcAwU5ji5NCOGkqg1qpdR1QIrWemNVy2mtZ2qt47XW8WFhYVYrsL4xmRSvDO9MWr4r/zE9Cv2egsR5lT5AVwghLGlR9wKuV0odAuYC/ZVSn9m0qnquQ7gfE/u05ZstJ1jV9HYYOQfS9sLMfnBkraPLE0I4mWqDWmv9H611c611K2AU8KvWepzNK6vn7u/XjtahPjy5YDs5bQfBnT+BmyfMHgi/vgRFcr21EMIg11E7iKebCy8P68yRM9m8+UsShEfCPSshZiSsfA0+/JtcwieEAC4xqLXWv2mtr7NVMQ1Nz7Yh3BzfnPdXHWDniXPGMxmHvWcM7HT2ELx3Jax7X64KEaKBkxa1gz0xuBOBXm7855tEikoe3RV1A9z7J7S8AhY/ZlzGlylDpQrRUElQO1igtzvPDIlk67EMPvnz0F8z/JvAuPkweAocWgX/1xN2fe+oMoUQDiRB7QSu79KUPh3CeH3ZHo6nl7meWinofjfcswoCI2DeOPj2fsg957hihRB2J0HtBJRSvHhDNFrDkwu2ocv3SYd1MK4KufIx2Po5vNcLDv/pmGKFEHYnQe0kWgR78++Bl/HbnlS+2njs4gVc3eHqp2G8+UG6Hw2Gn5+Hwnz7FyuEsCsJaidyW89WdG8dzH+/38mJ9EpuKY/oARNXQ9dxsHoqfHA1pOy2b6FCCLuSoHYiJpNiyoguFBZrJn1TQRdICQ8/uP4tGPU5nDsOM/vAmveguNKhWIQQdZgEtZOJCPHmP4M7snJvKvPWH6164Y7Xwn1roHUfWPo4fDYcMo7bp1AhhN1IUDuhcT1a0rNNCC/+sItjZ7OrXti3EYyZB9dNg6Nr4e14WP4y5GXZp1ghhM1JUDshk0nx2ogYtNY8Pj+x8i6QEkpB/HijdX3ZIFjxKkzvChs/gqJCu9QshLAdCWon1SLYmyeu7cTv+04zZ+0Ry1YKagkjZsFdv0BIW/j+YXivt/EkGbkNXYg6S4LaiY3pHkHvdqG8vHgXR89U0wVSVvN4GL8ERn4GRXkwZwR8egOc2ma7YoUQNiNB7cSUUky+sTMmpfj314kUF19Cq1gp6DQE7lsLA1+Fk1uNQZ6+vV8eUCBEHSNB7eSaB3nz1LWd+PPAaT5be/jSN+DqDgkT4aEtcMWDsO1LmB5njHmdl2n9goUQVidBXQeMvLwFV3UI45XFuzly+hK6QMryCoQB/4UH1kPHwcaY19PjYMNsOeEohJOToK4DlFK8emNnXE2Kx77eemldIOUFtbrwhOOiR+SEoxBOToK6jmgS4MXTQyJZd/AMH/95qPYbrOyE47ENtd+2EMKqJKjrkJu6NaffZWG8unQ3B9PO136DFZ1w/OBq+OAa2Pa1DPgkhJOQoK5DlFK8MjwGdxcT//pq619PhKmtkhOOj2yDQa9D9hmYfydM6wwrXoOsFOvsRwhRIxLUdUzjAE+eHRLFhsNnmf37Qetu3MMPekyABzbA2K+hcTQsfwneiIIFE+HEZuvuTwhhEQnqOmh4XDOu6dSI15ftYX+qDcb0MJmg/d+MR4E9sAG63W48BmxmX/hwAGyfD0UF1t+vEKJCEtR1kFKKl4d1xtPNxbpdIBUJbQ+DX4dHd8LAyUY3yNd3GN0iK1+H82m227cQApCgrrMa+XvywtAoNh1J58PVB2y/Q88ASLgXHtwEY76ERp3g1xdhaiR8e59xIlIIYRPVBrVSylMptU4ptVUptUMp9bw9ChPVu75LU/4eFc6UH/eyL8VOdxmaTNDh73DLArh/HcTdAju+hRlXwayBsOULyEm3Ty1CNBCquiE0lVIK8NFaZyml3IDVwMNa6zWVrRMfH683bJDrce0hNTOPAW+sICLEh/kTe+Lq4oBfknLSYcscWDcTzh4Ckxu06QuRQ42HG3gH278mIeoYpdRGrXV8RfOq/VetDSVnrNzML7mFzUmE+XnwwtBoth5NZ+YqO3SBVMQrEHreDw9uNu54TJgIaXth4QPwejv4ZCis/1Au8xOihqptUQMopVyAjUA74B2t9eMVLDMBmAAQERHR7fDhGgwgJGpEa839n2/i550pLHqoNx3C/RxdknE7+smtsGsh7PwOTu8DFLS8wmhpdxoC/k0dXaUQTqOqFrVFQV1mQ4HAAuBBrfX2ypaTrg/7O52Vx4A3VhLi686C+3rh4+Hq6JL+ojWk7DICe+d3kLrL+Lx5d4i8Hjpdbzz0QIgGzGpBbd7Ys8B5rfWUypaRoHaMVUmp3DZrHYOim/D2mK4YpxecUOpe2PUd7FwIpxKNz5rEGi3tDgMhrKNx0lKIBqRWQa2UCgMKtNbpSikv4EfgVa31osrWkaB2nBkr9vPKkt1MGtSRiX3aOrqc6p05YAT2roVwfKPxmVew0UVS8grvDC5O9BuCEDZQVVBb8u1vAnxs7qc2AV9WFdLCsSZc1YbE4xm8tnQ3kU38uapDmKNLqlpwG+j9iPFKPwoHV8LhP+Dw77Db/DVz94OIBHNw94KmXY3xSYRoIC6568MS0qJ2rOz8Qob/3x+czMjl+wd6ExHi7eiSaibjOBz50wjtw39A6m7jc1cvaHG5Edotr4Bm8eBeR/+MQphZtY/aEhLUjnf49HmGvLWapoFefHPfFXi714Oug/Np5ta2ucV9ahugjeu2m3UzQrv55RAeBYERxjCuQtQREtQN1G97Uhj/0XqGxDTlzVGxzntysaZy0uHo2r9a3Cc2Q7H5sWIe/kZgh0dBeLT5FQnuPo6tWYhK1LaPWtRRfS9rxGMDLuP1ZXuIaR7AXVe2cXRJ1uUVaNzO3uHvxs/55yF5ByRvh1Pbjemt8yD/A/MKCoJbm8O7s/HeOBoCIuQqE+HUJKjrufv6tmX78QxeXryLyCb+XNEu1NEl2Y67D7TobrxKaA3ph43QPrXdCPHkHbBrEaU32Lr7Ga3t8GgI7WB0mwS2MN49AxzyRxGiLOn6aACy8goZ9s7vpGXlsfCB3rQIlhNv5GUZJydPbTO3ws2vvIwLl/MMMFrcgREXBnhgBAS0AK8g6QsXViF91IKDaee5/u3VtAjyZv69V+Dl7uLokpyP1sYJy4wjkF7yOlpm+ggUlHtWpbvfhQHu3xR8w8G3Efg0MqZ9QsEkx1tUTYJaAPDr7mTu/HgDQ7s05Y2R9fDkoq1pDTlnLwzujHJBnnfu4vWUCbxDygW4OcR9w8E37K9pz0DpL2+g5GSiAKB/x3D+cU0Hpv60l5jmgdzRu7WjS6pblDKGbPUOhqaxFS+TlwXnU4yRArNSICvZeD9f5ue0fcZ7UV5FOzGeXenhZ1y54uEHnv7lfg6oZH6A0U/v5mlca+7qId0ytqK1cYVRUb7xWLqiAmMaDQHNrb47CeoG5oF+7dh2PIOXFu+iUxN/erYNcXRJ9YuHr/EKruYKG60hN6NMiJsDPecs5J4zWuZ554zp7DPGON95mcbPhTkWFqPAzQtcPS98r/QzL3BxM7pplKnMq+RnZbxXOF+V+VkZ+652mr/WQ/31mS42XsXmd11U5rMy02VfJZ8XF/71Kioo814yXWhMl8wrO7/svJLgLS4zXf7ziviGw2N7Lfz7sZx0fTRAmbkFDH3ndzKyC1j4YG+aBXo5uiRxKYoKjNAuCfKS6bxM41WYCwU55d5zoSC7knnZxvzCXCOEyodgnaTM/+m4GePEmNzMP7sarwvmlZvv4m5Mu7j9NW1ys+xzd1/oPKJmFUsftShvX0oWN7zzO61DffhqYk883eRkl6iA1uZXBa3b0pZs+fkaKLPeBdNc/Dkl65uz6KIWu6lcS77MfFO5lr3JxQjPOtjPL33U4iLtGvky9eYuTPh0I08u2M6Um2Lk5KK4mCrpkqh7wVefyNFvwAZENeahq9szf9MxPl0jT88x2msAABFiSURBVOQRwllJUDdwj1zdnqs7NuKF73ey7uAZR5cjhKiABHUDZzIp3hgVS0SwN/fN2cjJDEuvKBBC2IsEtcDf040Zt3QjJ7+I22etJy2rout7hRCOIkEtAGgf7sf7t8Zz+Mx5Rs9cQ0pmrqNLEkKYSVCLUle0C+Wj8d05np7DqJlrSD4nYS2EM5CgFhdIaBPCx3d0Jzkjl1Ez10iftRBOQIJaXOTyVsF8cmcP0jLzGDljDcfTJayFcCQJalGhbi2D+PSuHqRn5zNyxp8cPZPt6JKEaLAkqEWlYlsEMueuBDJzCxk5408Onz5f/UpCCKurNqiVUi2UUsuVUruUUjuUUg/bozDhHDo3D+Dzu3uQU1DEyBlrOJgmYS2EvVnSoi4E/qm17gQkAPcrpSJtW5ZwJlFNA/hiQgIFRcWMnPEn+1KyHF2SEA1KtUGttT6ptd5kns4EdgHNbF2YcC4dG/szd0ICxRpGzVzD3uRMR5ckRINxSX3USqlWQFdgrS2KEc6tfbgfcyckYFIweuYadp+q4LFTQgirsziolVK+wHzgEa31Rf9ClVITlFIblFIbUlNTrVmjcCLtGvky756euLmYGD1zDTtOZFS/khCiViwKaqWUG0ZIz9Faf1PRMlrrmVrreK11fFhYmDVrFE6mdagP8+5JwMvNhTHvr2XbMQlrIWzJkqs+FPAhsEtrPdX2JYm6oGWID/Pu6YmfpytjPljDlqPpji5JiHrLkhZ1L+AWoL9Saov5NdjGdYk6oEWwN/Pu6UmQtzu3fLCWjYfPOrokIeolS676WK21VlrrGK11rPm12B7FCefXLNCLefckEOrnwa0frmXNgdOOLkmIekfuTBS11iTAi7kTEmgc4MnYD9by7m/7KS62/kOThWioJKiFVYT7e7Lg/l4MjGrMq0t3M/6j9ZyWBxAIYRUS1MJq/D3deHtMV14aFs2fB04zePoq6QoRwgokqIVVKaUY26Ml397XCx93V8a8v4bpvyRRJF0hQtSYBLWwicim/nz/YG+GxjZj6k97uXXWWnm8lxA1JEEtbMbHw5WpN3fhtRExbDx8lsFvrmJ1UpqjyxKizpGgFjallOLm+BYsfKC3cb31rLVMWbaHwqJiR5cmRJ0hQS3sokO4Hwsf6M3N3Vrw9vJ9jHl/rTyPUQgLSVALu/Fyd+HVETFMGxnL9hMZDH5zFct3pzi6LCGcngS1sLsbujZj0YO9aRzgxfiP1vPK4l0USFeIEJWSoBYO0SbMlwX3XcG4hAhmrDzAzTP+5NhZeYCuEBWRoBYO4+nmwos3dObtMV3Zl5zF4DdXsXDrCbSWa66FKEuCWjjcdTFNWfRQb1qH+vDQF5u5ecafJB6TYVOFKCFBLZxCyxAfvrmvF68M78yB1PNc//bv/PPLrSSfk5tkhJCgFk7DxaQY3T2C5f/qyz192vD91hP0m/Ibb/2SRG5BkaPLE8JhJKiF0/H3dOM/gzrx86N96NMhjP/9tJf+U36T/mvRYElQC6cVEeLNu+O6MXdCAoHe7jz0xWZufPcPeeyXaHAkqIXTS2gTwvcP9ua1G2M4ciaHG975nX/M2yJ3NooGQ4Ja1AkuJsXNl7fgt3/15b6+bflh20n6TfmNaT/vJSdf+q9F/SZBLeoUXw9X/j2wI7882oerO4Uz7eck+v/vNxZsPiaP/xL1lgS1qJNaBHvzzpg4vrynJ6G+Hvxj3laGvfsHf+4/LSccRb2jbPGljo+P1xs2bLD6doWoSHGx5pvNx3lt6W5SMvOIaurPHb1aM6RLU9xdpS0i6gal1EatdXyF8ySoRX2Rk1/Egs3HmfX7QfalZBHm58GtCS0Z0yOCEF8PR5cnRJVqFdRKqVnAdUCK1jrakh1KUAtH0lqzMimND1cfZOXeVDxcTQzr2ozxvVpzWWM/R5cnRIVqG9RXAVnAJxLUoq5JSs5k1u+H+GbTMfIKi7myfSh39G5Nn/ZhmEzK0eUJUarWXR9KqVbAIglqUVedOZ/PF+uO8PEfh0jJzKNtmA/je7VmeFwzvN1dHV2eEPYJaqXUBGACQERERLfDhw/XqFghbCm/sJjF207y4eqDbDueQYCXG2N6RHBbz1Y0DvB0dHmiAZMWtRDlaK3ZcPgsH646yI87T2FSisGdm3BLz5Z0iwiSbhFhd1UFtfzOJxokpRSXtwrm8lbBHD2TzUd/HGLe+qMs3HqCJgGeDO7chGtjmtC1RSBKSWgLx5IWtRBmWXmF/LIrme+3nmTl3lTyi4ppFujFdTFGaHduFiChLWymtld9fAH0BUKBZOBZrfWHVa0jQS3quoycAn7amcwPiSdYlZRGYbGmZYg315pb2pFN/CW0hVXJDS9C1EJ6dj7LdpxiUeJJ/th/mqJiTZtQH3NLu6lcmy2sQoJaCCs5nZXH0h2nWLT1JGsPnqZYQ/tGvlwX05TrujShbZivo0sUdZQEtRA2kJKZy9LtRmivP3wGraFdI196twuld7tQEtqG4Osh5+uFZSSohbCxUxm5LN52kuV7Ulh38Ax5hcW4mhSxLQLp3d4I7i4tAnFzkUGiRMUkqIWwo9yCIjYdPsvqfWms3pfGtuMZaG2MpZ3QJthocbcPpW2Yr5yQFKUkqIVwoPTsfP7cf5pV+9L4fV8ah09nA9DY35Ne7UK5sn0oV7QLoZGf3BnZkElQC+FEjp7JLm1t/7EvjbPZBQB0bOxHj9bBxEYEEtsiiFYh3tLibkAkqIVwUsXFmp0nz7EqKY3V+1LZfCSdbPMzIAO93ejSPJAuLQLp2sJ4D/Zxd3DFwlYkqIWoI4qKNXuTM9l6NJ0t5tfe5ExKHgfZMsSbLs0DiW0RSGxEIJFN/PF0c3Fs0cIqJKiFqMPO5xWSeCyDrcfS2XLECO9T53IBcHNRdGribwR3i0CimwXQKsRHHkFWB0lQC1HPnMrIZcvRs2w5msGWo2dJPJZR2mXialK0DvWhfbgv7Rr50SHcl/aN/GgdKgHuzGT0PCHqmcYBngwMaMLA6CaA0WWSlJLJrpPnSErOYm9yFjtPnGPJ9lOUtMVcTIpWId60N4d3u3DjvXWoDx6u0n3izCSohagHXEyKjo396djY/4LPcwuK2J+axb6ULPYmZ5pDPJMfd54q7fd2MSlahnjTvpEvbcJ8aR7kRfMgb5oHedEs0Ev6wJ2ABLUQ9ZinmwtRTQOIahpwwee5BUUcTDtPUkoWSSUBnpLJr7tTKCi6sDs0zM/jgvCWILc/CWohGiBPNxc6NfGnU5MLW+BFxZqUzFyOnc3h2Nlsjp3JMabTs0k8ls7S7ScvCvJQX4/SAG8W6EW4v6f55UG4vyeN/D2ka6WWJKiFEKVcTIomAV40CfDi8lbBF82vOsgz+HFHMvlFxRetF+zjTiM/DxoHeBLu50l4gDnI/TxpHGCEeaiPhzwCrRIS1EIIi1UX5FprzmYXkHwut8wrj1Pnckk5l8upc7nsOHGOtKw8yl9w5mpShPi6E+TtTrCPO0E+7gR7uxPk7WZM+1w8z8u9YbTUJaiFEFajlCLYHKrlu1XKKiwqJjUrzwjxjFxSMnM5lZFLamYeZ7MLOJudz66T5zh7Pp/0nIKLQr2Ep5uJIO+/AjzQ2w1/Lzf8Pd3w93I1v7vh7+l60ed1qW9dgloIYXeuLqbSljktql62qFiTkVPAmfP5nM3O56z5/cz5AvP7X5+dSM/hXG4h53IKKuyCKcvd1XRRoPt5uuLr7oqvpys+Hq74erjg6+GGj4cLfp6u+Jjn+XoYLx8PVzxcTTYfk0WCWgjh1FxMf7XSL0VuQRHncgs4l1Nofi8oDfHKPj92NpvzeYWczysiK6/Qov24uShzqLvSNMCLLyf2rMkfs0oS1EKIesnTzQVPNxca1fCRlsXFmuyCIrJyC8nKM17n8wrJzDXez+f/NV0y391GD4aQoBZCiAqYTKq0i8PR5MZ/IYRwchLUQgjh5CwKaqXUQKXUHqXUPqXUJFsXJYQQ4i/VBrVSygV4BxgERAKjlVKRti5MCCGEwZIWdXdgn9b6gNY6H5gLDLVtWUIIIUpYEtTNgKNlfj5m/uwCSqkJSqkNSqkNqamp1qpPCCEaPEuCuqJbbi66oVNrPVNrHa+1jg8LC6t9ZUIIIQDLgvoYF97k2Rw4YZtyhBBClFftMxOVUq7AXuBq4DiwHhijtd5RxTqpwOEa1hQKpNVwXXuQ+mpH6qsdqa92nLm+llrrCrsjqr3lRmtdqJR6AFgGuACzqgpp8zo17vtQSm2o7AGPzkDqqx2pr3akvtpx9voqY9G9kVrrxcBiG9cihBCiAnJnohBCODlnDOqZji6gGlJf7Uh9tSP11Y6z11ehak8mCiGEcCxnbFELIYQoQ4JaCCGcnMOCuroR+ZRSHkqpeeb5a5VSrexYWwul1HKl1C6l1A6l1MMVLNNXKZWhlNpifj1jr/rM+z+klNpm3veGCuYrpdR08/FLVErF2bG2y8ocly1KqXNKqUfKLWPX46eUmqWUSlFKbS/zWbBS6ielVJL5PaiSdW8zL5OklLrNjvW9rpTabf77W6CUCqxk3Sq/Czas7zml1PEyf4eDK1nX5qNvVlLfvDK1HVJKbalkXZsfv1rTWtv9hXE99n6gDeAObAUiyy1zH/CeeXoUMM+O9TUB4szTfhg3/JSvry+wyBHHz7z/Q0BoFfMHA0swhgBIANY68O/6FMbF/A47fsBVQBywvcxnrwGTzNOTgFcrWC8YOGB+DzJPB9mpvgGAq3n61Yrqs+S7YMP6ngMes+Dvv8p/67aqr9z8/wHPOOr41fblqBa1JSPyDQU+Nk9/DVytbP2oXzOt9Umt9SbzdCawiwoGonJyQ4FPtGENEKiUauKAOq4G9muta3qnqlVorVcCZ8p9XPY79jFwQwWr/h34SWt9Rmt9FvgJGGiP+rTWP2qtS56wugZj+AaHqOT4WcIuo29WVZ85N24GvrD2fu3FUUFtyYh8pcuYv6wZQIhdqivD3OXSFVhbweyeSqmtSqklSqkouxZmDIz1o1Jqo1JqQgXzLRr10A5GUfk/EEceP4BwrfVJMP5zBhpVsIyzHMc7MH5Dqkh13wVbesDcNTOrkq4jZzh+VwLJWuukSuY78vhZxFFBbcmIfBaN2mdLSilfYD7wiNb6XLnZmzB+ne8CvAV8a8/agF5a6ziMBzrcr5S6qtx8Zzh+7sD1wFcVzHb08bOUMxzHJ4FCYE4li1T3XbCVd4G2QCxwEqN7oTyHHz9gNFW3ph11/CzmqKC2ZES+0mXMA0MFULNfvWpEKeWGEdJztNbflJ+vtT6ntc4yTy8G3JRSofaqT2t9wvyeAizA+BWzLGcY9XAQsElrnVx+hqOPn1lySXeQ+T2lgmUcehzNJy+vA8Zqc4dqeRZ8F2xCa52stS7SWhcD71eyX0cfP1dgODCvsmUcdfwuhaOCej3QXinV2tzqGgUsLLfMQqDkDPsI4NfKvqjWZu7T+hDYpbWeWskyjUv6zJVS3TGO5Wk71eejlPIrmcY46bS93GILgVvNV38kABklv+bbUaUtGUcevzLKfsduA76rYJllwAClVJD5V/sB5s9sTik1EHgcuF5rnV3JMpZ8F2xVX9lzHsMq2a8l/9Zt6Rpgt9b6WEUzHXn8LomjzmJiXJWwF+OM8JPmz17A+FICeGL8yrwPWAe0sWNtvTF+PUsEtphfg4GJwETzMg8AOzDOYq8BrrBjfW3M+91qrqHk+JWtT2E863I/sA2It/PfrzdG8AaU+cxhxw/jP4yTQAFGK+9OjHMevwBJ5vdg87LxwAdl1r3D/D3cB4y3Y337MPp3S76DJVdBNQUWV/VdsFN9n5q/W4kY4dukfH3mny/6t26P+syff1TynSuzrN2PX21fcgu5EEI4ObkzUQghnJwEtRBCODkJaiGEcHIS1EII4eQkqIUQwslJUAshhJOToBZCCCf3/wypPjMkbQFTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label = 'Training loss')\n",
    "plt.plot(valid_losses, label = 'Validation loss')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking into a sample of predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "getbatch = iter(get_batch(x_test, y_test , 16))\n",
    "sentences, verbs = next(getbatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "output = model(sentences.cuda().float())\n",
    "ps = torch.exp(output)\n",
    "top_p, top_class = ps.topk(10, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting\n",
      "\ttold\tplay\tfind\thead\ttour\twork\tmove\tbreak\texpected\ttravelled\t\n",
      "got\n",
      "\tgot\tsaid\truns\tright\ttop\tpushing\tnamed\tgerrard\tthink\tlooked\t\n",
      "break\n",
      "\ttalks\tsaid\tdeal\trewarded\trejected\texpires\tstart\ttour\tongoing\tsigned\t\n",
      "club\n",
      "\tclub\tforced\tmake\tworded\tsteven\tgerrard\tstep\tthink\tright\tstart\t\n",
      "feels\n",
      "\tfeels\tsuspended\ttest\tbegan\tstep\tknew\twithdrew\tbroke\thoping\tmade\t\n",
      "thumped\n",
      "\treturn\tthumped\tback\treferee\tsaid\tclaiming\tclose\tdraw\tscored\tbelieves\t\n",
      "given\n",
      "\tgiven\tcaptain\twins\truled\tnamed\tput\treturn\tireland\tlikes\tmissed\t\n",
      "following\n",
      "\tend\tfollowing\tcoach\tinjured\tskipper\tmoved\tset\tqualifying\tboss\tput\t\n",
      "took\n",
      "\ttook\tdriven\tdeclined\tstood\ttry\thits\tbacks\thelped\trumbled\tback\t\n",
      "opening\n",
      "\topening\theading\trun\tend\tknew\tqualifying\ttries\tclose\tfell\ttry\t\n",
      "keeper\n",
      "\ttold\tsigned\tboss\tquit\tagreed\twarned\tcaptain\tkeep\tdrawn\tcalled\t\n",
      "squad\n",
      "\treturns\ttaking\trest\trun\tdefend\tset\tback\twin\tstart\tleaving\t\n",
      "asked\n",
      "\tasked\twanted\tstraight\tsee\tknow\twant\ttold\tsay\tlive\tthink\t\n",
      "avoid\n",
      "\tneeding\tsecond\tneeded\tmaintain\tset\tsuffered\tround\tstraight\tclinch\tsixth\t\n",
      "insists\n",
      "\tconsidered\tinsists\tadmits\treturn\tround\tclub\thamstring\tsaid\tknocked\trecall\t\n",
      "prove\n",
      "\tprove\tsee\tcoach\tworking\ttour\tcalling\tthink\tsquad\tlooked\tlike\t\n"
     ]
    }
   ],
   "source": [
    "for clas, t in zip(top_class, verbs):\n",
    "    print(corpus.get_verb_from_index(t.item()) , ': ')\n",
    "    print('\\t' ,  end='' )\n",
    "    for val in clas:\n",
    "        print(corpus.get_verb_from_index(val.item()), end='\\t' )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['official', 'line', 'irish', 'ball', 'lewsey', 'josh']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 8\n",
    "sent = np.where(np.array(sentences[i]) != 0)[0]\n",
    "corpus.get_vocab_from_index(sent.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = top_p[i].tolist()\n",
    "vrbs = corpus.get_verb_from_index(top_class[i].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "props = dict(boxstyle='round', facecolor='grey', alpha=0.2)\n",
    "ax.text(0.05, 0.95, 'Input: '+str(corpus.get_vocab_from_index(sent.tolist())), transform=ax.transAxes, fontsize=10, verticalalignment='top', bbox=props)\n",
    "ax.text(0.05, 0.85, 'Target: '+corpus.get_verb_from_index(verbs[i].item()), transform=ax.transAxes, fontsize=10, verticalalignment='top', bbox=props)\n",
    "ax.barh(vrbs, probs, align='center')\n",
    "plt.xlabel('Probabilities')\n",
    "plt.ylabel('Predicted Verbs')\n",
    "ax.set_xticks(np.arange(0,1.1,0.1))\n",
    "ax.xaxis.grid(True)\n",
    "plt.savefig(category+'-probs.pdf', dpi=500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5- Obtaining prediction results when learning the verbs in technology articles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'tech'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting:...-> Lemmatize = False , window = 3 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.650592 \tValidation Loss: 6.109626\n",
      "Validation loss decreased (inf --> 6.10963).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.168304 \tValidation Loss: 5.970748\n",
      "Validation loss decreased (6.10963 --> 5.97075).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.886780 \tValidation Loss: 5.748413\n",
      "Validation loss decreased (5.97075 --> 5.74841).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.447449 \tValidation Loss: 5.460475\n",
      "Validation loss decreased (5.74841 --> 5.46047).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.879715 \tValidation Loss: 5.157799\n",
      "Validation loss decreased (5.46047 --> 5.15780).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.261708 \tValidation Loss: 4.887161\n",
      "Validation loss decreased (5.15780 --> 4.88716).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.680004 \tValidation Loss: 4.675061\n",
      "Validation loss decreased (4.88716 --> 4.67506).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.184083 \tValidation Loss: 4.519666\n",
      "Validation loss decreased (4.67506 --> 4.51967).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.785582 \tValidation Loss: 4.411056\n",
      "Validation loss decreased (4.51967 --> 4.41106).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.471808 \tValidation Loss: 4.339887\n",
      "Validation loss decreased (4.41106 --> 4.33989).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.225474 \tValidation Loss: 4.293959\n",
      "Validation loss decreased (4.33989 --> 4.29396).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.031358 \tValidation Loss: 4.266460\n",
      "Validation loss decreased (4.29396 --> 4.26646).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.876451 \tValidation Loss: 4.254573\n",
      "Validation loss decreased (4.26646 --> 4.25457).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.755082 \tValidation Loss: 4.254025\n",
      "Validation loss decreased (4.25457 --> 4.25402).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.654293 \tValidation Loss: 4.263787\n",
      "Epoch: 16 \tTraining Loss: 1.571266 \tValidation Loss: 4.280677\n",
      "Epoch: 17 \tTraining Loss: 1.501028 \tValidation Loss: 4.299851\n",
      "Epoch: 18 \tTraining Loss: 1.446357 \tValidation Loss: 4.323399\n",
      "Epoch: 19 \tTraining Loss: 1.397781 \tValidation Loss: 4.352329\n",
      "Epoch: 20 \tTraining Loss: 1.356916 \tValidation Loss: 4.382635\n",
      "Epoch: 1 \tTraining Loss: 6.656908 \tValidation Loss: 6.106692\n",
      "Validation loss decreased (inf --> 6.10669).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.159897 \tValidation Loss: 5.954503\n",
      "Validation loss decreased (6.10669 --> 5.95450).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.867784 \tValidation Loss: 5.727332\n",
      "Validation loss decreased (5.95450 --> 5.72733).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.424093 \tValidation Loss: 5.438814\n",
      "Validation loss decreased (5.72733 --> 5.43881).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.861107 \tValidation Loss: 5.137353\n",
      "Validation loss decreased (5.43881 --> 5.13735).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.252695 \tValidation Loss: 4.866131\n",
      "Validation loss decreased (5.13735 --> 4.86613).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.677864 \tValidation Loss: 4.647808\n",
      "Validation loss decreased (4.86613 --> 4.64781).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.186508 \tValidation Loss: 4.487987\n",
      "Validation loss decreased (4.64781 --> 4.48799).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.787581 \tValidation Loss: 4.375880\n",
      "Validation loss decreased (4.48799 --> 4.37588).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.477924 \tValidation Loss: 4.299886\n",
      "Validation loss decreased (4.37588 --> 4.29989).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.228803 \tValidation Loss: 4.251734\n",
      "Validation loss decreased (4.29989 --> 4.25173).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.036432 \tValidation Loss: 4.222607\n",
      "Validation loss decreased (4.25173 --> 4.22261).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.880821 \tValidation Loss: 4.209566\n",
      "Validation loss decreased (4.22261 --> 4.20957).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.757451 \tValidation Loss: 4.209494\n",
      "Validation loss decreased (4.20957 --> 4.20949).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.657235 \tValidation Loss: 4.217929\n",
      "Epoch: 16 \tTraining Loss: 1.577472 \tValidation Loss: 4.230997\n",
      "Epoch: 17 \tTraining Loss: 1.508357 \tValidation Loss: 4.254084\n",
      "Epoch: 18 \tTraining Loss: 1.447241 \tValidation Loss: 4.278128\n",
      "Epoch: 19 \tTraining Loss: 1.402374 \tValidation Loss: 4.307411\n",
      "Epoch: 20 \tTraining Loss: 1.359319 \tValidation Loss: 4.337594\n",
      "Epoch: 1 \tTraining Loss: 6.659987 \tValidation Loss: 6.090795\n",
      "Validation loss decreased (inf --> 6.09080).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.168391 \tValidation Loss: 5.947644\n",
      "Validation loss decreased (6.09080 --> 5.94764).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.880466 \tValidation Loss: 5.721091\n",
      "Validation loss decreased (5.94764 --> 5.72109).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.431778 \tValidation Loss: 5.432784\n",
      "Validation loss decreased (5.72109 --> 5.43278).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.863237 \tValidation Loss: 5.135008\n",
      "Validation loss decreased (5.43278 --> 5.13501).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.252630 \tValidation Loss: 4.865971\n",
      "Validation loss decreased (5.13501 --> 4.86597).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.676143 \tValidation Loss: 4.652614\n",
      "Validation loss decreased (4.86597 --> 4.65261).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.187753 \tValidation Loss: 4.498258\n",
      "Validation loss decreased (4.65261 --> 4.49826).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.790133 \tValidation Loss: 4.391738\n",
      "Validation loss decreased (4.49826 --> 4.39174).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.476607 \tValidation Loss: 4.319390\n",
      "Validation loss decreased (4.39174 --> 4.31939).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.230385 \tValidation Loss: 4.275461\n",
      "Validation loss decreased (4.31939 --> 4.27546).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.035455 \tValidation Loss: 4.251895\n",
      "Validation loss decreased (4.27546 --> 4.25189).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.880261 \tValidation Loss: 4.242055\n",
      "Validation loss decreased (4.25189 --> 4.24206).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.756622 \tValidation Loss: 4.241668\n",
      "Validation loss decreased (4.24206 --> 4.24167).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.656684 \tValidation Loss: 4.248845\n",
      "Epoch: 16 \tTraining Loss: 1.573428 \tValidation Loss: 4.262740\n",
      "Epoch: 17 \tTraining Loss: 1.504515 \tValidation Loss: 4.283785\n",
      "Epoch: 18 \tTraining Loss: 1.444820 \tValidation Loss: 4.309034\n",
      "Epoch: 19 \tTraining Loss: 1.396406 \tValidation Loss: 4.335435\n",
      "Epoch: 20 \tTraining Loss: 1.356628 \tValidation Loss: 4.367790\n",
      "Epoch: 1 \tTraining Loss: 6.655447 \tValidation Loss: 6.105034\n",
      "Validation loss decreased (inf --> 6.10503).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.160681 \tValidation Loss: 5.956091\n",
      "Validation loss decreased (6.10503 --> 5.95609).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.870387 \tValidation Loss: 5.728470\n",
      "Validation loss decreased (5.95609 --> 5.72847).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.427227 \tValidation Loss: 5.435485\n",
      "Validation loss decreased (5.72847 --> 5.43549).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.862354 \tValidation Loss: 5.134647\n",
      "Validation loss decreased (5.43549 --> 5.13465).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.251660 \tValidation Loss: 4.868157\n",
      "Validation loss decreased (5.13465 --> 4.86816).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.674680 \tValidation Loss: 4.658092\n",
      "Validation loss decreased (4.86816 --> 4.65809).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.183017 \tValidation Loss: 4.504423\n",
      "Validation loss decreased (4.65809 --> 4.50442).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.787880 \tValidation Loss: 4.394814\n",
      "Validation loss decreased (4.50442 --> 4.39481).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.476149 \tValidation Loss: 4.320386\n",
      "Validation loss decreased (4.39481 --> 4.32039).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.231336 \tValidation Loss: 4.272134\n",
      "Validation loss decreased (4.32039 --> 4.27213).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.038287 \tValidation Loss: 4.243896\n",
      "Validation loss decreased (4.27213 --> 4.24390).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.881285 \tValidation Loss: 4.231197\n",
      "Validation loss decreased (4.24390 --> 4.23120).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 \tTraining Loss: 1.759983 \tValidation Loss: 4.231416\n",
      "Epoch: 15 \tTraining Loss: 1.660636 \tValidation Loss: 4.236756\n",
      "Epoch: 16 \tTraining Loss: 1.574689 \tValidation Loss: 4.252353\n",
      "Epoch: 17 \tTraining Loss: 1.506427 \tValidation Loss: 4.273470\n",
      "Epoch: 18 \tTraining Loss: 1.450455 \tValidation Loss: 4.297932\n",
      "Epoch: 19 \tTraining Loss: 1.403677 \tValidation Loss: 4.324033\n",
      "Epoch: 20 \tTraining Loss: 1.355965 \tValidation Loss: 4.354522\n",
      "Epoch: 1 \tTraining Loss: 6.649862 \tValidation Loss: 6.143558\n",
      "Validation loss decreased (inf --> 6.14356).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.160882 \tValidation Loss: 6.007074\n",
      "Validation loss decreased (6.14356 --> 6.00707).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.876364 \tValidation Loss: 5.785992\n",
      "Validation loss decreased (6.00707 --> 5.78599).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.435913 \tValidation Loss: 5.500904\n",
      "Validation loss decreased (5.78599 --> 5.50090).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.873930 \tValidation Loss: 5.202164\n",
      "Validation loss decreased (5.50090 --> 5.20216).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.264499 \tValidation Loss: 4.934861\n",
      "Validation loss decreased (5.20216 --> 4.93486).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.685527 \tValidation Loss: 4.723968\n",
      "Validation loss decreased (4.93486 --> 4.72397).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.192707 \tValidation Loss: 4.570603\n",
      "Validation loss decreased (4.72397 --> 4.57060).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.794941 \tValidation Loss: 4.461395\n",
      "Validation loss decreased (4.57060 --> 4.46139).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.481501 \tValidation Loss: 4.385702\n",
      "Validation loss decreased (4.46139 --> 4.38570).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.235432 \tValidation Loss: 4.336355\n",
      "Validation loss decreased (4.38570 --> 4.33636).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.040066 \tValidation Loss: 4.309102\n",
      "Validation loss decreased (4.33636 --> 4.30910).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.887119 \tValidation Loss: 4.295267\n",
      "Validation loss decreased (4.30910 --> 4.29527).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.760889 \tValidation Loss: 4.294724\n",
      "Validation loss decreased (4.29527 --> 4.29472).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.663174 \tValidation Loss: 4.302412\n",
      "Epoch: 16 \tTraining Loss: 1.577245 \tValidation Loss: 4.316246\n",
      "Epoch: 17 \tTraining Loss: 1.510399 \tValidation Loss: 4.335915\n",
      "Epoch: 18 \tTraining Loss: 1.452403 \tValidation Loss: 4.364250\n",
      "Epoch: 19 \tTraining Loss: 1.402222 \tValidation Loss: 4.395120\n",
      "Epoch: 20 \tTraining Loss: 1.363714 \tValidation Loss: 4.426603\n",
      "Epoch: 1 \tTraining Loss: 6.651496 \tValidation Loss: 6.097282\n",
      "Validation loss decreased (inf --> 6.09728).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.167981 \tValidation Loss: 5.957649\n",
      "Validation loss decreased (6.09728 --> 5.95765).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.881134 \tValidation Loss: 5.741206\n",
      "Validation loss decreased (5.95765 --> 5.74121).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.439075 \tValidation Loss: 5.457154\n",
      "Validation loss decreased (5.74121 --> 5.45715).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.874373 \tValidation Loss: 5.156307\n",
      "Validation loss decreased (5.45715 --> 5.15631).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.260582 \tValidation Loss: 4.882183\n",
      "Validation loss decreased (5.15631 --> 4.88218).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.677023 \tValidation Loss: 4.659540\n",
      "Validation loss decreased (4.88218 --> 4.65954).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.184548 \tValidation Loss: 4.495316\n",
      "Validation loss decreased (4.65954 --> 4.49532).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.787214 \tValidation Loss: 4.380083\n",
      "Validation loss decreased (4.49532 --> 4.38008).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.471567 \tValidation Loss: 4.301250\n",
      "Validation loss decreased (4.38008 --> 4.30125).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.227095 \tValidation Loss: 4.251135\n",
      "Validation loss decreased (4.30125 --> 4.25114).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.032257 \tValidation Loss: 4.221282\n",
      "Validation loss decreased (4.25114 --> 4.22128).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.878234 \tValidation Loss: 4.206082\n",
      "Validation loss decreased (4.22128 --> 4.20608).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.755513 \tValidation Loss: 4.204373\n",
      "Validation loss decreased (4.20608 --> 4.20437).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.656158 \tValidation Loss: 4.212424\n",
      "Epoch: 16 \tTraining Loss: 1.572721 \tValidation Loss: 4.227185\n",
      "Epoch: 17 \tTraining Loss: 1.505022 \tValidation Loss: 4.248439\n",
      "Epoch: 18 \tTraining Loss: 1.448223 \tValidation Loss: 4.271284\n",
      "Epoch: 19 \tTraining Loss: 1.401641 \tValidation Loss: 4.301294\n",
      "Epoch: 20 \tTraining Loss: 1.362489 \tValidation Loss: 4.330933\n",
      "Epoch: 1 \tTraining Loss: 6.653259 \tValidation Loss: 6.077773\n",
      "Validation loss decreased (inf --> 6.07777).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.166153 \tValidation Loss: 5.939108\n",
      "Validation loss decreased (6.07777 --> 5.93911).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.880790 \tValidation Loss: 5.718567\n",
      "Validation loss decreased (5.93911 --> 5.71857).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.437107 \tValidation Loss: 5.430566\n",
      "Validation loss decreased (5.71857 --> 5.43057).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.871421 \tValidation Loss: 5.133419\n",
      "Validation loss decreased (5.43057 --> 5.13342).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.260044 \tValidation Loss: 4.864900\n",
      "Validation loss decreased (5.13342 --> 4.86490).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.681441 \tValidation Loss: 4.650857\n",
      "Validation loss decreased (4.86490 --> 4.65086).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.187040 \tValidation Loss: 4.494848\n",
      "Validation loss decreased (4.65086 --> 4.49485).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.791431 \tValidation Loss: 4.385788\n",
      "Validation loss decreased (4.49485 --> 4.38579).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.475686 \tValidation Loss: 4.310804\n",
      "Validation loss decreased (4.38579 --> 4.31080).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.229026 \tValidation Loss: 4.263332\n",
      "Validation loss decreased (4.31080 --> 4.26333).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.036106 \tValidation Loss: 4.236708\n",
      "Validation loss decreased (4.26333 --> 4.23671).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.883665 \tValidation Loss: 4.226601\n",
      "Validation loss decreased (4.23671 --> 4.22660).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.759769 \tValidation Loss: 4.226961\n",
      "Epoch: 15 \tTraining Loss: 1.656901 \tValidation Loss: 4.235778\n",
      "Epoch: 16 \tTraining Loss: 1.573096 \tValidation Loss: 4.251557\n",
      "Epoch: 17 \tTraining Loss: 1.505411 \tValidation Loss: 4.274071\n",
      "Epoch: 18 \tTraining Loss: 1.447134 \tValidation Loss: 4.301229\n",
      "Epoch: 19 \tTraining Loss: 1.400977 \tValidation Loss: 4.329553\n",
      "Epoch: 20 \tTraining Loss: 1.359367 \tValidation Loss: 4.361250\n",
      "Epoch: 1 \tTraining Loss: 6.646764 \tValidation Loss: 6.119176\n",
      "Validation loss decreased (inf --> 6.11918).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.160950 \tValidation Loss: 5.983493\n",
      "Validation loss decreased (6.11918 --> 5.98349).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.874245 \tValidation Loss: 5.768775\n",
      "Validation loss decreased (5.98349 --> 5.76878).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.433602 \tValidation Loss: 5.485943\n",
      "Validation loss decreased (5.76878 --> 5.48594).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.871812 \tValidation Loss: 5.183689\n",
      "Validation loss decreased (5.48594 --> 5.18369).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.264073 \tValidation Loss: 4.903344\n",
      "Validation loss decreased (5.18369 --> 4.90334).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.686571 \tValidation Loss: 4.673897\n",
      "Validation loss decreased (4.90334 --> 4.67390).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.192145 \tValidation Loss: 4.502997\n",
      "Validation loss decreased (4.67390 --> 4.50300).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.791349 \tValidation Loss: 4.384392\n",
      "Validation loss decreased (4.50300 --> 4.38439).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.478891 \tValidation Loss: 4.304959\n",
      "Validation loss decreased (4.38439 --> 4.30496).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.230996 \tValidation Loss: 4.254320\n",
      "Validation loss decreased (4.30496 --> 4.25432).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 \tTraining Loss: 2.034692 \tValidation Loss: 4.222850\n",
      "Validation loss decreased (4.25432 --> 4.22285).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.881789 \tValidation Loss: 4.208470\n",
      "Validation loss decreased (4.22285 --> 4.20847).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.758124 \tValidation Loss: 4.204765\n",
      "Validation loss decreased (4.20847 --> 4.20477).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.655572 \tValidation Loss: 4.211185\n",
      "Epoch: 16 \tTraining Loss: 1.576117 \tValidation Loss: 4.226928\n",
      "Epoch: 17 \tTraining Loss: 1.506352 \tValidation Loss: 4.245986\n",
      "Epoch: 18 \tTraining Loss: 1.450718 \tValidation Loss: 4.270054\n",
      "Epoch: 19 \tTraining Loss: 1.402580 \tValidation Loss: 4.298672\n",
      "Epoch: 20 \tTraining Loss: 1.357513 \tValidation Loss: 4.329343\n",
      "Epoch: 1 \tTraining Loss: 6.651689 \tValidation Loss: 6.112896\n",
      "Validation loss decreased (inf --> 6.11290).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.169310 \tValidation Loss: 5.975051\n",
      "Validation loss decreased (6.11290 --> 5.97505).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.884571 \tValidation Loss: 5.753866\n",
      "Validation loss decreased (5.97505 --> 5.75387).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.440326 \tValidation Loss: 5.459654\n",
      "Validation loss decreased (5.75387 --> 5.45965).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.870759 \tValidation Loss: 5.154759\n",
      "Validation loss decreased (5.45965 --> 5.15476).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.258969 \tValidation Loss: 4.882597\n",
      "Validation loss decreased (5.15476 --> 4.88260).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.680257 \tValidation Loss: 4.665871\n",
      "Validation loss decreased (4.88260 --> 4.66587).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.186217 \tValidation Loss: 4.506220\n",
      "Validation loss decreased (4.66587 --> 4.50622).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.785278 \tValidation Loss: 4.397241\n",
      "Validation loss decreased (4.50622 --> 4.39724).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.470673 \tValidation Loss: 4.324946\n",
      "Validation loss decreased (4.39724 --> 4.32495).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.223313 \tValidation Loss: 4.281610\n",
      "Validation loss decreased (4.32495 --> 4.28161).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.029995 \tValidation Loss: 4.259227\n",
      "Validation loss decreased (4.28161 --> 4.25923).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.875099 \tValidation Loss: 4.250699\n",
      "Validation loss decreased (4.25923 --> 4.25070).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.751976 \tValidation Loss: 4.252389\n",
      "Epoch: 15 \tTraining Loss: 1.650942 \tValidation Loss: 4.265291\n",
      "Epoch: 16 \tTraining Loss: 1.569675 \tValidation Loss: 4.282165\n",
      "Epoch: 17 \tTraining Loss: 1.498666 \tValidation Loss: 4.304933\n",
      "Epoch: 18 \tTraining Loss: 1.443779 \tValidation Loss: 4.332319\n",
      "Epoch: 19 \tTraining Loss: 1.393964 \tValidation Loss: 4.362355\n",
      "Epoch: 20 \tTraining Loss: 1.357223 \tValidation Loss: 4.395870\n",
      "Epoch: 1 \tTraining Loss: 6.656203 \tValidation Loss: 6.090430\n",
      "Validation loss decreased (inf --> 6.09043).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.163272 \tValidation Loss: 5.943558\n",
      "Validation loss decreased (6.09043 --> 5.94356).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.876792 \tValidation Loss: 5.717406\n",
      "Validation loss decreased (5.94356 --> 5.71741).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 5.434925 \tValidation Loss: 5.426200\n",
      "Validation loss decreased (5.71741 --> 5.42620).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.869287 \tValidation Loss: 5.122331\n",
      "Validation loss decreased (5.42620 --> 5.12233).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 4.256267 \tValidation Loss: 4.850268\n",
      "Validation loss decreased (5.12233 --> 4.85027).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.680158 \tValidation Loss: 4.630763\n",
      "Validation loss decreased (4.85027 --> 4.63076).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.185462 \tValidation Loss: 4.467066\n",
      "Validation loss decreased (4.63076 --> 4.46707).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.787821 \tValidation Loss: 4.351346\n",
      "Validation loss decreased (4.46707 --> 4.35135).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.474801 \tValidation Loss: 4.273143\n",
      "Validation loss decreased (4.35135 --> 4.27314).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.228864 \tValidation Loss: 4.222353\n",
      "Validation loss decreased (4.27314 --> 4.22235).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.035823 \tValidation Loss: 4.191474\n",
      "Validation loss decreased (4.22235 --> 4.19147).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.880198 \tValidation Loss: 4.175518\n",
      "Validation loss decreased (4.19147 --> 4.17552).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.756570 \tValidation Loss: 4.172638\n",
      "Validation loss decreased (4.17552 --> 4.17264).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 1.656142 \tValidation Loss: 4.180600\n",
      "Epoch: 16 \tTraining Loss: 1.574410 \tValidation Loss: 4.194660\n",
      "Epoch: 17 \tTraining Loss: 1.506255 \tValidation Loss: 4.216018\n",
      "Epoch: 18 \tTraining Loss: 1.451507 \tValidation Loss: 4.237818\n",
      "Epoch: 19 \tTraining Loss: 1.402550 \tValidation Loss: 4.264389\n",
      "Epoch: 20 \tTraining Loss: 1.360727 \tValidation Loss: 4.296784\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 4 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.658517 \tValidation Loss: 5.976302\n",
      "Validation loss decreased (inf --> 5.97630).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.090251 \tValidation Loss: 5.724090\n",
      "Validation loss decreased (5.97630 --> 5.72409).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.592302 \tValidation Loss: 5.309262\n",
      "Validation loss decreased (5.72409 --> 5.30926).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.846388 \tValidation Loss: 4.819502\n",
      "Validation loss decreased (5.30926 --> 4.81950).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.000844 \tValidation Loss: 4.364054\n",
      "Validation loss decreased (4.81950 --> 4.36405).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.229652 \tValidation Loss: 4.000302\n",
      "Validation loss decreased (4.36405 --> 4.00030).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.612496 \tValidation Loss: 3.731169\n",
      "Validation loss decreased (4.00030 --> 3.73117).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.139289 \tValidation Loss: 3.537446\n",
      "Validation loss decreased (3.73117 --> 3.53745).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.788150 \tValidation Loss: 3.398809\n",
      "Validation loss decreased (3.53745 --> 3.39881).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.525436 \tValidation Loss: 3.303876\n",
      "Validation loss decreased (3.39881 --> 3.30388).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.323346 \tValidation Loss: 3.240420\n",
      "Validation loss decreased (3.30388 --> 3.24042).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.168538 \tValidation Loss: 3.197153\n",
      "Validation loss decreased (3.24042 --> 3.19715).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.043409 \tValidation Loss: 3.171532\n",
      "Validation loss decreased (3.19715 --> 3.17153).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.948346 \tValidation Loss: 3.162567\n",
      "Validation loss decreased (3.17153 --> 3.16257).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.866659 \tValidation Loss: 3.160284\n",
      "Validation loss decreased (3.16257 --> 3.16028).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.800505 \tValidation Loss: 3.168757\n",
      "Epoch: 17 \tTraining Loss: 0.745417 \tValidation Loss: 3.182312\n",
      "Epoch: 18 \tTraining Loss: 0.700407 \tValidation Loss: 3.203040\n",
      "Epoch: 19 \tTraining Loss: 0.665304 \tValidation Loss: 3.221851\n",
      "Epoch: 20 \tTraining Loss: 0.629429 \tValidation Loss: 3.249585\n",
      "Epoch: 1 \tTraining Loss: 6.660983 \tValidation Loss: 5.962267\n",
      "Validation loss decreased (inf --> 5.96227).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.085637 \tValidation Loss: 5.706386\n",
      "Validation loss decreased (5.96227 --> 5.70639).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.578058 \tValidation Loss: 5.296350\n",
      "Validation loss decreased (5.70639 --> 5.29635).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.828572 \tValidation Loss: 4.801587\n",
      "Validation loss decreased (5.29635 --> 4.80159).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.981690 \tValidation Loss: 4.337747\n",
      "Validation loss decreased (4.80159 --> 4.33775).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.206806 \tValidation Loss: 3.970952\n",
      "Validation loss decreased (4.33775 --> 3.97095).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.589796 \tValidation Loss: 3.706474\n",
      "Validation loss decreased (3.97095 --> 3.70647).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 \tTraining Loss: 2.122789 \tValidation Loss: 3.516954\n",
      "Validation loss decreased (3.70647 --> 3.51695).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.771719 \tValidation Loss: 3.383704\n",
      "Validation loss decreased (3.51695 --> 3.38370).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.510670 \tValidation Loss: 3.290271\n",
      "Validation loss decreased (3.38370 --> 3.29027).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.311734 \tValidation Loss: 3.229172\n",
      "Validation loss decreased (3.29027 --> 3.22917).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.154608 \tValidation Loss: 3.188571\n",
      "Validation loss decreased (3.22917 --> 3.18857).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.034346 \tValidation Loss: 3.165745\n",
      "Validation loss decreased (3.18857 --> 3.16574).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.935244 \tValidation Loss: 3.154884\n",
      "Validation loss decreased (3.16574 --> 3.15488).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.857274 \tValidation Loss: 3.155184\n",
      "Epoch: 16 \tTraining Loss: 0.792055 \tValidation Loss: 3.164184\n",
      "Epoch: 17 \tTraining Loss: 0.739386 \tValidation Loss: 3.178001\n",
      "Epoch: 18 \tTraining Loss: 0.694648 \tValidation Loss: 3.199849\n",
      "Epoch: 19 \tTraining Loss: 0.656625 \tValidation Loss: 3.222319\n",
      "Epoch: 20 \tTraining Loss: 0.623252 \tValidation Loss: 3.251446\n",
      "Epoch: 1 \tTraining Loss: 6.659556 \tValidation Loss: 5.933850\n",
      "Validation loss decreased (inf --> 5.93385).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.086608 \tValidation Loss: 5.678391\n",
      "Validation loss decreased (5.93385 --> 5.67839).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.579808 \tValidation Loss: 5.270114\n",
      "Validation loss decreased (5.67839 --> 5.27011).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.833914 \tValidation Loss: 4.787548\n",
      "Validation loss decreased (5.27011 --> 4.78755).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.991931 \tValidation Loss: 4.342128\n",
      "Validation loss decreased (4.78755 --> 4.34213).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.221493 \tValidation Loss: 3.990759\n",
      "Validation loss decreased (4.34213 --> 3.99076).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.602548 \tValidation Loss: 3.736378\n",
      "Validation loss decreased (3.99076 --> 3.73638).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.130437 \tValidation Loss: 3.557557\n",
      "Validation loss decreased (3.73638 --> 3.55756).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.781262 \tValidation Loss: 3.431474\n",
      "Validation loss decreased (3.55756 --> 3.43147).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.518606 \tValidation Loss: 3.343273\n",
      "Validation loss decreased (3.43147 --> 3.34327).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.313301 \tValidation Loss: 3.285702\n",
      "Validation loss decreased (3.34327 --> 3.28570).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.160664 \tValidation Loss: 3.246605\n",
      "Validation loss decreased (3.28570 --> 3.24661).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.039033 \tValidation Loss: 3.226710\n",
      "Validation loss decreased (3.24661 --> 3.22671).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.939352 \tValidation Loss: 3.218011\n",
      "Validation loss decreased (3.22671 --> 3.21801).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.860964 \tValidation Loss: 3.221208\n",
      "Epoch: 16 \tTraining Loss: 0.796941 \tValidation Loss: 3.227924\n",
      "Epoch: 17 \tTraining Loss: 0.740941 \tValidation Loss: 3.242246\n",
      "Epoch: 18 \tTraining Loss: 0.696587 \tValidation Loss: 3.262354\n",
      "Epoch: 19 \tTraining Loss: 0.658105 \tValidation Loss: 3.287485\n",
      "Epoch: 20 \tTraining Loss: 0.627423 \tValidation Loss: 3.313657\n",
      "Epoch: 1 \tTraining Loss: 6.662395 \tValidation Loss: 5.958386\n",
      "Validation loss decreased (inf --> 5.95839).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.085324 \tValidation Loss: 5.700082\n",
      "Validation loss decreased (5.95839 --> 5.70008).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.578611 \tValidation Loss: 5.284203\n",
      "Validation loss decreased (5.70008 --> 5.28420).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.831607 \tValidation Loss: 4.790639\n",
      "Validation loss decreased (5.28420 --> 4.79064).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.992465 \tValidation Loss: 4.334837\n",
      "Validation loss decreased (4.79064 --> 4.33484).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.224716 \tValidation Loss: 3.973859\n",
      "Validation loss decreased (4.33484 --> 3.97386).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.607437 \tValidation Loss: 3.708687\n",
      "Validation loss decreased (3.97386 --> 3.70869).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.141709 \tValidation Loss: 3.518873\n",
      "Validation loss decreased (3.70869 --> 3.51887).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.788641 \tValidation Loss: 3.386177\n",
      "Validation loss decreased (3.51887 --> 3.38618).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.523015 \tValidation Loss: 3.290844\n",
      "Validation loss decreased (3.38618 --> 3.29084).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.323132 \tValidation Loss: 3.224287\n",
      "Validation loss decreased (3.29084 --> 3.22429).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.166877 \tValidation Loss: 3.181982\n",
      "Validation loss decreased (3.22429 --> 3.18198).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.043554 \tValidation Loss: 3.160164\n",
      "Validation loss decreased (3.18198 --> 3.16016).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.944114 \tValidation Loss: 3.147388\n",
      "Validation loss decreased (3.16016 --> 3.14739).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.865517 \tValidation Loss: 3.146936\n",
      "Validation loss decreased (3.14739 --> 3.14694).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.797950 \tValidation Loss: 3.155686\n",
      "Epoch: 17 \tTraining Loss: 0.746337 \tValidation Loss: 3.169493\n",
      "Epoch: 18 \tTraining Loss: 0.699184 \tValidation Loss: 3.187587\n",
      "Epoch: 19 \tTraining Loss: 0.661371 \tValidation Loss: 3.209677\n",
      "Epoch: 20 \tTraining Loss: 0.627677 \tValidation Loss: 3.237867\n",
      "Epoch: 1 \tTraining Loss: 6.658636 \tValidation Loss: 5.939672\n",
      "Validation loss decreased (inf --> 5.93967).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.089973 \tValidation Loss: 5.685755\n",
      "Validation loss decreased (5.93967 --> 5.68575).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.585563 \tValidation Loss: 5.276282\n",
      "Validation loss decreased (5.68575 --> 5.27628).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.836791 \tValidation Loss: 4.797208\n",
      "Validation loss decreased (5.27628 --> 4.79721).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.993116 \tValidation Loss: 4.349466\n",
      "Validation loss decreased (4.79721 --> 4.34947).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.225649 \tValidation Loss: 3.989821\n",
      "Validation loss decreased (4.34947 --> 3.98982).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.607820 \tValidation Loss: 3.724640\n",
      "Validation loss decreased (3.98982 --> 3.72464).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.136897 \tValidation Loss: 3.537478\n",
      "Validation loss decreased (3.72464 --> 3.53748).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.785427 \tValidation Loss: 3.405758\n",
      "Validation loss decreased (3.53748 --> 3.40576).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.521863 \tValidation Loss: 3.314513\n",
      "Validation loss decreased (3.40576 --> 3.31451).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.315766 \tValidation Loss: 3.253298\n",
      "Validation loss decreased (3.31451 --> 3.25330).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.159095 \tValidation Loss: 3.214870\n",
      "Validation loss decreased (3.25330 --> 3.21487).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.036485 \tValidation Loss: 3.192330\n",
      "Validation loss decreased (3.21487 --> 3.19233).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.935036 \tValidation Loss: 3.185107\n",
      "Validation loss decreased (3.19233 --> 3.18511).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.860219 \tValidation Loss: 3.187999\n",
      "Epoch: 16 \tTraining Loss: 0.791177 \tValidation Loss: 3.197001\n",
      "Epoch: 17 \tTraining Loss: 0.738922 \tValidation Loss: 3.211406\n",
      "Epoch: 18 \tTraining Loss: 0.694239 \tValidation Loss: 3.233722\n",
      "Epoch: 19 \tTraining Loss: 0.656764 \tValidation Loss: 3.257221\n",
      "Epoch: 20 \tTraining Loss: 0.623210 \tValidation Loss: 3.282167\n",
      "Epoch: 1 \tTraining Loss: 6.656190 \tValidation Loss: 5.960903\n",
      "Validation loss decreased (inf --> 5.96090).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.091555 \tValidation Loss: 5.712746\n",
      "Validation loss decreased (5.96090 --> 5.71275).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.592993 \tValidation Loss: 5.302579\n",
      "Validation loss decreased (5.71275 --> 5.30258).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 \tTraining Loss: 4.855042 \tValidation Loss: 4.813033\n",
      "Validation loss decreased (5.30258 --> 4.81303).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.016308 \tValidation Loss: 4.353063\n",
      "Validation loss decreased (4.81303 --> 4.35306).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.240598 \tValidation Loss: 3.984221\n",
      "Validation loss decreased (4.35306 --> 3.98422).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.618298 \tValidation Loss: 3.712157\n",
      "Validation loss decreased (3.98422 --> 3.71216).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.145776 \tValidation Loss: 3.514682\n",
      "Validation loss decreased (3.71216 --> 3.51468).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.790879 \tValidation Loss: 3.375241\n",
      "Validation loss decreased (3.51468 --> 3.37524).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.525651 \tValidation Loss: 3.273644\n",
      "Validation loss decreased (3.37524 --> 3.27364).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.323864 \tValidation Loss: 3.206152\n",
      "Validation loss decreased (3.27364 --> 3.20615).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.168231 \tValidation Loss: 3.163340\n",
      "Validation loss decreased (3.20615 --> 3.16334).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.045922 \tValidation Loss: 3.137638\n",
      "Validation loss decreased (3.16334 --> 3.13764).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.946852 \tValidation Loss: 3.127248\n",
      "Validation loss decreased (3.13764 --> 3.12725).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.866022 \tValidation Loss: 3.127215\n",
      "Validation loss decreased (3.12725 --> 3.12722).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.800379 \tValidation Loss: 3.135041\n",
      "Epoch: 17 \tTraining Loss: 0.744732 \tValidation Loss: 3.150279\n",
      "Epoch: 18 \tTraining Loss: 0.698144 \tValidation Loss: 3.167876\n",
      "Epoch: 19 \tTraining Loss: 0.662607 \tValidation Loss: 3.195769\n",
      "Epoch: 20 \tTraining Loss: 0.628722 \tValidation Loss: 3.219286\n",
      "Epoch: 1 \tTraining Loss: 6.660471 \tValidation Loss: 5.975325\n",
      "Validation loss decreased (inf --> 5.97532).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.087429 \tValidation Loss: 5.721089\n",
      "Validation loss decreased (5.97532 --> 5.72109).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.583934 \tValidation Loss: 5.307617\n",
      "Validation loss decreased (5.72109 --> 5.30762).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.834166 \tValidation Loss: 4.815519\n",
      "Validation loss decreased (5.30762 --> 4.81552).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.990539 \tValidation Loss: 4.357450\n",
      "Validation loss decreased (4.81552 --> 4.35745).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.222933 \tValidation Loss: 3.993981\n",
      "Validation loss decreased (4.35745 --> 3.99398).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.604752 \tValidation Loss: 3.725842\n",
      "Validation loss decreased (3.99398 --> 3.72584).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.136511 \tValidation Loss: 3.532646\n",
      "Validation loss decreased (3.72584 --> 3.53265).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.783125 \tValidation Loss: 3.393868\n",
      "Validation loss decreased (3.53265 --> 3.39387).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.520698 \tValidation Loss: 3.300145\n",
      "Validation loss decreased (3.39387 --> 3.30015).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.319178 \tValidation Loss: 3.231604\n",
      "Validation loss decreased (3.30015 --> 3.23160).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.163641 \tValidation Loss: 3.189896\n",
      "Validation loss decreased (3.23160 --> 3.18990).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.040851 \tValidation Loss: 3.165355\n",
      "Validation loss decreased (3.18990 --> 3.16535).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.940797 \tValidation Loss: 3.152826\n",
      "Validation loss decreased (3.16535 --> 3.15283).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.860215 \tValidation Loss: 3.154301\n",
      "Epoch: 16 \tTraining Loss: 0.799605 \tValidation Loss: 3.160473\n",
      "Epoch: 17 \tTraining Loss: 0.743391 \tValidation Loss: 3.175982\n",
      "Epoch: 18 \tTraining Loss: 0.697102 \tValidation Loss: 3.193093\n",
      "Epoch: 19 \tTraining Loss: 0.663245 \tValidation Loss: 3.218465\n",
      "Epoch: 20 \tTraining Loss: 0.624091 \tValidation Loss: 3.242554\n",
      "Epoch: 1 \tTraining Loss: 6.660331 \tValidation Loss: 5.961983\n",
      "Validation loss decreased (inf --> 5.96198).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.088337 \tValidation Loss: 5.710625\n",
      "Validation loss decreased (5.96198 --> 5.71062).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.583065 \tValidation Loss: 5.309086\n",
      "Validation loss decreased (5.71062 --> 5.30909).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.832384 \tValidation Loss: 4.830597\n",
      "Validation loss decreased (5.30909 --> 4.83060).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.989555 \tValidation Loss: 4.385868\n",
      "Validation loss decreased (4.83060 --> 4.38587).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.220598 \tValidation Loss: 4.032389\n",
      "Validation loss decreased (4.38587 --> 4.03239).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.603484 \tValidation Loss: 3.771105\n",
      "Validation loss decreased (4.03239 --> 3.77110).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.135875 \tValidation Loss: 3.583110\n",
      "Validation loss decreased (3.77110 --> 3.58311).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.785387 \tValidation Loss: 3.450076\n",
      "Validation loss decreased (3.58311 --> 3.45008).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.520114 \tValidation Loss: 3.356716\n",
      "Validation loss decreased (3.45008 --> 3.35672).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.318726 \tValidation Loss: 3.292299\n",
      "Validation loss decreased (3.35672 --> 3.29230).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.161931 \tValidation Loss: 3.251215\n",
      "Validation loss decreased (3.29230 --> 3.25121).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.039156 \tValidation Loss: 3.227331\n",
      "Validation loss decreased (3.25121 --> 3.22733).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.939635 \tValidation Loss: 3.216679\n",
      "Validation loss decreased (3.22733 --> 3.21668).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.860799 \tValidation Loss: 3.217858\n",
      "Epoch: 16 \tTraining Loss: 0.794529 \tValidation Loss: 3.226368\n",
      "Epoch: 17 \tTraining Loss: 0.741602 \tValidation Loss: 3.239803\n",
      "Epoch: 18 \tTraining Loss: 0.695862 \tValidation Loss: 3.261671\n",
      "Epoch: 19 \tTraining Loss: 0.658124 \tValidation Loss: 3.285383\n",
      "Epoch: 20 \tTraining Loss: 0.625264 \tValidation Loss: 3.309243\n",
      "Epoch: 1 \tTraining Loss: 6.651339 \tValidation Loss: 5.966455\n",
      "Validation loss decreased (inf --> 5.96646).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.094417 \tValidation Loss: 5.719573\n",
      "Validation loss decreased (5.96646 --> 5.71957).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.596252 \tValidation Loss: 5.311920\n",
      "Validation loss decreased (5.71957 --> 5.31192).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.851453 \tValidation Loss: 4.816270\n",
      "Validation loss decreased (5.31192 --> 4.81627).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.009832 \tValidation Loss: 4.352326\n",
      "Validation loss decreased (4.81627 --> 4.35233).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.234637 \tValidation Loss: 3.982962\n",
      "Validation loss decreased (4.35233 --> 3.98296).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.615771 \tValidation Loss: 3.713717\n",
      "Validation loss decreased (3.98296 --> 3.71372).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.142315 \tValidation Loss: 3.521134\n",
      "Validation loss decreased (3.71372 --> 3.52113).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.791956 \tValidation Loss: 3.384550\n",
      "Validation loss decreased (3.52113 --> 3.38455).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.524250 \tValidation Loss: 3.288321\n",
      "Validation loss decreased (3.38455 --> 3.28832).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.322501 \tValidation Loss: 3.223766\n",
      "Validation loss decreased (3.28832 --> 3.22377).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.165335 \tValidation Loss: 3.182622\n",
      "Validation loss decreased (3.22377 --> 3.18262).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.041713 \tValidation Loss: 3.157871\n",
      "Validation loss decreased (3.18262 --> 3.15787).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.943553 \tValidation Loss: 3.146657\n",
      "Validation loss decreased (3.15787 --> 3.14666).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.862088 \tValidation Loss: 3.146985\n",
      "Epoch: 16 \tTraining Loss: 0.794240 \tValidation Loss: 3.157367\n",
      "Epoch: 17 \tTraining Loss: 0.742292 \tValidation Loss: 3.172230\n",
      "Epoch: 18 \tTraining Loss: 0.698685 \tValidation Loss: 3.191104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 \tTraining Loss: 0.659809 \tValidation Loss: 3.213482\n",
      "Epoch: 20 \tTraining Loss: 0.623521 \tValidation Loss: 3.238484\n",
      "Epoch: 1 \tTraining Loss: 6.666756 \tValidation Loss: 5.991655\n",
      "Validation loss decreased (inf --> 5.99166).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 6.096434 \tValidation Loss: 5.734284\n",
      "Validation loss decreased (5.99166 --> 5.73428).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.599718 \tValidation Loss: 5.322657\n",
      "Validation loss decreased (5.73428 --> 5.32266).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.857489 \tValidation Loss: 4.832966\n",
      "Validation loss decreased (5.32266 --> 4.83297).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.016659 \tValidation Loss: 4.364322\n",
      "Validation loss decreased (4.83297 --> 4.36432).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.239520 \tValidation Loss: 3.985911\n",
      "Validation loss decreased (4.36432 --> 3.98591).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.617718 \tValidation Loss: 3.707361\n",
      "Validation loss decreased (3.98591 --> 3.70736).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.143979 \tValidation Loss: 3.507567\n",
      "Validation loss decreased (3.70736 --> 3.50757).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.792119 \tValidation Loss: 3.366963\n",
      "Validation loss decreased (3.50757 --> 3.36696).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.525010 \tValidation Loss: 3.268825\n",
      "Validation loss decreased (3.36696 --> 3.26882).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.321325 \tValidation Loss: 3.200457\n",
      "Validation loss decreased (3.26882 --> 3.20046).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.166337 \tValidation Loss: 3.153993\n",
      "Validation loss decreased (3.20046 --> 3.15399).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.040276 \tValidation Loss: 3.123596\n",
      "Validation loss decreased (3.15399 --> 3.12360).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.940329 \tValidation Loss: 3.110242\n",
      "Validation loss decreased (3.12360 --> 3.11024).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.861468 \tValidation Loss: 3.105846\n",
      "Validation loss decreased (3.11024 --> 3.10585).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.794732 \tValidation Loss: 3.110291\n",
      "Epoch: 17 \tTraining Loss: 0.743669 \tValidation Loss: 3.122504\n",
      "Epoch: 18 \tTraining Loss: 0.698742 \tValidation Loss: 3.141074\n",
      "Epoch: 19 \tTraining Loss: 0.658200 \tValidation Loss: 3.160410\n",
      "Epoch: 20 \tTraining Loss: 0.625722 \tValidation Loss: 3.181447\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 5 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.593562 \tValidation Loss: 5.659046\n",
      "Validation loss decreased (inf --> 5.65905).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.934152 \tValidation Loss: 5.327689\n",
      "Validation loss decreased (5.65905 --> 5.32769).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.283989 \tValidation Loss: 4.814912\n",
      "Validation loss decreased (5.32769 --> 4.81491).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.370313 \tValidation Loss: 4.238335\n",
      "Validation loss decreased (4.81491 --> 4.23833).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.431855 \tValidation Loss: 3.735310\n",
      "Validation loss decreased (4.23833 --> 3.73531).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.648879 \tValidation Loss: 3.359333\n",
      "Validation loss decreased (3.73531 --> 3.35933).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.059415 \tValidation Loss: 3.093078\n",
      "Validation loss decreased (3.35933 --> 3.09308).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.627708 \tValidation Loss: 2.907315\n",
      "Validation loss decreased (3.09308 --> 2.90731).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.313627 \tValidation Loss: 2.778893\n",
      "Validation loss decreased (2.90731 --> 2.77889).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.081858 \tValidation Loss: 2.688203\n",
      "Validation loss decreased (2.77889 --> 2.68820).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.903979 \tValidation Loss: 2.627290\n",
      "Validation loss decreased (2.68820 --> 2.62729).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.768377 \tValidation Loss: 2.588574\n",
      "Validation loss decreased (2.62729 --> 2.58857).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.664381 \tValidation Loss: 2.562686\n",
      "Validation loss decreased (2.58857 --> 2.56269).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.580003 \tValidation Loss: 2.553941\n",
      "Validation loss decreased (2.56269 --> 2.55394).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.513486 \tValidation Loss: 2.554309\n",
      "Epoch: 16 \tTraining Loss: 0.463004 \tValidation Loss: 2.562752\n",
      "Epoch: 17 \tTraining Loss: 0.418840 \tValidation Loss: 2.573441\n",
      "Epoch: 18 \tTraining Loss: 0.386524 \tValidation Loss: 2.586515\n",
      "Epoch: 19 \tTraining Loss: 0.358780 \tValidation Loss: 2.608765\n",
      "Epoch: 20 \tTraining Loss: 0.334670 \tValidation Loss: 2.628830\n",
      "Epoch: 1 \tTraining Loss: 6.586603 \tValidation Loss: 5.643970\n",
      "Validation loss decreased (inf --> 5.64397).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.935159 \tValidation Loss: 5.324739\n",
      "Validation loss decreased (5.64397 --> 5.32474).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.282290 \tValidation Loss: 4.818794\n",
      "Validation loss decreased (5.32474 --> 4.81879).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.365001 \tValidation Loss: 4.248301\n",
      "Validation loss decreased (4.81879 --> 4.24830).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.419973 \tValidation Loss: 3.763387\n",
      "Validation loss decreased (4.24830 --> 3.76339).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.637126 \tValidation Loss: 3.401261\n",
      "Validation loss decreased (3.76339 --> 3.40126).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.049056 \tValidation Loss: 3.140583\n",
      "Validation loss decreased (3.40126 --> 3.14058).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.617357 \tValidation Loss: 2.954835\n",
      "Validation loss decreased (3.14058 --> 2.95484).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.299154 \tValidation Loss: 2.824655\n",
      "Validation loss decreased (2.95484 --> 2.82465).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.069587 \tValidation Loss: 2.733075\n",
      "Validation loss decreased (2.82465 --> 2.73308).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.892451 \tValidation Loss: 2.672090\n",
      "Validation loss decreased (2.73308 --> 2.67209).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.758817 \tValidation Loss: 2.633792\n",
      "Validation loss decreased (2.67209 --> 2.63379).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.653900 \tValidation Loss: 2.609465\n",
      "Validation loss decreased (2.63379 --> 2.60946).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.572671 \tValidation Loss: 2.599396\n",
      "Validation loss decreased (2.60946 --> 2.59940).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.508003 \tValidation Loss: 2.603519\n",
      "Epoch: 16 \tTraining Loss: 0.455622 \tValidation Loss: 2.611142\n",
      "Epoch: 17 \tTraining Loss: 0.413253 \tValidation Loss: 2.622677\n",
      "Epoch: 18 \tTraining Loss: 0.379626 \tValidation Loss: 2.639347\n",
      "Epoch: 19 \tTraining Loss: 0.349810 \tValidation Loss: 2.658147\n",
      "Epoch: 20 \tTraining Loss: 0.329513 \tValidation Loss: 2.681491\n",
      "Epoch: 1 \tTraining Loss: 6.586679 \tValidation Loss: 5.645748\n",
      "Validation loss decreased (inf --> 5.64575).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.931931 \tValidation Loss: 5.320231\n",
      "Validation loss decreased (5.64575 --> 5.32023).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.277086 \tValidation Loss: 4.799509\n",
      "Validation loss decreased (5.32023 --> 4.79951).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.357623 \tValidation Loss: 4.211085\n",
      "Validation loss decreased (4.79951 --> 4.21108).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.411520 \tValidation Loss: 3.702262\n",
      "Validation loss decreased (4.21108 --> 3.70226).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.621621 \tValidation Loss: 3.324530\n",
      "Validation loss decreased (3.70226 --> 3.32453).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.028764 \tValidation Loss: 3.062805\n",
      "Validation loss decreased (3.32453 --> 3.06280).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.599412 \tValidation Loss: 2.880545\n",
      "Validation loss decreased (3.06280 --> 2.88055).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.287286 \tValidation Loss: 2.752817\n",
      "Validation loss decreased (2.88055 --> 2.75282).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.055144 \tValidation Loss: 2.663990\n",
      "Validation loss decreased (2.75282 --> 2.66399).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.883110 \tValidation Loss: 2.605578\n",
      "Validation loss decreased (2.66399 --> 2.60558).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.752445 \tValidation Loss: 2.567773\n",
      "Validation loss decreased (2.60558 --> 2.56777).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 \tTraining Loss: 0.645938 \tValidation Loss: 2.545925\n",
      "Validation loss decreased (2.56777 --> 2.54592).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.563344 \tValidation Loss: 2.535090\n",
      "Validation loss decreased (2.54592 --> 2.53509).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.501096 \tValidation Loss: 2.534384\n",
      "Validation loss decreased (2.53509 --> 2.53438).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.449283 \tValidation Loss: 2.539698\n",
      "Epoch: 17 \tTraining Loss: 0.409962 \tValidation Loss: 2.555196\n",
      "Epoch: 18 \tTraining Loss: 0.377608 \tValidation Loss: 2.568546\n",
      "Epoch: 19 \tTraining Loss: 0.346685 \tValidation Loss: 2.590887\n",
      "Epoch: 20 \tTraining Loss: 0.324647 \tValidation Loss: 2.609777\n",
      "Epoch: 1 \tTraining Loss: 6.587440 \tValidation Loss: 5.637474\n",
      "Validation loss decreased (inf --> 5.63747).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.928996 \tValidation Loss: 5.320217\n",
      "Validation loss decreased (5.63747 --> 5.32022).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.276946 \tValidation Loss: 4.816473\n",
      "Validation loss decreased (5.32022 --> 4.81647).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.352233 \tValidation Loss: 4.251242\n",
      "Validation loss decreased (4.81647 --> 4.25124).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.404796 \tValidation Loss: 3.769824\n",
      "Validation loss decreased (4.25124 --> 3.76982).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.624444 \tValidation Loss: 3.408266\n",
      "Validation loss decreased (3.76982 --> 3.40827).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.039354 \tValidation Loss: 3.146663\n",
      "Validation loss decreased (3.40827 --> 3.14666).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.610983 \tValidation Loss: 2.956832\n",
      "Validation loss decreased (3.14666 --> 2.95683).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.298165 \tValidation Loss: 2.818999\n",
      "Validation loss decreased (2.95683 --> 2.81900).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.068244 \tValidation Loss: 2.721577\n",
      "Validation loss decreased (2.81900 --> 2.72158).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.893701 \tValidation Loss: 2.652902\n",
      "Validation loss decreased (2.72158 --> 2.65290).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.756965 \tValidation Loss: 2.608532\n",
      "Validation loss decreased (2.65290 --> 2.60853).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.654035 \tValidation Loss: 2.580323\n",
      "Validation loss decreased (2.60853 --> 2.58032).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.574551 \tValidation Loss: 2.565999\n",
      "Validation loss decreased (2.58032 --> 2.56600).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.507329 \tValidation Loss: 2.563538\n",
      "Validation loss decreased (2.56600 --> 2.56354).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.455535 \tValidation Loss: 2.564432\n",
      "Epoch: 17 \tTraining Loss: 0.414194 \tValidation Loss: 2.573226\n",
      "Epoch: 18 \tTraining Loss: 0.378853 \tValidation Loss: 2.588517\n",
      "Epoch: 19 \tTraining Loss: 0.352648 \tValidation Loss: 2.605223\n",
      "Epoch: 20 \tTraining Loss: 0.329168 \tValidation Loss: 2.624097\n",
      "Epoch: 1 \tTraining Loss: 6.587157 \tValidation Loss: 5.625619\n",
      "Validation loss decreased (inf --> 5.62562).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.942859 \tValidation Loss: 5.296178\n",
      "Validation loss decreased (5.62562 --> 5.29618).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.296202 \tValidation Loss: 4.780302\n",
      "Validation loss decreased (5.29618 --> 4.78030).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.378058 \tValidation Loss: 4.194302\n",
      "Validation loss decreased (4.78030 --> 4.19430).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.429552 \tValidation Loss: 3.687849\n",
      "Validation loss decreased (4.19430 --> 3.68785).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.644249 \tValidation Loss: 3.312124\n",
      "Validation loss decreased (3.68785 --> 3.31212).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.053846 \tValidation Loss: 3.041646\n",
      "Validation loss decreased (3.31212 --> 3.04165).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.624712 \tValidation Loss: 2.846418\n",
      "Validation loss decreased (3.04165 --> 2.84642).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.309851 \tValidation Loss: 2.709685\n",
      "Validation loss decreased (2.84642 --> 2.70968).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.075177 \tValidation Loss: 2.614511\n",
      "Validation loss decreased (2.70968 --> 2.61451).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.898694 \tValidation Loss: 2.550132\n",
      "Validation loss decreased (2.61451 --> 2.55013).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.763203 \tValidation Loss: 2.509095\n",
      "Validation loss decreased (2.55013 --> 2.50909).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.659369 \tValidation Loss: 2.484930\n",
      "Validation loss decreased (2.50909 --> 2.48493).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.576315 \tValidation Loss: 2.472353\n",
      "Validation loss decreased (2.48493 --> 2.47235).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.510505 \tValidation Loss: 2.467202\n",
      "Validation loss decreased (2.47235 --> 2.46720).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.460509 \tValidation Loss: 2.473536\n",
      "Epoch: 17 \tTraining Loss: 0.416440 \tValidation Loss: 2.479370\n",
      "Epoch: 18 \tTraining Loss: 0.385659 \tValidation Loss: 2.493051\n",
      "Epoch: 19 \tTraining Loss: 0.353930 \tValidation Loss: 2.509208\n",
      "Epoch: 20 \tTraining Loss: 0.329396 \tValidation Loss: 2.528258\n",
      "Epoch: 1 \tTraining Loss: 6.581416 \tValidation Loss: 5.643502\n",
      "Validation loss decreased (inf --> 5.64350).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.934824 \tValidation Loss: 5.327599\n",
      "Validation loss decreased (5.64350 --> 5.32760).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.294521 \tValidation Loss: 4.816599\n",
      "Validation loss decreased (5.32760 --> 4.81660).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.370861 \tValidation Loss: 4.239658\n",
      "Validation loss decreased (4.81660 --> 4.23966).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.412216 \tValidation Loss: 3.751809\n",
      "Validation loss decreased (4.23966 --> 3.75181).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.620865 \tValidation Loss: 3.387824\n",
      "Validation loss decreased (3.75181 --> 3.38782).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.029352 \tValidation Loss: 3.125755\n",
      "Validation loss decreased (3.38782 --> 3.12576).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.600307 \tValidation Loss: 2.938588\n",
      "Validation loss decreased (3.12576 --> 2.93859).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.290150 \tValidation Loss: 2.807207\n",
      "Validation loss decreased (2.93859 --> 2.80721).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.057955 \tValidation Loss: 2.717918\n",
      "Validation loss decreased (2.80721 --> 2.71792).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.885198 \tValidation Loss: 2.658048\n",
      "Validation loss decreased (2.71792 --> 2.65805).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.750114 \tValidation Loss: 2.618348\n",
      "Validation loss decreased (2.65805 --> 2.61835).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.646077 \tValidation Loss: 2.598809\n",
      "Validation loss decreased (2.61835 --> 2.59881).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.566472 \tValidation Loss: 2.591270\n",
      "Validation loss decreased (2.59881 --> 2.59127).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.503452 \tValidation Loss: 2.592016\n",
      "Epoch: 16 \tTraining Loss: 0.451602 \tValidation Loss: 2.598750\n",
      "Epoch: 17 \tTraining Loss: 0.410521 \tValidation Loss: 2.613005\n",
      "Epoch: 18 \tTraining Loss: 0.374891 \tValidation Loss: 2.629669\n",
      "Epoch: 19 \tTraining Loss: 0.350032 \tValidation Loss: 2.647514\n",
      "Epoch: 20 \tTraining Loss: 0.325755 \tValidation Loss: 2.672259\n",
      "Epoch: 1 \tTraining Loss: 6.589994 \tValidation Loss: 5.637208\n",
      "Validation loss decreased (inf --> 5.63721).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.941475 \tValidation Loss: 5.310450\n",
      "Validation loss decreased (5.63721 --> 5.31045).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.288676 \tValidation Loss: 4.795258\n",
      "Validation loss decreased (5.31045 --> 4.79526).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.361866 \tValidation Loss: 4.219191\n",
      "Validation loss decreased (4.79526 --> 4.21919).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.410517 \tValidation Loss: 3.731047\n",
      "Validation loss decreased (4.21919 --> 3.73105).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.628157 \tValidation Loss: 3.370026\n",
      "Validation loss decreased (3.73105 --> 3.37003).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.038885 \tValidation Loss: 3.109235\n",
      "Validation loss decreased (3.37003 --> 3.10924).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 \tTraining Loss: 1.612466 \tValidation Loss: 2.921167\n",
      "Validation loss decreased (3.10924 --> 2.92117).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.300877 \tValidation Loss: 2.787409\n",
      "Validation loss decreased (2.92117 --> 2.78741).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.072287 \tValidation Loss: 2.692711\n",
      "Validation loss decreased (2.78741 --> 2.69271).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.894845 \tValidation Loss: 2.626476\n",
      "Validation loss decreased (2.69271 --> 2.62648).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.759107 \tValidation Loss: 2.583367\n",
      "Validation loss decreased (2.62648 --> 2.58337).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.654278 \tValidation Loss: 2.555224\n",
      "Validation loss decreased (2.58337 --> 2.55522).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.573348 \tValidation Loss: 2.541752\n",
      "Validation loss decreased (2.55522 --> 2.54175).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.506837 \tValidation Loss: 2.537986\n",
      "Validation loss decreased (2.54175 --> 2.53799).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.455109 \tValidation Loss: 2.543968\n",
      "Epoch: 17 \tTraining Loss: 0.414259 \tValidation Loss: 2.555887\n",
      "Epoch: 18 \tTraining Loss: 0.378890 \tValidation Loss: 2.571958\n",
      "Epoch: 19 \tTraining Loss: 0.350316 \tValidation Loss: 2.589948\n",
      "Epoch: 20 \tTraining Loss: 0.327225 \tValidation Loss: 2.612026\n",
      "Epoch: 1 \tTraining Loss: 6.582578 \tValidation Loss: 5.630060\n",
      "Validation loss decreased (inf --> 5.63006).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.928442 \tValidation Loss: 5.308290\n",
      "Validation loss decreased (5.63006 --> 5.30829).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.270622 \tValidation Loss: 4.808446\n",
      "Validation loss decreased (5.30829 --> 4.80845).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.347007 \tValidation Loss: 4.243313\n",
      "Validation loss decreased (4.80845 --> 4.24331).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.395784 \tValidation Loss: 3.762695\n",
      "Validation loss decreased (4.24331 --> 3.76270).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.614260 \tValidation Loss: 3.409458\n",
      "Validation loss decreased (3.76270 --> 3.40946).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.026184 \tValidation Loss: 3.157466\n",
      "Validation loss decreased (3.40946 --> 3.15747).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.601173 \tValidation Loss: 2.975803\n",
      "Validation loss decreased (3.15747 --> 2.97580).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.290329 \tValidation Loss: 2.846178\n",
      "Validation loss decreased (2.97580 --> 2.84618).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.060154 \tValidation Loss: 2.755159\n",
      "Validation loss decreased (2.84618 --> 2.75516).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.884726 \tValidation Loss: 2.693676\n",
      "Validation loss decreased (2.75516 --> 2.69368).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.752605 \tValidation Loss: 2.654284\n",
      "Validation loss decreased (2.69368 --> 2.65428).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.648637 \tValidation Loss: 2.629821\n",
      "Validation loss decreased (2.65428 --> 2.62982).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.568527 \tValidation Loss: 2.620438\n",
      "Validation loss decreased (2.62982 --> 2.62044).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.503639 \tValidation Loss: 2.621376\n",
      "Epoch: 16 \tTraining Loss: 0.454880 \tValidation Loss: 2.630283\n",
      "Epoch: 17 \tTraining Loss: 0.411116 \tValidation Loss: 2.643181\n",
      "Epoch: 18 \tTraining Loss: 0.378580 \tValidation Loss: 2.658656\n",
      "Epoch: 19 \tTraining Loss: 0.349999 \tValidation Loss: 2.676947\n",
      "Epoch: 20 \tTraining Loss: 0.326728 \tValidation Loss: 2.700946\n",
      "Epoch: 1 \tTraining Loss: 6.586377 \tValidation Loss: 5.642298\n",
      "Validation loss decreased (inf --> 5.64230).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.938572 \tValidation Loss: 5.310304\n",
      "Validation loss decreased (5.64230 --> 5.31030).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.292785 \tValidation Loss: 4.791743\n",
      "Validation loss decreased (5.31030 --> 4.79174).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.374990 \tValidation Loss: 4.206491\n",
      "Validation loss decreased (4.79174 --> 4.20649).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.424613 \tValidation Loss: 3.698851\n",
      "Validation loss decreased (4.20649 --> 3.69885).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.636251 \tValidation Loss: 3.315188\n",
      "Validation loss decreased (3.69885 --> 3.31519).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.046445 \tValidation Loss: 3.042824\n",
      "Validation loss decreased (3.31519 --> 3.04282).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.617249 \tValidation Loss: 2.850662\n",
      "Validation loss decreased (3.04282 --> 2.85066).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.307077 \tValidation Loss: 2.716182\n",
      "Validation loss decreased (2.85066 --> 2.71618).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.071415 \tValidation Loss: 2.623118\n",
      "Validation loss decreased (2.71618 --> 2.62312).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.897878 \tValidation Loss: 2.557616\n",
      "Validation loss decreased (2.62312 --> 2.55762).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.766315 \tValidation Loss: 2.514509\n",
      "Validation loss decreased (2.55762 --> 2.51451).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.658186 \tValidation Loss: 2.488525\n",
      "Validation loss decreased (2.51451 --> 2.48852).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.576704 \tValidation Loss: 2.476035\n",
      "Validation loss decreased (2.48852 --> 2.47604).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.513199 \tValidation Loss: 2.475001\n",
      "Validation loss decreased (2.47604 --> 2.47500).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.458534 \tValidation Loss: 2.479104\n",
      "Epoch: 17 \tTraining Loss: 0.420056 \tValidation Loss: 2.490502\n",
      "Epoch: 18 \tTraining Loss: 0.384730 \tValidation Loss: 2.507160\n",
      "Epoch: 19 \tTraining Loss: 0.357358 \tValidation Loss: 2.522814\n",
      "Epoch: 20 \tTraining Loss: 0.332746 \tValidation Loss: 2.546583\n",
      "Epoch: 1 \tTraining Loss: 6.577932 \tValidation Loss: 5.658443\n",
      "Validation loss decreased (inf --> 5.65844).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.932033 \tValidation Loss: 5.344306\n",
      "Validation loss decreased (5.65844 --> 5.34431).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.286986 \tValidation Loss: 4.840919\n",
      "Validation loss decreased (5.34431 --> 4.84092).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.367948 \tValidation Loss: 4.280576\n",
      "Validation loss decreased (4.84092 --> 4.28058).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.418934 \tValidation Loss: 3.798003\n",
      "Validation loss decreased (4.28058 --> 3.79800).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.632218 \tValidation Loss: 3.432220\n",
      "Validation loss decreased (3.79800 --> 3.43222).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.042324 \tValidation Loss: 3.168993\n",
      "Validation loss decreased (3.43222 --> 3.16899).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.612409 \tValidation Loss: 2.982438\n",
      "Validation loss decreased (3.16899 --> 2.98244).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.294622 \tValidation Loss: 2.850573\n",
      "Validation loss decreased (2.98244 --> 2.85057).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.066936 \tValidation Loss: 2.759468\n",
      "Validation loss decreased (2.85057 --> 2.75947).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.891049 \tValidation Loss: 2.696269\n",
      "Validation loss decreased (2.75947 --> 2.69627).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.757600 \tValidation Loss: 2.655314\n",
      "Validation loss decreased (2.69627 --> 2.65531).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.650117 \tValidation Loss: 2.630362\n",
      "Validation loss decreased (2.65531 --> 2.63036).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.570574 \tValidation Loss: 2.616931\n",
      "Validation loss decreased (2.63036 --> 2.61693).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.504882 \tValidation Loss: 2.616911\n",
      "Validation loss decreased (2.61693 --> 2.61691).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.456865 \tValidation Loss: 2.619841\n",
      "Epoch: 17 \tTraining Loss: 0.410586 \tValidation Loss: 2.630775\n",
      "Epoch: 18 \tTraining Loss: 0.378227 \tValidation Loss: 2.645064\n",
      "Epoch: 19 \tTraining Loss: 0.351328 \tValidation Loss: 2.663802\n",
      "Epoch: 20 \tTraining Loss: 0.325499 \tValidation Loss: 2.685708\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 6 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.603973 \tValidation Loss: 6.171892\n",
      "Validation loss decreased (inf --> 6.17189).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.874508 \tValidation Loss: 5.761308\n",
      "Validation loss decreased (6.17189 --> 5.76131).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \tTraining Loss: 5.122588 \tValidation Loss: 5.126507\n",
      "Validation loss decreased (5.76131 --> 5.12651).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.101972 \tValidation Loss: 4.448330\n",
      "Validation loss decreased (5.12651 --> 4.44833).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.116720 \tValidation Loss: 3.902133\n",
      "Validation loss decreased (4.44833 --> 3.90213).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.340816 \tValidation Loss: 3.503604\n",
      "Validation loss decreased (3.90213 --> 3.50360).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.774243 \tValidation Loss: 3.220326\n",
      "Validation loss decreased (3.50360 --> 3.22033).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.367007 \tValidation Loss: 3.018740\n",
      "Validation loss decreased (3.22033 --> 3.01874).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.074888 \tValidation Loss: 2.878771\n",
      "Validation loss decreased (3.01874 --> 2.87877).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.856726 \tValidation Loss: 2.783999\n",
      "Validation loss decreased (2.87877 --> 2.78400).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.696689 \tValidation Loss: 2.718109\n",
      "Validation loss decreased (2.78400 --> 2.71811).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.573172 \tValidation Loss: 2.675254\n",
      "Validation loss decreased (2.71811 --> 2.67525).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.480229 \tValidation Loss: 2.652418\n",
      "Validation loss decreased (2.67525 --> 2.65242).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.408438 \tValidation Loss: 2.642708\n",
      "Validation loss decreased (2.65242 --> 2.64271).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.354950 \tValidation Loss: 2.642922\n",
      "Epoch: 16 \tTraining Loss: 0.313376 \tValidation Loss: 2.649560\n",
      "Epoch: 17 \tTraining Loss: 0.277091 \tValidation Loss: 2.659173\n",
      "Epoch: 18 \tTraining Loss: 0.251905 \tValidation Loss: 2.674811\n",
      "Epoch: 19 \tTraining Loss: 0.232977 \tValidation Loss: 2.694886\n",
      "Epoch: 20 \tTraining Loss: 0.213192 \tValidation Loss: 2.713233\n",
      "Epoch: 1 \tTraining Loss: 6.604350 \tValidation Loss: 6.166664\n",
      "Validation loss decreased (inf --> 6.16666).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.896239 \tValidation Loss: 5.761288\n",
      "Validation loss decreased (6.16666 --> 5.76129).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.165106 \tValidation Loss: 5.123901\n",
      "Validation loss decreased (5.76129 --> 5.12390).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.144501 \tValidation Loss: 4.433366\n",
      "Validation loss decreased (5.12390 --> 4.43337).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.145534 \tValidation Loss: 3.870222\n",
      "Validation loss decreased (4.43337 --> 3.87022).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.357475 \tValidation Loss: 3.461886\n",
      "Validation loss decreased (3.87022 --> 3.46189).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.781462 \tValidation Loss: 3.169008\n",
      "Validation loss decreased (3.46189 --> 3.16901).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.372763 \tValidation Loss: 2.958833\n",
      "Validation loss decreased (3.16901 --> 2.95883).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.076070 \tValidation Loss: 2.806723\n",
      "Validation loss decreased (2.95883 --> 2.80672).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.857877 \tValidation Loss: 2.698793\n",
      "Validation loss decreased (2.80672 --> 2.69879).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.691737 \tValidation Loss: 2.623862\n",
      "Validation loss decreased (2.69879 --> 2.62386).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.570806 \tValidation Loss: 2.575966\n",
      "Validation loss decreased (2.62386 --> 2.57597).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.476200 \tValidation Loss: 2.544912\n",
      "Validation loss decreased (2.57597 --> 2.54491).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.404801 \tValidation Loss: 2.528798\n",
      "Validation loss decreased (2.54491 --> 2.52880).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.350464 \tValidation Loss: 2.523121\n",
      "Validation loss decreased (2.52880 --> 2.52312).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.307525 \tValidation Loss: 2.526755\n",
      "Epoch: 17 \tTraining Loss: 0.273075 \tValidation Loss: 2.535198\n",
      "Epoch: 18 \tTraining Loss: 0.249138 \tValidation Loss: 2.549534\n",
      "Epoch: 19 \tTraining Loss: 0.227364 \tValidation Loss: 2.566640\n",
      "Epoch: 20 \tTraining Loss: 0.209652 \tValidation Loss: 2.582973\n",
      "Epoch: 1 \tTraining Loss: 6.608259 \tValidation Loss: 6.173671\n",
      "Validation loss decreased (inf --> 6.17367).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.889494 \tValidation Loss: 5.753724\n",
      "Validation loss decreased (6.17367 --> 5.75372).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.150156 \tValidation Loss: 5.108496\n",
      "Validation loss decreased (5.75372 --> 5.10850).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.128956 \tValidation Loss: 4.404478\n",
      "Validation loss decreased (5.10850 --> 4.40448).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.128361 \tValidation Loss: 3.839709\n",
      "Validation loss decreased (4.40448 --> 3.83971).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.344929 \tValidation Loss: 3.434565\n",
      "Validation loss decreased (3.83971 --> 3.43457).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.775099 \tValidation Loss: 3.145053\n",
      "Validation loss decreased (3.43457 --> 3.14505).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.369183 \tValidation Loss: 2.935893\n",
      "Validation loss decreased (3.14505 --> 2.93589).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.073073 \tValidation Loss: 2.785543\n",
      "Validation loss decreased (2.93589 --> 2.78554).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.856408 \tValidation Loss: 2.680211\n",
      "Validation loss decreased (2.78554 --> 2.68021).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.691112 \tValidation Loss: 2.606233\n",
      "Validation loss decreased (2.68021 --> 2.60623).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.569588 \tValidation Loss: 2.555057\n",
      "Validation loss decreased (2.60623 --> 2.55506).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.477289 \tValidation Loss: 2.523286\n",
      "Validation loss decreased (2.55506 --> 2.52329).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.406002 \tValidation Loss: 2.510646\n",
      "Validation loss decreased (2.52329 --> 2.51065).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.347874 \tValidation Loss: 2.506781\n",
      "Validation loss decreased (2.51065 --> 2.50678).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.308948 \tValidation Loss: 2.512022\n",
      "Epoch: 17 \tTraining Loss: 0.273922 \tValidation Loss: 2.518769\n",
      "Epoch: 18 \tTraining Loss: 0.245907 \tValidation Loss: 2.532988\n",
      "Epoch: 19 \tTraining Loss: 0.226923 \tValidation Loss: 2.544160\n",
      "Epoch: 20 \tTraining Loss: 0.209643 \tValidation Loss: 2.562077\n",
      "Epoch: 1 \tTraining Loss: 6.605855 \tValidation Loss: 6.200051\n",
      "Validation loss decreased (inf --> 6.20005).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.868799 \tValidation Loss: 5.764267\n",
      "Validation loss decreased (6.20005 --> 5.76427).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.110312 \tValidation Loss: 5.106880\n",
      "Validation loss decreased (5.76427 --> 5.10688).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.089152 \tValidation Loss: 4.415177\n",
      "Validation loss decreased (5.10688 --> 4.41518).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.106179 \tValidation Loss: 3.860599\n",
      "Validation loss decreased (4.41518 --> 3.86060).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.334357 \tValidation Loss: 3.449347\n",
      "Validation loss decreased (3.86060 --> 3.44935).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.768752 \tValidation Loss: 3.152381\n",
      "Validation loss decreased (3.44935 --> 3.15238).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.362365 \tValidation Loss: 2.941064\n",
      "Validation loss decreased (3.15238 --> 2.94106).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.072476 \tValidation Loss: 2.789283\n",
      "Validation loss decreased (2.94106 --> 2.78928).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.854025 \tValidation Loss: 2.680757\n",
      "Validation loss decreased (2.78928 --> 2.68076).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.693339 \tValidation Loss: 2.605997\n",
      "Validation loss decreased (2.68076 --> 2.60600).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.570120 \tValidation Loss: 2.557782\n",
      "Validation loss decreased (2.60600 --> 2.55778).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.474891 \tValidation Loss: 2.528221\n",
      "Validation loss decreased (2.55778 --> 2.52822).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.406594 \tValidation Loss: 2.514081\n",
      "Validation loss decreased (2.52822 --> 2.51408).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.350017 \tValidation Loss: 2.515935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 \tTraining Loss: 0.309117 \tValidation Loss: 2.524781\n",
      "Epoch: 17 \tTraining Loss: 0.277326 \tValidation Loss: 2.531235\n",
      "Epoch: 18 \tTraining Loss: 0.248919 \tValidation Loss: 2.546562\n",
      "Epoch: 19 \tTraining Loss: 0.227323 \tValidation Loss: 2.563406\n",
      "Epoch: 20 \tTraining Loss: 0.210614 \tValidation Loss: 2.584310\n",
      "Epoch: 1 \tTraining Loss: 6.601822 \tValidation Loss: 6.187160\n",
      "Validation loss decreased (inf --> 6.18716).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.873483 \tValidation Loss: 5.771268\n",
      "Validation loss decreased (6.18716 --> 5.77127).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.121449 \tValidation Loss: 5.125341\n",
      "Validation loss decreased (5.77127 --> 5.12534).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.099701 \tValidation Loss: 4.439855\n",
      "Validation loss decreased (5.12534 --> 4.43986).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.113975 \tValidation Loss: 3.883419\n",
      "Validation loss decreased (4.43986 --> 3.88342).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.340446 \tValidation Loss: 3.475201\n",
      "Validation loss decreased (3.88342 --> 3.47520).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.773964 \tValidation Loss: 3.175297\n",
      "Validation loss decreased (3.47520 --> 3.17530).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.369799 \tValidation Loss: 2.959654\n",
      "Validation loss decreased (3.17530 --> 2.95965).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.077359 \tValidation Loss: 2.804659\n",
      "Validation loss decreased (2.95965 --> 2.80466).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.862685 \tValidation Loss: 2.696622\n",
      "Validation loss decreased (2.80466 --> 2.69662).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.700121 \tValidation Loss: 2.625235\n",
      "Validation loss decreased (2.69662 --> 2.62524).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.576695 \tValidation Loss: 2.575968\n",
      "Validation loss decreased (2.62524 --> 2.57597).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.484316 \tValidation Loss: 2.547743\n",
      "Validation loss decreased (2.57597 --> 2.54774).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.410881 \tValidation Loss: 2.532000\n",
      "Validation loss decreased (2.54774 --> 2.53200).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.356786 \tValidation Loss: 2.528328\n",
      "Validation loss decreased (2.53200 --> 2.52833).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.314364 \tValidation Loss: 2.536018\n",
      "Epoch: 17 \tTraining Loss: 0.277153 \tValidation Loss: 2.548404\n",
      "Epoch: 18 \tTraining Loss: 0.252927 \tValidation Loss: 2.559888\n",
      "Epoch: 19 \tTraining Loss: 0.232223 \tValidation Loss: 2.576427\n",
      "Epoch: 20 \tTraining Loss: 0.214238 \tValidation Loss: 2.595747\n",
      "Epoch: 1 \tTraining Loss: 6.603439 \tValidation Loss: 6.224140\n",
      "Validation loss decreased (inf --> 6.22414).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.881010 \tValidation Loss: 5.810739\n",
      "Validation loss decreased (6.22414 --> 5.81074).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.139750 \tValidation Loss: 5.165583\n",
      "Validation loss decreased (5.81074 --> 5.16558).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.123592 \tValidation Loss: 4.465554\n",
      "Validation loss decreased (5.16558 --> 4.46555).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.136351 \tValidation Loss: 3.890081\n",
      "Validation loss decreased (4.46555 --> 3.89008).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.356047 \tValidation Loss: 3.469709\n",
      "Validation loss decreased (3.89008 --> 3.46971).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.782461 \tValidation Loss: 3.170544\n",
      "Validation loss decreased (3.46971 --> 3.17054).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.375115 \tValidation Loss: 2.955517\n",
      "Validation loss decreased (3.17054 --> 2.95552).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.079402 \tValidation Loss: 2.803428\n",
      "Validation loss decreased (2.95552 --> 2.80343).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.862670 \tValidation Loss: 2.691079\n",
      "Validation loss decreased (2.80343 --> 2.69108).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.699663 \tValidation Loss: 2.609474\n",
      "Validation loss decreased (2.69108 --> 2.60947).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.573454 \tValidation Loss: 2.558496\n",
      "Validation loss decreased (2.60947 --> 2.55850).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.477901 \tValidation Loss: 2.523834\n",
      "Validation loss decreased (2.55850 --> 2.52383).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.407319 \tValidation Loss: 2.505724\n",
      "Validation loss decreased (2.52383 --> 2.50572).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.352250 \tValidation Loss: 2.498019\n",
      "Validation loss decreased (2.50572 --> 2.49802).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.307523 \tValidation Loss: 2.501806\n",
      "Epoch: 17 \tTraining Loss: 0.275016 \tValidation Loss: 2.507662\n",
      "Epoch: 18 \tTraining Loss: 0.246707 \tValidation Loss: 2.522336\n",
      "Epoch: 19 \tTraining Loss: 0.226087 \tValidation Loss: 2.536296\n",
      "Epoch: 20 \tTraining Loss: 0.209307 \tValidation Loss: 2.552565\n",
      "Epoch: 1 \tTraining Loss: 6.606171 \tValidation Loss: 6.179969\n",
      "Validation loss decreased (inf --> 6.17997).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.887492 \tValidation Loss: 5.761433\n",
      "Validation loss decreased (6.17997 --> 5.76143).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.146778 \tValidation Loss: 5.116879\n",
      "Validation loss decreased (5.76143 --> 5.11688).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.124722 \tValidation Loss: 4.421371\n",
      "Validation loss decreased (5.11688 --> 4.42137).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.128174 \tValidation Loss: 3.855211\n",
      "Validation loss decreased (4.42137 --> 3.85521).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.339885 \tValidation Loss: 3.449353\n",
      "Validation loss decreased (3.85521 --> 3.44935).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.767924 \tValidation Loss: 3.165741\n",
      "Validation loss decreased (3.44935 --> 3.16574).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.362148 \tValidation Loss: 2.966121\n",
      "Validation loss decreased (3.16574 --> 2.96612).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.070560 \tValidation Loss: 2.821845\n",
      "Validation loss decreased (2.96612 --> 2.82184).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.851720 \tValidation Loss: 2.722799\n",
      "Validation loss decreased (2.82184 --> 2.72280).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.689606 \tValidation Loss: 2.652447\n",
      "Validation loss decreased (2.72280 --> 2.65245).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.569102 \tValidation Loss: 2.608069\n",
      "Validation loss decreased (2.65245 --> 2.60807).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.474149 \tValidation Loss: 2.583814\n",
      "Validation loss decreased (2.60807 --> 2.58381).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.402683 \tValidation Loss: 2.571845\n",
      "Validation loss decreased (2.58381 --> 2.57184).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.346474 \tValidation Loss: 2.565647\n",
      "Validation loss decreased (2.57184 --> 2.56565).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.306572 \tValidation Loss: 2.572097\n",
      "Epoch: 17 \tTraining Loss: 0.273959 \tValidation Loss: 2.579823\n",
      "Epoch: 18 \tTraining Loss: 0.246627 \tValidation Loss: 2.596217\n",
      "Epoch: 19 \tTraining Loss: 0.223423 \tValidation Loss: 2.613384\n",
      "Epoch: 20 \tTraining Loss: 0.206570 \tValidation Loss: 2.632174\n",
      "Epoch: 1 \tTraining Loss: 6.599494 \tValidation Loss: 6.212237\n",
      "Validation loss decreased (inf --> 6.21224).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.875668 \tValidation Loss: 5.810966\n",
      "Validation loss decreased (6.21224 --> 5.81097).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.130272 \tValidation Loss: 5.172359\n",
      "Validation loss decreased (5.81097 --> 5.17236).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.113424 \tValidation Loss: 4.482786\n",
      "Validation loss decreased (5.17236 --> 4.48279).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.124649 \tValidation Loss: 3.925291\n",
      "Validation loss decreased (4.48279 --> 3.92529).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.344674 \tValidation Loss: 3.519117\n",
      "Validation loss decreased (3.92529 --> 3.51912).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.776717 \tValidation Loss: 3.227247\n",
      "Validation loss decreased (3.51912 --> 3.22725).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.369643 \tValidation Loss: 3.014981\n",
      "Validation loss decreased (3.22725 --> 3.01498).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.074884 \tValidation Loss: 2.861748\n",
      "Validation loss decreased (3.01498 --> 2.86175).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.861283 \tValidation Loss: 2.753376\n",
      "Validation loss decreased (2.86175 --> 2.75338).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 \tTraining Loss: 0.696046 \tValidation Loss: 2.677145\n",
      "Validation loss decreased (2.75338 --> 2.67715).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.574824 \tValidation Loss: 2.624980\n",
      "Validation loss decreased (2.67715 --> 2.62498).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.480952 \tValidation Loss: 2.595897\n",
      "Validation loss decreased (2.62498 --> 2.59590).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.408201 \tValidation Loss: 2.578916\n",
      "Validation loss decreased (2.59590 --> 2.57892).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.352724 \tValidation Loss: 2.574633\n",
      "Validation loss decreased (2.57892 --> 2.57463).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.309079 \tValidation Loss: 2.573938\n",
      "Validation loss decreased (2.57463 --> 2.57394).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.277084 \tValidation Loss: 2.583637\n",
      "Epoch: 18 \tTraining Loss: 0.250622 \tValidation Loss: 2.595341\n",
      "Epoch: 19 \tTraining Loss: 0.229864 \tValidation Loss: 2.611190\n",
      "Epoch: 20 \tTraining Loss: 0.210964 \tValidation Loss: 2.629919\n",
      "Epoch: 1 \tTraining Loss: 6.603110 \tValidation Loss: 6.174087\n",
      "Validation loss decreased (inf --> 6.17409).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.891826 \tValidation Loss: 5.763849\n",
      "Validation loss decreased (6.17409 --> 5.76385).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.156004 \tValidation Loss: 5.111864\n",
      "Validation loss decreased (5.76385 --> 5.11186).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.133140 \tValidation Loss: 4.400603\n",
      "Validation loss decreased (5.11186 --> 4.40060).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.137136 \tValidation Loss: 3.820694\n",
      "Validation loss decreased (4.40060 --> 3.82069).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.345275 \tValidation Loss: 3.406324\n",
      "Validation loss decreased (3.82069 --> 3.40632).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.772915 \tValidation Loss: 3.113323\n",
      "Validation loss decreased (3.40632 --> 3.11332).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.364784 \tValidation Loss: 2.907132\n",
      "Validation loss decreased (3.11332 --> 2.90713).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.070085 \tValidation Loss: 2.759551\n",
      "Validation loss decreased (2.90713 --> 2.75955).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.856663 \tValidation Loss: 2.655443\n",
      "Validation loss decreased (2.75955 --> 2.65544).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.695245 \tValidation Loss: 2.583336\n",
      "Validation loss decreased (2.65544 --> 2.58334).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.572653 \tValidation Loss: 2.535454\n",
      "Validation loss decreased (2.58334 --> 2.53545).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.478525 \tValidation Loss: 2.505374\n",
      "Validation loss decreased (2.53545 --> 2.50537).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.406823 \tValidation Loss: 2.492504\n",
      "Validation loss decreased (2.50537 --> 2.49250).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.352221 \tValidation Loss: 2.486479\n",
      "Validation loss decreased (2.49250 --> 2.48648).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.311214 \tValidation Loss: 2.491925\n",
      "Epoch: 17 \tTraining Loss: 0.278955 \tValidation Loss: 2.503042\n",
      "Epoch: 18 \tTraining Loss: 0.251510 \tValidation Loss: 2.516574\n",
      "Epoch: 19 \tTraining Loss: 0.230652 \tValidation Loss: 2.528361\n",
      "Epoch: 20 \tTraining Loss: 0.211990 \tValidation Loss: 2.550785\n",
      "Epoch: 1 \tTraining Loss: 6.608697 \tValidation Loss: 6.180666\n",
      "Validation loss decreased (inf --> 6.18067).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.887066 \tValidation Loss: 5.774489\n",
      "Validation loss decreased (6.18067 --> 5.77449).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.137839 \tValidation Loss: 5.143824\n",
      "Validation loss decreased (5.77449 --> 5.14382).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.110565 \tValidation Loss: 4.459444\n",
      "Validation loss decreased (5.14382 --> 4.45944).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.116085 \tValidation Loss: 3.905014\n",
      "Validation loss decreased (4.45944 --> 3.90501).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.335398 \tValidation Loss: 3.508565\n",
      "Validation loss decreased (3.90501 --> 3.50856).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.766763 \tValidation Loss: 3.228659\n",
      "Validation loss decreased (3.50856 --> 3.22866).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.362728 \tValidation Loss: 3.030178\n",
      "Validation loss decreased (3.22866 --> 3.03018).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.069496 \tValidation Loss: 2.889046\n",
      "Validation loss decreased (3.03018 --> 2.88905).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.855542 \tValidation Loss: 2.787986\n",
      "Validation loss decreased (2.88905 --> 2.78799).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.696073 \tValidation Loss: 2.717215\n",
      "Validation loss decreased (2.78799 --> 2.71722).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.569150 \tValidation Loss: 2.670085\n",
      "Validation loss decreased (2.71722 --> 2.67009).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.475930 \tValidation Loss: 2.643181\n",
      "Validation loss decreased (2.67009 --> 2.64318).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.405138 \tValidation Loss: 2.627063\n",
      "Validation loss decreased (2.64318 --> 2.62706).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.352035 \tValidation Loss: 2.624465\n",
      "Validation loss decreased (2.62706 --> 2.62447).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.310318 \tValidation Loss: 2.631212\n",
      "Epoch: 17 \tTraining Loss: 0.276813 \tValidation Loss: 2.641459\n",
      "Epoch: 18 \tTraining Loss: 0.248863 \tValidation Loss: 2.657931\n",
      "Epoch: 19 \tTraining Loss: 0.227911 \tValidation Loss: 2.677313\n",
      "Epoch: 20 \tTraining Loss: 0.210792 \tValidation Loss: 2.697450\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 7 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.624765 \tValidation Loss: 5.459064\n",
      "Validation loss decreased (inf --> 5.45906).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.855713 \tValidation Loss: 5.071066\n",
      "Validation loss decreased (5.45906 --> 5.07107).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.087889 \tValidation Loss: 4.472509\n",
      "Validation loss decreased (5.07107 --> 4.47251).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.043448 \tValidation Loss: 3.840632\n",
      "Validation loss decreased (4.47251 --> 3.84063).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.044616 \tValidation Loss: 3.348102\n",
      "Validation loss decreased (3.84063 --> 3.34810).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.270448 \tValidation Loss: 2.992856\n",
      "Validation loss decreased (3.34810 --> 2.99286).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.706149 \tValidation Loss: 2.735140\n",
      "Validation loss decreased (2.99286 --> 2.73514).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.295411 \tValidation Loss: 2.550839\n",
      "Validation loss decreased (2.73514 --> 2.55084).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.001702 \tValidation Loss: 2.418655\n",
      "Validation loss decreased (2.55084 --> 2.41866).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.781834 \tValidation Loss: 2.322755\n",
      "Validation loss decreased (2.41866 --> 2.32275).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.618753 \tValidation Loss: 2.259589\n",
      "Validation loss decreased (2.32275 --> 2.25959).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.496371 \tValidation Loss: 2.213925\n",
      "Validation loss decreased (2.25959 --> 2.21392).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.404396 \tValidation Loss: 2.187897\n",
      "Validation loss decreased (2.21392 --> 2.18790).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.335663 \tValidation Loss: 2.172610\n",
      "Validation loss decreased (2.18790 --> 2.17261).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.283111 \tValidation Loss: 2.169793\n",
      "Validation loss decreased (2.17261 --> 2.16979).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.241385 \tValidation Loss: 2.170227\n",
      "Epoch: 17 \tTraining Loss: 0.216198 \tValidation Loss: 2.175576\n",
      "Epoch: 18 \tTraining Loss: 0.191441 \tValidation Loss: 2.184349\n",
      "Epoch: 19 \tTraining Loss: 0.170239 \tValidation Loss: 2.197624\n",
      "Epoch: 20 \tTraining Loss: 0.157619 \tValidation Loss: 2.211334\n",
      "Epoch: 1 \tTraining Loss: 6.617968 \tValidation Loss: 5.451909\n",
      "Validation loss decreased (inf --> 5.45191).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.855307 \tValidation Loss: 5.071505\n",
      "Validation loss decreased (5.45191 --> 5.07150).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.088154 \tValidation Loss: 4.476414\n",
      "Validation loss decreased (5.07150 --> 4.47641).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.046306 \tValidation Loss: 3.843850\n",
      "Validation loss decreased (4.47641 --> 3.84385).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \tTraining Loss: 3.051633 \tValidation Loss: 3.342131\n",
      "Validation loss decreased (3.84385 --> 3.34213).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.274282 \tValidation Loss: 2.983879\n",
      "Validation loss decreased (3.34213 --> 2.98388).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.707008 \tValidation Loss: 2.728942\n",
      "Validation loss decreased (2.98388 --> 2.72894).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.299284 \tValidation Loss: 2.549285\n",
      "Validation loss decreased (2.72894 --> 2.54928).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.004993 \tValidation Loss: 2.423268\n",
      "Validation loss decreased (2.54928 --> 2.42327).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.784967 \tValidation Loss: 2.333860\n",
      "Validation loss decreased (2.42327 --> 2.33386).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.620425 \tValidation Loss: 2.270474\n",
      "Validation loss decreased (2.33386 --> 2.27047).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.496018 \tValidation Loss: 2.228927\n",
      "Validation loss decreased (2.27047 --> 2.22893).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.405401 \tValidation Loss: 2.204214\n",
      "Validation loss decreased (2.22893 --> 2.20421).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.336415 \tValidation Loss: 2.189189\n",
      "Validation loss decreased (2.20421 --> 2.18919).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.284616 \tValidation Loss: 2.188624\n",
      "Validation loss decreased (2.18919 --> 2.18862).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.245240 \tValidation Loss: 2.192305\n",
      "Epoch: 17 \tTraining Loss: 0.217575 \tValidation Loss: 2.200606\n",
      "Epoch: 18 \tTraining Loss: 0.193492 \tValidation Loss: 2.212122\n",
      "Epoch: 19 \tTraining Loss: 0.172450 \tValidation Loss: 2.222145\n",
      "Epoch: 20 \tTraining Loss: 0.158969 \tValidation Loss: 2.239287\n",
      "Epoch: 1 \tTraining Loss: 6.626215 \tValidation Loss: 5.481589\n",
      "Validation loss decreased (inf --> 5.48159).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.854428 \tValidation Loss: 5.088257\n",
      "Validation loss decreased (5.48159 --> 5.08826).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.076268 \tValidation Loss: 4.501388\n",
      "Validation loss decreased (5.08826 --> 4.50139).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.031484 \tValidation Loss: 3.879224\n",
      "Validation loss decreased (4.50139 --> 3.87922).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.037304 \tValidation Loss: 3.382332\n",
      "Validation loss decreased (3.87922 --> 3.38233).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.260651 \tValidation Loss: 3.023222\n",
      "Validation loss decreased (3.38233 --> 3.02322).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.698365 \tValidation Loss: 2.768586\n",
      "Validation loss decreased (3.02322 --> 2.76859).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.290410 \tValidation Loss: 2.589748\n",
      "Validation loss decreased (2.76859 --> 2.58975).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 0.998609 \tValidation Loss: 2.457063\n",
      "Validation loss decreased (2.58975 --> 2.45706).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.782016 \tValidation Loss: 2.362558\n",
      "Validation loss decreased (2.45706 --> 2.36256).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.620337 \tValidation Loss: 2.296027\n",
      "Validation loss decreased (2.36256 --> 2.29603).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.496391 \tValidation Loss: 2.254230\n",
      "Validation loss decreased (2.29603 --> 2.25423).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.406490 \tValidation Loss: 2.230468\n",
      "Validation loss decreased (2.25423 --> 2.23047).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.337485 \tValidation Loss: 2.215495\n",
      "Validation loss decreased (2.23047 --> 2.21549).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.284655 \tValidation Loss: 2.211665\n",
      "Validation loss decreased (2.21549 --> 2.21167).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.244753 \tValidation Loss: 2.217129\n",
      "Epoch: 17 \tTraining Loss: 0.216813 \tValidation Loss: 2.224785\n",
      "Epoch: 18 \tTraining Loss: 0.192059 \tValidation Loss: 2.235358\n",
      "Epoch: 19 \tTraining Loss: 0.172167 \tValidation Loss: 2.247258\n",
      "Epoch: 20 \tTraining Loss: 0.158145 \tValidation Loss: 2.261117\n",
      "Epoch: 1 \tTraining Loss: 6.619601 \tValidation Loss: 5.475529\n",
      "Validation loss decreased (inf --> 5.47553).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.858705 \tValidation Loss: 5.106334\n",
      "Validation loss decreased (5.47553 --> 5.10633).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.089025 \tValidation Loss: 4.529002\n",
      "Validation loss decreased (5.10633 --> 4.52900).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.044835 \tValidation Loss: 3.895240\n",
      "Validation loss decreased (4.52900 --> 3.89524).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.039983 \tValidation Loss: 3.393059\n",
      "Validation loss decreased (3.89524 --> 3.39306).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.265043 \tValidation Loss: 3.029846\n",
      "Validation loss decreased (3.39306 --> 3.02985).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.701345 \tValidation Loss: 2.768452\n",
      "Validation loss decreased (3.02985 --> 2.76845).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.292916 \tValidation Loss: 2.581803\n",
      "Validation loss decreased (2.76845 --> 2.58180).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 0.998704 \tValidation Loss: 2.449620\n",
      "Validation loss decreased (2.58180 --> 2.44962).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.782333 \tValidation Loss: 2.353757\n",
      "Validation loss decreased (2.44962 --> 2.35376).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.617461 \tValidation Loss: 2.288797\n",
      "Validation loss decreased (2.35376 --> 2.28880).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.496681 \tValidation Loss: 2.246155\n",
      "Validation loss decreased (2.28880 --> 2.24615).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.403906 \tValidation Loss: 2.221116\n",
      "Validation loss decreased (2.24615 --> 2.22112).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.334476 \tValidation Loss: 2.208111\n",
      "Validation loss decreased (2.22112 --> 2.20811).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.283620 \tValidation Loss: 2.206268\n",
      "Validation loss decreased (2.20811 --> 2.20627).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.243617 \tValidation Loss: 2.210795\n",
      "Epoch: 17 \tTraining Loss: 0.214092 \tValidation Loss: 2.215902\n",
      "Epoch: 18 \tTraining Loss: 0.190631 \tValidation Loss: 2.231653\n",
      "Epoch: 19 \tTraining Loss: 0.173022 \tValidation Loss: 2.239990\n",
      "Epoch: 20 \tTraining Loss: 0.157749 \tValidation Loss: 2.253973\n",
      "Epoch: 1 \tTraining Loss: 6.617367 \tValidation Loss: 5.476561\n",
      "Validation loss decreased (inf --> 5.47656).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.837748 \tValidation Loss: 5.092453\n",
      "Validation loss decreased (5.47656 --> 5.09245).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.054694 \tValidation Loss: 4.504981\n",
      "Validation loss decreased (5.09245 --> 4.50498).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.006366 \tValidation Loss: 3.885723\n",
      "Validation loss decreased (4.50498 --> 3.88572).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.019228 \tValidation Loss: 3.390910\n",
      "Validation loss decreased (3.88572 --> 3.39091).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.250765 \tValidation Loss: 3.036868\n",
      "Validation loss decreased (3.39091 --> 3.03687).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.693679 \tValidation Loss: 2.786997\n",
      "Validation loss decreased (3.03687 --> 2.78700).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.291666 \tValidation Loss: 2.610123\n",
      "Validation loss decreased (2.78700 --> 2.61012).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 0.998839 \tValidation Loss: 2.482502\n",
      "Validation loss decreased (2.61012 --> 2.48250).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.779494 \tValidation Loss: 2.393952\n",
      "Validation loss decreased (2.48250 --> 2.39395).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.618270 \tValidation Loss: 2.330150\n",
      "Validation loss decreased (2.39395 --> 2.33015).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.495489 \tValidation Loss: 2.288065\n",
      "Validation loss decreased (2.33015 --> 2.28807).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.403104 \tValidation Loss: 2.263384\n",
      "Validation loss decreased (2.28807 --> 2.26338).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.332867 \tValidation Loss: 2.249245\n",
      "Validation loss decreased (2.26338 --> 2.24924).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.281082 \tValidation Loss: 2.248155\n",
      "Validation loss decreased (2.24924 --> 2.24815).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.242339 \tValidation Loss: 2.253177\n",
      "Epoch: 17 \tTraining Loss: 0.211274 \tValidation Loss: 2.260297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 \tTraining Loss: 0.189576 \tValidation Loss: 2.268558\n",
      "Epoch: 19 \tTraining Loss: 0.171129 \tValidation Loss: 2.278911\n",
      "Epoch: 20 \tTraining Loss: 0.157716 \tValidation Loss: 2.295835\n",
      "Epoch: 1 \tTraining Loss: 6.617966 \tValidation Loss: 5.489991\n",
      "Validation loss decreased (inf --> 5.48999).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.854408 \tValidation Loss: 5.117455\n",
      "Validation loss decreased (5.48999 --> 5.11745).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.087895 \tValidation Loss: 4.527190\n",
      "Validation loss decreased (5.11745 --> 4.52719).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.042476 \tValidation Loss: 3.896922\n",
      "Validation loss decreased (4.52719 --> 3.89692).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.041935 \tValidation Loss: 3.396866\n",
      "Validation loss decreased (3.89692 --> 3.39687).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.266306 \tValidation Loss: 3.037379\n",
      "Validation loss decreased (3.39687 --> 3.03738).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.698540 \tValidation Loss: 2.780309\n",
      "Validation loss decreased (3.03738 --> 2.78031).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.293003 \tValidation Loss: 2.594779\n",
      "Validation loss decreased (2.78031 --> 2.59478).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.000821 \tValidation Loss: 2.459068\n",
      "Validation loss decreased (2.59478 --> 2.45907).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.781258 \tValidation Loss: 2.365095\n",
      "Validation loss decreased (2.45907 --> 2.36509).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.619211 \tValidation Loss: 2.297730\n",
      "Validation loss decreased (2.36509 --> 2.29773).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.495500 \tValidation Loss: 2.250968\n",
      "Validation loss decreased (2.29773 --> 2.25097).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.405659 \tValidation Loss: 2.222777\n",
      "Validation loss decreased (2.25097 --> 2.22278).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.334473 \tValidation Loss: 2.209733\n",
      "Validation loss decreased (2.22278 --> 2.20973).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.283737 \tValidation Loss: 2.205072\n",
      "Validation loss decreased (2.20973 --> 2.20507).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.244478 \tValidation Loss: 2.206525\n",
      "Epoch: 17 \tTraining Loss: 0.212744 \tValidation Loss: 2.212546\n",
      "Epoch: 18 \tTraining Loss: 0.191222 \tValidation Loss: 2.224579\n",
      "Epoch: 19 \tTraining Loss: 0.173411 \tValidation Loss: 2.237787\n",
      "Epoch: 20 \tTraining Loss: 0.156467 \tValidation Loss: 2.250282\n",
      "Epoch: 1 \tTraining Loss: 6.622558 \tValidation Loss: 5.474946\n",
      "Validation loss decreased (inf --> 5.47495).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.846265 \tValidation Loss: 5.113084\n",
      "Validation loss decreased (5.47495 --> 5.11308).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.067365 \tValidation Loss: 4.552907\n",
      "Validation loss decreased (5.11308 --> 4.55291).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.018899 \tValidation Loss: 3.963934\n",
      "Validation loss decreased (4.55291 --> 3.96393).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.032681 \tValidation Loss: 3.484764\n",
      "Validation loss decreased (3.96393 --> 3.48476).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.263022 \tValidation Loss: 3.126376\n",
      "Validation loss decreased (3.48476 --> 3.12638).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.699883 \tValidation Loss: 2.862807\n",
      "Validation loss decreased (3.12638 --> 2.86281).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.294653 \tValidation Loss: 2.673482\n",
      "Validation loss decreased (2.86281 --> 2.67348).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.001005 \tValidation Loss: 2.532661\n",
      "Validation loss decreased (2.67348 --> 2.53266).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.783984 \tValidation Loss: 2.427843\n",
      "Validation loss decreased (2.53266 --> 2.42784).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.620236 \tValidation Loss: 2.356117\n",
      "Validation loss decreased (2.42784 --> 2.35612).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.495550 \tValidation Loss: 2.309142\n",
      "Validation loss decreased (2.35612 --> 2.30914).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.403255 \tValidation Loss: 2.276592\n",
      "Validation loss decreased (2.30914 --> 2.27659).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.336132 \tValidation Loss: 2.259480\n",
      "Validation loss decreased (2.27659 --> 2.25948).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.283775 \tValidation Loss: 2.250622\n",
      "Validation loss decreased (2.25948 --> 2.25062).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.246105 \tValidation Loss: 2.252973\n",
      "Epoch: 17 \tTraining Loss: 0.215187 \tValidation Loss: 2.257739\n",
      "Epoch: 18 \tTraining Loss: 0.190884 \tValidation Loss: 2.265721\n",
      "Epoch: 19 \tTraining Loss: 0.172837 \tValidation Loss: 2.275296\n",
      "Epoch: 20 \tTraining Loss: 0.159695 \tValidation Loss: 2.288579\n",
      "Epoch: 1 \tTraining Loss: 6.626357 \tValidation Loss: 5.501904\n",
      "Validation loss decreased (inf --> 5.50190).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.853679 \tValidation Loss: 5.124228\n",
      "Validation loss decreased (5.50190 --> 5.12423).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.079432 \tValidation Loss: 4.523214\n",
      "Validation loss decreased (5.12423 --> 4.52321).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.033493 \tValidation Loss: 3.880985\n",
      "Validation loss decreased (4.52321 --> 3.88098).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.041670 \tValidation Loss: 3.368175\n",
      "Validation loss decreased (3.88098 --> 3.36817).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.268682 \tValidation Loss: 2.995591\n",
      "Validation loss decreased (3.36817 --> 2.99559).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.706459 \tValidation Loss: 2.730578\n",
      "Validation loss decreased (2.99559 --> 2.73058).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.302096 \tValidation Loss: 2.542140\n",
      "Validation loss decreased (2.73058 --> 2.54214).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.006473 \tValidation Loss: 2.407401\n",
      "Validation loss decreased (2.54214 --> 2.40740).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.789110 \tValidation Loss: 2.310467\n",
      "Validation loss decreased (2.40740 --> 2.31047).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.626720 \tValidation Loss: 2.242613\n",
      "Validation loss decreased (2.31047 --> 2.24261).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.501883 \tValidation Loss: 2.195176\n",
      "Validation loss decreased (2.24261 --> 2.19518).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.409911 \tValidation Loss: 2.167952\n",
      "Validation loss decreased (2.19518 --> 2.16795).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.340276 \tValidation Loss: 2.151361\n",
      "Validation loss decreased (2.16795 --> 2.15136).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.287491 \tValidation Loss: 2.148632\n",
      "Validation loss decreased (2.15136 --> 2.14863).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.248295 \tValidation Loss: 2.148274\n",
      "Validation loss decreased (2.14863 --> 2.14827).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.216422 \tValidation Loss: 2.156426\n",
      "Epoch: 18 \tTraining Loss: 0.193975 \tValidation Loss: 2.163519\n",
      "Epoch: 19 \tTraining Loss: 0.174502 \tValidation Loss: 2.174051\n",
      "Epoch: 20 \tTraining Loss: 0.158388 \tValidation Loss: 2.183710\n",
      "Epoch: 1 \tTraining Loss: 6.623550 \tValidation Loss: 5.506703\n",
      "Validation loss decreased (inf --> 5.50670).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.847879 \tValidation Loss: 5.134144\n",
      "Validation loss decreased (5.50670 --> 5.13414).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.080160 \tValidation Loss: 4.552239\n",
      "Validation loss decreased (5.13414 --> 4.55224).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.037824 \tValidation Loss: 3.935523\n",
      "Validation loss decreased (4.55224 --> 3.93552).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.044984 \tValidation Loss: 3.439163\n",
      "Validation loss decreased (3.93552 --> 3.43916).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.269292 \tValidation Loss: 3.071637\n",
      "Validation loss decreased (3.43916 --> 3.07164).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.703649 \tValidation Loss: 2.807007\n",
      "Validation loss decreased (3.07164 --> 2.80701).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.295989 \tValidation Loss: 2.616209\n",
      "Validation loss decreased (2.80701 --> 2.61621).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 0.997995 \tValidation Loss: 2.479407\n",
      "Validation loss decreased (2.61621 --> 2.47941).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.782804 \tValidation Loss: 2.381424\n",
      "Validation loss decreased (2.47941 --> 2.38142).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 \tTraining Loss: 0.619348 \tValidation Loss: 2.311141\n",
      "Validation loss decreased (2.38142 --> 2.31114).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.495998 \tValidation Loss: 2.267128\n",
      "Validation loss decreased (2.31114 --> 2.26713).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.404917 \tValidation Loss: 2.238007\n",
      "Validation loss decreased (2.26713 --> 2.23801).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.332735 \tValidation Loss: 2.221219\n",
      "Validation loss decreased (2.23801 --> 2.22122).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.284113 \tValidation Loss: 2.217175\n",
      "Validation loss decreased (2.22122 --> 2.21718).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.242453 \tValidation Loss: 2.217540\n",
      "Epoch: 17 \tTraining Loss: 0.213985 \tValidation Loss: 2.225878\n",
      "Epoch: 18 \tTraining Loss: 0.190939 \tValidation Loss: 2.236328\n",
      "Epoch: 19 \tTraining Loss: 0.169898 \tValidation Loss: 2.247349\n",
      "Epoch: 20 \tTraining Loss: 0.157612 \tValidation Loss: 2.261814\n",
      "Epoch: 1 \tTraining Loss: 6.619974 \tValidation Loss: 5.483033\n",
      "Validation loss decreased (inf --> 5.48303).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.849170 \tValidation Loss: 5.109734\n",
      "Validation loss decreased (5.48303 --> 5.10973).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.080285 \tValidation Loss: 4.516365\n",
      "Validation loss decreased (5.10973 --> 4.51636).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.036887 \tValidation Loss: 3.884916\n",
      "Validation loss decreased (4.51636 --> 3.88492).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.045186 \tValidation Loss: 3.391168\n",
      "Validation loss decreased (3.88492 --> 3.39117).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.268714 \tValidation Loss: 3.035546\n",
      "Validation loss decreased (3.39117 --> 3.03555).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.707828 \tValidation Loss: 2.784116\n",
      "Validation loss decreased (3.03555 --> 2.78412).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.301659 \tValidation Loss: 2.602190\n",
      "Validation loss decreased (2.78412 --> 2.60219).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.007078 \tValidation Loss: 2.472736\n",
      "Validation loss decreased (2.60219 --> 2.47274).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.788900 \tValidation Loss: 2.379360\n",
      "Validation loss decreased (2.47274 --> 2.37936).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.625055 \tValidation Loss: 2.314379\n",
      "Validation loss decreased (2.37936 --> 2.31438).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.499025 \tValidation Loss: 2.271111\n",
      "Validation loss decreased (2.31438 --> 2.27111).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.407230 \tValidation Loss: 2.245796\n",
      "Validation loss decreased (2.27111 --> 2.24580).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.337198 \tValidation Loss: 2.231530\n",
      "Validation loss decreased (2.24580 --> 2.23153).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.285563 \tValidation Loss: 2.229913\n",
      "Validation loss decreased (2.23153 --> 2.22991).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.246788 \tValidation Loss: 2.228706\n",
      "Validation loss decreased (2.22991 --> 2.22871).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.215522 \tValidation Loss: 2.236930\n",
      "Epoch: 18 \tTraining Loss: 0.193405 \tValidation Loss: 2.248767\n",
      "Epoch: 19 \tTraining Loss: 0.175617 \tValidation Loss: 2.260624\n",
      "Epoch: 20 \tTraining Loss: 0.158388 \tValidation Loss: 2.275849\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 8 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.703690 \tValidation Loss: 5.473379\n",
      "Validation loss decreased (inf --> 5.47338).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.879417 \tValidation Loss: 5.111278\n",
      "Validation loss decreased (5.47338 --> 5.11128).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.116129 \tValidation Loss: 4.547348\n",
      "Validation loss decreased (5.11128 --> 4.54735).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.080552 \tValidation Loss: 3.951148\n",
      "Validation loss decreased (4.54735 --> 3.95115).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.086650 \tValidation Loss: 3.472251\n",
      "Validation loss decreased (3.95115 --> 3.47225).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.295407 \tValidation Loss: 3.119931\n",
      "Validation loss decreased (3.47225 --> 3.11993).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.720716 \tValidation Loss: 2.861318\n",
      "Validation loss decreased (3.11993 --> 2.86132).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.301157 \tValidation Loss: 2.671629\n",
      "Validation loss decreased (2.86132 --> 2.67163).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 0.993045 \tValidation Loss: 2.529467\n",
      "Validation loss decreased (2.67163 --> 2.52947).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.768060 \tValidation Loss: 2.429041\n",
      "Validation loss decreased (2.52947 --> 2.42904).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.598546 \tValidation Loss: 2.357616\n",
      "Validation loss decreased (2.42904 --> 2.35762).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.471214 \tValidation Loss: 2.311076\n",
      "Validation loss decreased (2.35762 --> 2.31108).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.376632 \tValidation Loss: 2.280539\n",
      "Validation loss decreased (2.31108 --> 2.28054).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.306046 \tValidation Loss: 2.265746\n",
      "Validation loss decreased (2.28054 --> 2.26575).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.253120 \tValidation Loss: 2.255936\n",
      "Validation loss decreased (2.26575 --> 2.25594).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.215081 \tValidation Loss: 2.255036\n",
      "Validation loss decreased (2.25594 --> 2.25504).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.186232 \tValidation Loss: 2.263447\n",
      "Epoch: 18 \tTraining Loss: 0.163741 \tValidation Loss: 2.267727\n",
      "Epoch: 19 \tTraining Loss: 0.148092 \tValidation Loss: 2.281169\n",
      "Epoch: 20 \tTraining Loss: 0.132218 \tValidation Loss: 2.291662\n",
      "Epoch: 1 \tTraining Loss: 6.698119 \tValidation Loss: 5.494139\n",
      "Validation loss decreased (inf --> 5.49414).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.874515 \tValidation Loss: 5.130316\n",
      "Validation loss decreased (5.49414 --> 5.13032).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.109985 \tValidation Loss: 4.572350\n",
      "Validation loss decreased (5.13032 --> 4.57235).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.071998 \tValidation Loss: 3.973862\n",
      "Validation loss decreased (4.57235 --> 3.97386).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.076792 \tValidation Loss: 3.484163\n",
      "Validation loss decreased (3.97386 --> 3.48416).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.290538 \tValidation Loss: 3.113853\n",
      "Validation loss decreased (3.48416 --> 3.11385).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.712567 \tValidation Loss: 2.848428\n",
      "Validation loss decreased (3.11385 --> 2.84843).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.294332 \tValidation Loss: 2.660567\n",
      "Validation loss decreased (2.84843 --> 2.66057).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 0.991006 \tValidation Loss: 2.522930\n",
      "Validation loss decreased (2.66057 --> 2.52293).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.762421 \tValidation Loss: 2.426838\n",
      "Validation loss decreased (2.52293 --> 2.42684).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.593554 \tValidation Loss: 2.362208\n",
      "Validation loss decreased (2.42684 --> 2.36221).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.466996 \tValidation Loss: 2.319592\n",
      "Validation loss decreased (2.36221 --> 2.31959).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.373117 \tValidation Loss: 2.297090\n",
      "Validation loss decreased (2.31959 --> 2.29709).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.301917 \tValidation Loss: 2.285235\n",
      "Validation loss decreased (2.29709 --> 2.28523).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.250442 \tValidation Loss: 2.282161\n",
      "Validation loss decreased (2.28523 --> 2.28216).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.212703 \tValidation Loss: 2.284833\n",
      "Epoch: 17 \tTraining Loss: 0.183018 \tValidation Loss: 2.293249\n",
      "Epoch: 18 \tTraining Loss: 0.162005 \tValidation Loss: 2.301917\n",
      "Epoch: 19 \tTraining Loss: 0.144938 \tValidation Loss: 2.313241\n",
      "Epoch: 20 \tTraining Loss: 0.130989 \tValidation Loss: 2.324301\n",
      "Epoch: 1 \tTraining Loss: 6.689942 \tValidation Loss: 5.496963\n",
      "Validation loss decreased (inf --> 5.49696).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.866491 \tValidation Loss: 5.144549\n",
      "Validation loss decreased (5.49696 --> 5.14455).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.109446 \tValidation Loss: 4.599524\n",
      "Validation loss decreased (5.14455 --> 4.59952).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 \tTraining Loss: 4.085280 \tValidation Loss: 4.005360\n",
      "Validation loss decreased (4.59952 --> 4.00536).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.096539 \tValidation Loss: 3.508975\n",
      "Validation loss decreased (4.00536 --> 3.50897).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.308631 \tValidation Loss: 3.142834\n",
      "Validation loss decreased (3.50897 --> 3.14283).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.729192 \tValidation Loss: 2.880149\n",
      "Validation loss decreased (3.14283 --> 2.88015).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.307295 \tValidation Loss: 2.686926\n",
      "Validation loss decreased (2.88015 --> 2.68693).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.005484 \tValidation Loss: 2.544150\n",
      "Validation loss decreased (2.68693 --> 2.54415).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.775702 \tValidation Loss: 2.441624\n",
      "Validation loss decreased (2.54415 --> 2.44162).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.604020 \tValidation Loss: 2.365143\n",
      "Validation loss decreased (2.44162 --> 2.36514).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.478200 \tValidation Loss: 2.310799\n",
      "Validation loss decreased (2.36514 --> 2.31080).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.382147 \tValidation Loss: 2.280062\n",
      "Validation loss decreased (2.31080 --> 2.28006).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.309149 \tValidation Loss: 2.262632\n",
      "Validation loss decreased (2.28006 --> 2.26263).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.258154 \tValidation Loss: 2.254392\n",
      "Validation loss decreased (2.26263 --> 2.25439).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.218448 \tValidation Loss: 2.254600\n",
      "Epoch: 17 \tTraining Loss: 0.186543 \tValidation Loss: 2.253425\n",
      "Validation loss decreased (2.25439 --> 2.25343).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.165107 \tValidation Loss: 2.262094\n",
      "Epoch: 19 \tTraining Loss: 0.146399 \tValidation Loss: 2.271876\n",
      "Epoch: 20 \tTraining Loss: 0.135857 \tValidation Loss: 2.280324\n",
      "Epoch: 1 \tTraining Loss: 6.694732 \tValidation Loss: 5.463098\n",
      "Validation loss decreased (inf --> 5.46310).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.881888 \tValidation Loss: 5.088781\n",
      "Validation loss decreased (5.46310 --> 5.08878).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.125423 \tValidation Loss: 4.520590\n",
      "Validation loss decreased (5.08878 --> 4.52059).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.097692 \tValidation Loss: 3.897205\n",
      "Validation loss decreased (4.52059 --> 3.89720).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.094467 \tValidation Loss: 3.398199\n",
      "Validation loss decreased (3.89720 --> 3.39820).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.299702 \tValidation Loss: 3.030894\n",
      "Validation loss decreased (3.39820 --> 3.03089).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.720798 \tValidation Loss: 2.762401\n",
      "Validation loss decreased (3.03089 --> 2.76240).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.301369 \tValidation Loss: 2.568207\n",
      "Validation loss decreased (2.76240 --> 2.56821).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 0.998201 \tValidation Loss: 2.428121\n",
      "Validation loss decreased (2.56821 --> 2.42812).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.770337 \tValidation Loss: 2.324309\n",
      "Validation loss decreased (2.42812 --> 2.32431).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.602436 \tValidation Loss: 2.248804\n",
      "Validation loss decreased (2.32431 --> 2.24880).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.472724 \tValidation Loss: 2.198624\n",
      "Validation loss decreased (2.24880 --> 2.19862).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.380211 \tValidation Loss: 2.167334\n",
      "Validation loss decreased (2.19862 --> 2.16733).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.307632 \tValidation Loss: 2.147080\n",
      "Validation loss decreased (2.16733 --> 2.14708).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.253923 \tValidation Loss: 2.136683\n",
      "Validation loss decreased (2.14708 --> 2.13668).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.215631 \tValidation Loss: 2.136869\n",
      "Epoch: 17 \tTraining Loss: 0.187569 \tValidation Loss: 2.141965\n",
      "Epoch: 18 \tTraining Loss: 0.163378 \tValidation Loss: 2.148232\n",
      "Epoch: 19 \tTraining Loss: 0.148063 \tValidation Loss: 2.154907\n",
      "Epoch: 20 \tTraining Loss: 0.133364 \tValidation Loss: 2.163334\n",
      "Epoch: 1 \tTraining Loss: 6.694366 \tValidation Loss: 5.508563\n",
      "Validation loss decreased (inf --> 5.50856).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.875408 \tValidation Loss: 5.132508\n",
      "Validation loss decreased (5.50856 --> 5.13251).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.121500 \tValidation Loss: 4.550984\n",
      "Validation loss decreased (5.13251 --> 4.55098).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.098508 \tValidation Loss: 3.928273\n",
      "Validation loss decreased (4.55098 --> 3.92827).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.107825 \tValidation Loss: 3.418506\n",
      "Validation loss decreased (3.92827 --> 3.41851).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.320338 \tValidation Loss: 3.037061\n",
      "Validation loss decreased (3.41851 --> 3.03706).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.738512 \tValidation Loss: 2.764713\n",
      "Validation loss decreased (3.03706 --> 2.76471).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.315371 \tValidation Loss: 2.568460\n",
      "Validation loss decreased (2.76471 --> 2.56846).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.008476 \tValidation Loss: 2.423586\n",
      "Validation loss decreased (2.56846 --> 2.42359).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.781068 \tValidation Loss: 2.321392\n",
      "Validation loss decreased (2.42359 --> 2.32139).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.607013 \tValidation Loss: 2.247729\n",
      "Validation loss decreased (2.32139 --> 2.24773).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.478080 \tValidation Loss: 2.197012\n",
      "Validation loss decreased (2.24773 --> 2.19701).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.380179 \tValidation Loss: 2.163456\n",
      "Validation loss decreased (2.19701 --> 2.16346).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.310855 \tValidation Loss: 2.143721\n",
      "Validation loss decreased (2.16346 --> 2.14372).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.255839 \tValidation Loss: 2.132254\n",
      "Validation loss decreased (2.14372 --> 2.13225).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.218381 \tValidation Loss: 2.128613\n",
      "Validation loss decreased (2.13225 --> 2.12861).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.186730 \tValidation Loss: 2.131396\n",
      "Epoch: 18 \tTraining Loss: 0.164912 \tValidation Loss: 2.135394\n",
      "Epoch: 19 \tTraining Loss: 0.148134 \tValidation Loss: 2.144062\n",
      "Epoch: 20 \tTraining Loss: 0.133436 \tValidation Loss: 2.153380\n",
      "Epoch: 1 \tTraining Loss: 6.702687 \tValidation Loss: 5.480452\n",
      "Validation loss decreased (inf --> 5.48045).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.878493 \tValidation Loss: 5.104561\n",
      "Validation loss decreased (5.48045 --> 5.10456).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.110808 \tValidation Loss: 4.536104\n",
      "Validation loss decreased (5.10456 --> 4.53610).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.073172 \tValidation Loss: 3.923820\n",
      "Validation loss decreased (4.53610 --> 3.92382).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.074025 \tValidation Loss: 3.431247\n",
      "Validation loss decreased (3.92382 --> 3.43125).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.288012 \tValidation Loss: 3.074586\n",
      "Validation loss decreased (3.43125 --> 3.07459).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.711838 \tValidation Loss: 2.818008\n",
      "Validation loss decreased (3.07459 --> 2.81801).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.297823 \tValidation Loss: 2.628539\n",
      "Validation loss decreased (2.81801 --> 2.62854).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 0.990992 \tValidation Loss: 2.493463\n",
      "Validation loss decreased (2.62854 --> 2.49346).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.766982 \tValidation Loss: 2.394415\n",
      "Validation loss decreased (2.49346 --> 2.39442).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.598221 \tValidation Loss: 2.326209\n",
      "Validation loss decreased (2.39442 --> 2.32621).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.468943 \tValidation Loss: 2.281763\n",
      "Validation loss decreased (2.32621 --> 2.28176).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.374947 \tValidation Loss: 2.254133\n",
      "Validation loss decreased (2.28176 --> 2.25413).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.301918 \tValidation Loss: 2.245772\n",
      "Validation loss decreased (2.25413 --> 2.24577).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 \tTraining Loss: 0.252581 \tValidation Loss: 2.235886\n",
      "Validation loss decreased (2.24577 --> 2.23589).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.214660 \tValidation Loss: 2.239225\n",
      "Epoch: 17 \tTraining Loss: 0.185697 \tValidation Loss: 2.247643\n",
      "Epoch: 18 \tTraining Loss: 0.161730 \tValidation Loss: 2.255435\n",
      "Epoch: 19 \tTraining Loss: 0.145438 \tValidation Loss: 2.265669\n",
      "Epoch: 20 \tTraining Loss: 0.131602 \tValidation Loss: 2.278070\n",
      "Epoch: 1 \tTraining Loss: 6.695612 \tValidation Loss: 5.499063\n",
      "Validation loss decreased (inf --> 5.49906).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.863462 \tValidation Loss: 5.127601\n",
      "Validation loss decreased (5.49906 --> 5.12760).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.095619 \tValidation Loss: 4.550717\n",
      "Validation loss decreased (5.12760 --> 4.55072).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.062380 \tValidation Loss: 3.928544\n",
      "Validation loss decreased (4.55072 --> 3.92854).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.072954 \tValidation Loss: 3.428782\n",
      "Validation loss decreased (3.92854 --> 3.42878).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.295326 \tValidation Loss: 3.061501\n",
      "Validation loss decreased (3.42878 --> 3.06150).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.721080 \tValidation Loss: 2.798002\n",
      "Validation loss decreased (3.06150 --> 2.79800).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.303739 \tValidation Loss: 2.608741\n",
      "Validation loss decreased (2.79800 --> 2.60874).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 0.998601 \tValidation Loss: 2.467942\n",
      "Validation loss decreased (2.60874 --> 2.46794).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.773145 \tValidation Loss: 2.364184\n",
      "Validation loss decreased (2.46794 --> 2.36418).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.603243 \tValidation Loss: 2.289765\n",
      "Validation loss decreased (2.36418 --> 2.28976).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.474072 \tValidation Loss: 2.235809\n",
      "Validation loss decreased (2.28976 --> 2.23581).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.378105 \tValidation Loss: 2.201694\n",
      "Validation loss decreased (2.23581 --> 2.20169).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.307253 \tValidation Loss: 2.182831\n",
      "Validation loss decreased (2.20169 --> 2.18283).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.254975 \tValidation Loss: 2.174722\n",
      "Validation loss decreased (2.18283 --> 2.17472).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.215073 \tValidation Loss: 2.171338\n",
      "Validation loss decreased (2.17472 --> 2.17134).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.187864 \tValidation Loss: 2.173013\n",
      "Epoch: 18 \tTraining Loss: 0.166397 \tValidation Loss: 2.182242\n",
      "Epoch: 19 \tTraining Loss: 0.147954 \tValidation Loss: 2.188699\n",
      "Epoch: 20 \tTraining Loss: 0.134737 \tValidation Loss: 2.202118\n",
      "Epoch: 1 \tTraining Loss: 6.688996 \tValidation Loss: 5.513573\n",
      "Validation loss decreased (inf --> 5.51357).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.875930 \tValidation Loss: 5.146066\n",
      "Validation loss decreased (5.51357 --> 5.14607).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.114539 \tValidation Loss: 4.581616\n",
      "Validation loss decreased (5.14607 --> 4.58162).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.084725 \tValidation Loss: 3.975607\n",
      "Validation loss decreased (4.58162 --> 3.97561).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.089603 \tValidation Loss: 3.482643\n",
      "Validation loss decreased (3.97561 --> 3.48264).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.298362 \tValidation Loss: 3.120645\n",
      "Validation loss decreased (3.48264 --> 3.12064).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.717756 \tValidation Loss: 2.860182\n",
      "Validation loss decreased (3.12064 --> 2.86018).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.299868 \tValidation Loss: 2.671978\n",
      "Validation loss decreased (2.86018 --> 2.67198).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 0.995502 \tValidation Loss: 2.534935\n",
      "Validation loss decreased (2.67198 --> 2.53494).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.768187 \tValidation Loss: 2.432643\n",
      "Validation loss decreased (2.53494 --> 2.43264).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.598106 \tValidation Loss: 2.359974\n",
      "Validation loss decreased (2.43264 --> 2.35997).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.472111 \tValidation Loss: 2.312348\n",
      "Validation loss decreased (2.35997 --> 2.31235).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.379800 \tValidation Loss: 2.282283\n",
      "Validation loss decreased (2.31235 --> 2.28228).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.308146 \tValidation Loss: 2.263764\n",
      "Validation loss decreased (2.28228 --> 2.26376).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.256684 \tValidation Loss: 2.254850\n",
      "Validation loss decreased (2.26376 --> 2.25485).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.216286 \tValidation Loss: 2.253983\n",
      "Validation loss decreased (2.25485 --> 2.25398).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.188712 \tValidation Loss: 2.259364\n",
      "Epoch: 18 \tTraining Loss: 0.167365 \tValidation Loss: 2.264827\n",
      "Epoch: 19 \tTraining Loss: 0.148741 \tValidation Loss: 2.274654\n",
      "Epoch: 20 \tTraining Loss: 0.133563 \tValidation Loss: 2.284366\n",
      "Epoch: 1 \tTraining Loss: 6.694256 \tValidation Loss: 5.480937\n",
      "Validation loss decreased (inf --> 5.48094).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.875720 \tValidation Loss: 5.088524\n",
      "Validation loss decreased (5.48094 --> 5.08852).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.115703 \tValidation Loss: 4.503910\n",
      "Validation loss decreased (5.08852 --> 4.50391).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.087891 \tValidation Loss: 3.883196\n",
      "Validation loss decreased (4.50391 --> 3.88320).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.090367 \tValidation Loss: 3.396327\n",
      "Validation loss decreased (3.88320 --> 3.39633).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.303299 \tValidation Loss: 3.043179\n",
      "Validation loss decreased (3.39633 --> 3.04318).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.729235 \tValidation Loss: 2.785589\n",
      "Validation loss decreased (3.04318 --> 2.78559).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.314944 \tValidation Loss: 2.593794\n",
      "Validation loss decreased (2.78559 --> 2.59379).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.006295 \tValidation Loss: 2.452428\n",
      "Validation loss decreased (2.59379 --> 2.45243).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.778314 \tValidation Loss: 2.348243\n",
      "Validation loss decreased (2.45243 --> 2.34824).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.605363 \tValidation Loss: 2.272884\n",
      "Validation loss decreased (2.34824 --> 2.27288).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.474754 \tValidation Loss: 2.222927\n",
      "Validation loss decreased (2.27288 --> 2.22293).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.380217 \tValidation Loss: 2.188960\n",
      "Validation loss decreased (2.22293 --> 2.18896).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.308631 \tValidation Loss: 2.173655\n",
      "Validation loss decreased (2.18896 --> 2.17366).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.255975 \tValidation Loss: 2.165069\n",
      "Validation loss decreased (2.17366 --> 2.16507).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.216483 \tValidation Loss: 2.169461\n",
      "Epoch: 17 \tTraining Loss: 0.188537 \tValidation Loss: 2.176852\n",
      "Epoch: 18 \tTraining Loss: 0.166210 \tValidation Loss: 2.183467\n",
      "Epoch: 19 \tTraining Loss: 0.147338 \tValidation Loss: 2.190720\n",
      "Epoch: 20 \tTraining Loss: 0.135098 \tValidation Loss: 2.200204\n",
      "Epoch: 1 \tTraining Loss: 6.695500 \tValidation Loss: 5.503107\n",
      "Validation loss decreased (inf --> 5.50311).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.867391 \tValidation Loss: 5.125000\n",
      "Validation loss decreased (5.50311 --> 5.12500).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.100936 \tValidation Loss: 4.544209\n",
      "Validation loss decreased (5.12500 --> 4.54421).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.064425 \tValidation Loss: 3.931448\n",
      "Validation loss decreased (4.54421 --> 3.93145).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.063596 \tValidation Loss: 3.450459\n",
      "Validation loss decreased (3.93145 --> 3.45046).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.279464 \tValidation Loss: 3.092951\n",
      "Validation loss decreased (3.45046 --> 3.09295).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.712110 \tValidation Loss: 2.833693\n",
      "Validation loss decreased (3.09295 --> 2.83369).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.299881 \tValidation Loss: 2.640963\n",
      "Validation loss decreased (2.83369 --> 2.64096).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 \tTraining Loss: 0.995868 \tValidation Loss: 2.494853\n",
      "Validation loss decreased (2.64096 --> 2.49485).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.774000 \tValidation Loss: 2.389352\n",
      "Validation loss decreased (2.49485 --> 2.38935).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.602363 \tValidation Loss: 2.311620\n",
      "Validation loss decreased (2.38935 --> 2.31162).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.476201 \tValidation Loss: 2.257362\n",
      "Validation loss decreased (2.31162 --> 2.25736).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.379316 \tValidation Loss: 2.219143\n",
      "Validation loss decreased (2.25736 --> 2.21914).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.307257 \tValidation Loss: 2.196729\n",
      "Validation loss decreased (2.21914 --> 2.19673).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.252297 \tValidation Loss: 2.184963\n",
      "Validation loss decreased (2.19673 --> 2.18496).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.215783 \tValidation Loss: 2.183699\n",
      "Validation loss decreased (2.18496 --> 2.18370).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.186360 \tValidation Loss: 2.185239\n",
      "Epoch: 18 \tTraining Loss: 0.164009 \tValidation Loss: 2.192786\n",
      "Epoch: 19 \tTraining Loss: 0.145263 \tValidation Loss: 2.200540\n",
      "Epoch: 20 \tTraining Loss: 0.132890 \tValidation Loss: 2.209821\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 9 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.649703 \tValidation Loss: 5.525213\n",
      "Validation loss decreased (inf --> 5.52521).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.811793 \tValidation Loss: 5.176014\n",
      "Validation loss decreased (5.52521 --> 5.17601).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.124777 \tValidation Loss: 4.668555\n",
      "Validation loss decreased (5.17601 --> 4.66856).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.181186 \tValidation Loss: 4.091536\n",
      "Validation loss decreased (4.66856 --> 4.09154).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.228693 \tValidation Loss: 3.594054\n",
      "Validation loss decreased (4.09154 --> 3.59405).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.445558 \tValidation Loss: 3.213023\n",
      "Validation loss decreased (3.59405 --> 3.21302).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.852823 \tValidation Loss: 2.933948\n",
      "Validation loss decreased (3.21302 --> 2.93395).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.410322 \tValidation Loss: 2.728831\n",
      "Validation loss decreased (2.93395 --> 2.72883).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.084436 \tValidation Loss: 2.578283\n",
      "Validation loss decreased (2.72883 --> 2.57828).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.832338 \tValidation Loss: 2.466805\n",
      "Validation loss decreased (2.57828 --> 2.46680).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.643586 \tValidation Loss: 2.389447\n",
      "Validation loss decreased (2.46680 --> 2.38945).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.499764 \tValidation Loss: 2.333363\n",
      "Validation loss decreased (2.38945 --> 2.33336).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.394847 \tValidation Loss: 2.299573\n",
      "Validation loss decreased (2.33336 --> 2.29957).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.315206 \tValidation Loss: 2.277635\n",
      "Validation loss decreased (2.29957 --> 2.27763).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.257923 \tValidation Loss: 2.269074\n",
      "Validation loss decreased (2.27763 --> 2.26907).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.216956 \tValidation Loss: 2.265504\n",
      "Validation loss decreased (2.26907 --> 2.26550).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.184519 \tValidation Loss: 2.270270\n",
      "Epoch: 18 \tTraining Loss: 0.160827 \tValidation Loss: 2.274093\n",
      "Epoch: 19 \tTraining Loss: 0.142261 \tValidation Loss: 2.281626\n",
      "Epoch: 20 \tTraining Loss: 0.127532 \tValidation Loss: 2.289542\n",
      "Epoch: 1 \tTraining Loss: 6.644401 \tValidation Loss: 5.544525\n",
      "Validation loss decreased (inf --> 5.54452).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.811445 \tValidation Loss: 5.191606\n",
      "Validation loss decreased (5.54452 --> 5.19161).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.123420 \tValidation Loss: 4.678973\n",
      "Validation loss decreased (5.19161 --> 4.67897).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.178556 \tValidation Loss: 4.100146\n",
      "Validation loss decreased (4.67897 --> 4.10015).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.221257 \tValidation Loss: 3.615583\n",
      "Validation loss decreased (4.10015 --> 3.61558).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.435387 \tValidation Loss: 3.252406\n",
      "Validation loss decreased (3.61558 --> 3.25241).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.843574 \tValidation Loss: 2.985631\n",
      "Validation loss decreased (3.25241 --> 2.98563).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.402083 \tValidation Loss: 2.794318\n",
      "Validation loss decreased (2.98563 --> 2.79432).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.073856 \tValidation Loss: 2.655616\n",
      "Validation loss decreased (2.79432 --> 2.65562).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.824792 \tValidation Loss: 2.560575\n",
      "Validation loss decreased (2.65562 --> 2.56057).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.634837 \tValidation Loss: 2.497073\n",
      "Validation loss decreased (2.56057 --> 2.49707).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.495428 \tValidation Loss: 2.453471\n",
      "Validation loss decreased (2.49707 --> 2.45347).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.387911 \tValidation Loss: 2.428602\n",
      "Validation loss decreased (2.45347 --> 2.42860).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.311259 \tValidation Loss: 2.414389\n",
      "Validation loss decreased (2.42860 --> 2.41439).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.255421 \tValidation Loss: 2.411917\n",
      "Validation loss decreased (2.41439 --> 2.41192).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.211645 \tValidation Loss: 2.413066\n",
      "Epoch: 17 \tTraining Loss: 0.179055 \tValidation Loss: 2.421437\n",
      "Epoch: 18 \tTraining Loss: 0.156345 \tValidation Loss: 2.430087\n",
      "Epoch: 19 \tTraining Loss: 0.139056 \tValidation Loss: 2.439905\n",
      "Epoch: 20 \tTraining Loss: 0.124848 \tValidation Loss: 2.449322\n",
      "Epoch: 1 \tTraining Loss: 6.659721 \tValidation Loss: 5.512494\n",
      "Validation loss decreased (inf --> 5.51249).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.811385 \tValidation Loss: 5.144127\n",
      "Validation loss decreased (5.51249 --> 5.14413).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.116409 \tValidation Loss: 4.621674\n",
      "Validation loss decreased (5.14413 --> 4.62167).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.167875 \tValidation Loss: 4.049066\n",
      "Validation loss decreased (4.62167 --> 4.04907).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.220584 \tValidation Loss: 3.563425\n",
      "Validation loss decreased (4.04907 --> 3.56342).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.435694 \tValidation Loss: 3.198293\n",
      "Validation loss decreased (3.56342 --> 3.19829).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.843269 \tValidation Loss: 2.938794\n",
      "Validation loss decreased (3.19829 --> 2.93879).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.403177 \tValidation Loss: 2.753659\n",
      "Validation loss decreased (2.93879 --> 2.75366).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.076196 \tValidation Loss: 2.619078\n",
      "Validation loss decreased (2.75366 --> 2.61908).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.828508 \tValidation Loss: 2.520225\n",
      "Validation loss decreased (2.61908 --> 2.52023).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.638786 \tValidation Loss: 2.452478\n",
      "Validation loss decreased (2.52023 --> 2.45248).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.495671 \tValidation Loss: 2.407038\n",
      "Validation loss decreased (2.45248 --> 2.40704).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.392193 \tValidation Loss: 2.378133\n",
      "Validation loss decreased (2.40704 --> 2.37813).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.312625 \tValidation Loss: 2.363420\n",
      "Validation loss decreased (2.37813 --> 2.36342).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.256243 \tValidation Loss: 2.359893\n",
      "Validation loss decreased (2.36342 --> 2.35989).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.213086 \tValidation Loss: 2.362279\n",
      "Epoch: 17 \tTraining Loss: 0.180924 \tValidation Loss: 2.366648\n",
      "Epoch: 18 \tTraining Loss: 0.158018 \tValidation Loss: 2.372460\n",
      "Epoch: 19 \tTraining Loss: 0.138964 \tValidation Loss: 2.384067\n",
      "Epoch: 20 \tTraining Loss: 0.124309 \tValidation Loss: 2.397416\n",
      "Epoch: 1 \tTraining Loss: 6.640589 \tValidation Loss: 5.595491\n",
      "Validation loss decreased (inf --> 5.59549).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 5.804730 \tValidation Loss: 5.242312\n",
      "Validation loss decreased (5.59549 --> 5.24231).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.125446 \tValidation Loss: 4.733918\n",
      "Validation loss decreased (5.24231 --> 4.73392).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.183348 \tValidation Loss: 4.154149\n",
      "Validation loss decreased (4.73392 --> 4.15415).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.228037 \tValidation Loss: 3.663686\n",
      "Validation loss decreased (4.15415 --> 3.66369).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.446318 \tValidation Loss: 3.290574\n",
      "Validation loss decreased (3.66369 --> 3.29057).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.853539 \tValidation Loss: 3.018978\n",
      "Validation loss decreased (3.29057 --> 3.01898).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.411144 \tValidation Loss: 2.819537\n",
      "Validation loss decreased (3.01898 --> 2.81954).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.082287 \tValidation Loss: 2.671645\n",
      "Validation loss decreased (2.81954 --> 2.67165).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.834856 \tValidation Loss: 2.562300\n",
      "Validation loss decreased (2.67165 --> 2.56230).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.644083 \tValidation Loss: 2.484826\n",
      "Validation loss decreased (2.56230 --> 2.48483).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.501835 \tValidation Loss: 2.431512\n",
      "Validation loss decreased (2.48483 --> 2.43151).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.393550 \tValidation Loss: 2.396117\n",
      "Validation loss decreased (2.43151 --> 2.39612).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.317713 \tValidation Loss: 2.375438\n",
      "Validation loss decreased (2.39612 --> 2.37544).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.258577 \tValidation Loss: 2.366535\n",
      "Validation loss decreased (2.37544 --> 2.36654).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.216403 \tValidation Loss: 2.365032\n",
      "Validation loss decreased (2.36654 --> 2.36503).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.183911 \tValidation Loss: 2.368644\n",
      "Epoch: 18 \tTraining Loss: 0.160031 \tValidation Loss: 2.373882\n",
      "Epoch: 19 \tTraining Loss: 0.141520 \tValidation Loss: 2.382421\n",
      "Epoch: 20 \tTraining Loss: 0.126789 \tValidation Loss: 2.390102\n",
      "Epoch: 1 \tTraining Loss: 6.643310 \tValidation Loss: 5.570789\n",
      "Validation loss decreased (inf --> 5.57079).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.809980 \tValidation Loss: 5.214992\n",
      "Validation loss decreased (5.57079 --> 5.21499).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.130047 \tValidation Loss: 4.700978\n",
      "Validation loss decreased (5.21499 --> 4.70098).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.185870 \tValidation Loss: 4.112564\n",
      "Validation loss decreased (4.70098 --> 4.11256).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.225541 \tValidation Loss: 3.617896\n",
      "Validation loss decreased (4.11256 --> 3.61790).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.437318 \tValidation Loss: 3.240686\n",
      "Validation loss decreased (3.61790 --> 3.24069).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.841587 \tValidation Loss: 2.962583\n",
      "Validation loss decreased (3.24069 --> 2.96258).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.406959 \tValidation Loss: 2.755653\n",
      "Validation loss decreased (2.96258 --> 2.75565).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.077277 \tValidation Loss: 2.602028\n",
      "Validation loss decreased (2.75565 --> 2.60203).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.827418 \tValidation Loss: 2.487495\n",
      "Validation loss decreased (2.60203 --> 2.48749).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.640831 \tValidation Loss: 2.402401\n",
      "Validation loss decreased (2.48749 --> 2.40240).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.498579 \tValidation Loss: 2.343136\n",
      "Validation loss decreased (2.40240 --> 2.34314).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.391622 \tValidation Loss: 2.303086\n",
      "Validation loss decreased (2.34314 --> 2.30309).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.315403 \tValidation Loss: 2.282640\n",
      "Validation loss decreased (2.30309 --> 2.28264).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.258530 \tValidation Loss: 2.273312\n",
      "Validation loss decreased (2.28264 --> 2.27331).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.213330 \tValidation Loss: 2.267277\n",
      "Validation loss decreased (2.27331 --> 2.26728).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.184014 \tValidation Loss: 2.267014\n",
      "Validation loss decreased (2.26728 --> 2.26701).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.158458 \tValidation Loss: 2.269914\n",
      "Epoch: 19 \tTraining Loss: 0.141056 \tValidation Loss: 2.276681\n",
      "Epoch: 20 \tTraining Loss: 0.126050 \tValidation Loss: 2.283646\n",
      "Epoch: 1 \tTraining Loss: 6.647744 \tValidation Loss: 5.519799\n",
      "Validation loss decreased (inf --> 5.51980).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.808780 \tValidation Loss: 5.171855\n",
      "Validation loss decreased (5.51980 --> 5.17185).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.114297 \tValidation Loss: 4.668558\n",
      "Validation loss decreased (5.17185 --> 4.66856).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.163615 \tValidation Loss: 4.115846\n",
      "Validation loss decreased (4.66856 --> 4.11585).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.205609 \tValidation Loss: 3.658756\n",
      "Validation loss decreased (4.11585 --> 3.65876).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.427891 \tValidation Loss: 3.312505\n",
      "Validation loss decreased (3.65876 --> 3.31250).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.837871 \tValidation Loss: 3.054633\n",
      "Validation loss decreased (3.31250 --> 3.05463).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.403233 \tValidation Loss: 2.860819\n",
      "Validation loss decreased (3.05463 --> 2.86082).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.077623 \tValidation Loss: 2.715018\n",
      "Validation loss decreased (2.86082 --> 2.71502).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.830481 \tValidation Loss: 2.607162\n",
      "Validation loss decreased (2.71502 --> 2.60716).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.642519 \tValidation Loss: 2.529196\n",
      "Validation loss decreased (2.60716 --> 2.52920).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.497110 \tValidation Loss: 2.475583\n",
      "Validation loss decreased (2.52920 --> 2.47558).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.391086 \tValidation Loss: 2.439385\n",
      "Validation loss decreased (2.47558 --> 2.43938).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.312268 \tValidation Loss: 2.422027\n",
      "Validation loss decreased (2.43938 --> 2.42203).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.255179 \tValidation Loss: 2.414840\n",
      "Validation loss decreased (2.42203 --> 2.41484).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.213568 \tValidation Loss: 2.412591\n",
      "Validation loss decreased (2.41484 --> 2.41259).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.181320 \tValidation Loss: 2.416911\n",
      "Epoch: 18 \tTraining Loss: 0.156906 \tValidation Loss: 2.422302\n",
      "Epoch: 19 \tTraining Loss: 0.139138 \tValidation Loss: 2.432487\n",
      "Epoch: 20 \tTraining Loss: 0.124321 \tValidation Loss: 2.441321\n",
      "Epoch: 1 \tTraining Loss: 6.644041 \tValidation Loss: 5.534962\n",
      "Validation loss decreased (inf --> 5.53496).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.805334 \tValidation Loss: 5.185510\n",
      "Validation loss decreased (5.53496 --> 5.18551).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.118146 \tValidation Loss: 4.669433\n",
      "Validation loss decreased (5.18551 --> 4.66943).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.175252 \tValidation Loss: 4.080375\n",
      "Validation loss decreased (4.66943 --> 4.08037).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.222865 \tValidation Loss: 3.591846\n",
      "Validation loss decreased (4.08037 --> 3.59185).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.441768 \tValidation Loss: 3.227056\n",
      "Validation loss decreased (3.59185 --> 3.22706).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.852446 \tValidation Loss: 2.958477\n",
      "Validation loss decreased (3.22706 --> 2.95848).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.415308 \tValidation Loss: 2.755201\n",
      "Validation loss decreased (2.95848 --> 2.75520).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.081228 \tValidation Loss: 2.601498\n",
      "Validation loss decreased (2.75520 --> 2.60150).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.833355 \tValidation Loss: 2.485171\n",
      "Validation loss decreased (2.60150 --> 2.48517).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.644134 \tValidation Loss: 2.398527\n",
      "Validation loss decreased (2.48517 --> 2.39853).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 \tTraining Loss: 0.499457 \tValidation Loss: 2.340538\n",
      "Validation loss decreased (2.39853 --> 2.34054).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.392665 \tValidation Loss: 2.298996\n",
      "Validation loss decreased (2.34054 --> 2.29900).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.312951 \tValidation Loss: 2.271768\n",
      "Validation loss decreased (2.29900 --> 2.27177).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.256344 \tValidation Loss: 2.260839\n",
      "Validation loss decreased (2.27177 --> 2.26084).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.214468 \tValidation Loss: 2.256434\n",
      "Validation loss decreased (2.26084 --> 2.25643).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.182154 \tValidation Loss: 2.254976\n",
      "Validation loss decreased (2.25643 --> 2.25498).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.161261 \tValidation Loss: 2.259396\n",
      "Epoch: 19 \tTraining Loss: 0.141947 \tValidation Loss: 2.264878\n",
      "Epoch: 20 \tTraining Loss: 0.126991 \tValidation Loss: 2.271604\n",
      "Epoch: 1 \tTraining Loss: 6.647299 \tValidation Loss: 5.562152\n",
      "Validation loss decreased (inf --> 5.56215).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.808921 \tValidation Loss: 5.232863\n",
      "Validation loss decreased (5.56215 --> 5.23286).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.121571 \tValidation Loss: 4.752142\n",
      "Validation loss decreased (5.23286 --> 4.75214).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.176332 \tValidation Loss: 4.201175\n",
      "Validation loss decreased (4.75214 --> 4.20117).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.220836 \tValidation Loss: 3.730119\n",
      "Validation loss decreased (4.20117 --> 3.73012).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.437009 \tValidation Loss: 3.364800\n",
      "Validation loss decreased (3.73012 --> 3.36480).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.844938 \tValidation Loss: 3.086672\n",
      "Validation loss decreased (3.36480 --> 3.08667).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.404112 \tValidation Loss: 2.880062\n",
      "Validation loss decreased (3.08667 --> 2.88006).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.076579 \tValidation Loss: 2.725129\n",
      "Validation loss decreased (2.88006 --> 2.72513).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.830369 \tValidation Loss: 2.610429\n",
      "Validation loss decreased (2.72513 --> 2.61043).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.639977 \tValidation Loss: 2.529497\n",
      "Validation loss decreased (2.61043 --> 2.52950).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.497199 \tValidation Loss: 2.474099\n",
      "Validation loss decreased (2.52950 --> 2.47410).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.390833 \tValidation Loss: 2.439321\n",
      "Validation loss decreased (2.47410 --> 2.43932).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.311537 \tValidation Loss: 2.419430\n",
      "Validation loss decreased (2.43932 --> 2.41943).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.255270 \tValidation Loss: 2.411535\n",
      "Validation loss decreased (2.41943 --> 2.41153).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.212458 \tValidation Loss: 2.410142\n",
      "Validation loss decreased (2.41153 --> 2.41014).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.181598 \tValidation Loss: 2.416033\n",
      "Epoch: 18 \tTraining Loss: 0.156875 \tValidation Loss: 2.420640\n",
      "Epoch: 19 \tTraining Loss: 0.139250 \tValidation Loss: 2.433203\n",
      "Epoch: 20 \tTraining Loss: 0.126195 \tValidation Loss: 2.439957\n",
      "Epoch: 1 \tTraining Loss: 6.650865 \tValidation Loss: 5.451081\n",
      "Validation loss decreased (inf --> 5.45108).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.823293 \tValidation Loss: 5.113729\n",
      "Validation loss decreased (5.45108 --> 5.11373).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.148500 \tValidation Loss: 4.603142\n",
      "Validation loss decreased (5.11373 --> 4.60314).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.202078 \tValidation Loss: 4.039504\n",
      "Validation loss decreased (4.60314 --> 4.03950).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.240340 \tValidation Loss: 3.578164\n",
      "Validation loss decreased (4.03950 --> 3.57816).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.446560 \tValidation Loss: 3.233752\n",
      "Validation loss decreased (3.57816 --> 3.23375).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.852765 \tValidation Loss: 2.983000\n",
      "Validation loss decreased (3.23375 --> 2.98300).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.410732 \tValidation Loss: 2.798292\n",
      "Validation loss decreased (2.98300 --> 2.79829).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.082915 \tValidation Loss: 2.660028\n",
      "Validation loss decreased (2.79829 --> 2.66003).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.835416 \tValidation Loss: 2.561223\n",
      "Validation loss decreased (2.66003 --> 2.56122).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.645338 \tValidation Loss: 2.491131\n",
      "Validation loss decreased (2.56122 --> 2.49113).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.502900 \tValidation Loss: 2.443443\n",
      "Validation loss decreased (2.49113 --> 2.44344).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.393068 \tValidation Loss: 2.417335\n",
      "Validation loss decreased (2.44344 --> 2.41734).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.315359 \tValidation Loss: 2.402118\n",
      "Validation loss decreased (2.41734 --> 2.40212).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.259558 \tValidation Loss: 2.398805\n",
      "Validation loss decreased (2.40212 --> 2.39881).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.214985 \tValidation Loss: 2.397770\n",
      "Validation loss decreased (2.39881 --> 2.39777).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.183285 \tValidation Loss: 2.401578\n",
      "Epoch: 18 \tTraining Loss: 0.158954 \tValidation Loss: 2.410960\n",
      "Epoch: 19 \tTraining Loss: 0.140499 \tValidation Loss: 2.421815\n",
      "Epoch: 20 \tTraining Loss: 0.126719 \tValidation Loss: 2.432732\n",
      "Epoch: 1 \tTraining Loss: 6.644506 \tValidation Loss: 5.591513\n",
      "Validation loss decreased (inf --> 5.59151).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.817084 \tValidation Loss: 5.245425\n",
      "Validation loss decreased (5.59151 --> 5.24543).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.148622 \tValidation Loss: 4.736124\n",
      "Validation loss decreased (5.24543 --> 4.73612).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.214251 \tValidation Loss: 4.149345\n",
      "Validation loss decreased (4.73612 --> 4.14935).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.252876 \tValidation Loss: 3.665844\n",
      "Validation loss decreased (4.14935 --> 3.66584).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.460281 \tValidation Loss: 3.303081\n",
      "Validation loss decreased (3.66584 --> 3.30308).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.867448 \tValidation Loss: 3.032486\n",
      "Validation loss decreased (3.30308 --> 3.03249).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.422900 \tValidation Loss: 2.833305\n",
      "Validation loss decreased (3.03249 --> 2.83330).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.090789 \tValidation Loss: 2.687065\n",
      "Validation loss decreased (2.83330 --> 2.68706).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.841179 \tValidation Loss: 2.581719\n",
      "Validation loss decreased (2.68706 --> 2.58172).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.650455 \tValidation Loss: 2.504281\n",
      "Validation loss decreased (2.58172 --> 2.50428).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.504228 \tValidation Loss: 2.452149\n",
      "Validation loss decreased (2.50428 --> 2.45215).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.396833 \tValidation Loss: 2.420392\n",
      "Validation loss decreased (2.45215 --> 2.42039).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.316861 \tValidation Loss: 2.401378\n",
      "Validation loss decreased (2.42039 --> 2.40138).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.257007 \tValidation Loss: 2.393008\n",
      "Validation loss decreased (2.40138 --> 2.39301).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.216592 \tValidation Loss: 2.392549\n",
      "Validation loss decreased (2.39301 --> 2.39255).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.183226 \tValidation Loss: 2.393077\n",
      "Epoch: 18 \tTraining Loss: 0.157552 \tValidation Loss: 2.401315\n",
      "Epoch: 19 \tTraining Loss: 0.139739 \tValidation Loss: 2.410835\n",
      "Epoch: 20 \tTraining Loss: 0.125465 \tValidation Loss: 2.420780\n",
      "\n",
      " Starting:...-> Lemmatize = False , window = 10 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.775043 \tValidation Loss: 5.468232\n",
      "Validation loss decreased (inf --> 5.46823).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.863786 \tValidation Loss: 5.189759\n",
      "Validation loss decreased (5.46823 --> 5.18976).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.237368 \tValidation Loss: 4.754118\n",
      "Validation loss decreased (5.18976 --> 4.75412).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 \tTraining Loss: 4.376948 \tValidation Loss: 4.224119\n",
      "Validation loss decreased (4.75412 --> 4.22412).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.461360 \tValidation Loss: 3.757838\n",
      "Validation loss decreased (4.22412 --> 3.75784).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.668831 \tValidation Loss: 3.399447\n",
      "Validation loss decreased (3.75784 --> 3.39945).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.046721 \tValidation Loss: 3.134212\n",
      "Validation loss decreased (3.39945 --> 3.13421).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.572416 \tValidation Loss: 2.938843\n",
      "Validation loss decreased (3.13421 --> 2.93884).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.212427 \tValidation Loss: 2.788725\n",
      "Validation loss decreased (2.93884 --> 2.78872).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.942335 \tValidation Loss: 2.674773\n",
      "Validation loss decreased (2.78872 --> 2.67477).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.729883 \tValidation Loss: 2.589997\n",
      "Validation loss decreased (2.67477 --> 2.59000).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.568315 \tValidation Loss: 2.532324\n",
      "Validation loss decreased (2.59000 --> 2.53232).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.445362 \tValidation Loss: 2.494897\n",
      "Validation loss decreased (2.53232 --> 2.49490).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.354949 \tValidation Loss: 2.471611\n",
      "Validation loss decreased (2.49490 --> 2.47161).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.286442 \tValidation Loss: 2.459722\n",
      "Validation loss decreased (2.47161 --> 2.45972).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.235140 \tValidation Loss: 2.458275\n",
      "Validation loss decreased (2.45972 --> 2.45827).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.199725 \tValidation Loss: 2.459440\n",
      "Epoch: 18 \tTraining Loss: 0.170591 \tValidation Loss: 2.464588\n",
      "Epoch: 19 \tTraining Loss: 0.149807 \tValidation Loss: 2.471576\n",
      "Epoch: 20 \tTraining Loss: 0.133566 \tValidation Loss: 2.480363\n",
      "Epoch: 1 \tTraining Loss: 6.780198 \tValidation Loss: 5.476271\n",
      "Validation loss decreased (inf --> 5.47627).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.869432 \tValidation Loss: 5.192944\n",
      "Validation loss decreased (5.47627 --> 5.19294).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.238603 \tValidation Loss: 4.747059\n",
      "Validation loss decreased (5.19294 --> 4.74706).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.368750 \tValidation Loss: 4.218994\n",
      "Validation loss decreased (4.74706 --> 4.21899).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.444983 \tValidation Loss: 3.762783\n",
      "Validation loss decreased (4.21899 --> 3.76278).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.656391 \tValidation Loss: 3.413394\n",
      "Validation loss decreased (3.76278 --> 3.41339).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.032877 \tValidation Loss: 3.157539\n",
      "Validation loss decreased (3.41339 --> 3.15754).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.563148 \tValidation Loss: 2.966990\n",
      "Validation loss decreased (3.15754 --> 2.96699).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.214119 \tValidation Loss: 2.823266\n",
      "Validation loss decreased (2.96699 --> 2.82327).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.940708 \tValidation Loss: 2.716279\n",
      "Validation loss decreased (2.82327 --> 2.71628).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.731844 \tValidation Loss: 2.639935\n",
      "Validation loss decreased (2.71628 --> 2.63993).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.566435 \tValidation Loss: 2.588620\n",
      "Validation loss decreased (2.63993 --> 2.58862).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.446304 \tValidation Loss: 2.558204\n",
      "Validation loss decreased (2.58862 --> 2.55820).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.352869 \tValidation Loss: 2.543249\n",
      "Validation loss decreased (2.55820 --> 2.54325).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.286585 \tValidation Loss: 2.538720\n",
      "Validation loss decreased (2.54325 --> 2.53872).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.235100 \tValidation Loss: 2.541144\n",
      "Epoch: 17 \tTraining Loss: 0.195933 \tValidation Loss: 2.548103\n",
      "Epoch: 18 \tTraining Loss: 0.169068 \tValidation Loss: 2.555938\n",
      "Epoch: 19 \tTraining Loss: 0.147924 \tValidation Loss: 2.563149\n",
      "Epoch: 20 \tTraining Loss: 0.131610 \tValidation Loss: 2.570883\n",
      "Epoch: 1 \tTraining Loss: 6.776070 \tValidation Loss: 5.431038\n",
      "Validation loss decreased (inf --> 5.43104).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.878597 \tValidation Loss: 5.145334\n",
      "Validation loss decreased (5.43104 --> 5.14533).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.252313 \tValidation Loss: 4.701321\n",
      "Validation loss decreased (5.14533 --> 4.70132).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.385706 \tValidation Loss: 4.188910\n",
      "Validation loss decreased (4.70132 --> 4.18891).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.462092 \tValidation Loss: 3.738483\n",
      "Validation loss decreased (4.18891 --> 3.73848).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.661714 \tValidation Loss: 3.395809\n",
      "Validation loss decreased (3.73848 --> 3.39581).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.042049 \tValidation Loss: 3.139374\n",
      "Validation loss decreased (3.39581 --> 3.13937).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.572330 \tValidation Loss: 2.944302\n",
      "Validation loss decreased (3.13937 --> 2.94430).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.217472 \tValidation Loss: 2.799833\n",
      "Validation loss decreased (2.94430 --> 2.79983).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.942386 \tValidation Loss: 2.694442\n",
      "Validation loss decreased (2.79983 --> 2.69444).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.731381 \tValidation Loss: 2.622568\n",
      "Validation loss decreased (2.69444 --> 2.62257).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.568316 \tValidation Loss: 2.574781\n",
      "Validation loss decreased (2.62257 --> 2.57478).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.447466 \tValidation Loss: 2.544961\n",
      "Validation loss decreased (2.57478 --> 2.54496).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.356140 \tValidation Loss: 2.528936\n",
      "Validation loss decreased (2.54496 --> 2.52894).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.287980 \tValidation Loss: 2.526439\n",
      "Validation loss decreased (2.52894 --> 2.52644).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.239589 \tValidation Loss: 2.525782\n",
      "Validation loss decreased (2.52644 --> 2.52578).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.200585 \tValidation Loss: 2.532851\n",
      "Epoch: 18 \tTraining Loss: 0.172050 \tValidation Loss: 2.543898\n",
      "Epoch: 19 \tTraining Loss: 0.149126 \tValidation Loss: 2.552218\n",
      "Epoch: 20 \tTraining Loss: 0.131852 \tValidation Loss: 2.563454\n",
      "Epoch: 1 \tTraining Loss: 6.768821 \tValidation Loss: 5.414251\n",
      "Validation loss decreased (inf --> 5.41425).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.881567 \tValidation Loss: 5.137297\n",
      "Validation loss decreased (5.41425 --> 5.13730).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.256112 \tValidation Loss: 4.709403\n",
      "Validation loss decreased (5.13730 --> 4.70940).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.395446 \tValidation Loss: 4.190981\n",
      "Validation loss decreased (4.70940 --> 4.19098).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.472138 \tValidation Loss: 3.724506\n",
      "Validation loss decreased (4.19098 --> 3.72451).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.675777 \tValidation Loss: 3.363605\n",
      "Validation loss decreased (3.72451 --> 3.36360).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.051476 \tValidation Loss: 3.097689\n",
      "Validation loss decreased (3.36360 --> 3.09769).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.581887 \tValidation Loss: 2.906886\n",
      "Validation loss decreased (3.09769 --> 2.90689).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.223140 \tValidation Loss: 2.768346\n",
      "Validation loss decreased (2.90689 --> 2.76835).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.950176 \tValidation Loss: 2.665374\n",
      "Validation loss decreased (2.76835 --> 2.66537).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.734988 \tValidation Loss: 2.589440\n",
      "Validation loss decreased (2.66537 --> 2.58944).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.573598 \tValidation Loss: 2.539143\n",
      "Validation loss decreased (2.58944 --> 2.53914).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.448718 \tValidation Loss: 2.509721\n",
      "Validation loss decreased (2.53914 --> 2.50972).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.355236 \tValidation Loss: 2.495624\n",
      "Validation loss decreased (2.50972 --> 2.49562).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 \tTraining Loss: 0.287700 \tValidation Loss: 2.491606\n",
      "Validation loss decreased (2.49562 --> 2.49161).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.237414 \tValidation Loss: 2.493353\n",
      "Epoch: 17 \tTraining Loss: 0.201699 \tValidation Loss: 2.499692\n",
      "Epoch: 18 \tTraining Loss: 0.172742 \tValidation Loss: 2.506397\n",
      "Epoch: 19 \tTraining Loss: 0.151315 \tValidation Loss: 2.514734\n",
      "Epoch: 20 \tTraining Loss: 0.132755 \tValidation Loss: 2.524458\n",
      "Epoch: 1 \tTraining Loss: 6.767661 \tValidation Loss: 5.439148\n",
      "Validation loss decreased (inf --> 5.43915).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.879286 \tValidation Loss: 5.157274\n",
      "Validation loss decreased (5.43915 --> 5.15727).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.254623 \tValidation Loss: 4.719342\n",
      "Validation loss decreased (5.15727 --> 4.71934).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.388449 \tValidation Loss: 4.207467\n",
      "Validation loss decreased (4.71934 --> 4.20747).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.464017 \tValidation Loss: 3.758380\n",
      "Validation loss decreased (4.20747 --> 3.75838).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.671064 \tValidation Loss: 3.400841\n",
      "Validation loss decreased (3.75838 --> 3.40084).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.048489 \tValidation Loss: 3.131471\n",
      "Validation loss decreased (3.40084 --> 3.13147).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.578239 \tValidation Loss: 2.929372\n",
      "Validation loss decreased (3.13147 --> 2.92937).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.222767 \tValidation Loss: 2.779678\n",
      "Validation loss decreased (2.92937 --> 2.77968).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.949669 \tValidation Loss: 2.669892\n",
      "Validation loss decreased (2.77968 --> 2.66989).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.738732 \tValidation Loss: 2.587284\n",
      "Validation loss decreased (2.66989 --> 2.58728).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.574708 \tValidation Loss: 2.531360\n",
      "Validation loss decreased (2.58728 --> 2.53136).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.450518 \tValidation Loss: 2.493245\n",
      "Validation loss decreased (2.53136 --> 2.49325).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.357978 \tValidation Loss: 2.474253\n",
      "Validation loss decreased (2.49325 --> 2.47425).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.289464 \tValidation Loss: 2.463596\n",
      "Validation loss decreased (2.47425 --> 2.46360).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.239885 \tValidation Loss: 2.460691\n",
      "Validation loss decreased (2.46360 --> 2.46069).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.200761 \tValidation Loss: 2.464663\n",
      "Epoch: 18 \tTraining Loss: 0.173754 \tValidation Loss: 2.472674\n",
      "Epoch: 19 \tTraining Loss: 0.152391 \tValidation Loss: 2.479625\n",
      "Epoch: 20 \tTraining Loss: 0.133929 \tValidation Loss: 2.489985\n",
      "Epoch: 1 \tTraining Loss: 6.777382 \tValidation Loss: 5.416551\n",
      "Validation loss decreased (inf --> 5.41655).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.877299 \tValidation Loss: 5.130470\n",
      "Validation loss decreased (5.41655 --> 5.13047).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.250129 \tValidation Loss: 4.684524\n",
      "Validation loss decreased (5.13047 --> 4.68452).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.385055 \tValidation Loss: 4.155856\n",
      "Validation loss decreased (4.68452 --> 4.15586).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.461484 \tValidation Loss: 3.687289\n",
      "Validation loss decreased (4.15586 --> 3.68729).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.656903 \tValidation Loss: 3.328696\n",
      "Validation loss decreased (3.68729 --> 3.32870).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.035047 \tValidation Loss: 3.059806\n",
      "Validation loss decreased (3.32870 --> 3.05981).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.567814 \tValidation Loss: 2.858814\n",
      "Validation loss decreased (3.05981 --> 2.85881).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.212665 \tValidation Loss: 2.709669\n",
      "Validation loss decreased (2.85881 --> 2.70967).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.937706 \tValidation Loss: 2.598595\n",
      "Validation loss decreased (2.70967 --> 2.59860).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.731452 \tValidation Loss: 2.513780\n",
      "Validation loss decreased (2.59860 --> 2.51378).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.569009 \tValidation Loss: 2.456134\n",
      "Validation loss decreased (2.51378 --> 2.45613).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.444940 \tValidation Loss: 2.416774\n",
      "Validation loss decreased (2.45613 --> 2.41677).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.354484 \tValidation Loss: 2.392854\n",
      "Validation loss decreased (2.41677 --> 2.39285).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.287168 \tValidation Loss: 2.380218\n",
      "Validation loss decreased (2.39285 --> 2.38022).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.236143 \tValidation Loss: 2.375573\n",
      "Validation loss decreased (2.38022 --> 2.37557).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.199773 \tValidation Loss: 2.378619\n",
      "Epoch: 18 \tTraining Loss: 0.171273 \tValidation Loss: 2.379051\n",
      "Epoch: 19 \tTraining Loss: 0.150004 \tValidation Loss: 2.383751\n",
      "Epoch: 20 \tTraining Loss: 0.132766 \tValidation Loss: 2.393331\n",
      "Epoch: 1 \tTraining Loss: 6.776534 \tValidation Loss: 5.422332\n",
      "Validation loss decreased (inf --> 5.42233).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.862847 \tValidation Loss: 5.120895\n",
      "Validation loss decreased (5.42233 --> 5.12089).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.228531 \tValidation Loss: 4.673989\n",
      "Validation loss decreased (5.12089 --> 4.67399).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.363255 \tValidation Loss: 4.164010\n",
      "Validation loss decreased (4.67399 --> 4.16401).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.440383 \tValidation Loss: 3.716016\n",
      "Validation loss decreased (4.16401 --> 3.71602).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.647612 \tValidation Loss: 3.364305\n",
      "Validation loss decreased (3.71602 --> 3.36431).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.030253 \tValidation Loss: 3.101549\n",
      "Validation loss decreased (3.36431 --> 3.10155).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.563958 \tValidation Loss: 2.907270\n",
      "Validation loss decreased (3.10155 --> 2.90727).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.208985 \tValidation Loss: 2.762716\n",
      "Validation loss decreased (2.90727 --> 2.76272).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.938851 \tValidation Loss: 2.656074\n",
      "Validation loss decreased (2.76272 --> 2.65607).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.729360 \tValidation Loss: 2.576800\n",
      "Validation loss decreased (2.65607 --> 2.57680).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.564062 \tValidation Loss: 2.521919\n",
      "Validation loss decreased (2.57680 --> 2.52192).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.442360 \tValidation Loss: 2.490527\n",
      "Validation loss decreased (2.52192 --> 2.49053).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.350779 \tValidation Loss: 2.471493\n",
      "Validation loss decreased (2.49053 --> 2.47149).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.283603 \tValidation Loss: 2.464108\n",
      "Validation loss decreased (2.47149 --> 2.46411).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.232442 \tValidation Loss: 2.465989\n",
      "Epoch: 17 \tTraining Loss: 0.197519 \tValidation Loss: 2.472115\n",
      "Epoch: 18 \tTraining Loss: 0.169251 \tValidation Loss: 2.476571\n",
      "Epoch: 19 \tTraining Loss: 0.147253 \tValidation Loss: 2.488017\n",
      "Epoch: 20 \tTraining Loss: 0.131418 \tValidation Loss: 2.498583\n",
      "Epoch: 1 \tTraining Loss: 6.769454 \tValidation Loss: 5.410538\n",
      "Validation loss decreased (inf --> 5.41054).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.867014 \tValidation Loss: 5.123694\n",
      "Validation loss decreased (5.41054 --> 5.12369).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.236870 \tValidation Loss: 4.674943\n",
      "Validation loss decreased (5.12369 --> 4.67494).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.376525 \tValidation Loss: 4.155506\n",
      "Validation loss decreased (4.67494 --> 4.15551).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.461661 \tValidation Loss: 3.694756\n",
      "Validation loss decreased (4.15551 --> 3.69476).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.668228 \tValidation Loss: 3.347321\n",
      "Validation loss decreased (3.69476 --> 3.34732).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.044533 \tValidation Loss: 3.098426\n",
      "Validation loss decreased (3.34732 --> 3.09843).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.571994 \tValidation Loss: 2.916687\n",
      "Validation loss decreased (3.09843 --> 2.91669).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 \tTraining Loss: 1.211857 \tValidation Loss: 2.785837\n",
      "Validation loss decreased (2.91669 --> 2.78584).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.936536 \tValidation Loss: 2.692147\n",
      "Validation loss decreased (2.78584 --> 2.69215).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.726614 \tValidation Loss: 2.629389\n",
      "Validation loss decreased (2.69215 --> 2.62939).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.567634 \tValidation Loss: 2.587831\n",
      "Validation loss decreased (2.62939 --> 2.58783).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.445644 \tValidation Loss: 2.563404\n",
      "Validation loss decreased (2.58783 --> 2.56340).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.352800 \tValidation Loss: 2.550368\n",
      "Validation loss decreased (2.56340 --> 2.55037).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.286067 \tValidation Loss: 2.548143\n",
      "Validation loss decreased (2.55037 --> 2.54814).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.238166 \tValidation Loss: 2.553784\n",
      "Epoch: 17 \tTraining Loss: 0.200003 \tValidation Loss: 2.561918\n",
      "Epoch: 18 \tTraining Loss: 0.171675 \tValidation Loss: 2.570460\n",
      "Epoch: 19 \tTraining Loss: 0.150199 \tValidation Loss: 2.581570\n",
      "Epoch: 20 \tTraining Loss: 0.132340 \tValidation Loss: 2.592110\n",
      "Epoch: 1 \tTraining Loss: 6.765404 \tValidation Loss: 5.420147\n",
      "Validation loss decreased (inf --> 5.42015).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.874549 \tValidation Loss: 5.147342\n",
      "Validation loss decreased (5.42015 --> 5.14734).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.252841 \tValidation Loss: 4.712898\n",
      "Validation loss decreased (5.14734 --> 4.71290).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.389827 \tValidation Loss: 4.191641\n",
      "Validation loss decreased (4.71290 --> 4.19164).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.460210 \tValidation Loss: 3.736005\n",
      "Validation loss decreased (4.19164 --> 3.73600).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.659033 \tValidation Loss: 3.386240\n",
      "Validation loss decreased (3.73600 --> 3.38624).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.035577 \tValidation Loss: 3.125236\n",
      "Validation loss decreased (3.38624 --> 3.12524).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.564903 \tValidation Loss: 2.930850\n",
      "Validation loss decreased (3.12524 --> 2.93085).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.206393 \tValidation Loss: 2.787422\n",
      "Validation loss decreased (2.93085 --> 2.78742).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.932815 \tValidation Loss: 2.681402\n",
      "Validation loss decreased (2.78742 --> 2.68140).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.724847 \tValidation Loss: 2.601140\n",
      "Validation loss decreased (2.68140 --> 2.60114).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.560627 \tValidation Loss: 2.547581\n",
      "Validation loss decreased (2.60114 --> 2.54758).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.439649 \tValidation Loss: 2.517254\n",
      "Validation loss decreased (2.54758 --> 2.51725).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.349730 \tValidation Loss: 2.493914\n",
      "Validation loss decreased (2.51725 --> 2.49391).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.281356 \tValidation Loss: 2.487652\n",
      "Validation loss decreased (2.49391 --> 2.48765).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.234314 \tValidation Loss: 2.484140\n",
      "Validation loss decreased (2.48765 --> 2.48414).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.199598 \tValidation Loss: 2.489137\n",
      "Epoch: 18 \tTraining Loss: 0.170076 \tValidation Loss: 2.494783\n",
      "Epoch: 19 \tTraining Loss: 0.149842 \tValidation Loss: 2.498507\n",
      "Epoch: 20 \tTraining Loss: 0.132722 \tValidation Loss: 2.506801\n",
      "Epoch: 1 \tTraining Loss: 6.769518 \tValidation Loss: 5.394647\n",
      "Validation loss decreased (inf --> 5.39465).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.877122 \tValidation Loss: 5.101315\n",
      "Validation loss decreased (5.39465 --> 5.10131).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.250169 \tValidation Loss: 4.657422\n",
      "Validation loss decreased (5.10131 --> 4.65742).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.380998 \tValidation Loss: 4.142961\n",
      "Validation loss decreased (4.65742 --> 4.14296).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.453186 \tValidation Loss: 3.694443\n",
      "Validation loss decreased (4.14296 --> 3.69444).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.654486 \tValidation Loss: 3.346914\n",
      "Validation loss decreased (3.69444 --> 3.34691).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.034089 \tValidation Loss: 3.090070\n",
      "Validation loss decreased (3.34691 --> 3.09007).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.566211 \tValidation Loss: 2.898430\n",
      "Validation loss decreased (3.09007 --> 2.89843).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.209451 \tValidation Loss: 2.757413\n",
      "Validation loss decreased (2.89843 --> 2.75741).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.940118 \tValidation Loss: 2.655329\n",
      "Validation loss decreased (2.75741 --> 2.65533).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.728049 \tValidation Loss: 2.582049\n",
      "Validation loss decreased (2.65533 --> 2.58205).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.568729 \tValidation Loss: 2.532807\n",
      "Validation loss decreased (2.58205 --> 2.53281).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.445908 \tValidation Loss: 2.502154\n",
      "Validation loss decreased (2.53281 --> 2.50215).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.353298 \tValidation Loss: 2.484084\n",
      "Validation loss decreased (2.50215 --> 2.48408).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.285609 \tValidation Loss: 2.475246\n",
      "Validation loss decreased (2.48408 --> 2.47525).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.238332 \tValidation Loss: 2.471424\n",
      "Validation loss decreased (2.47525 --> 2.47142).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.199496 \tValidation Loss: 2.475308\n",
      "Epoch: 18 \tTraining Loss: 0.172586 \tValidation Loss: 2.480712\n",
      "Epoch: 19 \tTraining Loss: 0.150035 \tValidation Loss: 2.487304\n",
      "Epoch: 20 \tTraining Loss: 0.134246 \tValidation Loss: 2.497358\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 3 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.105596 \tValidation Loss: 5.401614\n",
      "Validation loss decreased (inf --> 5.40161).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.644460 \tValidation Loss: 5.249203\n",
      "Validation loss decreased (5.40161 --> 5.24920).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.341819 \tValidation Loss: 5.022701\n",
      "Validation loss decreased (5.24920 --> 5.02270).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.916101 \tValidation Loss: 4.775715\n",
      "Validation loss decreased (5.02270 --> 4.77572).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.440005 \tValidation Loss: 4.561367\n",
      "Validation loss decreased (4.77572 --> 4.56137).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.979089 \tValidation Loss: 4.394356\n",
      "Validation loss decreased (4.56137 --> 4.39436).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.576236 \tValidation Loss: 4.276189\n",
      "Validation loss decreased (4.39436 --> 4.27619).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.239940 \tValidation Loss: 4.196752\n",
      "Validation loss decreased (4.27619 --> 4.19675).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.972873 \tValidation Loss: 4.147613\n",
      "Validation loss decreased (4.19675 --> 4.14761).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.754402 \tValidation Loss: 4.118797\n",
      "Validation loss decreased (4.14761 --> 4.11880).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.582848 \tValidation Loss: 4.107243\n",
      "Validation loss decreased (4.11880 --> 4.10724).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.442526 \tValidation Loss: 4.106872\n",
      "Validation loss decreased (4.10724 --> 4.10687).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.334617 \tValidation Loss: 4.114362\n",
      "Epoch: 14 \tTraining Loss: 2.240201 \tValidation Loss: 4.127863\n",
      "Epoch: 15 \tTraining Loss: 2.162601 \tValidation Loss: 4.145094\n",
      "Epoch: 16 \tTraining Loss: 2.104034 \tValidation Loss: 4.165649\n",
      "Epoch: 17 \tTraining Loss: 2.045311 \tValidation Loss: 4.189259\n",
      "Epoch: 18 \tTraining Loss: 2.000904 \tValidation Loss: 4.216182\n",
      "Epoch: 19 \tTraining Loss: 1.964143 \tValidation Loss: 4.242571\n",
      "Epoch: 20 \tTraining Loss: 1.922676 \tValidation Loss: 4.269328\n",
      "Epoch: 1 \tTraining Loss: 6.101972 \tValidation Loss: 5.379672\n",
      "Validation loss decreased (inf --> 5.37967).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.648536 \tValidation Loss: 5.231304\n",
      "Validation loss decreased (5.37967 --> 5.23130).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.345759 \tValidation Loss: 5.006916\n",
      "Validation loss decreased (5.23130 --> 5.00692).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 \tTraining Loss: 4.915306 \tValidation Loss: 4.768245\n",
      "Validation loss decreased (5.00692 --> 4.76825).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.438693 \tValidation Loss: 4.563133\n",
      "Validation loss decreased (4.76825 --> 4.56313).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.976362 \tValidation Loss: 4.404309\n",
      "Validation loss decreased (4.56313 --> 4.40431).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.576288 \tValidation Loss: 4.293754\n",
      "Validation loss decreased (4.40431 --> 4.29375).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.245232 \tValidation Loss: 4.219080\n",
      "Validation loss decreased (4.29375 --> 4.21908).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.977880 \tValidation Loss: 4.171435\n",
      "Validation loss decreased (4.21908 --> 4.17143).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.764001 \tValidation Loss: 4.143919\n",
      "Validation loss decreased (4.17143 --> 4.14392).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.589774 \tValidation Loss: 4.130147\n",
      "Validation loss decreased (4.14392 --> 4.13015).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.455120 \tValidation Loss: 4.127234\n",
      "Validation loss decreased (4.13015 --> 4.12723).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.339702 \tValidation Loss: 4.131914\n",
      "Epoch: 14 \tTraining Loss: 2.246518 \tValidation Loss: 4.142610\n",
      "Epoch: 15 \tTraining Loss: 2.170572 \tValidation Loss: 4.158993\n",
      "Epoch: 16 \tTraining Loss: 2.108721 \tValidation Loss: 4.177646\n",
      "Epoch: 17 \tTraining Loss: 2.051180 \tValidation Loss: 4.201966\n",
      "Epoch: 18 \tTraining Loss: 2.008360 \tValidation Loss: 4.225652\n",
      "Epoch: 19 \tTraining Loss: 1.967544 \tValidation Loss: 4.250425\n",
      "Epoch: 20 \tTraining Loss: 1.935168 \tValidation Loss: 4.277672\n",
      "Epoch: 1 \tTraining Loss: 6.096916 \tValidation Loss: 5.405869\n",
      "Validation loss decreased (inf --> 5.40587).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.642816 \tValidation Loss: 5.251760\n",
      "Validation loss decreased (5.40587 --> 5.25176).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.340636 \tValidation Loss: 5.022119\n",
      "Validation loss decreased (5.25176 --> 5.02212).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.912849 \tValidation Loss: 4.771715\n",
      "Validation loss decreased (5.02212 --> 4.77172).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.437801 \tValidation Loss: 4.550890\n",
      "Validation loss decreased (4.77172 --> 4.55089).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.978019 \tValidation Loss: 4.377112\n",
      "Validation loss decreased (4.55089 --> 4.37711).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.574583 \tValidation Loss: 4.255872\n",
      "Validation loss decreased (4.37711 --> 4.25587).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.241478 \tValidation Loss: 4.176926\n",
      "Validation loss decreased (4.25587 --> 4.17693).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.971219 \tValidation Loss: 4.127232\n",
      "Validation loss decreased (4.17693 --> 4.12723).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.755147 \tValidation Loss: 4.100249\n",
      "Validation loss decreased (4.12723 --> 4.10025).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.584552 \tValidation Loss: 4.086980\n",
      "Validation loss decreased (4.10025 --> 4.08698).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.442920 \tValidation Loss: 4.085591\n",
      "Validation loss decreased (4.08698 --> 4.08559).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.332878 \tValidation Loss: 4.091311\n",
      "Epoch: 14 \tTraining Loss: 2.238862 \tValidation Loss: 4.103660\n",
      "Epoch: 15 \tTraining Loss: 2.160274 \tValidation Loss: 4.118244\n",
      "Epoch: 16 \tTraining Loss: 2.097183 \tValidation Loss: 4.137906\n",
      "Epoch: 17 \tTraining Loss: 2.046128 \tValidation Loss: 4.162244\n",
      "Epoch: 18 \tTraining Loss: 1.998496 \tValidation Loss: 4.184609\n",
      "Epoch: 19 \tTraining Loss: 1.960169 \tValidation Loss: 4.209467\n",
      "Epoch: 20 \tTraining Loss: 1.926511 \tValidation Loss: 4.235289\n",
      "Epoch: 1 \tTraining Loss: 6.100889 \tValidation Loss: 5.410107\n",
      "Validation loss decreased (inf --> 5.41011).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.635283 \tValidation Loss: 5.251560\n",
      "Validation loss decreased (5.41011 --> 5.25156).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.325635 \tValidation Loss: 5.011232\n",
      "Validation loss decreased (5.25156 --> 5.01123).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.894695 \tValidation Loss: 4.757629\n",
      "Validation loss decreased (5.01123 --> 4.75763).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.422973 \tValidation Loss: 4.537231\n",
      "Validation loss decreased (4.75763 --> 4.53723).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.968872 \tValidation Loss: 4.364928\n",
      "Validation loss decreased (4.53723 --> 4.36493).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.572942 \tValidation Loss: 4.241029\n",
      "Validation loss decreased (4.36493 --> 4.24103).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.241169 \tValidation Loss: 4.157109\n",
      "Validation loss decreased (4.24103 --> 4.15711).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.973568 \tValidation Loss: 4.102609\n",
      "Validation loss decreased (4.15711 --> 4.10261).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.758891 \tValidation Loss: 4.071487\n",
      "Validation loss decreased (4.10261 --> 4.07149).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.585809 \tValidation Loss: 4.058655\n",
      "Validation loss decreased (4.07149 --> 4.05866).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.445888 \tValidation Loss: 4.058103\n",
      "Validation loss decreased (4.05866 --> 4.05810).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.330151 \tValidation Loss: 4.066613\n",
      "Epoch: 14 \tTraining Loss: 2.237523 \tValidation Loss: 4.081493\n",
      "Epoch: 15 \tTraining Loss: 2.166165 \tValidation Loss: 4.100507\n",
      "Epoch: 16 \tTraining Loss: 2.101346 \tValidation Loss: 4.123536\n",
      "Epoch: 17 \tTraining Loss: 2.047423 \tValidation Loss: 4.147091\n",
      "Epoch: 18 \tTraining Loss: 2.001303 \tValidation Loss: 4.174008\n",
      "Epoch: 19 \tTraining Loss: 1.965668 \tValidation Loss: 4.202302\n",
      "Epoch: 20 \tTraining Loss: 1.931335 \tValidation Loss: 4.229734\n",
      "Epoch: 1 \tTraining Loss: 6.100049 \tValidation Loss: 5.425202\n",
      "Validation loss decreased (inf --> 5.42520).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.643637 \tValidation Loss: 5.276164\n",
      "Validation loss decreased (5.42520 --> 5.27616).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.340009 \tValidation Loss: 5.047604\n",
      "Validation loss decreased (5.27616 --> 5.04760).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.913165 \tValidation Loss: 4.799969\n",
      "Validation loss decreased (5.04760 --> 4.79997).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.440635 \tValidation Loss: 4.585439\n",
      "Validation loss decreased (4.79997 --> 4.58544).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.983479 \tValidation Loss: 4.414994\n",
      "Validation loss decreased (4.58544 --> 4.41499).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.581146 \tValidation Loss: 4.291687\n",
      "Validation loss decreased (4.41499 --> 4.29169).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.248049 \tValidation Loss: 4.205172\n",
      "Validation loss decreased (4.29169 --> 4.20517).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.977727 \tValidation Loss: 4.145995\n",
      "Validation loss decreased (4.20517 --> 4.14599).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.765375 \tValidation Loss: 4.109551\n",
      "Validation loss decreased (4.14599 --> 4.10955).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.592280 \tValidation Loss: 4.087732\n",
      "Validation loss decreased (4.10955 --> 4.08773).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.451225 \tValidation Loss: 4.077526\n",
      "Validation loss decreased (4.08773 --> 4.07753).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.339701 \tValidation Loss: 4.077417\n",
      "Validation loss decreased (4.07753 --> 4.07742).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 2.247516 \tValidation Loss: 4.084659\n",
      "Epoch: 15 \tTraining Loss: 2.169007 \tValidation Loss: 4.095908\n",
      "Epoch: 16 \tTraining Loss: 2.108328 \tValidation Loss: 4.112046\n",
      "Epoch: 17 \tTraining Loss: 2.051675 \tValidation Loss: 4.131053\n",
      "Epoch: 18 \tTraining Loss: 2.006109 \tValidation Loss: 4.153160\n",
      "Epoch: 19 \tTraining Loss: 1.966139 \tValidation Loss: 4.175194\n",
      "Epoch: 20 \tTraining Loss: 1.935960 \tValidation Loss: 4.198057\n",
      "Epoch: 1 \tTraining Loss: 6.103673 \tValidation Loss: 5.384076\n",
      "Validation loss decreased (inf --> 5.38408).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.643044 \tValidation Loss: 5.225022\n",
      "Validation loss decreased (5.38408 --> 5.22502).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.336826 \tValidation Loss: 4.988480\n",
      "Validation loss decreased (5.22502 --> 4.98848).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.910828 \tValidation Loss: 4.734934\n",
      "Validation loss decreased (4.98848 --> 4.73493).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \tTraining Loss: 4.437042 \tValidation Loss: 4.515269\n",
      "Validation loss decreased (4.73493 --> 4.51527).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.980464 \tValidation Loss: 4.343904\n",
      "Validation loss decreased (4.51527 --> 4.34390).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.577472 \tValidation Loss: 4.220691\n",
      "Validation loss decreased (4.34390 --> 4.22069).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.246315 \tValidation Loss: 4.136630\n",
      "Validation loss decreased (4.22069 --> 4.13663).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.975556 \tValidation Loss: 4.081750\n",
      "Validation loss decreased (4.13663 --> 4.08175).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.760822 \tValidation Loss: 4.047606\n",
      "Validation loss decreased (4.08175 --> 4.04761).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.585883 \tValidation Loss: 4.029284\n",
      "Validation loss decreased (4.04761 --> 4.02928).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.445880 \tValidation Loss: 4.022780\n",
      "Validation loss decreased (4.02928 --> 4.02278).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.334295 \tValidation Loss: 4.025777\n",
      "Epoch: 14 \tTraining Loss: 2.241419 \tValidation Loss: 4.034178\n",
      "Epoch: 15 \tTraining Loss: 2.164073 \tValidation Loss: 4.046563\n",
      "Epoch: 16 \tTraining Loss: 2.103812 \tValidation Loss: 4.064537\n",
      "Epoch: 17 \tTraining Loss: 2.045569 \tValidation Loss: 4.084993\n",
      "Epoch: 18 \tTraining Loss: 2.000129 \tValidation Loss: 4.106390\n",
      "Epoch: 19 \tTraining Loss: 1.960839 \tValidation Loss: 4.130516\n",
      "Epoch: 20 \tTraining Loss: 1.925482 \tValidation Loss: 4.155168\n",
      "Epoch: 1 \tTraining Loss: 6.108958 \tValidation Loss: 5.395538\n",
      "Validation loss decreased (inf --> 5.39554).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.646153 \tValidation Loss: 5.242346\n",
      "Validation loss decreased (5.39554 --> 5.24235).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.340036 \tValidation Loss: 5.010216\n",
      "Validation loss decreased (5.24235 --> 5.01022).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.911303 \tValidation Loss: 4.765653\n",
      "Validation loss decreased (5.01022 --> 4.76565).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.435383 \tValidation Loss: 4.555761\n",
      "Validation loss decreased (4.76565 --> 4.55576).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.975255 \tValidation Loss: 4.393933\n",
      "Validation loss decreased (4.55576 --> 4.39393).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.573973 \tValidation Loss: 4.279953\n",
      "Validation loss decreased (4.39393 --> 4.27995).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.241468 \tValidation Loss: 4.203313\n",
      "Validation loss decreased (4.27995 --> 4.20331).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.972849 \tValidation Loss: 4.154338\n",
      "Validation loss decreased (4.20331 --> 4.15434).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.758723 \tValidation Loss: 4.123846\n",
      "Validation loss decreased (4.15434 --> 4.12385).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.586944 \tValidation Loss: 4.106492\n",
      "Validation loss decreased (4.12385 --> 4.10649).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.447061 \tValidation Loss: 4.101700\n",
      "Validation loss decreased (4.10649 --> 4.10170).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.337170 \tValidation Loss: 4.104586\n",
      "Epoch: 14 \tTraining Loss: 2.243031 \tValidation Loss: 4.114209\n",
      "Epoch: 15 \tTraining Loss: 2.167488 \tValidation Loss: 4.128300\n",
      "Epoch: 16 \tTraining Loss: 2.103796 \tValidation Loss: 4.145092\n",
      "Epoch: 17 \tTraining Loss: 2.050059 \tValidation Loss: 4.163852\n",
      "Epoch: 18 \tTraining Loss: 2.005431 \tValidation Loss: 4.186132\n",
      "Epoch: 19 \tTraining Loss: 1.965429 \tValidation Loss: 4.210498\n",
      "Epoch: 20 \tTraining Loss: 1.931685 \tValidation Loss: 4.235916\n",
      "Epoch: 1 \tTraining Loss: 6.106199 \tValidation Loss: 5.360448\n",
      "Validation loss decreased (inf --> 5.36045).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.639587 \tValidation Loss: 5.195694\n",
      "Validation loss decreased (5.36045 --> 5.19569).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.331543 \tValidation Loss: 4.959534\n",
      "Validation loss decreased (5.19569 --> 4.95953).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.903888 \tValidation Loss: 4.713603\n",
      "Validation loss decreased (4.95953 --> 4.71360).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.428946 \tValidation Loss: 4.500680\n",
      "Validation loss decreased (4.71360 --> 4.50068).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.968060 \tValidation Loss: 4.333565\n",
      "Validation loss decreased (4.50068 --> 4.33356).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.568957 \tValidation Loss: 4.214052\n",
      "Validation loss decreased (4.33356 --> 4.21405).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.238686 \tValidation Loss: 4.134128\n",
      "Validation loss decreased (4.21405 --> 4.13413).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.971600 \tValidation Loss: 4.082280\n",
      "Validation loss decreased (4.13413 --> 4.08228).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.756515 \tValidation Loss: 4.051714\n",
      "Validation loss decreased (4.08228 --> 4.05171).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.586045 \tValidation Loss: 4.036087\n",
      "Validation loss decreased (4.05171 --> 4.03609).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.447149 \tValidation Loss: 4.032395\n",
      "Validation loss decreased (4.03609 --> 4.03240).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.335924 \tValidation Loss: 4.038248\n",
      "Epoch: 14 \tTraining Loss: 2.242538 \tValidation Loss: 4.049457\n",
      "Epoch: 15 \tTraining Loss: 2.165628 \tValidation Loss: 4.065491\n",
      "Epoch: 16 \tTraining Loss: 2.102352 \tValidation Loss: 4.086003\n",
      "Epoch: 17 \tTraining Loss: 2.049485 \tValidation Loss: 4.108433\n",
      "Epoch: 18 \tTraining Loss: 2.005231 \tValidation Loss: 4.133514\n",
      "Epoch: 19 \tTraining Loss: 1.962719 \tValidation Loss: 4.159672\n",
      "Epoch: 20 \tTraining Loss: 1.929821 \tValidation Loss: 4.184844\n",
      "Epoch: 1 \tTraining Loss: 6.098186 \tValidation Loss: 5.364299\n",
      "Validation loss decreased (inf --> 5.36430).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.643023 \tValidation Loss: 5.211341\n",
      "Validation loss decreased (5.36430 --> 5.21134).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.337041 \tValidation Loss: 4.984200\n",
      "Validation loss decreased (5.21134 --> 4.98420).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.910357 \tValidation Loss: 4.742779\n",
      "Validation loss decreased (4.98420 --> 4.74278).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.436730 \tValidation Loss: 4.530365\n",
      "Validation loss decreased (4.74278 --> 4.53036).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.980700 \tValidation Loss: 4.363096\n",
      "Validation loss decreased (4.53036 --> 4.36310).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.578418 \tValidation Loss: 4.242071\n",
      "Validation loss decreased (4.36310 --> 4.24207).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.246191 \tValidation Loss: 4.157891\n",
      "Validation loss decreased (4.24207 --> 4.15789).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.973746 \tValidation Loss: 4.102599\n",
      "Validation loss decreased (4.15789 --> 4.10260).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.757554 \tValidation Loss: 4.068995\n",
      "Validation loss decreased (4.10260 --> 4.06900).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.583740 \tValidation Loss: 4.051587\n",
      "Validation loss decreased (4.06900 --> 4.05159).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.443618 \tValidation Loss: 4.049105\n",
      "Validation loss decreased (4.05159 --> 4.04910).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.331466 \tValidation Loss: 4.053499\n",
      "Epoch: 14 \tTraining Loss: 2.239794 \tValidation Loss: 4.064905\n",
      "Epoch: 15 \tTraining Loss: 2.163714 \tValidation Loss: 4.081794\n",
      "Epoch: 16 \tTraining Loss: 2.099906 \tValidation Loss: 4.102322\n",
      "Epoch: 17 \tTraining Loss: 2.046203 \tValidation Loss: 4.122819\n",
      "Epoch: 18 \tTraining Loss: 1.999187 \tValidation Loss: 4.147863\n",
      "Epoch: 19 \tTraining Loss: 1.959818 \tValidation Loss: 4.173525\n",
      "Epoch: 20 \tTraining Loss: 1.923128 \tValidation Loss: 4.198207\n",
      "Epoch: 1 \tTraining Loss: 6.098344 \tValidation Loss: 5.394196\n",
      "Validation loss decreased (inf --> 5.39420).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.640111 \tValidation Loss: 5.240393\n",
      "Validation loss decreased (5.39420 --> 5.24039).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.333084 \tValidation Loss: 4.997215\n",
      "Validation loss decreased (5.24039 --> 4.99721).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.904228 \tValidation Loss: 4.737981\n",
      "Validation loss decreased (4.99721 --> 4.73798).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 4.432416 \tValidation Loss: 4.513427\n",
      "Validation loss decreased (4.73798 --> 4.51343).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 \tTraining Loss: 3.973743 \tValidation Loss: 4.338619\n",
      "Validation loss decreased (4.51343 --> 4.33862).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 3.575668 \tValidation Loss: 4.212477\n",
      "Validation loss decreased (4.33862 --> 4.21248).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 3.246293 \tValidation Loss: 4.126610\n",
      "Validation loss decreased (4.21248 --> 4.12661).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.979400 \tValidation Loss: 4.068464\n",
      "Validation loss decreased (4.12661 --> 4.06846).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.766093 \tValidation Loss: 4.033260\n",
      "Validation loss decreased (4.06846 --> 4.03326).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 2.591388 \tValidation Loss: 4.014582\n",
      "Validation loss decreased (4.03326 --> 4.01458).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 2.456013 \tValidation Loss: 4.007421\n",
      "Validation loss decreased (4.01458 --> 4.00742).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 2.342871 \tValidation Loss: 4.007847\n",
      "Epoch: 14 \tTraining Loss: 2.250771 \tValidation Loss: 4.017156\n",
      "Epoch: 15 \tTraining Loss: 2.173047 \tValidation Loss: 4.030229\n",
      "Epoch: 16 \tTraining Loss: 2.110910 \tValidation Loss: 4.045912\n",
      "Epoch: 17 \tTraining Loss: 2.058794 \tValidation Loss: 4.064449\n",
      "Epoch: 18 \tTraining Loss: 2.008299 \tValidation Loss: 4.085751\n",
      "Epoch: 19 \tTraining Loss: 1.970176 \tValidation Loss: 4.106837\n",
      "Epoch: 20 \tTraining Loss: 1.937012 \tValidation Loss: 4.131786\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 4 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.101273 \tValidation Loss: 5.435521\n",
      "Validation loss decreased (inf --> 5.43552).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.562373 \tValidation Loss: 5.176028\n",
      "Validation loss decreased (5.43552 --> 5.17603).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.079766 \tValidation Loss: 4.814592\n",
      "Validation loss decreased (5.17603 --> 4.81459).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.457782 \tValidation Loss: 4.464493\n",
      "Validation loss decreased (4.81459 --> 4.46449).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.831690 \tValidation Loss: 4.170538\n",
      "Validation loss decreased (4.46449 --> 4.17054).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.282287 \tValidation Loss: 3.946973\n",
      "Validation loss decreased (4.17054 --> 3.94697).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.838578 \tValidation Loss: 3.787424\n",
      "Validation loss decreased (3.94697 --> 3.78742).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.488154 \tValidation Loss: 3.676227\n",
      "Validation loss decreased (3.78742 --> 3.67623).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.219927 \tValidation Loss: 3.600989\n",
      "Validation loss decreased (3.67623 --> 3.60099).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.006698 \tValidation Loss: 3.550847\n",
      "Validation loss decreased (3.60099 --> 3.55085).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.836886 \tValidation Loss: 3.520709\n",
      "Validation loss decreased (3.55085 --> 3.52071).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.702089 \tValidation Loss: 3.506312\n",
      "Validation loss decreased (3.52071 --> 3.50631).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.588609 \tValidation Loss: 3.504533\n",
      "Validation loss decreased (3.50631 --> 3.50453).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.495701 \tValidation Loss: 3.510935\n",
      "Epoch: 15 \tTraining Loss: 1.423431 \tValidation Loss: 3.524791\n",
      "Epoch: 16 \tTraining Loss: 1.357221 \tValidation Loss: 3.541320\n",
      "Epoch: 17 \tTraining Loss: 1.303271 \tValidation Loss: 3.564004\n",
      "Epoch: 18 \tTraining Loss: 1.255180 \tValidation Loss: 3.591652\n",
      "Epoch: 19 \tTraining Loss: 1.210090 \tValidation Loss: 3.619710\n",
      "Epoch: 20 \tTraining Loss: 1.178134 \tValidation Loss: 3.647983\n",
      "Epoch: 1 \tTraining Loss: 6.104606 \tValidation Loss: 5.448211\n",
      "Validation loss decreased (inf --> 5.44821).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.564373 \tValidation Loss: 5.194392\n",
      "Validation loss decreased (5.44821 --> 5.19439).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.079614 \tValidation Loss: 4.829131\n",
      "Validation loss decreased (5.19439 --> 4.82913).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.456273 \tValidation Loss: 4.461286\n",
      "Validation loss decreased (4.82913 --> 4.46129).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.827005 \tValidation Loss: 4.144943\n",
      "Validation loss decreased (4.46129 --> 4.14494).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.273440 \tValidation Loss: 3.906280\n",
      "Validation loss decreased (4.14494 --> 3.90628).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.829079 \tValidation Loss: 3.734493\n",
      "Validation loss decreased (3.90628 --> 3.73449).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.479603 \tValidation Loss: 3.614008\n",
      "Validation loss decreased (3.73449 --> 3.61401).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.208928 \tValidation Loss: 3.530337\n",
      "Validation loss decreased (3.61401 --> 3.53034).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.998547 \tValidation Loss: 3.474290\n",
      "Validation loss decreased (3.53034 --> 3.47429).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.833802 \tValidation Loss: 3.437709\n",
      "Validation loss decreased (3.47429 --> 3.43771).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.696234 \tValidation Loss: 3.416759\n",
      "Validation loss decreased (3.43771 --> 3.41676).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.585521 \tValidation Loss: 3.408951\n",
      "Validation loss decreased (3.41676 --> 3.40895).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.495455 \tValidation Loss: 3.409594\n",
      "Epoch: 15 \tTraining Loss: 1.421366 \tValidation Loss: 3.417710\n",
      "Epoch: 16 \tTraining Loss: 1.355710 \tValidation Loss: 3.434119\n",
      "Epoch: 17 \tTraining Loss: 1.298317 \tValidation Loss: 3.453170\n",
      "Epoch: 18 \tTraining Loss: 1.253356 \tValidation Loss: 3.478316\n",
      "Epoch: 19 \tTraining Loss: 1.210820 \tValidation Loss: 3.500691\n",
      "Epoch: 20 \tTraining Loss: 1.176728 \tValidation Loss: 3.530486\n",
      "Epoch: 1 \tTraining Loss: 6.105360 \tValidation Loss: 5.439472\n",
      "Validation loss decreased (inf --> 5.43947).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.565301 \tValidation Loss: 5.185860\n",
      "Validation loss decreased (5.43947 --> 5.18586).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.077216 \tValidation Loss: 4.822768\n",
      "Validation loss decreased (5.18586 --> 4.82277).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.444867 \tValidation Loss: 4.466038\n",
      "Validation loss decreased (4.82277 --> 4.46604).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.809720 \tValidation Loss: 4.173640\n",
      "Validation loss decreased (4.46604 --> 4.17364).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.260390 \tValidation Loss: 3.956779\n",
      "Validation loss decreased (4.17364 --> 3.95678).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.822915 \tValidation Loss: 3.799186\n",
      "Validation loss decreased (3.95678 --> 3.79919).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.479321 \tValidation Loss: 3.688831\n",
      "Validation loss decreased (3.79919 --> 3.68883).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.209137 \tValidation Loss: 3.611357\n",
      "Validation loss decreased (3.68883 --> 3.61136).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.995520 \tValidation Loss: 3.561546\n",
      "Validation loss decreased (3.61136 --> 3.56155).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.831083 \tValidation Loss: 3.528626\n",
      "Validation loss decreased (3.56155 --> 3.52863).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.693395 \tValidation Loss: 3.508978\n",
      "Validation loss decreased (3.52863 --> 3.50898).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.582018 \tValidation Loss: 3.502258\n",
      "Validation loss decreased (3.50898 --> 3.50226).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.490179 \tValidation Loss: 3.505445\n",
      "Epoch: 15 \tTraining Loss: 1.416369 \tValidation Loss: 3.517720\n",
      "Epoch: 16 \tTraining Loss: 1.350874 \tValidation Loss: 3.533671\n",
      "Epoch: 17 \tTraining Loss: 1.297543 \tValidation Loss: 3.553931\n",
      "Epoch: 18 \tTraining Loss: 1.250270 \tValidation Loss: 3.576708\n",
      "Epoch: 19 \tTraining Loss: 1.209307 \tValidation Loss: 3.602234\n",
      "Epoch: 20 \tTraining Loss: 1.170856 \tValidation Loss: 3.630747\n",
      "Epoch: 1 \tTraining Loss: 6.099515 \tValidation Loss: 5.446828\n",
      "Validation loss decreased (inf --> 5.44683).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.566165 \tValidation Loss: 5.203606\n",
      "Validation loss decreased (5.44683 --> 5.20361).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.087134 \tValidation Loss: 4.844056\n",
      "Validation loss decreased (5.20361 --> 4.84406).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.464210 \tValidation Loss: 4.485498\n",
      "Validation loss decreased (4.84406 --> 4.48550).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \tTraining Loss: 3.830176 \tValidation Loss: 4.185246\n",
      "Validation loss decreased (4.48550 --> 4.18525).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.275108 \tValidation Loss: 3.961149\n",
      "Validation loss decreased (4.18525 --> 3.96115).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.828593 \tValidation Loss: 3.802622\n",
      "Validation loss decreased (3.96115 --> 3.80262).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.479699 \tValidation Loss: 3.694582\n",
      "Validation loss decreased (3.80262 --> 3.69458).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.208445 \tValidation Loss: 3.621373\n",
      "Validation loss decreased (3.69458 --> 3.62137).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.995710 \tValidation Loss: 3.574459\n",
      "Validation loss decreased (3.62137 --> 3.57446).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.828115 \tValidation Loss: 3.547040\n",
      "Validation loss decreased (3.57446 --> 3.54704).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.692861 \tValidation Loss: 3.534223\n",
      "Validation loss decreased (3.54704 --> 3.53422).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.582781 \tValidation Loss: 3.532414\n",
      "Validation loss decreased (3.53422 --> 3.53241).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.493052 \tValidation Loss: 3.538043\n",
      "Epoch: 15 \tTraining Loss: 1.416496 \tValidation Loss: 3.550491\n",
      "Epoch: 16 \tTraining Loss: 1.353746 \tValidation Loss: 3.571165\n",
      "Epoch: 17 \tTraining Loss: 1.298255 \tValidation Loss: 3.591098\n",
      "Epoch: 18 \tTraining Loss: 1.247383 \tValidation Loss: 3.616457\n",
      "Epoch: 19 \tTraining Loss: 1.207870 \tValidation Loss: 3.644769\n",
      "Epoch: 20 \tTraining Loss: 1.170628 \tValidation Loss: 3.677517\n",
      "Epoch: 1 \tTraining Loss: 6.095169 \tValidation Loss: 5.434638\n",
      "Validation loss decreased (inf --> 5.43464).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.565448 \tValidation Loss: 5.181266\n",
      "Validation loss decreased (5.43464 --> 5.18127).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.088600 \tValidation Loss: 4.809274\n",
      "Validation loss decreased (5.18127 --> 4.80927).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.464650 \tValidation Loss: 4.440947\n",
      "Validation loss decreased (4.80927 --> 4.44095).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.827214 \tValidation Loss: 4.133700\n",
      "Validation loss decreased (4.44095 --> 4.13370).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.274730 \tValidation Loss: 3.906250\n",
      "Validation loss decreased (4.13370 --> 3.90625).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.829125 \tValidation Loss: 3.746672\n",
      "Validation loss decreased (3.90625 --> 3.74667).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.480612 \tValidation Loss: 3.637946\n",
      "Validation loss decreased (3.74667 --> 3.63795).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.211519 \tValidation Loss: 3.561751\n",
      "Validation loss decreased (3.63795 --> 3.56175).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.000147 \tValidation Loss: 3.513207\n",
      "Validation loss decreased (3.56175 --> 3.51321).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.830230 \tValidation Loss: 3.483534\n",
      "Validation loss decreased (3.51321 --> 3.48353).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.694370 \tValidation Loss: 3.469125\n",
      "Validation loss decreased (3.48353 --> 3.46912).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.587240 \tValidation Loss: 3.467526\n",
      "Validation loss decreased (3.46912 --> 3.46753).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.495882 \tValidation Loss: 3.472852\n",
      "Epoch: 15 \tTraining Loss: 1.419790 \tValidation Loss: 3.487005\n",
      "Epoch: 16 \tTraining Loss: 1.358057 \tValidation Loss: 3.507533\n",
      "Epoch: 17 \tTraining Loss: 1.301433 \tValidation Loss: 3.530609\n",
      "Epoch: 18 \tTraining Loss: 1.254740 \tValidation Loss: 3.556756\n",
      "Epoch: 19 \tTraining Loss: 1.213791 \tValidation Loss: 3.586712\n",
      "Epoch: 20 \tTraining Loss: 1.176874 \tValidation Loss: 3.615692\n",
      "Epoch: 1 \tTraining Loss: 6.102191 \tValidation Loss: 5.458675\n",
      "Validation loss decreased (inf --> 5.45868).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.565511 \tValidation Loss: 5.207763\n",
      "Validation loss decreased (5.45868 --> 5.20776).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.086249 \tValidation Loss: 4.841747\n",
      "Validation loss decreased (5.20776 --> 4.84175).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.462034 \tValidation Loss: 4.478893\n",
      "Validation loss decreased (4.84175 --> 4.47889).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.827947 \tValidation Loss: 4.179225\n",
      "Validation loss decreased (4.47889 --> 4.17922).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.277932 \tValidation Loss: 3.955746\n",
      "Validation loss decreased (4.17922 --> 3.95575).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.833818 \tValidation Loss: 3.796940\n",
      "Validation loss decreased (3.95575 --> 3.79694).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.483813 \tValidation Loss: 3.685405\n",
      "Validation loss decreased (3.79694 --> 3.68541).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.214529 \tValidation Loss: 3.608786\n",
      "Validation loss decreased (3.68541 --> 3.60879).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.001518 \tValidation Loss: 3.557423\n",
      "Validation loss decreased (3.60879 --> 3.55742).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.833192 \tValidation Loss: 3.527220\n",
      "Validation loss decreased (3.55742 --> 3.52722).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.698944 \tValidation Loss: 3.512654\n",
      "Validation loss decreased (3.52722 --> 3.51265).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.590101 \tValidation Loss: 3.506885\n",
      "Validation loss decreased (3.51265 --> 3.50689).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.497966 \tValidation Loss: 3.509514\n",
      "Epoch: 15 \tTraining Loss: 1.422713 \tValidation Loss: 3.520004\n",
      "Epoch: 16 \tTraining Loss: 1.356249 \tValidation Loss: 3.535110\n",
      "Epoch: 17 \tTraining Loss: 1.301456 \tValidation Loss: 3.554002\n",
      "Epoch: 18 \tTraining Loss: 1.257081 \tValidation Loss: 3.576308\n",
      "Epoch: 19 \tTraining Loss: 1.218998 \tValidation Loss: 3.601141\n",
      "Epoch: 20 \tTraining Loss: 1.179413 \tValidation Loss: 3.627340\n",
      "Epoch: 1 \tTraining Loss: 6.109227 \tValidation Loss: 5.439666\n",
      "Validation loss decreased (inf --> 5.43967).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.562932 \tValidation Loss: 5.180376\n",
      "Validation loss decreased (5.43967 --> 5.18038).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.075169 \tValidation Loss: 4.816138\n",
      "Validation loss decreased (5.18038 --> 4.81614).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.446412 \tValidation Loss: 4.457962\n",
      "Validation loss decreased (4.81614 --> 4.45796).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.815034 \tValidation Loss: 4.160327\n",
      "Validation loss decreased (4.45796 --> 4.16033).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.266690 \tValidation Loss: 3.938533\n",
      "Validation loss decreased (4.16033 --> 3.93853).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.825431 \tValidation Loss: 3.783024\n",
      "Validation loss decreased (3.93853 --> 3.78302).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.481591 \tValidation Loss: 3.674522\n",
      "Validation loss decreased (3.78302 --> 3.67452).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.216153 \tValidation Loss: 3.600119\n",
      "Validation loss decreased (3.67452 --> 3.60012).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.001563 \tValidation Loss: 3.550218\n",
      "Validation loss decreased (3.60012 --> 3.55022).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.838590 \tValidation Loss: 3.519471\n",
      "Validation loss decreased (3.55022 --> 3.51947).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.703253 \tValidation Loss: 3.503655\n",
      "Validation loss decreased (3.51947 --> 3.50365).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.589660 \tValidation Loss: 3.498810\n",
      "Validation loss decreased (3.50365 --> 3.49881).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.497974 \tValidation Loss: 3.503268\n",
      "Epoch: 15 \tTraining Loss: 1.422023 \tValidation Loss: 3.514865\n",
      "Epoch: 16 \tTraining Loss: 1.357402 \tValidation Loss: 3.529711\n",
      "Epoch: 17 \tTraining Loss: 1.302968 \tValidation Loss: 3.548478\n",
      "Epoch: 18 \tTraining Loss: 1.255100 \tValidation Loss: 3.575388\n",
      "Epoch: 19 \tTraining Loss: 1.213287 \tValidation Loss: 3.601719\n",
      "Epoch: 20 \tTraining Loss: 1.180170 \tValidation Loss: 3.629624\n",
      "Epoch: 1 \tTraining Loss: 6.105458 \tValidation Loss: 5.427702\n",
      "Validation loss decreased (inf --> 5.42770).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.567565 \tValidation Loss: 5.184472\n",
      "Validation loss decreased (5.42770 --> 5.18447).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.084591 \tValidation Loss: 4.825672\n",
      "Validation loss decreased (5.18447 --> 4.82567).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 \tTraining Loss: 4.455679 \tValidation Loss: 4.468719\n",
      "Validation loss decreased (4.82567 --> 4.46872).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.822033 \tValidation Loss: 4.174935\n",
      "Validation loss decreased (4.46872 --> 4.17494).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.271397 \tValidation Loss: 3.955651\n",
      "Validation loss decreased (4.17494 --> 3.95565).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.826912 \tValidation Loss: 3.797953\n",
      "Validation loss decreased (3.95565 --> 3.79795).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.483580 \tValidation Loss: 3.687829\n",
      "Validation loss decreased (3.79795 --> 3.68783).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.212226 \tValidation Loss: 3.613775\n",
      "Validation loss decreased (3.68783 --> 3.61377).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.003828 \tValidation Loss: 3.565247\n",
      "Validation loss decreased (3.61377 --> 3.56525).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.833641 \tValidation Loss: 3.538652\n",
      "Validation loss decreased (3.56525 --> 3.53865).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.697635 \tValidation Loss: 3.527275\n",
      "Validation loss decreased (3.53865 --> 3.52728).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.588104 \tValidation Loss: 3.524787\n",
      "Validation loss decreased (3.52728 --> 3.52479).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.498107 \tValidation Loss: 3.532049\n",
      "Epoch: 15 \tTraining Loss: 1.421937 \tValidation Loss: 3.545213\n",
      "Epoch: 16 \tTraining Loss: 1.358443 \tValidation Loss: 3.563360\n",
      "Epoch: 17 \tTraining Loss: 1.302062 \tValidation Loss: 3.585565\n",
      "Epoch: 18 \tTraining Loss: 1.256197 \tValidation Loss: 3.609779\n",
      "Epoch: 19 \tTraining Loss: 1.215007 \tValidation Loss: 3.634126\n",
      "Epoch: 20 \tTraining Loss: 1.182310 \tValidation Loss: 3.663333\n",
      "Epoch: 1 \tTraining Loss: 6.103840 \tValidation Loss: 5.433936\n",
      "Validation loss decreased (inf --> 5.43394).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.565444 \tValidation Loss: 5.177954\n",
      "Validation loss decreased (5.43394 --> 5.17795).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.082428 \tValidation Loss: 4.812383\n",
      "Validation loss decreased (5.17795 --> 4.81238).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.450976 \tValidation Loss: 4.457076\n",
      "Validation loss decreased (4.81238 --> 4.45708).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.812620 \tValidation Loss: 4.165443\n",
      "Validation loss decreased (4.45708 --> 4.16544).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.259292 \tValidation Loss: 3.949209\n",
      "Validation loss decreased (4.16544 --> 3.94921).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.817469 \tValidation Loss: 3.796450\n",
      "Validation loss decreased (3.94921 --> 3.79645).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.470437 \tValidation Loss: 3.690298\n",
      "Validation loss decreased (3.79645 --> 3.69030).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.200714 \tValidation Loss: 3.617437\n",
      "Validation loss decreased (3.69030 --> 3.61744).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.994560 \tValidation Loss: 3.570378\n",
      "Validation loss decreased (3.61744 --> 3.57038).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.822968 \tValidation Loss: 3.541460\n",
      "Validation loss decreased (3.57038 --> 3.54146).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.689225 \tValidation Loss: 3.525480\n",
      "Validation loss decreased (3.54146 --> 3.52548).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.579946 \tValidation Loss: 3.521860\n",
      "Validation loss decreased (3.52548 --> 3.52186).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.489678 \tValidation Loss: 3.527901\n",
      "Epoch: 15 \tTraining Loss: 1.413091 \tValidation Loss: 3.536544\n",
      "Epoch: 16 \tTraining Loss: 1.348324 \tValidation Loss: 3.554477\n",
      "Epoch: 17 \tTraining Loss: 1.296880 \tValidation Loss: 3.573103\n",
      "Epoch: 18 \tTraining Loss: 1.251635 \tValidation Loss: 3.598706\n",
      "Epoch: 19 \tTraining Loss: 1.211267 \tValidation Loss: 3.623252\n",
      "Epoch: 20 \tTraining Loss: 1.173084 \tValidation Loss: 3.650966\n",
      "Epoch: 1 \tTraining Loss: 6.100018 \tValidation Loss: 5.418912\n",
      "Validation loss decreased (inf --> 5.41891).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.566313 \tValidation Loss: 5.166619\n",
      "Validation loss decreased (5.41891 --> 5.16662).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.085871 \tValidation Loss: 4.806324\n",
      "Validation loss decreased (5.16662 --> 4.80632).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.463482 \tValidation Loss: 4.452138\n",
      "Validation loss decreased (4.80632 --> 4.45214).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.826366 \tValidation Loss: 4.159647\n",
      "Validation loss decreased (4.45214 --> 4.15965).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 3.274222 \tValidation Loss: 3.946120\n",
      "Validation loss decreased (4.15965 --> 3.94612).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.830458 \tValidation Loss: 3.792123\n",
      "Validation loss decreased (3.94612 --> 3.79212).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.483702 \tValidation Loss: 3.683752\n",
      "Validation loss decreased (3.79212 --> 3.68375).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.213404 \tValidation Loss: 3.605899\n",
      "Validation loss decreased (3.68375 --> 3.60590).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 2.000987 \tValidation Loss: 3.558002\n",
      "Validation loss decreased (3.60590 --> 3.55800).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.831862 \tValidation Loss: 3.527895\n",
      "Validation loss decreased (3.55800 --> 3.52789).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.698242 \tValidation Loss: 3.512119\n",
      "Validation loss decreased (3.52789 --> 3.51212).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.587696 \tValidation Loss: 3.506327\n",
      "Validation loss decreased (3.51212 --> 3.50633).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.495837 \tValidation Loss: 3.511086\n",
      "Epoch: 15 \tTraining Loss: 1.417039 \tValidation Loss: 3.523701\n",
      "Epoch: 16 \tTraining Loss: 1.351697 \tValidation Loss: 3.538575\n",
      "Epoch: 17 \tTraining Loss: 1.300145 \tValidation Loss: 3.559752\n",
      "Epoch: 18 \tTraining Loss: 1.253802 \tValidation Loss: 3.584770\n",
      "Epoch: 19 \tTraining Loss: 1.212868 \tValidation Loss: 3.610360\n",
      "Epoch: 20 \tTraining Loss: 1.176973 \tValidation Loss: 3.636434\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 5 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.076508 \tValidation Loss: 5.285485\n",
      "Validation loss decreased (inf --> 5.28548).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.475076 \tValidation Loss: 4.971849\n",
      "Validation loss decreased (5.28548 --> 4.97185).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.894356 \tValidation Loss: 4.534839\n",
      "Validation loss decreased (4.97185 --> 4.53484).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.166486 \tValidation Loss: 4.110759\n",
      "Validation loss decreased (4.53484 --> 4.11076).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.454719 \tValidation Loss: 3.777554\n",
      "Validation loss decreased (4.11076 --> 3.77755).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.866829 \tValidation Loss: 3.535837\n",
      "Validation loss decreased (3.77755 --> 3.53584).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.401574 \tValidation Loss: 3.360772\n",
      "Validation loss decreased (3.53584 --> 3.36077).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.051251 \tValidation Loss: 3.236387\n",
      "Validation loss decreased (3.36077 --> 3.23639).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.776207 \tValidation Loss: 3.150158\n",
      "Validation loss decreased (3.23639 --> 3.15016).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.565090 \tValidation Loss: 3.091131\n",
      "Validation loss decreased (3.15016 --> 3.09113).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.397240 \tValidation Loss: 3.052135\n",
      "Validation loss decreased (3.09113 --> 3.05213).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.261775 \tValidation Loss: 3.029070\n",
      "Validation loss decreased (3.05213 --> 3.02907).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.150050 \tValidation Loss: 3.019322\n",
      "Validation loss decreased (3.02907 --> 3.01932).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.058101 \tValidation Loss: 3.018732\n",
      "Validation loss decreased (3.01932 --> 3.01873).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.982365 \tValidation Loss: 3.027587\n",
      "Epoch: 16 \tTraining Loss: 0.918039 \tValidation Loss: 3.037992\n",
      "Epoch: 17 \tTraining Loss: 0.865962 \tValidation Loss: 3.058479\n",
      "Epoch: 18 \tTraining Loss: 0.815230 \tValidation Loss: 3.080711\n",
      "Epoch: 19 \tTraining Loss: 0.778123 \tValidation Loss: 3.106034\n",
      "Epoch: 20 \tTraining Loss: 0.743043 \tValidation Loss: 3.132608\n",
      "Epoch: 1 \tTraining Loss: 6.073077 \tValidation Loss: 5.293089\n",
      "Validation loss decreased (inf --> 5.29309).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 5.473608 \tValidation Loss: 4.976508\n",
      "Validation loss decreased (5.29309 --> 4.97651).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.885373 \tValidation Loss: 4.541086\n",
      "Validation loss decreased (4.97651 --> 4.54109).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.155236 \tValidation Loss: 4.124689\n",
      "Validation loss decreased (4.54109 --> 4.12469).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.449460 \tValidation Loss: 3.792118\n",
      "Validation loss decreased (4.12469 --> 3.79212).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.856285 \tValidation Loss: 3.550853\n",
      "Validation loss decreased (3.79212 --> 3.55085).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.395721 \tValidation Loss: 3.380743\n",
      "Validation loss decreased (3.55085 --> 3.38074).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.043315 \tValidation Loss: 3.260266\n",
      "Validation loss decreased (3.38074 --> 3.26027).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.769118 \tValidation Loss: 3.175397\n",
      "Validation loss decreased (3.26027 --> 3.17540).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.558769 \tValidation Loss: 3.120628\n",
      "Validation loss decreased (3.17540 --> 3.12063).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.391984 \tValidation Loss: 3.085463\n",
      "Validation loss decreased (3.12063 --> 3.08546).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.250572 \tValidation Loss: 3.067357\n",
      "Validation loss decreased (3.08546 --> 3.06736).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.142700 \tValidation Loss: 3.060617\n",
      "Validation loss decreased (3.06736 --> 3.06062).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.051920 \tValidation Loss: 3.064495\n",
      "Epoch: 15 \tTraining Loss: 0.975674 \tValidation Loss: 3.076206\n",
      "Epoch: 16 \tTraining Loss: 0.910608 \tValidation Loss: 3.095183\n",
      "Epoch: 17 \tTraining Loss: 0.859153 \tValidation Loss: 3.114292\n",
      "Epoch: 18 \tTraining Loss: 0.811512 \tValidation Loss: 3.140498\n",
      "Epoch: 19 \tTraining Loss: 0.771051 \tValidation Loss: 3.167256\n",
      "Epoch: 20 \tTraining Loss: 0.737755 \tValidation Loss: 3.195972\n",
      "Epoch: 1 \tTraining Loss: 6.079831 \tValidation Loss: 5.272384\n",
      "Validation loss decreased (inf --> 5.27238).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.473408 \tValidation Loss: 4.953670\n",
      "Validation loss decreased (5.27238 --> 4.95367).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.883399 \tValidation Loss: 4.523072\n",
      "Validation loss decreased (4.95367 --> 4.52307).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.150555 \tValidation Loss: 4.109719\n",
      "Validation loss decreased (4.52307 --> 4.10972).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.443423 \tValidation Loss: 3.776240\n",
      "Validation loss decreased (4.10972 --> 3.77624).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.855350 \tValidation Loss: 3.535349\n",
      "Validation loss decreased (3.77624 --> 3.53535).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.396867 \tValidation Loss: 3.365041\n",
      "Validation loss decreased (3.53535 --> 3.36504).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.044079 \tValidation Loss: 3.243800\n",
      "Validation loss decreased (3.36504 --> 3.24380).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.772239 \tValidation Loss: 3.158245\n",
      "Validation loss decreased (3.24380 --> 3.15824).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.561730 \tValidation Loss: 3.099468\n",
      "Validation loss decreased (3.15824 --> 3.09947).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.391971 \tValidation Loss: 3.061814\n",
      "Validation loss decreased (3.09947 --> 3.06181).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.258102 \tValidation Loss: 3.038156\n",
      "Validation loss decreased (3.06181 --> 3.03816).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.149886 \tValidation Loss: 3.029880\n",
      "Validation loss decreased (3.03816 --> 3.02988).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.059417 \tValidation Loss: 3.028732\n",
      "Validation loss decreased (3.02988 --> 3.02873).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.976709 \tValidation Loss: 3.033879\n",
      "Epoch: 16 \tTraining Loss: 0.918578 \tValidation Loss: 3.051145\n",
      "Epoch: 17 \tTraining Loss: 0.862031 \tValidation Loss: 3.068324\n",
      "Epoch: 18 \tTraining Loss: 0.817778 \tValidation Loss: 3.090869\n",
      "Epoch: 19 \tTraining Loss: 0.776548 \tValidation Loss: 3.115263\n",
      "Epoch: 20 \tTraining Loss: 0.740527 \tValidation Loss: 3.142007\n",
      "Epoch: 1 \tTraining Loss: 6.083074 \tValidation Loss: 5.292126\n",
      "Validation loss decreased (inf --> 5.29213).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.481558 \tValidation Loss: 4.981146\n",
      "Validation loss decreased (5.29213 --> 4.98115).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.898497 \tValidation Loss: 4.549535\n",
      "Validation loss decreased (4.98115 --> 4.54953).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.166100 \tValidation Loss: 4.128817\n",
      "Validation loss decreased (4.54953 --> 4.12882).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.453771 \tValidation Loss: 3.790318\n",
      "Validation loss decreased (4.12882 --> 3.79032).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.862796 \tValidation Loss: 3.544774\n",
      "Validation loss decreased (3.79032 --> 3.54477).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.399803 \tValidation Loss: 3.368662\n",
      "Validation loss decreased (3.54477 --> 3.36866).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.046036 \tValidation Loss: 3.245136\n",
      "Validation loss decreased (3.36866 --> 3.24514).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.774101 \tValidation Loss: 3.155150\n",
      "Validation loss decreased (3.24514 --> 3.15515).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.559895 \tValidation Loss: 3.096533\n",
      "Validation loss decreased (3.15515 --> 3.09653).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.390800 \tValidation Loss: 3.058820\n",
      "Validation loss decreased (3.09653 --> 3.05882).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.255286 \tValidation Loss: 3.034728\n",
      "Validation loss decreased (3.05882 --> 3.03473).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.145739 \tValidation Loss: 3.026622\n",
      "Validation loss decreased (3.03473 --> 3.02662).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.056722 \tValidation Loss: 3.028969\n",
      "Epoch: 15 \tTraining Loss: 0.976243 \tValidation Loss: 3.036556\n",
      "Epoch: 16 \tTraining Loss: 0.916037 \tValidation Loss: 3.051539\n",
      "Epoch: 17 \tTraining Loss: 0.861978 \tValidation Loss: 3.070087\n",
      "Epoch: 18 \tTraining Loss: 0.811151 \tValidation Loss: 3.094763\n",
      "Epoch: 19 \tTraining Loss: 0.776618 \tValidation Loss: 3.118195\n",
      "Epoch: 20 \tTraining Loss: 0.742563 \tValidation Loss: 3.147728\n",
      "Epoch: 1 \tTraining Loss: 6.080227 \tValidation Loss: 5.312708\n",
      "Validation loss decreased (inf --> 5.31271).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.475848 \tValidation Loss: 4.993322\n",
      "Validation loss decreased (5.31271 --> 4.99332).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.891553 \tValidation Loss: 4.543817\n",
      "Validation loss decreased (4.99332 --> 4.54382).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.159191 \tValidation Loss: 4.113886\n",
      "Validation loss decreased (4.54382 --> 4.11389).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.451614 \tValidation Loss: 3.769937\n",
      "Validation loss decreased (4.11389 --> 3.76994).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.863529 \tValidation Loss: 3.519172\n",
      "Validation loss decreased (3.76994 --> 3.51917).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.405329 \tValidation Loss: 3.340752\n",
      "Validation loss decreased (3.51917 --> 3.34075).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.053254 \tValidation Loss: 3.213244\n",
      "Validation loss decreased (3.34075 --> 3.21324).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.780163 \tValidation Loss: 3.123801\n",
      "Validation loss decreased (3.21324 --> 3.12380).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.568308 \tValidation Loss: 3.065344\n",
      "Validation loss decreased (3.12380 --> 3.06534).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.399923 \tValidation Loss: 3.030540\n",
      "Validation loss decreased (3.06534 --> 3.03054).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.265562 \tValidation Loss: 3.009964\n",
      "Validation loss decreased (3.03054 --> 3.00996).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.151437 \tValidation Loss: 3.003946\n",
      "Validation loss decreased (3.00996 --> 3.00395).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.063587 \tValidation Loss: 3.003996\n",
      "Epoch: 15 \tTraining Loss: 0.986775 \tValidation Loss: 3.012152\n",
      "Epoch: 16 \tTraining Loss: 0.921550 \tValidation Loss: 3.027292\n",
      "Epoch: 17 \tTraining Loss: 0.868375 \tValidation Loss: 3.051081\n",
      "Epoch: 18 \tTraining Loss: 0.822821 \tValidation Loss: 3.076403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 \tTraining Loss: 0.780822 \tValidation Loss: 3.103247\n",
      "Epoch: 20 \tTraining Loss: 0.745088 \tValidation Loss: 3.136560\n",
      "Epoch: 1 \tTraining Loss: 6.078558 \tValidation Loss: 5.278142\n",
      "Validation loss decreased (inf --> 5.27814).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.477468 \tValidation Loss: 4.943972\n",
      "Validation loss decreased (5.27814 --> 4.94397).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.892602 \tValidation Loss: 4.490378\n",
      "Validation loss decreased (4.94397 --> 4.49038).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.163362 \tValidation Loss: 4.056625\n",
      "Validation loss decreased (4.49038 --> 4.05662).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.456280 \tValidation Loss: 3.711398\n",
      "Validation loss decreased (4.05662 --> 3.71140).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.865219 \tValidation Loss: 3.458257\n",
      "Validation loss decreased (3.71140 --> 3.45826).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.407415 \tValidation Loss: 3.278410\n",
      "Validation loss decreased (3.45826 --> 3.27841).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.054807 \tValidation Loss: 3.151453\n",
      "Validation loss decreased (3.27841 --> 3.15145).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.783791 \tValidation Loss: 3.063808\n",
      "Validation loss decreased (3.15145 --> 3.06381).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.569943 \tValidation Loss: 3.002564\n",
      "Validation loss decreased (3.06381 --> 3.00256).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.400247 \tValidation Loss: 2.965135\n",
      "Validation loss decreased (3.00256 --> 2.96513).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.262584 \tValidation Loss: 2.940811\n",
      "Validation loss decreased (2.96513 --> 2.94081).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.151177 \tValidation Loss: 2.928154\n",
      "Validation loss decreased (2.94081 --> 2.92815).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.061683 \tValidation Loss: 2.929389\n",
      "Epoch: 15 \tTraining Loss: 0.984306 \tValidation Loss: 2.937519\n",
      "Epoch: 16 \tTraining Loss: 0.923328 \tValidation Loss: 2.950806\n",
      "Epoch: 17 \tTraining Loss: 0.869718 \tValidation Loss: 2.970849\n",
      "Epoch: 18 \tTraining Loss: 0.823545 \tValidation Loss: 2.989862\n",
      "Epoch: 19 \tTraining Loss: 0.779638 \tValidation Loss: 3.017149\n",
      "Epoch: 20 \tTraining Loss: 0.745429 \tValidation Loss: 3.044705\n",
      "Epoch: 1 \tTraining Loss: 6.084130 \tValidation Loss: 5.286841\n",
      "Validation loss decreased (inf --> 5.28684).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.479685 \tValidation Loss: 4.961212\n",
      "Validation loss decreased (5.28684 --> 4.96121).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.895057 \tValidation Loss: 4.517507\n",
      "Validation loss decreased (4.96121 --> 4.51751).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.161040 \tValidation Loss: 4.094656\n",
      "Validation loss decreased (4.51751 --> 4.09466).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.451693 \tValidation Loss: 3.756720\n",
      "Validation loss decreased (4.09466 --> 3.75672).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.859507 \tValidation Loss: 3.509457\n",
      "Validation loss decreased (3.75672 --> 3.50946).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.403312 \tValidation Loss: 3.334016\n",
      "Validation loss decreased (3.50946 --> 3.33402).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.047720 \tValidation Loss: 3.210597\n",
      "Validation loss decreased (3.33402 --> 3.21060).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.778637 \tValidation Loss: 3.124683\n",
      "Validation loss decreased (3.21060 --> 3.12468).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.568023 \tValidation Loss: 3.066738\n",
      "Validation loss decreased (3.12468 --> 3.06674).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.399784 \tValidation Loss: 3.026920\n",
      "Validation loss decreased (3.06674 --> 3.02692).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.265477 \tValidation Loss: 3.004316\n",
      "Validation loss decreased (3.02692 --> 3.00432).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.152602 \tValidation Loss: 2.998091\n",
      "Validation loss decreased (3.00432 --> 2.99809).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.062917 \tValidation Loss: 2.994970\n",
      "Validation loss decreased (2.99809 --> 2.99497).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.987318 \tValidation Loss: 3.005576\n",
      "Epoch: 16 \tTraining Loss: 0.921912 \tValidation Loss: 3.020377\n",
      "Epoch: 17 \tTraining Loss: 0.866880 \tValidation Loss: 3.037350\n",
      "Epoch: 18 \tTraining Loss: 0.820547 \tValidation Loss: 3.059351\n",
      "Epoch: 19 \tTraining Loss: 0.781889 \tValidation Loss: 3.083288\n",
      "Epoch: 20 \tTraining Loss: 0.749719 \tValidation Loss: 3.113209\n",
      "Epoch: 1 \tTraining Loss: 6.092216 \tValidation Loss: 5.258913\n",
      "Validation loss decreased (inf --> 5.25891).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.488503 \tValidation Loss: 4.940658\n",
      "Validation loss decreased (5.25891 --> 4.94066).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.904183 \tValidation Loss: 4.500109\n",
      "Validation loss decreased (4.94066 --> 4.50011).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.171561 \tValidation Loss: 4.080543\n",
      "Validation loss decreased (4.50011 --> 4.08054).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.456951 \tValidation Loss: 3.748206\n",
      "Validation loss decreased (4.08054 --> 3.74821).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.861900 \tValidation Loss: 3.503604\n",
      "Validation loss decreased (3.74821 --> 3.50360).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.399472 \tValidation Loss: 3.328636\n",
      "Validation loss decreased (3.50360 --> 3.32864).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.044982 \tValidation Loss: 3.202787\n",
      "Validation loss decreased (3.32864 --> 3.20279).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.773099 \tValidation Loss: 3.113469\n",
      "Validation loss decreased (3.20279 --> 3.11347).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.559078 \tValidation Loss: 3.049466\n",
      "Validation loss decreased (3.11347 --> 3.04947).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.390586 \tValidation Loss: 3.009195\n",
      "Validation loss decreased (3.04947 --> 3.00919).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.254810 \tValidation Loss: 2.984887\n",
      "Validation loss decreased (3.00919 --> 2.98489).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.146608 \tValidation Loss: 2.971756\n",
      "Validation loss decreased (2.98489 --> 2.97176).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.054457 \tValidation Loss: 2.967769\n",
      "Validation loss decreased (2.97176 --> 2.96777).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.978345 \tValidation Loss: 2.971401\n",
      "Epoch: 16 \tTraining Loss: 0.911629 \tValidation Loss: 2.982764\n",
      "Epoch: 17 \tTraining Loss: 0.860754 \tValidation Loss: 3.003304\n",
      "Epoch: 18 \tTraining Loss: 0.815923 \tValidation Loss: 3.026799\n",
      "Epoch: 19 \tTraining Loss: 0.775727 \tValidation Loss: 3.049932\n",
      "Epoch: 20 \tTraining Loss: 0.738597 \tValidation Loss: 3.079510\n",
      "Epoch: 1 \tTraining Loss: 6.076666 \tValidation Loss: 5.288036\n",
      "Validation loss decreased (inf --> 5.28804).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.479980 \tValidation Loss: 4.962902\n",
      "Validation loss decreased (5.28804 --> 4.96290).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.895009 \tValidation Loss: 4.517445\n",
      "Validation loss decreased (4.96290 --> 4.51745).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.163541 \tValidation Loss: 4.089061\n",
      "Validation loss decreased (4.51745 --> 4.08906).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.455548 \tValidation Loss: 3.745760\n",
      "Validation loss decreased (4.08906 --> 3.74576).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.866105 \tValidation Loss: 3.494945\n",
      "Validation loss decreased (3.74576 --> 3.49494).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.405181 \tValidation Loss: 3.320601\n",
      "Validation loss decreased (3.49494 --> 3.32060).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.052942 \tValidation Loss: 3.198727\n",
      "Validation loss decreased (3.32060 --> 3.19873).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.783162 \tValidation Loss: 3.113170\n",
      "Validation loss decreased (3.19873 --> 3.11317).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.572312 \tValidation Loss: 3.053016\n",
      "Validation loss decreased (3.11317 --> 3.05302).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.404006 \tValidation Loss: 3.013242\n",
      "Validation loss decreased (3.05302 --> 3.01324).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.267626 \tValidation Loss: 2.989333\n",
      "Validation loss decreased (3.01324 --> 2.98933).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.153515 \tValidation Loss: 2.980517\n",
      "Validation loss decreased (2.98933 --> 2.98052).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 \tTraining Loss: 1.063939 \tValidation Loss: 2.978935\n",
      "Validation loss decreased (2.98052 --> 2.97894).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.988674 \tValidation Loss: 2.984171\n",
      "Epoch: 16 \tTraining Loss: 0.924863 \tValidation Loss: 2.998721\n",
      "Epoch: 17 \tTraining Loss: 0.868227 \tValidation Loss: 3.014544\n",
      "Epoch: 18 \tTraining Loss: 0.823903 \tValidation Loss: 3.038343\n",
      "Epoch: 19 \tTraining Loss: 0.783391 \tValidation Loss: 3.065697\n",
      "Epoch: 20 \tTraining Loss: 0.747327 \tValidation Loss: 3.094491\n",
      "Epoch: 1 \tTraining Loss: 6.085732 \tValidation Loss: 5.274264\n",
      "Validation loss decreased (inf --> 5.27426).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.481349 \tValidation Loss: 4.959347\n",
      "Validation loss decreased (5.27426 --> 4.95935).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.888386 \tValidation Loss: 4.525432\n",
      "Validation loss decreased (4.95935 --> 4.52543).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.149274 \tValidation Loss: 4.107349\n",
      "Validation loss decreased (4.52543 --> 4.10735).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.437902 \tValidation Loss: 3.773081\n",
      "Validation loss decreased (4.10735 --> 3.77308).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.849468 \tValidation Loss: 3.530154\n",
      "Validation loss decreased (3.77308 --> 3.53015).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.392204 \tValidation Loss: 3.357989\n",
      "Validation loss decreased (3.53015 --> 3.35799).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 2.039596 \tValidation Loss: 3.236757\n",
      "Validation loss decreased (3.35799 --> 3.23676).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.768562 \tValidation Loss: 3.153162\n",
      "Validation loss decreased (3.23676 --> 3.15316).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.559506 \tValidation Loss: 3.093792\n",
      "Validation loss decreased (3.15316 --> 3.09379).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.393736 \tValidation Loss: 3.055207\n",
      "Validation loss decreased (3.09379 --> 3.05521).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.258571 \tValidation Loss: 3.034665\n",
      "Validation loss decreased (3.05521 --> 3.03467).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 1.146727 \tValidation Loss: 3.024970\n",
      "Validation loss decreased (3.03467 --> 3.02497).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 1.059163 \tValidation Loss: 3.024187\n",
      "Validation loss decreased (3.02497 --> 3.02419).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.977356 \tValidation Loss: 3.033259\n",
      "Epoch: 16 \tTraining Loss: 0.917471 \tValidation Loss: 3.048194\n",
      "Epoch: 17 \tTraining Loss: 0.864575 \tValidation Loss: 3.066296\n",
      "Epoch: 18 \tTraining Loss: 0.816341 \tValidation Loss: 3.089783\n",
      "Epoch: 19 \tTraining Loss: 0.777707 \tValidation Loss: 3.113321\n",
      "Epoch: 20 \tTraining Loss: 0.741503 \tValidation Loss: 3.141225\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 6 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.033893 \tValidation Loss: 5.367434\n",
      "Validation loss decreased (inf --> 5.36743).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.389210 \tValidation Loss: 5.033096\n",
      "Validation loss decreased (5.36743 --> 5.03310).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.759042 \tValidation Loss: 4.563189\n",
      "Validation loss decreased (5.03310 --> 4.56319).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 3.978092 \tValidation Loss: 4.097835\n",
      "Validation loss decreased (4.56319 --> 4.09783).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.231137 \tValidation Loss: 3.720697\n",
      "Validation loss decreased (4.09783 --> 3.72070).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.622480 \tValidation Loss: 3.445446\n",
      "Validation loss decreased (3.72070 --> 3.44545).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.152133 \tValidation Loss: 3.249566\n",
      "Validation loss decreased (3.44545 --> 3.24957).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.794390 \tValidation Loss: 3.112446\n",
      "Validation loss decreased (3.24957 --> 3.11245).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.519918 \tValidation Loss: 3.015496\n",
      "Validation loss decreased (3.11245 --> 3.01550).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.302823 \tValidation Loss: 2.947960\n",
      "Validation loss decreased (3.01550 --> 2.94796).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.133317 \tValidation Loss: 2.902548\n",
      "Validation loss decreased (2.94796 --> 2.90255).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.996170 \tValidation Loss: 2.877459\n",
      "Validation loss decreased (2.90255 --> 2.87746).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.882458 \tValidation Loss: 2.863216\n",
      "Validation loss decreased (2.87746 --> 2.86322).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.794289 \tValidation Loss: 2.858065\n",
      "Validation loss decreased (2.86322 --> 2.85806).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.717103 \tValidation Loss: 2.864260\n",
      "Epoch: 16 \tTraining Loss: 0.656741 \tValidation Loss: 2.879060\n",
      "Epoch: 17 \tTraining Loss: 0.607353 \tValidation Loss: 2.896474\n",
      "Epoch: 18 \tTraining Loss: 0.561142 \tValidation Loss: 2.916233\n",
      "Epoch: 19 \tTraining Loss: 0.519715 \tValidation Loss: 2.943446\n",
      "Epoch: 20 \tTraining Loss: 0.489073 \tValidation Loss: 2.970488\n",
      "Epoch: 1 \tTraining Loss: 6.037891 \tValidation Loss: 5.338412\n",
      "Validation loss decreased (inf --> 5.33841).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.386420 \tValidation Loss: 4.999388\n",
      "Validation loss decreased (5.33841 --> 4.99939).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.753401 \tValidation Loss: 4.535992\n",
      "Validation loss decreased (4.99939 --> 4.53599).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 3.973306 \tValidation Loss: 4.085122\n",
      "Validation loss decreased (4.53599 --> 4.08512).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.230208 \tValidation Loss: 3.723029\n",
      "Validation loss decreased (4.08512 --> 3.72303).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.621618 \tValidation Loss: 3.456658\n",
      "Validation loss decreased (3.72303 --> 3.45666).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.151998 \tValidation Loss: 3.266990\n",
      "Validation loss decreased (3.45666 --> 3.26699).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.793414 \tValidation Loss: 3.132322\n",
      "Validation loss decreased (3.26699 --> 3.13232).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.518979 \tValidation Loss: 3.035924\n",
      "Validation loss decreased (3.13232 --> 3.03592).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.303298 \tValidation Loss: 2.971256\n",
      "Validation loss decreased (3.03592 --> 2.97126).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.132784 \tValidation Loss: 2.928476\n",
      "Validation loss decreased (2.97126 --> 2.92848).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.995621 \tValidation Loss: 2.904077\n",
      "Validation loss decreased (2.92848 --> 2.90408).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.885261 \tValidation Loss: 2.890841\n",
      "Validation loss decreased (2.90408 --> 2.89084).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.793212 \tValidation Loss: 2.891473\n",
      "Epoch: 15 \tTraining Loss: 0.720724 \tValidation Loss: 2.895675\n",
      "Epoch: 16 \tTraining Loss: 0.656079 \tValidation Loss: 2.910585\n",
      "Epoch: 17 \tTraining Loss: 0.603156 \tValidation Loss: 2.929907\n",
      "Epoch: 18 \tTraining Loss: 0.557253 \tValidation Loss: 2.954315\n",
      "Epoch: 19 \tTraining Loss: 0.521489 \tValidation Loss: 2.983160\n",
      "Epoch: 20 \tTraining Loss: 0.487709 \tValidation Loss: 3.013844\n",
      "Epoch: 1 \tTraining Loss: 6.041392 \tValidation Loss: 5.328941\n",
      "Validation loss decreased (inf --> 5.32894).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.392938 \tValidation Loss: 4.983999\n",
      "Validation loss decreased (5.32894 --> 4.98400).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.765861 \tValidation Loss: 4.506604\n",
      "Validation loss decreased (4.98400 --> 4.50660).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 3.985474 \tValidation Loss: 4.050863\n",
      "Validation loss decreased (4.50660 --> 4.05086).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.238841 \tValidation Loss: 3.688687\n",
      "Validation loss decreased (4.05086 --> 3.68869).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.626003 \tValidation Loss: 3.427411\n",
      "Validation loss decreased (3.68869 --> 3.42741).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.153961 \tValidation Loss: 3.243122\n",
      "Validation loss decreased (3.42741 --> 3.24312).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.794258 \tValidation Loss: 3.114400\n",
      "Validation loss decreased (3.24312 --> 3.11440).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.521217 \tValidation Loss: 3.022598\n",
      "Validation loss decreased (3.11440 --> 3.02260).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.305799 \tValidation Loss: 2.958513\n",
      "Validation loss decreased (3.02260 --> 2.95851).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 \tTraining Loss: 1.132465 \tValidation Loss: 2.913723\n",
      "Validation loss decreased (2.95851 --> 2.91372).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.996795 \tValidation Loss: 2.890083\n",
      "Validation loss decreased (2.91372 --> 2.89008).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.884546 \tValidation Loss: 2.876096\n",
      "Validation loss decreased (2.89008 --> 2.87610).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.795994 \tValidation Loss: 2.872752\n",
      "Validation loss decreased (2.87610 --> 2.87275).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.719848 \tValidation Loss: 2.878337\n",
      "Epoch: 16 \tTraining Loss: 0.656924 \tValidation Loss: 2.889537\n",
      "Epoch: 17 \tTraining Loss: 0.606469 \tValidation Loss: 2.909116\n",
      "Epoch: 18 \tTraining Loss: 0.560162 \tValidation Loss: 2.932506\n",
      "Epoch: 19 \tTraining Loss: 0.522956 \tValidation Loss: 2.960767\n",
      "Epoch: 20 \tTraining Loss: 0.490971 \tValidation Loss: 2.987415\n",
      "Epoch: 1 \tTraining Loss: 6.038873 \tValidation Loss: 5.310181\n",
      "Validation loss decreased (inf --> 5.31018).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.397941 \tValidation Loss: 4.974202\n",
      "Validation loss decreased (5.31018 --> 4.97420).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.775620 \tValidation Loss: 4.508073\n",
      "Validation loss decreased (4.97420 --> 4.50807).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 3.994343 \tValidation Loss: 4.051303\n",
      "Validation loss decreased (4.50807 --> 4.05130).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.246485 \tValidation Loss: 3.689428\n",
      "Validation loss decreased (4.05130 --> 3.68943).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.634536 \tValidation Loss: 3.428687\n",
      "Validation loss decreased (3.68943 --> 3.42869).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.160249 \tValidation Loss: 3.241765\n",
      "Validation loss decreased (3.42869 --> 3.24176).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.800526 \tValidation Loss: 3.108103\n",
      "Validation loss decreased (3.24176 --> 3.10810).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.522484 \tValidation Loss: 3.012048\n",
      "Validation loss decreased (3.10810 --> 3.01205).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.306534 \tValidation Loss: 2.945721\n",
      "Validation loss decreased (3.01205 --> 2.94572).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.133381 \tValidation Loss: 2.902283\n",
      "Validation loss decreased (2.94572 --> 2.90228).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.998569 \tValidation Loss: 2.876907\n",
      "Validation loss decreased (2.90228 --> 2.87691).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.886463 \tValidation Loss: 2.865180\n",
      "Validation loss decreased (2.87691 --> 2.86518).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.794882 \tValidation Loss: 2.863718\n",
      "Validation loss decreased (2.86518 --> 2.86372).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.719495 \tValidation Loss: 2.869609\n",
      "Epoch: 16 \tTraining Loss: 0.657459 \tValidation Loss: 2.881914\n",
      "Epoch: 17 \tTraining Loss: 0.607185 \tValidation Loss: 2.899138\n",
      "Epoch: 18 \tTraining Loss: 0.557367 \tValidation Loss: 2.923992\n",
      "Epoch: 19 \tTraining Loss: 0.521243 \tValidation Loss: 2.950945\n",
      "Epoch: 20 \tTraining Loss: 0.488982 \tValidation Loss: 2.979438\n",
      "Epoch: 1 \tTraining Loss: 6.042612 \tValidation Loss: 5.329454\n",
      "Validation loss decreased (inf --> 5.32945).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.396688 \tValidation Loss: 4.989955\n",
      "Validation loss decreased (5.32945 --> 4.98995).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.765638 \tValidation Loss: 4.532669\n",
      "Validation loss decreased (4.98995 --> 4.53267).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 3.984937 \tValidation Loss: 4.093124\n",
      "Validation loss decreased (4.53267 --> 4.09312).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.240308 \tValidation Loss: 3.740764\n",
      "Validation loss decreased (4.09312 --> 3.74076).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.629632 \tValidation Loss: 3.481172\n",
      "Validation loss decreased (3.74076 --> 3.48117).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.159691 \tValidation Loss: 3.293912\n",
      "Validation loss decreased (3.48117 --> 3.29391).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.801357 \tValidation Loss: 3.160525\n",
      "Validation loss decreased (3.29391 --> 3.16053).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.523085 \tValidation Loss: 3.064168\n",
      "Validation loss decreased (3.16053 --> 3.06417).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.307272 \tValidation Loss: 2.997433\n",
      "Validation loss decreased (3.06417 --> 2.99743).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.132797 \tValidation Loss: 2.952655\n",
      "Validation loss decreased (2.99743 --> 2.95266).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.995004 \tValidation Loss: 2.926490\n",
      "Validation loss decreased (2.95266 --> 2.92649).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.881573 \tValidation Loss: 2.913872\n",
      "Validation loss decreased (2.92649 --> 2.91387).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.791322 \tValidation Loss: 2.912945\n",
      "Validation loss decreased (2.91387 --> 2.91295).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.718338 \tValidation Loss: 2.918438\n",
      "Epoch: 16 \tTraining Loss: 0.655046 \tValidation Loss: 2.937342\n",
      "Epoch: 17 \tTraining Loss: 0.600552 \tValidation Loss: 2.955081\n",
      "Epoch: 18 \tTraining Loss: 0.554241 \tValidation Loss: 2.979611\n",
      "Epoch: 19 \tTraining Loss: 0.520602 \tValidation Loss: 3.006902\n",
      "Epoch: 20 \tTraining Loss: 0.485906 \tValidation Loss: 3.037167\n",
      "Epoch: 1 \tTraining Loss: 6.038762 \tValidation Loss: 5.352093\n",
      "Validation loss decreased (inf --> 5.35209).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.390414 \tValidation Loss: 5.010303\n",
      "Validation loss decreased (5.35209 --> 5.01030).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.759409 \tValidation Loss: 4.530028\n",
      "Validation loss decreased (5.01030 --> 4.53003).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 3.974318 \tValidation Loss: 4.061768\n",
      "Validation loss decreased (4.53003 --> 4.06177).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.229803 \tValidation Loss: 3.682473\n",
      "Validation loss decreased (4.06177 --> 3.68247).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.622454 \tValidation Loss: 3.404847\n",
      "Validation loss decreased (3.68247 --> 3.40485).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.154716 \tValidation Loss: 3.201917\n",
      "Validation loss decreased (3.40485 --> 3.20192).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.796668 \tValidation Loss: 3.055517\n",
      "Validation loss decreased (3.20192 --> 3.05552).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.521306 \tValidation Loss: 2.951871\n",
      "Validation loss decreased (3.05552 --> 2.95187).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.307779 \tValidation Loss: 2.880167\n",
      "Validation loss decreased (2.95187 --> 2.88017).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.133469 \tValidation Loss: 2.832579\n",
      "Validation loss decreased (2.88017 --> 2.83258).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.996820 \tValidation Loss: 2.804471\n",
      "Validation loss decreased (2.83258 --> 2.80447).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.888636 \tValidation Loss: 2.790531\n",
      "Validation loss decreased (2.80447 --> 2.79053).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.795066 \tValidation Loss: 2.787149\n",
      "Validation loss decreased (2.79053 --> 2.78715).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.720024 \tValidation Loss: 2.794947\n",
      "Epoch: 16 \tTraining Loss: 0.655996 \tValidation Loss: 2.808227\n",
      "Epoch: 17 \tTraining Loss: 0.604653 \tValidation Loss: 2.825333\n",
      "Epoch: 18 \tTraining Loss: 0.563500 \tValidation Loss: 2.847275\n",
      "Epoch: 19 \tTraining Loss: 0.524103 \tValidation Loss: 2.871501\n",
      "Epoch: 20 \tTraining Loss: 0.494124 \tValidation Loss: 2.901107\n",
      "Epoch: 1 \tTraining Loss: 6.034024 \tValidation Loss: 5.357052\n",
      "Validation loss decreased (inf --> 5.35705).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.387877 \tValidation Loss: 5.024435\n",
      "Validation loss decreased (5.35705 --> 5.02443).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.761575 \tValidation Loss: 4.558497\n",
      "Validation loss decreased (5.02443 --> 4.55850).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 3.981496 \tValidation Loss: 4.101243\n",
      "Validation loss decreased (4.55850 --> 4.10124).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.237764 \tValidation Loss: 3.730311\n",
      "Validation loss decreased (4.10124 --> 3.73031).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.629653 \tValidation Loss: 3.456610\n",
      "Validation loss decreased (3.73031 --> 3.45661).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.163465 \tValidation Loss: 3.258504\n",
      "Validation loss decreased (3.45661 --> 3.25850).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 \tTraining Loss: 1.805851 \tValidation Loss: 3.113463\n",
      "Validation loss decreased (3.25850 --> 3.11346).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.529272 \tValidation Loss: 3.010772\n",
      "Validation loss decreased (3.11346 --> 3.01077).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.312847 \tValidation Loss: 2.937075\n",
      "Validation loss decreased (3.01077 --> 2.93707).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.141751 \tValidation Loss: 2.886394\n",
      "Validation loss decreased (2.93707 --> 2.88639).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.000637 \tValidation Loss: 2.854292\n",
      "Validation loss decreased (2.88639 --> 2.85429).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.888110 \tValidation Loss: 2.835615\n",
      "Validation loss decreased (2.85429 --> 2.83562).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.797706 \tValidation Loss: 2.829571\n",
      "Validation loss decreased (2.83562 --> 2.82957).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.723227 \tValidation Loss: 2.830422\n",
      "Epoch: 16 \tTraining Loss: 0.660455 \tValidation Loss: 2.843929\n",
      "Epoch: 17 \tTraining Loss: 0.606087 \tValidation Loss: 2.862302\n",
      "Epoch: 18 \tTraining Loss: 0.563460 \tValidation Loss: 2.881183\n",
      "Epoch: 19 \tTraining Loss: 0.527056 \tValidation Loss: 2.903862\n",
      "Epoch: 20 \tTraining Loss: 0.493929 \tValidation Loss: 2.933085\n",
      "Epoch: 1 \tTraining Loss: 6.032171 \tValidation Loss: 5.342329\n",
      "Validation loss decreased (inf --> 5.34233).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.392747 \tValidation Loss: 5.008579\n",
      "Validation loss decreased (5.34233 --> 5.00858).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.768194 \tValidation Loss: 4.539329\n",
      "Validation loss decreased (5.00858 --> 4.53933).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 3.986668 \tValidation Loss: 4.079164\n",
      "Validation loss decreased (4.53933 --> 4.07916).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.242429 \tValidation Loss: 3.704777\n",
      "Validation loss decreased (4.07916 --> 3.70478).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.630384 \tValidation Loss: 3.425211\n",
      "Validation loss decreased (3.70478 --> 3.42521).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.160630 \tValidation Loss: 3.221810\n",
      "Validation loss decreased (3.42521 --> 3.22181).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.801825 \tValidation Loss: 3.077183\n",
      "Validation loss decreased (3.22181 --> 3.07718).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.524182 \tValidation Loss: 2.974552\n",
      "Validation loss decreased (3.07718 --> 2.97455).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.310731 \tValidation Loss: 2.905365\n",
      "Validation loss decreased (2.97455 --> 2.90537).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.136366 \tValidation Loss: 2.858001\n",
      "Validation loss decreased (2.90537 --> 2.85800).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 1.002877 \tValidation Loss: 2.829823\n",
      "Validation loss decreased (2.85800 --> 2.82982).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.890744 \tValidation Loss: 2.816071\n",
      "Validation loss decreased (2.82982 --> 2.81607).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.801229 \tValidation Loss: 2.813778\n",
      "Validation loss decreased (2.81607 --> 2.81378).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.724753 \tValidation Loss: 2.820140\n",
      "Epoch: 16 \tTraining Loss: 0.662706 \tValidation Loss: 2.831981\n",
      "Epoch: 17 \tTraining Loss: 0.609177 \tValidation Loss: 2.847664\n",
      "Epoch: 18 \tTraining Loss: 0.567505 \tValidation Loss: 2.869525\n",
      "Epoch: 19 \tTraining Loss: 0.526650 \tValidation Loss: 2.897768\n",
      "Epoch: 20 \tTraining Loss: 0.494669 \tValidation Loss: 2.924920\n",
      "Epoch: 1 \tTraining Loss: 6.043120 \tValidation Loss: 5.336777\n",
      "Validation loss decreased (inf --> 5.33678).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.401947 \tValidation Loss: 4.997398\n",
      "Validation loss decreased (5.33678 --> 4.99740).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.776415 \tValidation Loss: 4.517600\n",
      "Validation loss decreased (4.99740 --> 4.51760).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 3.988856 \tValidation Loss: 4.059153\n",
      "Validation loss decreased (4.51760 --> 4.05915).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.233783 \tValidation Loss: 3.699798\n",
      "Validation loss decreased (4.05915 --> 3.69980).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.622116 \tValidation Loss: 3.439979\n",
      "Validation loss decreased (3.69980 --> 3.43998).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.152443 \tValidation Loss: 3.253058\n",
      "Validation loss decreased (3.43998 --> 3.25306).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.793604 \tValidation Loss: 3.118619\n",
      "Validation loss decreased (3.25306 --> 3.11862).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.515770 \tValidation Loss: 3.024680\n",
      "Validation loss decreased (3.11862 --> 3.02468).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.300006 \tValidation Loss: 2.958321\n",
      "Validation loss decreased (3.02468 --> 2.95832).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.132169 \tValidation Loss: 2.914806\n",
      "Validation loss decreased (2.95832 --> 2.91481).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.993097 \tValidation Loss: 2.891257\n",
      "Validation loss decreased (2.91481 --> 2.89126).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.879265 \tValidation Loss: 2.883398\n",
      "Validation loss decreased (2.89126 --> 2.88340).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.790078 \tValidation Loss: 2.885225\n",
      "Epoch: 15 \tTraining Loss: 0.716062 \tValidation Loss: 2.895777\n",
      "Epoch: 16 \tTraining Loss: 0.655287 \tValidation Loss: 2.910891\n",
      "Epoch: 17 \tTraining Loss: 0.602480 \tValidation Loss: 2.933415\n",
      "Epoch: 18 \tTraining Loss: 0.558521 \tValidation Loss: 2.961814\n",
      "Epoch: 19 \tTraining Loss: 0.520171 \tValidation Loss: 2.991160\n",
      "Epoch: 20 \tTraining Loss: 0.484945 \tValidation Loss: 3.024069\n",
      "Epoch: 1 \tTraining Loss: 6.034700 \tValidation Loss: 5.342379\n",
      "Validation loss decreased (inf --> 5.34238).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.394942 \tValidation Loss: 5.001674\n",
      "Validation loss decreased (5.34238 --> 5.00167).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.770356 \tValidation Loss: 4.519913\n",
      "Validation loss decreased (5.00167 --> 4.51991).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 3.989456 \tValidation Loss: 4.053689\n",
      "Validation loss decreased (4.51991 --> 4.05369).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.242078 \tValidation Loss: 3.681851\n",
      "Validation loss decreased (4.05369 --> 3.68185).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.631839 \tValidation Loss: 3.411390\n",
      "Validation loss decreased (3.68185 --> 3.41139).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.157892 \tValidation Loss: 3.218553\n",
      "Validation loss decreased (3.41139 --> 3.21855).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.799288 \tValidation Loss: 3.081510\n",
      "Validation loss decreased (3.21855 --> 3.08151).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.520179 \tValidation Loss: 2.984720\n",
      "Validation loss decreased (3.08151 --> 2.98472).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.306589 \tValidation Loss: 2.918049\n",
      "Validation loss decreased (2.98472 --> 2.91805).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.132356 \tValidation Loss: 2.874977\n",
      "Validation loss decreased (2.91805 --> 2.87498).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.996387 \tValidation Loss: 2.849317\n",
      "Validation loss decreased (2.87498 --> 2.84932).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.883596 \tValidation Loss: 2.837988\n",
      "Validation loss decreased (2.84932 --> 2.83799).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.793393 \tValidation Loss: 2.837037\n",
      "Validation loss decreased (2.83799 --> 2.83704).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.712834 \tValidation Loss: 2.846469\n",
      "Epoch: 16 \tTraining Loss: 0.653614 \tValidation Loss: 2.863916\n",
      "Epoch: 17 \tTraining Loss: 0.599185 \tValidation Loss: 2.887321\n",
      "Epoch: 18 \tTraining Loss: 0.553405 \tValidation Loss: 2.911953\n",
      "Epoch: 19 \tTraining Loss: 0.519001 \tValidation Loss: 2.941043\n",
      "Epoch: 20 \tTraining Loss: 0.487739 \tValidation Loss: 2.974247\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 7 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.074073 \tValidation Loss: 5.485487\n",
      "Validation loss decreased (inf --> 5.48549).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.399595 \tValidation Loss: 5.130218\n",
      "Validation loss decreased (5.48549 --> 5.13022).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.766252 \tValidation Loss: 4.634332\n",
      "Validation loss decreased (5.13022 --> 4.63433).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 3.977740 \tValidation Loss: 4.151967\n",
      "Validation loss decreased (4.63433 --> 4.15197).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \tTraining Loss: 3.223424 \tValidation Loss: 3.762166\n",
      "Validation loss decreased (4.15197 --> 3.76217).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.591541 \tValidation Loss: 3.475298\n",
      "Validation loss decreased (3.76217 --> 3.47530).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.099724 \tValidation Loss: 3.268312\n",
      "Validation loss decreased (3.47530 --> 3.26831).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.720283 \tValidation Loss: 3.118758\n",
      "Validation loss decreased (3.26831 --> 3.11876).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.424711 \tValidation Loss: 3.009080\n",
      "Validation loss decreased (3.11876 --> 3.00908).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.199043 \tValidation Loss: 2.931366\n",
      "Validation loss decreased (3.00908 --> 2.93137).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.016503 \tValidation Loss: 2.878859\n",
      "Validation loss decreased (2.93137 --> 2.87886).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.870706 \tValidation Loss: 2.847326\n",
      "Validation loss decreased (2.87886 --> 2.84733).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.750827 \tValidation Loss: 2.828382\n",
      "Validation loss decreased (2.84733 --> 2.82838).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.656021 \tValidation Loss: 2.822311\n",
      "Validation loss decreased (2.82838 --> 2.82231).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.576107 \tValidation Loss: 2.828831\n",
      "Epoch: 16 \tTraining Loss: 0.512493 \tValidation Loss: 2.843003\n",
      "Epoch: 17 \tTraining Loss: 0.464010 \tValidation Loss: 2.860969\n",
      "Epoch: 18 \tTraining Loss: 0.421066 \tValidation Loss: 2.886337\n",
      "Epoch: 19 \tTraining Loss: 0.383912 \tValidation Loss: 2.914844\n",
      "Epoch: 20 \tTraining Loss: 0.352411 \tValidation Loss: 2.939262\n",
      "Epoch: 1 \tTraining Loss: 6.084385 \tValidation Loss: 5.443745\n",
      "Validation loss decreased (inf --> 5.44374).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.405352 \tValidation Loss: 5.088423\n",
      "Validation loss decreased (5.44374 --> 5.08842).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.763420 \tValidation Loss: 4.603006\n",
      "Validation loss decreased (5.08842 --> 4.60301).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 3.964984 \tValidation Loss: 4.134372\n",
      "Validation loss decreased (4.60301 --> 4.13437).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.206476 \tValidation Loss: 3.752079\n",
      "Validation loss decreased (4.13437 --> 3.75208).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.579616 \tValidation Loss: 3.467734\n",
      "Validation loss decreased (3.75208 --> 3.46773).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.093090 \tValidation Loss: 3.256416\n",
      "Validation loss decreased (3.46773 --> 3.25642).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.718732 \tValidation Loss: 3.100424\n",
      "Validation loss decreased (3.25642 --> 3.10042).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.423669 \tValidation Loss: 2.988580\n",
      "Validation loss decreased (3.10042 --> 2.98858).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.195873 \tValidation Loss: 2.908045\n",
      "Validation loss decreased (2.98858 --> 2.90805).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.015044 \tValidation Loss: 2.853873\n",
      "Validation loss decreased (2.90805 --> 2.85387).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.871375 \tValidation Loss: 2.819852\n",
      "Validation loss decreased (2.85387 --> 2.81985).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.752943 \tValidation Loss: 2.798100\n",
      "Validation loss decreased (2.81985 --> 2.79810).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.659423 \tValidation Loss: 2.792989\n",
      "Validation loss decreased (2.79810 --> 2.79299).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.583409 \tValidation Loss: 2.793106\n",
      "Epoch: 16 \tTraining Loss: 0.517377 \tValidation Loss: 2.802378\n",
      "Epoch: 17 \tTraining Loss: 0.464427 \tValidation Loss: 2.817784\n",
      "Epoch: 18 \tTraining Loss: 0.422833 \tValidation Loss: 2.836897\n",
      "Epoch: 19 \tTraining Loss: 0.384926 \tValidation Loss: 2.862352\n",
      "Epoch: 20 \tTraining Loss: 0.354863 \tValidation Loss: 2.888304\n",
      "Epoch: 1 \tTraining Loss: 6.086140 \tValidation Loss: 5.475417\n",
      "Validation loss decreased (inf --> 5.47542).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.405567 \tValidation Loss: 5.110470\n",
      "Validation loss decreased (5.47542 --> 5.11047).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.770829 \tValidation Loss: 4.600827\n",
      "Validation loss decreased (5.11047 --> 4.60083).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 3.978482 \tValidation Loss: 4.107893\n",
      "Validation loss decreased (4.60083 --> 4.10789).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.221884 \tValidation Loss: 3.716039\n",
      "Validation loss decreased (4.10789 --> 3.71604).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.594402 \tValidation Loss: 3.423431\n",
      "Validation loss decreased (3.71604 --> 3.42343).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.103824 \tValidation Loss: 3.207843\n",
      "Validation loss decreased (3.42343 --> 3.20784).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.725640 \tValidation Loss: 3.051045\n",
      "Validation loss decreased (3.20784 --> 3.05105).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.433758 \tValidation Loss: 2.938460\n",
      "Validation loss decreased (3.05105 --> 2.93846).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.203806 \tValidation Loss: 2.856595\n",
      "Validation loss decreased (2.93846 --> 2.85660).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.022677 \tValidation Loss: 2.800752\n",
      "Validation loss decreased (2.85660 --> 2.80075).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.877774 \tValidation Loss: 2.763870\n",
      "Validation loss decreased (2.80075 --> 2.76387).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.758149 \tValidation Loss: 2.743191\n",
      "Validation loss decreased (2.76387 --> 2.74319).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.661714 \tValidation Loss: 2.735828\n",
      "Validation loss decreased (2.74319 --> 2.73583).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.584582 \tValidation Loss: 2.735954\n",
      "Epoch: 16 \tTraining Loss: 0.521150 \tValidation Loss: 2.747465\n",
      "Epoch: 17 \tTraining Loss: 0.469786 \tValidation Loss: 2.762535\n",
      "Epoch: 18 \tTraining Loss: 0.424752 \tValidation Loss: 2.783396\n",
      "Epoch: 19 \tTraining Loss: 0.390041 \tValidation Loss: 2.811617\n",
      "Epoch: 20 \tTraining Loss: 0.358351 \tValidation Loss: 2.834069\n",
      "Epoch: 1 \tTraining Loss: 6.088682 \tValidation Loss: 5.421249\n",
      "Validation loss decreased (inf --> 5.42125).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.408058 \tValidation Loss: 5.052811\n",
      "Validation loss decreased (5.42125 --> 5.05281).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.759735 \tValidation Loss: 4.551983\n",
      "Validation loss decreased (5.05281 --> 4.55198).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 3.964762 \tValidation Loss: 4.080037\n",
      "Validation loss decreased (4.55198 --> 4.08004).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.207718 \tValidation Loss: 3.701247\n",
      "Validation loss decreased (4.08004 --> 3.70125).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.579502 \tValidation Loss: 3.414153\n",
      "Validation loss decreased (3.70125 --> 3.41415).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.090472 \tValidation Loss: 3.204845\n",
      "Validation loss decreased (3.41415 --> 3.20485).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.711720 \tValidation Loss: 3.053122\n",
      "Validation loss decreased (3.20485 --> 3.05312).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.421951 \tValidation Loss: 2.946234\n",
      "Validation loss decreased (3.05312 --> 2.94623).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.191069 \tValidation Loss: 2.872062\n",
      "Validation loss decreased (2.94623 --> 2.87206).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.011112 \tValidation Loss: 2.822153\n",
      "Validation loss decreased (2.87206 --> 2.82215).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.866729 \tValidation Loss: 2.792428\n",
      "Validation loss decreased (2.82215 --> 2.79243).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.749162 \tValidation Loss: 2.775603\n",
      "Validation loss decreased (2.79243 --> 2.77560).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.654297 \tValidation Loss: 2.771889\n",
      "Validation loss decreased (2.77560 --> 2.77189).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.577911 \tValidation Loss: 2.776078\n",
      "Epoch: 16 \tTraining Loss: 0.513811 \tValidation Loss: 2.789115\n",
      "Epoch: 17 \tTraining Loss: 0.461421 \tValidation Loss: 2.803533\n",
      "Epoch: 18 \tTraining Loss: 0.419421 \tValidation Loss: 2.828021\n",
      "Epoch: 19 \tTraining Loss: 0.382584 \tValidation Loss: 2.856416\n",
      "Epoch: 20 \tTraining Loss: 0.354036 \tValidation Loss: 2.883546\n",
      "Epoch: 1 \tTraining Loss: 6.084868 \tValidation Loss: 5.471758\n",
      "Validation loss decreased (inf --> 5.47176).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 5.409030 \tValidation Loss: 5.112223\n",
      "Validation loss decreased (5.47176 --> 5.11222).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.771005 \tValidation Loss: 4.616274\n",
      "Validation loss decreased (5.11222 --> 4.61627).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 3.974454 \tValidation Loss: 4.144420\n",
      "Validation loss decreased (4.61627 --> 4.14442).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.217199 \tValidation Loss: 3.765914\n",
      "Validation loss decreased (4.14442 --> 3.76591).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.586126 \tValidation Loss: 3.479827\n",
      "Validation loss decreased (3.76591 --> 3.47983).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.095010 \tValidation Loss: 3.268978\n",
      "Validation loss decreased (3.47983 --> 3.26898).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.715069 \tValidation Loss: 3.117777\n",
      "Validation loss decreased (3.26898 --> 3.11778).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.424483 \tValidation Loss: 3.005333\n",
      "Validation loss decreased (3.11778 --> 3.00533).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.191257 \tValidation Loss: 2.927502\n",
      "Validation loss decreased (3.00533 --> 2.92750).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.011907 \tValidation Loss: 2.873944\n",
      "Validation loss decreased (2.92750 --> 2.87394).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.865376 \tValidation Loss: 2.840236\n",
      "Validation loss decreased (2.87394 --> 2.84024).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.751697 \tValidation Loss: 2.823802\n",
      "Validation loss decreased (2.84024 --> 2.82380).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.655502 \tValidation Loss: 2.820302\n",
      "Validation loss decreased (2.82380 --> 2.82030).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.577089 \tValidation Loss: 2.821620\n",
      "Epoch: 16 \tTraining Loss: 0.516288 \tValidation Loss: 2.835886\n",
      "Epoch: 17 \tTraining Loss: 0.462244 \tValidation Loss: 2.856709\n",
      "Epoch: 18 \tTraining Loss: 0.418916 \tValidation Loss: 2.878846\n",
      "Epoch: 19 \tTraining Loss: 0.382890 \tValidation Loss: 2.903333\n",
      "Epoch: 20 \tTraining Loss: 0.354940 \tValidation Loss: 2.934977\n",
      "Epoch: 1 \tTraining Loss: 6.084161 \tValidation Loss: 5.451855\n",
      "Validation loss decreased (inf --> 5.45185).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.409882 \tValidation Loss: 5.104904\n",
      "Validation loss decreased (5.45185 --> 5.10490).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.780469 \tValidation Loss: 4.612177\n",
      "Validation loss decreased (5.10490 --> 4.61218).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 3.983168 \tValidation Loss: 4.124714\n",
      "Validation loss decreased (4.61218 --> 4.12471).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.218825 \tValidation Loss: 3.737883\n",
      "Validation loss decreased (4.12471 --> 3.73788).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.586667 \tValidation Loss: 3.451431\n",
      "Validation loss decreased (3.73788 --> 3.45143).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.093827 \tValidation Loss: 3.243171\n",
      "Validation loss decreased (3.45143 --> 3.24317).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.714791 \tValidation Loss: 3.091158\n",
      "Validation loss decreased (3.24317 --> 3.09116).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.423315 \tValidation Loss: 2.979760\n",
      "Validation loss decreased (3.09116 --> 2.97976).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.196004 \tValidation Loss: 2.899737\n",
      "Validation loss decreased (2.97976 --> 2.89974).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.013855 \tValidation Loss: 2.845912\n",
      "Validation loss decreased (2.89974 --> 2.84591).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.872771 \tValidation Loss: 2.810623\n",
      "Validation loss decreased (2.84591 --> 2.81062).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.753532 \tValidation Loss: 2.790013\n",
      "Validation loss decreased (2.81062 --> 2.79001).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.658000 \tValidation Loss: 2.782975\n",
      "Validation loss decreased (2.79001 --> 2.78297).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.582745 \tValidation Loss: 2.783916\n",
      "Epoch: 16 \tTraining Loss: 0.518441 \tValidation Loss: 2.795591\n",
      "Epoch: 17 \tTraining Loss: 0.464128 \tValidation Loss: 2.810746\n",
      "Epoch: 18 \tTraining Loss: 0.421164 \tValidation Loss: 2.829658\n",
      "Epoch: 19 \tTraining Loss: 0.387991 \tValidation Loss: 2.857614\n",
      "Epoch: 20 \tTraining Loss: 0.357307 \tValidation Loss: 2.877753\n",
      "Epoch: 1 \tTraining Loss: 6.083961 \tValidation Loss: 5.433950\n",
      "Validation loss decreased (inf --> 5.43395).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.404787 \tValidation Loss: 5.078862\n",
      "Validation loss decreased (5.43395 --> 5.07886).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.762726 \tValidation Loss: 4.586869\n",
      "Validation loss decreased (5.07886 --> 4.58687).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 3.962017 \tValidation Loss: 4.107660\n",
      "Validation loss decreased (4.58687 --> 4.10766).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.202755 \tValidation Loss: 3.724147\n",
      "Validation loss decreased (4.10766 --> 3.72415).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.580374 \tValidation Loss: 3.435328\n",
      "Validation loss decreased (3.72415 --> 3.43533).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.094226 \tValidation Loss: 3.222668\n",
      "Validation loss decreased (3.43533 --> 3.22267).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.718699 \tValidation Loss: 3.067291\n",
      "Validation loss decreased (3.22267 --> 3.06729).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.427497 \tValidation Loss: 2.953289\n",
      "Validation loss decreased (3.06729 --> 2.95329).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.199754 \tValidation Loss: 2.872039\n",
      "Validation loss decreased (2.95329 --> 2.87204).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.017651 \tValidation Loss: 2.818837\n",
      "Validation loss decreased (2.87204 --> 2.81884).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.870032 \tValidation Loss: 2.786212\n",
      "Validation loss decreased (2.81884 --> 2.78621).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.754741 \tValidation Loss: 2.768752\n",
      "Validation loss decreased (2.78621 --> 2.76875).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.658375 \tValidation Loss: 2.762537\n",
      "Validation loss decreased (2.76875 --> 2.76254).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.583583 \tValidation Loss: 2.764615\n",
      "Epoch: 16 \tTraining Loss: 0.518844 \tValidation Loss: 2.775921\n",
      "Epoch: 17 \tTraining Loss: 0.468857 \tValidation Loss: 2.790780\n",
      "Epoch: 18 \tTraining Loss: 0.425763 \tValidation Loss: 2.812468\n",
      "Epoch: 19 \tTraining Loss: 0.390520 \tValidation Loss: 2.836424\n",
      "Epoch: 20 \tTraining Loss: 0.354664 \tValidation Loss: 2.862584\n",
      "Epoch: 1 \tTraining Loss: 6.086887 \tValidation Loss: 5.464246\n",
      "Validation loss decreased (inf --> 5.46425).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.401428 \tValidation Loss: 5.098827\n",
      "Validation loss decreased (5.46425 --> 5.09883).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.758872 \tValidation Loss: 4.588094\n",
      "Validation loss decreased (5.09883 --> 4.58809).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 3.959710 \tValidation Loss: 4.099311\n",
      "Validation loss decreased (4.58809 --> 4.09931).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.202950 \tValidation Loss: 3.706403\n",
      "Validation loss decreased (4.09931 --> 3.70640).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.581568 \tValidation Loss: 3.411242\n",
      "Validation loss decreased (3.70640 --> 3.41124).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.092300 \tValidation Loss: 3.195216\n",
      "Validation loss decreased (3.41124 --> 3.19522).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.717784 \tValidation Loss: 3.034459\n",
      "Validation loss decreased (3.19522 --> 3.03446).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.426103 \tValidation Loss: 2.914705\n",
      "Validation loss decreased (3.03446 --> 2.91471).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.195065 \tValidation Loss: 2.828585\n",
      "Validation loss decreased (2.91471 --> 2.82859).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.013719 \tValidation Loss: 2.769931\n",
      "Validation loss decreased (2.82859 --> 2.76993).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.867941 \tValidation Loss: 2.729517\n",
      "Validation loss decreased (2.76993 --> 2.72952).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.751024 \tValidation Loss: 2.707819\n",
      "Validation loss decreased (2.72952 --> 2.70782).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.655023 \tValidation Loss: 2.697546\n",
      "Validation loss decreased (2.70782 --> 2.69755).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.579274 \tValidation Loss: 2.699440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 \tTraining Loss: 0.517348 \tValidation Loss: 2.706759\n",
      "Epoch: 17 \tTraining Loss: 0.464553 \tValidation Loss: 2.724977\n",
      "Epoch: 18 \tTraining Loss: 0.421467 \tValidation Loss: 2.743612\n",
      "Epoch: 19 \tTraining Loss: 0.387375 \tValidation Loss: 2.767950\n",
      "Epoch: 20 \tTraining Loss: 0.355634 \tValidation Loss: 2.792517\n",
      "Epoch: 1 \tTraining Loss: 6.088496 \tValidation Loss: 5.495578\n",
      "Validation loss decreased (inf --> 5.49558).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.410101 \tValidation Loss: 5.151329\n",
      "Validation loss decreased (5.49558 --> 5.15133).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.773098 \tValidation Loss: 4.667566\n",
      "Validation loss decreased (5.15133 --> 4.66757).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 3.976572 \tValidation Loss: 4.197017\n",
      "Validation loss decreased (4.66757 --> 4.19702).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.215361 \tValidation Loss: 3.816070\n",
      "Validation loss decreased (4.19702 --> 3.81607).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.583489 \tValidation Loss: 3.527153\n",
      "Validation loss decreased (3.81607 --> 3.52715).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.090781 \tValidation Loss: 3.316220\n",
      "Validation loss decreased (3.52715 --> 3.31622).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.713893 \tValidation Loss: 3.163380\n",
      "Validation loss decreased (3.31622 --> 3.16338).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.421114 \tValidation Loss: 3.052133\n",
      "Validation loss decreased (3.16338 --> 3.05213).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.194491 \tValidation Loss: 2.974079\n",
      "Validation loss decreased (3.05213 --> 2.97408).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.015381 \tValidation Loss: 2.918908\n",
      "Validation loss decreased (2.97408 --> 2.91891).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.868085 \tValidation Loss: 2.884710\n",
      "Validation loss decreased (2.91891 --> 2.88471).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.752005 \tValidation Loss: 2.864061\n",
      "Validation loss decreased (2.88471 --> 2.86406).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.657522 \tValidation Loss: 2.857743\n",
      "Validation loss decreased (2.86406 --> 2.85774).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.580583 \tValidation Loss: 2.859604\n",
      "Epoch: 16 \tTraining Loss: 0.517306 \tValidation Loss: 2.871272\n",
      "Epoch: 17 \tTraining Loss: 0.464032 \tValidation Loss: 2.887281\n",
      "Epoch: 18 \tTraining Loss: 0.420759 \tValidation Loss: 2.910988\n",
      "Epoch: 19 \tTraining Loss: 0.386686 \tValidation Loss: 2.941651\n",
      "Epoch: 20 \tTraining Loss: 0.355118 \tValidation Loss: 2.970367\n",
      "Epoch: 1 \tTraining Loss: 6.080242 \tValidation Loss: 5.449063\n",
      "Validation loss decreased (inf --> 5.44906).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.402385 \tValidation Loss: 5.100053\n",
      "Validation loss decreased (5.44906 --> 5.10005).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.770315 \tValidation Loss: 4.611463\n",
      "Validation loss decreased (5.10005 --> 4.61146).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 3.975321 \tValidation Loss: 4.141496\n",
      "Validation loss decreased (4.61146 --> 4.14150).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.215958 \tValidation Loss: 3.761354\n",
      "Validation loss decreased (4.14150 --> 3.76135).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.583189 \tValidation Loss: 3.474988\n",
      "Validation loss decreased (3.76135 --> 3.47499).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.090973 \tValidation Loss: 3.267037\n",
      "Validation loss decreased (3.47499 --> 3.26704).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.715270 \tValidation Loss: 3.112995\n",
      "Validation loss decreased (3.26704 --> 3.11300).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.422098 \tValidation Loss: 2.999719\n",
      "Validation loss decreased (3.11300 --> 2.99972).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.195782 \tValidation Loss: 2.915800\n",
      "Validation loss decreased (2.99972 --> 2.91580).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.016041 \tValidation Loss: 2.856215\n",
      "Validation loss decreased (2.91580 --> 2.85622).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.871208 \tValidation Loss: 2.818040\n",
      "Validation loss decreased (2.85622 --> 2.81804).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.752965 \tValidation Loss: 2.794028\n",
      "Validation loss decreased (2.81804 --> 2.79403).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.654875 \tValidation Loss: 2.784990\n",
      "Validation loss decreased (2.79403 --> 2.78499).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.578857 \tValidation Loss: 2.784873\n",
      "Validation loss decreased (2.78499 --> 2.78487).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.513033 \tValidation Loss: 2.792257\n",
      "Epoch: 17 \tTraining Loss: 0.463235 \tValidation Loss: 2.804685\n",
      "Epoch: 18 \tTraining Loss: 0.420683 \tValidation Loss: 2.822701\n",
      "Epoch: 19 \tTraining Loss: 0.385022 \tValidation Loss: 2.848592\n",
      "Epoch: 20 \tTraining Loss: 0.355566 \tValidation Loss: 2.874109\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 8 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.142732 \tValidation Loss: 5.609026\n",
      "Validation loss decreased (inf --> 5.60903).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.437869 \tValidation Loss: 5.256623\n",
      "Validation loss decreased (5.60903 --> 5.25662).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.820356 \tValidation Loss: 4.747014\n",
      "Validation loss decreased (5.25662 --> 4.74701).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.028648 \tValidation Loss: 4.237169\n",
      "Validation loss decreased (4.74701 --> 4.23717).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.263137 \tValidation Loss: 3.828771\n",
      "Validation loss decreased (4.23717 --> 3.82877).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.623865 \tValidation Loss: 3.530188\n",
      "Validation loss decreased (3.82877 --> 3.53019).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.116194 \tValidation Loss: 3.309974\n",
      "Validation loss decreased (3.53019 --> 3.30997).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.715713 \tValidation Loss: 3.145884\n",
      "Validation loss decreased (3.30997 --> 3.14588).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.401387 \tValidation Loss: 3.026174\n",
      "Validation loss decreased (3.14588 --> 3.02617).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.153430 \tValidation Loss: 2.937753\n",
      "Validation loss decreased (3.02617 --> 2.93775).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.961678 \tValidation Loss: 2.876709\n",
      "Validation loss decreased (2.93775 --> 2.87671).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.804578 \tValidation Loss: 2.838892\n",
      "Validation loss decreased (2.87671 --> 2.83889).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.678574 \tValidation Loss: 2.817452\n",
      "Validation loss decreased (2.83889 --> 2.81745).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.577765 \tValidation Loss: 2.806518\n",
      "Validation loss decreased (2.81745 --> 2.80652).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.499452 \tValidation Loss: 2.808731\n",
      "Epoch: 16 \tTraining Loss: 0.430673 \tValidation Loss: 2.820251\n",
      "Epoch: 17 \tTraining Loss: 0.381729 \tValidation Loss: 2.832852\n",
      "Epoch: 18 \tTraining Loss: 0.338567 \tValidation Loss: 2.851286\n",
      "Epoch: 19 \tTraining Loss: 0.303046 \tValidation Loss: 2.873089\n",
      "Epoch: 20 \tTraining Loss: 0.275868 \tValidation Loss: 2.898566\n",
      "Epoch: 1 \tTraining Loss: 6.147523 \tValidation Loss: 5.592741\n",
      "Validation loss decreased (inf --> 5.59274).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.428653 \tValidation Loss: 5.251990\n",
      "Validation loss decreased (5.59274 --> 5.25199).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.804052 \tValidation Loss: 4.774555\n",
      "Validation loss decreased (5.25199 --> 4.77455).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.014338 \tValidation Loss: 4.298184\n",
      "Validation loss decreased (4.77455 --> 4.29818).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.254358 \tValidation Loss: 3.909411\n",
      "Validation loss decreased (4.29818 --> 3.90941).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.617265 \tValidation Loss: 3.614833\n",
      "Validation loss decreased (3.90941 --> 3.61483).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.113010 \tValidation Loss: 3.393831\n",
      "Validation loss decreased (3.61483 --> 3.39383).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.716627 \tValidation Loss: 3.225744\n",
      "Validation loss decreased (3.39383 --> 3.22574).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.407567 \tValidation Loss: 3.103169\n",
      "Validation loss decreased (3.22574 --> 3.10317).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.160775 \tValidation Loss: 3.012443\n",
      "Validation loss decreased (3.10317 --> 3.01244).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 \tTraining Loss: 0.964050 \tValidation Loss: 2.944994\n",
      "Validation loss decreased (3.01244 --> 2.94499).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.805431 \tValidation Loss: 2.903977\n",
      "Validation loss decreased (2.94499 --> 2.90398).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.683547 \tValidation Loss: 2.880422\n",
      "Validation loss decreased (2.90398 --> 2.88042).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.580965 \tValidation Loss: 2.869082\n",
      "Validation loss decreased (2.88042 --> 2.86908).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.500596 \tValidation Loss: 2.872062\n",
      "Epoch: 16 \tTraining Loss: 0.437711 \tValidation Loss: 2.879496\n",
      "Epoch: 17 \tTraining Loss: 0.384323 \tValidation Loss: 2.895248\n",
      "Epoch: 18 \tTraining Loss: 0.343938 \tValidation Loss: 2.911325\n",
      "Epoch: 19 \tTraining Loss: 0.305821 \tValidation Loss: 2.932995\n",
      "Epoch: 20 \tTraining Loss: 0.280222 \tValidation Loss: 2.960161\n",
      "Epoch: 1 \tTraining Loss: 6.152416 \tValidation Loss: 5.610272\n",
      "Validation loss decreased (inf --> 5.61027).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.436315 \tValidation Loss: 5.274426\n",
      "Validation loss decreased (5.61027 --> 5.27443).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.816807 \tValidation Loss: 4.786660\n",
      "Validation loss decreased (5.27443 --> 4.78666).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.023435 \tValidation Loss: 4.291332\n",
      "Validation loss decreased (4.78666 --> 4.29133).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.255606 \tValidation Loss: 3.886558\n",
      "Validation loss decreased (4.29133 --> 3.88656).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.613195 \tValidation Loss: 3.577609\n",
      "Validation loss decreased (3.88656 --> 3.57761).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.107363 \tValidation Loss: 3.342571\n",
      "Validation loss decreased (3.57761 --> 3.34257).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.710241 \tValidation Loss: 3.164260\n",
      "Validation loss decreased (3.34257 --> 3.16426).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.400591 \tValidation Loss: 3.028639\n",
      "Validation loss decreased (3.16426 --> 3.02864).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.155968 \tValidation Loss: 2.929834\n",
      "Validation loss decreased (3.02864 --> 2.92983).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.962024 \tValidation Loss: 2.855767\n",
      "Validation loss decreased (2.92983 --> 2.85577).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.805683 \tValidation Loss: 2.805349\n",
      "Validation loss decreased (2.85577 --> 2.80535).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.677592 \tValidation Loss: 2.774407\n",
      "Validation loss decreased (2.80535 --> 2.77441).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.575448 \tValidation Loss: 2.756371\n",
      "Validation loss decreased (2.77441 --> 2.75637).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.498597 \tValidation Loss: 2.752037\n",
      "Validation loss decreased (2.75637 --> 2.75204).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.434090 \tValidation Loss: 2.748797\n",
      "Validation loss decreased (2.75204 --> 2.74880).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.382650 \tValidation Loss: 2.757242\n",
      "Epoch: 18 \tTraining Loss: 0.337675 \tValidation Loss: 2.772605\n",
      "Epoch: 19 \tTraining Loss: 0.303883 \tValidation Loss: 2.791056\n",
      "Epoch: 20 \tTraining Loss: 0.275842 \tValidation Loss: 2.810050\n",
      "Epoch: 1 \tTraining Loss: 6.147084 \tValidation Loss: 5.622272\n",
      "Validation loss decreased (inf --> 5.62227).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.435816 \tValidation Loss: 5.283868\n",
      "Validation loss decreased (5.62227 --> 5.28387).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.820144 \tValidation Loss: 4.787138\n",
      "Validation loss decreased (5.28387 --> 4.78714).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.029445 \tValidation Loss: 4.285453\n",
      "Validation loss decreased (4.78714 --> 4.28545).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.261129 \tValidation Loss: 3.886500\n",
      "Validation loss decreased (4.28545 --> 3.88650).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.621686 \tValidation Loss: 3.588072\n",
      "Validation loss decreased (3.88650 --> 3.58807).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.112567 \tValidation Loss: 3.364808\n",
      "Validation loss decreased (3.58807 --> 3.36481).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.719075 \tValidation Loss: 3.198498\n",
      "Validation loss decreased (3.36481 --> 3.19850).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.409712 \tValidation Loss: 3.071799\n",
      "Validation loss decreased (3.19850 --> 3.07180).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.162797 \tValidation Loss: 2.975275\n",
      "Validation loss decreased (3.07180 --> 2.97528).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.969026 \tValidation Loss: 2.907472\n",
      "Validation loss decreased (2.97528 --> 2.90747).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.811627 \tValidation Loss: 2.859605\n",
      "Validation loss decreased (2.90747 --> 2.85960).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.685841 \tValidation Loss: 2.825997\n",
      "Validation loss decreased (2.85960 --> 2.82600).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.583962 \tValidation Loss: 2.809748\n",
      "Validation loss decreased (2.82600 --> 2.80975).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.503772 \tValidation Loss: 2.803096\n",
      "Validation loss decreased (2.80975 --> 2.80310).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.438726 \tValidation Loss: 2.805326\n",
      "Epoch: 17 \tTraining Loss: 0.384872 \tValidation Loss: 2.811349\n",
      "Epoch: 18 \tTraining Loss: 0.341051 \tValidation Loss: 2.826411\n",
      "Epoch: 19 \tTraining Loss: 0.306951 \tValidation Loss: 2.846651\n",
      "Epoch: 20 \tTraining Loss: 0.278377 \tValidation Loss: 2.861124\n",
      "Epoch: 1 \tTraining Loss: 6.146496 \tValidation Loss: 5.584918\n",
      "Validation loss decreased (inf --> 5.58492).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.433243 \tValidation Loss: 5.235825\n",
      "Validation loss decreased (5.58492 --> 5.23582).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.810245 \tValidation Loss: 4.744684\n",
      "Validation loss decreased (5.23582 --> 4.74468).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.018176 \tValidation Loss: 4.263128\n",
      "Validation loss decreased (4.74468 --> 4.26313).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.250563 \tValidation Loss: 3.879527\n",
      "Validation loss decreased (4.26313 --> 3.87953).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.612227 \tValidation Loss: 3.600118\n",
      "Validation loss decreased (3.87953 --> 3.60012).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.104792 \tValidation Loss: 3.397068\n",
      "Validation loss decreased (3.60012 --> 3.39707).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.709037 \tValidation Loss: 3.243910\n",
      "Validation loss decreased (3.39707 --> 3.24391).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.398263 \tValidation Loss: 3.129562\n",
      "Validation loss decreased (3.24391 --> 3.12956).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.151605 \tValidation Loss: 3.046128\n",
      "Validation loss decreased (3.12956 --> 3.04613).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.957880 \tValidation Loss: 2.991065\n",
      "Validation loss decreased (3.04613 --> 2.99107).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.799772 \tValidation Loss: 2.954172\n",
      "Validation loss decreased (2.99107 --> 2.95417).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.676692 \tValidation Loss: 2.934657\n",
      "Validation loss decreased (2.95417 --> 2.93466).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.578023 \tValidation Loss: 2.926837\n",
      "Validation loss decreased (2.93466 --> 2.92684).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.495512 \tValidation Loss: 2.928960\n",
      "Epoch: 16 \tTraining Loss: 0.432247 \tValidation Loss: 2.937486\n",
      "Epoch: 17 \tTraining Loss: 0.382360 \tValidation Loss: 2.954630\n",
      "Epoch: 18 \tTraining Loss: 0.336998 \tValidation Loss: 2.978124\n",
      "Epoch: 19 \tTraining Loss: 0.303330 \tValidation Loss: 3.001251\n",
      "Epoch: 20 \tTraining Loss: 0.275772 \tValidation Loss: 3.028931\n",
      "Epoch: 1 \tTraining Loss: 6.148677 \tValidation Loss: 5.599183\n",
      "Validation loss decreased (inf --> 5.59918).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.441026 \tValidation Loss: 5.243274\n",
      "Validation loss decreased (5.59918 --> 5.24327).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.823181 \tValidation Loss: 4.741108\n",
      "Validation loss decreased (5.24327 --> 4.74111).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.030848 \tValidation Loss: 4.247912\n",
      "Validation loss decreased (4.74111 --> 4.24791).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.261132 \tValidation Loss: 3.851526\n",
      "Validation loss decreased (4.24791 --> 3.85153).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 \tTraining Loss: 2.622125 \tValidation Loss: 3.546317\n",
      "Validation loss decreased (3.85153 --> 3.54632).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.114988 \tValidation Loss: 3.316537\n",
      "Validation loss decreased (3.54632 --> 3.31654).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.718878 \tValidation Loss: 3.145214\n",
      "Validation loss decreased (3.31654 --> 3.14521).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.407779 \tValidation Loss: 3.017771\n",
      "Validation loss decreased (3.14521 --> 3.01777).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.161170 \tValidation Loss: 2.924291\n",
      "Validation loss decreased (3.01777 --> 2.92429).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.965531 \tValidation Loss: 2.858367\n",
      "Validation loss decreased (2.92429 --> 2.85837).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.811813 \tValidation Loss: 2.812559\n",
      "Validation loss decreased (2.85837 --> 2.81256).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.685920 \tValidation Loss: 2.783931\n",
      "Validation loss decreased (2.81256 --> 2.78393).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.586126 \tValidation Loss: 2.766753\n",
      "Validation loss decreased (2.78393 --> 2.76675).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.504590 \tValidation Loss: 2.765235\n",
      "Validation loss decreased (2.76675 --> 2.76523).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.440573 \tValidation Loss: 2.773173\n",
      "Epoch: 17 \tTraining Loss: 0.387737 \tValidation Loss: 2.782509\n",
      "Epoch: 18 \tTraining Loss: 0.342761 \tValidation Loss: 2.799152\n",
      "Epoch: 19 \tTraining Loss: 0.308154 \tValidation Loss: 2.819602\n",
      "Epoch: 20 \tTraining Loss: 0.279532 \tValidation Loss: 2.843494\n",
      "Epoch: 1 \tTraining Loss: 6.156352 \tValidation Loss: 5.594583\n",
      "Validation loss decreased (inf --> 5.59458).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.434771 \tValidation Loss: 5.253372\n",
      "Validation loss decreased (5.59458 --> 5.25337).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.807886 \tValidation Loss: 4.760966\n",
      "Validation loss decreased (5.25337 --> 4.76097).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.004428 \tValidation Loss: 4.285981\n",
      "Validation loss decreased (4.76097 --> 4.28598).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.238235 \tValidation Loss: 3.917261\n",
      "Validation loss decreased (4.28598 --> 3.91726).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.600387 \tValidation Loss: 3.639495\n",
      "Validation loss decreased (3.91726 --> 3.63949).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.100003 \tValidation Loss: 3.432862\n",
      "Validation loss decreased (3.63949 --> 3.43286).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.706069 \tValidation Loss: 3.277030\n",
      "Validation loss decreased (3.43286 --> 3.27703).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.395872 \tValidation Loss: 3.161436\n",
      "Validation loss decreased (3.27703 --> 3.16144).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.153049 \tValidation Loss: 3.077903\n",
      "Validation loss decreased (3.16144 --> 3.07790).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.959231 \tValidation Loss: 3.021850\n",
      "Validation loss decreased (3.07790 --> 3.02185).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.803148 \tValidation Loss: 2.986838\n",
      "Validation loss decreased (3.02185 --> 2.98684).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.680762 \tValidation Loss: 2.968536\n",
      "Validation loss decreased (2.98684 --> 2.96854).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.579074 \tValidation Loss: 2.964201\n",
      "Validation loss decreased (2.96854 --> 2.96420).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.499530 \tValidation Loss: 2.968044\n",
      "Epoch: 16 \tTraining Loss: 0.435767 \tValidation Loss: 2.980440\n",
      "Epoch: 17 \tTraining Loss: 0.383105 \tValidation Loss: 3.001039\n",
      "Epoch: 18 \tTraining Loss: 0.340809 \tValidation Loss: 3.024088\n",
      "Epoch: 19 \tTraining Loss: 0.305255 \tValidation Loss: 3.045485\n",
      "Epoch: 20 \tTraining Loss: 0.276794 \tValidation Loss: 3.074569\n",
      "Epoch: 1 \tTraining Loss: 6.138226 \tValidation Loss: 5.601109\n",
      "Validation loss decreased (inf --> 5.60111).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.445397 \tValidation Loss: 5.260440\n",
      "Validation loss decreased (5.60111 --> 5.26044).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.837939 \tValidation Loss: 4.768647\n",
      "Validation loss decreased (5.26044 --> 4.76865).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.047981 \tValidation Loss: 4.275357\n",
      "Validation loss decreased (4.76865 --> 4.27536).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.277514 \tValidation Loss: 3.879761\n",
      "Validation loss decreased (4.27536 --> 3.87976).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.628038 \tValidation Loss: 3.585567\n",
      "Validation loss decreased (3.87976 --> 3.58557).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.112176 \tValidation Loss: 3.371021\n",
      "Validation loss decreased (3.58557 --> 3.37102).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.714461 \tValidation Loss: 3.211835\n",
      "Validation loss decreased (3.37102 --> 3.21184).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.397212 \tValidation Loss: 3.095047\n",
      "Validation loss decreased (3.21184 --> 3.09505).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.151439 \tValidation Loss: 3.011828\n",
      "Validation loss decreased (3.09505 --> 3.01183).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.954546 \tValidation Loss: 2.955985\n",
      "Validation loss decreased (3.01183 --> 2.95599).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.798696 \tValidation Loss: 2.920534\n",
      "Validation loss decreased (2.95599 --> 2.92053).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.674224 \tValidation Loss: 2.902027\n",
      "Validation loss decreased (2.92053 --> 2.90203).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.574997 \tValidation Loss: 2.893555\n",
      "Validation loss decreased (2.90203 --> 2.89356).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.495265 \tValidation Loss: 2.898141\n",
      "Epoch: 16 \tTraining Loss: 0.429552 \tValidation Loss: 2.910144\n",
      "Epoch: 17 \tTraining Loss: 0.375733 \tValidation Loss: 2.927714\n",
      "Epoch: 18 \tTraining Loss: 0.337705 \tValidation Loss: 2.951363\n",
      "Epoch: 19 \tTraining Loss: 0.302505 \tValidation Loss: 2.978172\n",
      "Epoch: 20 \tTraining Loss: 0.274392 \tValidation Loss: 3.005465\n",
      "Epoch: 1 \tTraining Loss: 6.140846 \tValidation Loss: 5.605608\n",
      "Validation loss decreased (inf --> 5.60561).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.427495 \tValidation Loss: 5.253767\n",
      "Validation loss decreased (5.60561 --> 5.25377).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.807381 \tValidation Loss: 4.750052\n",
      "Validation loss decreased (5.25377 --> 4.75005).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.015104 \tValidation Loss: 4.259781\n",
      "Validation loss decreased (4.75005 --> 4.25978).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.249854 \tValidation Loss: 3.869862\n",
      "Validation loss decreased (4.25978 --> 3.86986).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.612962 \tValidation Loss: 3.575115\n",
      "Validation loss decreased (3.86986 --> 3.57512).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.110713 \tValidation Loss: 3.357236\n",
      "Validation loss decreased (3.57512 --> 3.35724).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.714808 \tValidation Loss: 3.192447\n",
      "Validation loss decreased (3.35724 --> 3.19245).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.405377 \tValidation Loss: 3.069747\n",
      "Validation loss decreased (3.19245 --> 3.06975).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.160614 \tValidation Loss: 2.981427\n",
      "Validation loss decreased (3.06975 --> 2.98143).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.964057 \tValidation Loss: 2.919467\n",
      "Validation loss decreased (2.98143 --> 2.91947).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.808445 \tValidation Loss: 2.878403\n",
      "Validation loss decreased (2.91947 --> 2.87840).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.680409 \tValidation Loss: 2.856460\n",
      "Validation loss decreased (2.87840 --> 2.85646).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.581818 \tValidation Loss: 2.845363\n",
      "Validation loss decreased (2.85646 --> 2.84536).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.501486 \tValidation Loss: 2.843185\n",
      "Validation loss decreased (2.84536 --> 2.84318).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.433818 \tValidation Loss: 2.850855\n",
      "Epoch: 17 \tTraining Loss: 0.380591 \tValidation Loss: 2.864599\n",
      "Epoch: 18 \tTraining Loss: 0.338925 \tValidation Loss: 2.882973\n",
      "Epoch: 19 \tTraining Loss: 0.306034 \tValidation Loss: 2.907040\n",
      "Epoch: 20 \tTraining Loss: 0.276317 \tValidation Loss: 2.931163\n",
      "Epoch: 1 \tTraining Loss: 6.145986 \tValidation Loss: 5.626370\n",
      "Validation loss decreased (inf --> 5.62637).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 5.430235 \tValidation Loss: 5.276207\n",
      "Validation loss decreased (5.62637 --> 5.27621).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.813387 \tValidation Loss: 4.779381\n",
      "Validation loss decreased (5.27621 --> 4.77938).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.022464 \tValidation Loss: 4.278881\n",
      "Validation loss decreased (4.77938 --> 4.27888).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.258858 \tValidation Loss: 3.871483\n",
      "Validation loss decreased (4.27888 --> 3.87148).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.623918 \tValidation Loss: 3.561490\n",
      "Validation loss decreased (3.87148 --> 3.56149).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.118702 \tValidation Loss: 3.330317\n",
      "Validation loss decreased (3.56149 --> 3.33032).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.719970 \tValidation Loss: 3.159552\n",
      "Validation loss decreased (3.33032 --> 3.15955).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.410415 \tValidation Loss: 3.036031\n",
      "Validation loss decreased (3.15955 --> 3.03603).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.162071 \tValidation Loss: 2.946556\n",
      "Validation loss decreased (3.03603 --> 2.94656).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.963103 \tValidation Loss: 2.885709\n",
      "Validation loss decreased (2.94656 --> 2.88571).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.809024 \tValidation Loss: 2.847829\n",
      "Validation loss decreased (2.88571 --> 2.84783).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.683839 \tValidation Loss: 2.824541\n",
      "Validation loss decreased (2.84783 --> 2.82454).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.581598 \tValidation Loss: 2.813868\n",
      "Validation loss decreased (2.82454 --> 2.81387).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.500180 \tValidation Loss: 2.812891\n",
      "Validation loss decreased (2.81387 --> 2.81289).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.435360 \tValidation Loss: 2.823148\n",
      "Epoch: 17 \tTraining Loss: 0.382582 \tValidation Loss: 2.843483\n",
      "Epoch: 18 \tTraining Loss: 0.339453 \tValidation Loss: 2.861025\n",
      "Epoch: 19 \tTraining Loss: 0.305977 \tValidation Loss: 2.883724\n",
      "Epoch: 20 \tTraining Loss: 0.273003 \tValidation Loss: 2.908396\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 9 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.178929 \tValidation Loss: 4.814982\n",
      "Validation loss decreased (inf --> 4.81498).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.449646 \tValidation Loss: 4.544002\n",
      "Validation loss decreased (4.81498 --> 4.54400).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.892593 \tValidation Loss: 4.150436\n",
      "Validation loss decreased (4.54400 --> 4.15044).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.143627 \tValidation Loss: 3.738691\n",
      "Validation loss decreased (4.15044 --> 3.73869).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.388931 \tValidation Loss: 3.397095\n",
      "Validation loss decreased (3.73869 --> 3.39710).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.739337 \tValidation Loss: 3.135893\n",
      "Validation loss decreased (3.39710 --> 3.13589).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.213380 \tValidation Loss: 2.938545\n",
      "Validation loss decreased (3.13589 --> 2.93854).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.793676 \tValidation Loss: 2.790542\n",
      "Validation loss decreased (2.93854 --> 2.79054).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.460769 \tValidation Loss: 2.678866\n",
      "Validation loss decreased (2.79054 --> 2.67887).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.192044 \tValidation Loss: 2.596057\n",
      "Validation loss decreased (2.67887 --> 2.59606).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.979430 \tValidation Loss: 2.534287\n",
      "Validation loss decreased (2.59606 --> 2.53429).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.809063 \tValidation Loss: 2.491051\n",
      "Validation loss decreased (2.53429 --> 2.49105).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.673031 \tValidation Loss: 2.462924\n",
      "Validation loss decreased (2.49105 --> 2.46292).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.564316 \tValidation Loss: 2.449576\n",
      "Validation loss decreased (2.46292 --> 2.44958).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.472121 \tValidation Loss: 2.442625\n",
      "Validation loss decreased (2.44958 --> 2.44262).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.404232 \tValidation Loss: 2.444538\n",
      "Epoch: 17 \tTraining Loss: 0.345107 \tValidation Loss: 2.454840\n",
      "Epoch: 18 \tTraining Loss: 0.302766 \tValidation Loss: 2.468175\n",
      "Epoch: 19 \tTraining Loss: 0.264424 \tValidation Loss: 2.484025\n",
      "Epoch: 20 \tTraining Loss: 0.237446 \tValidation Loss: 2.499534\n",
      "Epoch: 1 \tTraining Loss: 6.186372 \tValidation Loss: 4.832149\n",
      "Validation loss decreased (inf --> 4.83215).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.452694 \tValidation Loss: 4.560964\n",
      "Validation loss decreased (4.83215 --> 4.56096).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.891619 \tValidation Loss: 4.165013\n",
      "Validation loss decreased (4.56096 --> 4.16501).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.138805 \tValidation Loss: 3.751924\n",
      "Validation loss decreased (4.16501 --> 3.75192).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.380994 \tValidation Loss: 3.405736\n",
      "Validation loss decreased (3.75192 --> 3.40574).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.725770 \tValidation Loss: 3.138569\n",
      "Validation loss decreased (3.40574 --> 3.13857).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.196371 \tValidation Loss: 2.935839\n",
      "Validation loss decreased (3.13857 --> 2.93584).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.775728 \tValidation Loss: 2.782548\n",
      "Validation loss decreased (2.93584 --> 2.78255).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.442876 \tValidation Loss: 2.663849\n",
      "Validation loss decreased (2.78255 --> 2.66385).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.179622 \tValidation Loss: 2.574294\n",
      "Validation loss decreased (2.66385 --> 2.57429).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.964907 \tValidation Loss: 2.510726\n",
      "Validation loss decreased (2.57429 --> 2.51073).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.795286 \tValidation Loss: 2.468148\n",
      "Validation loss decreased (2.51073 --> 2.46815).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.657079 \tValidation Loss: 2.440467\n",
      "Validation loss decreased (2.46815 --> 2.44047).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.550196 \tValidation Loss: 2.425158\n",
      "Validation loss decreased (2.44047 --> 2.42516).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.462984 \tValidation Loss: 2.421067\n",
      "Validation loss decreased (2.42516 --> 2.42107).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.392115 \tValidation Loss: 2.425489\n",
      "Epoch: 17 \tTraining Loss: 0.338242 \tValidation Loss: 2.434930\n",
      "Epoch: 18 \tTraining Loss: 0.295023 \tValidation Loss: 2.447872\n",
      "Epoch: 19 \tTraining Loss: 0.262482 \tValidation Loss: 2.463494\n",
      "Epoch: 20 \tTraining Loss: 0.231820 \tValidation Loss: 2.482054\n",
      "Epoch: 1 \tTraining Loss: 6.179920 \tValidation Loss: 4.864552\n",
      "Validation loss decreased (inf --> 4.86455).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.442418 \tValidation Loss: 4.592179\n",
      "Validation loss decreased (4.86455 --> 4.59218).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.881667 \tValidation Loss: 4.204140\n",
      "Validation loss decreased (4.59218 --> 4.20414).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.131694 \tValidation Loss: 3.789684\n",
      "Validation loss decreased (4.20414 --> 3.78968).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.379961 \tValidation Loss: 3.443193\n",
      "Validation loss decreased (3.78968 --> 3.44319).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.736681 \tValidation Loss: 3.173554\n",
      "Validation loss decreased (3.44319 --> 3.17355).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.209239 \tValidation Loss: 2.970882\n",
      "Validation loss decreased (3.17355 --> 2.97088).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.790555 \tValidation Loss: 2.820264\n",
      "Validation loss decreased (2.97088 --> 2.82026).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.457066 \tValidation Loss: 2.708507\n",
      "Validation loss decreased (2.82026 --> 2.70851).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.189395 \tValidation Loss: 2.625867\n",
      "Validation loss decreased (2.70851 --> 2.62587).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.977528 \tValidation Loss: 2.564205\n",
      "Validation loss decreased (2.62587 --> 2.56421).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.805967 \tValidation Loss: 2.522413\n",
      "Validation loss decreased (2.56421 --> 2.52241).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.668896 \tValidation Loss: 2.497988\n",
      "Validation loss decreased (2.52241 --> 2.49799).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 \tTraining Loss: 0.561496 \tValidation Loss: 2.482715\n",
      "Validation loss decreased (2.49799 --> 2.48271).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.469067 \tValidation Loss: 2.482698\n",
      "Validation loss decreased (2.48271 --> 2.48270).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.401183 \tValidation Loss: 2.489437\n",
      "Epoch: 17 \tTraining Loss: 0.347957 \tValidation Loss: 2.502076\n",
      "Epoch: 18 \tTraining Loss: 0.300487 \tValidation Loss: 2.519200\n",
      "Epoch: 19 \tTraining Loss: 0.267036 \tValidation Loss: 2.536456\n",
      "Epoch: 20 \tTraining Loss: 0.236250 \tValidation Loss: 2.553132\n",
      "Epoch: 1 \tTraining Loss: 6.187463 \tValidation Loss: 4.829463\n",
      "Validation loss decreased (inf --> 4.82946).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.447277 \tValidation Loss: 4.565678\n",
      "Validation loss decreased (4.82946 --> 4.56568).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.882883 \tValidation Loss: 4.183085\n",
      "Validation loss decreased (4.56568 --> 4.18309).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.133004 \tValidation Loss: 3.778516\n",
      "Validation loss decreased (4.18309 --> 3.77852).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.381806 \tValidation Loss: 3.434503\n",
      "Validation loss decreased (3.77852 --> 3.43450).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.734643 \tValidation Loss: 3.166608\n",
      "Validation loss decreased (3.43450 --> 3.16661).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.210326 \tValidation Loss: 2.960849\n",
      "Validation loss decreased (3.16661 --> 2.96085).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.790930 \tValidation Loss: 2.801363\n",
      "Validation loss decreased (2.96085 --> 2.80136).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.458436 \tValidation Loss: 2.681133\n",
      "Validation loss decreased (2.80136 --> 2.68113).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.190093 \tValidation Loss: 2.589418\n",
      "Validation loss decreased (2.68113 --> 2.58942).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.974613 \tValidation Loss: 2.521574\n",
      "Validation loss decreased (2.58942 --> 2.52157).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.804131 \tValidation Loss: 2.474377\n",
      "Validation loss decreased (2.52157 --> 2.47438).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.666972 \tValidation Loss: 2.442478\n",
      "Validation loss decreased (2.47438 --> 2.44248).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.556233 \tValidation Loss: 2.425002\n",
      "Validation loss decreased (2.44248 --> 2.42500).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.466318 \tValidation Loss: 2.415982\n",
      "Validation loss decreased (2.42500 --> 2.41598).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.398475 \tValidation Loss: 2.418550\n",
      "Epoch: 17 \tTraining Loss: 0.342980 \tValidation Loss: 2.425526\n",
      "Epoch: 18 \tTraining Loss: 0.299008 \tValidation Loss: 2.439437\n",
      "Epoch: 19 \tTraining Loss: 0.262461 \tValidation Loss: 2.454222\n",
      "Epoch: 20 \tTraining Loss: 0.234369 \tValidation Loss: 2.469904\n",
      "Epoch: 1 \tTraining Loss: 6.180179 \tValidation Loss: 4.859306\n",
      "Validation loss decreased (inf --> 4.85931).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.445445 \tValidation Loss: 4.593042\n",
      "Validation loss decreased (4.85931 --> 4.59304).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.887795 \tValidation Loss: 4.213097\n",
      "Validation loss decreased (4.59304 --> 4.21310).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.135693 \tValidation Loss: 3.808883\n",
      "Validation loss decreased (4.21310 --> 3.80888).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.374742 \tValidation Loss: 3.466524\n",
      "Validation loss decreased (3.80888 --> 3.46652).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.725342 \tValidation Loss: 3.201477\n",
      "Validation loss decreased (3.46652 --> 3.20148).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.197495 \tValidation Loss: 2.996636\n",
      "Validation loss decreased (3.20148 --> 2.99664).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.781968 \tValidation Loss: 2.841720\n",
      "Validation loss decreased (2.99664 --> 2.84172).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.446764 \tValidation Loss: 2.725447\n",
      "Validation loss decreased (2.84172 --> 2.72545).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.180367 \tValidation Loss: 2.636665\n",
      "Validation loss decreased (2.72545 --> 2.63666).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.971837 \tValidation Loss: 2.573662\n",
      "Validation loss decreased (2.63666 --> 2.57366).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.796362 \tValidation Loss: 2.530532\n",
      "Validation loss decreased (2.57366 --> 2.53053).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.661061 \tValidation Loss: 2.500447\n",
      "Validation loss decreased (2.53053 --> 2.50045).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.552641 \tValidation Loss: 2.487657\n",
      "Validation loss decreased (2.50045 --> 2.48766).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.462657 \tValidation Loss: 2.481205\n",
      "Validation loss decreased (2.48766 --> 2.48120).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.394263 \tValidation Loss: 2.484423\n",
      "Epoch: 17 \tTraining Loss: 0.339750 \tValidation Loss: 2.491367\n",
      "Epoch: 18 \tTraining Loss: 0.297017 \tValidation Loss: 2.505008\n",
      "Epoch: 19 \tTraining Loss: 0.259010 \tValidation Loss: 2.524463\n",
      "Epoch: 20 \tTraining Loss: 0.230832 \tValidation Loss: 2.543050\n",
      "Epoch: 1 \tTraining Loss: 6.179866 \tValidation Loss: 4.859016\n",
      "Validation loss decreased (inf --> 4.85902).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.445038 \tValidation Loss: 4.586311\n",
      "Validation loss decreased (4.85902 --> 4.58631).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.877412 \tValidation Loss: 4.199838\n",
      "Validation loss decreased (4.58631 --> 4.19984).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.118540 \tValidation Loss: 3.789241\n",
      "Validation loss decreased (4.19984 --> 3.78924).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.359278 \tValidation Loss: 3.450683\n",
      "Validation loss decreased (3.78924 --> 3.45068).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.713312 \tValidation Loss: 3.192926\n",
      "Validation loss decreased (3.45068 --> 3.19293).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.187494 \tValidation Loss: 2.999623\n",
      "Validation loss decreased (3.19293 --> 2.99962).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.769129 \tValidation Loss: 2.856541\n",
      "Validation loss decreased (2.99962 --> 2.85654).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.439492 \tValidation Loss: 2.747389\n",
      "Validation loss decreased (2.85654 --> 2.74739).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.180171 \tValidation Loss: 2.664877\n",
      "Validation loss decreased (2.74739 --> 2.66488).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.968592 \tValidation Loss: 2.603749\n",
      "Validation loss decreased (2.66488 --> 2.60375).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.798358 \tValidation Loss: 2.562580\n",
      "Validation loss decreased (2.60375 --> 2.56258).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.663240 \tValidation Loss: 2.537383\n",
      "Validation loss decreased (2.56258 --> 2.53738).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.556509 \tValidation Loss: 2.525292\n",
      "Validation loss decreased (2.53738 --> 2.52529).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.468815 \tValidation Loss: 2.523181\n",
      "Validation loss decreased (2.52529 --> 2.52318).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.398327 \tValidation Loss: 2.528885\n",
      "Epoch: 17 \tTraining Loss: 0.342039 \tValidation Loss: 2.539816\n",
      "Epoch: 18 \tTraining Loss: 0.300366 \tValidation Loss: 2.550638\n",
      "Epoch: 19 \tTraining Loss: 0.265100 \tValidation Loss: 2.567952\n",
      "Epoch: 20 \tTraining Loss: 0.236415 \tValidation Loss: 2.587230\n",
      "Epoch: 1 \tTraining Loss: 6.183126 \tValidation Loss: 4.847335\n",
      "Validation loss decreased (inf --> 4.84734).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.442602 \tValidation Loss: 4.579864\n",
      "Validation loss decreased (4.84734 --> 4.57986).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.880395 \tValidation Loss: 4.192959\n",
      "Validation loss decreased (4.57986 --> 4.19296).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.125447 \tValidation Loss: 3.788923\n",
      "Validation loss decreased (4.19296 --> 3.78892).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.371959 \tValidation Loss: 3.455303\n",
      "Validation loss decreased (3.78892 --> 3.45530).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.722388 \tValidation Loss: 3.197046\n",
      "Validation loss decreased (3.45530 --> 3.19705).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.197956 \tValidation Loss: 2.996593\n",
      "Validation loss decreased (3.19705 --> 2.99659).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.778731 \tValidation Loss: 2.842283\n",
      "Validation loss decreased (2.99659 --> 2.84228).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 \tTraining Loss: 1.446199 \tValidation Loss: 2.725858\n",
      "Validation loss decreased (2.84228 --> 2.72586).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.182351 \tValidation Loss: 2.639364\n",
      "Validation loss decreased (2.72586 --> 2.63936).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.970769 \tValidation Loss: 2.575187\n",
      "Validation loss decreased (2.63936 --> 2.57519).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.801657 \tValidation Loss: 2.532359\n",
      "Validation loss decreased (2.57519 --> 2.53236).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.662511 \tValidation Loss: 2.503042\n",
      "Validation loss decreased (2.53236 --> 2.50304).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.553125 \tValidation Loss: 2.491697\n",
      "Validation loss decreased (2.50304 --> 2.49170).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.466745 \tValidation Loss: 2.491449\n",
      "Validation loss decreased (2.49170 --> 2.49145).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.398446 \tValidation Loss: 2.495556\n",
      "Epoch: 17 \tTraining Loss: 0.342432 \tValidation Loss: 2.509703\n",
      "Epoch: 18 \tTraining Loss: 0.299999 \tValidation Loss: 2.526817\n",
      "Epoch: 19 \tTraining Loss: 0.261555 \tValidation Loss: 2.542782\n",
      "Epoch: 20 \tTraining Loss: 0.231508 \tValidation Loss: 2.563829\n",
      "Epoch: 1 \tTraining Loss: 6.184424 \tValidation Loss: 4.837653\n",
      "Validation loss decreased (inf --> 4.83765).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.454042 \tValidation Loss: 4.580071\n",
      "Validation loss decreased (4.83765 --> 4.58007).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.898923 \tValidation Loss: 4.203883\n",
      "Validation loss decreased (4.58007 --> 4.20388).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.153991 \tValidation Loss: 3.798002\n",
      "Validation loss decreased (4.20388 --> 3.79800).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.393239 \tValidation Loss: 3.462842\n",
      "Validation loss decreased (3.79800 --> 3.46284).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.739946 \tValidation Loss: 3.204821\n",
      "Validation loss decreased (3.46284 --> 3.20482).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.214154 \tValidation Loss: 3.004063\n",
      "Validation loss decreased (3.20482 --> 3.00406).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.792671 \tValidation Loss: 2.848161\n",
      "Validation loss decreased (3.00406 --> 2.84816).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.459125 \tValidation Loss: 2.724244\n",
      "Validation loss decreased (2.84816 --> 2.72424).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.190008 \tValidation Loss: 2.632580\n",
      "Validation loss decreased (2.72424 --> 2.63258).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.977763 \tValidation Loss: 2.563630\n",
      "Validation loss decreased (2.63258 --> 2.56363).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.806753 \tValidation Loss: 2.515437\n",
      "Validation loss decreased (2.56363 --> 2.51544).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.668032 \tValidation Loss: 2.483218\n",
      "Validation loss decreased (2.51544 --> 2.48322).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.559812 \tValidation Loss: 2.466178\n",
      "Validation loss decreased (2.48322 --> 2.46618).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.472598 \tValidation Loss: 2.461773\n",
      "Validation loss decreased (2.46618 --> 2.46177).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.401307 \tValidation Loss: 2.469090\n",
      "Epoch: 17 \tTraining Loss: 0.345253 \tValidation Loss: 2.475920\n",
      "Epoch: 18 \tTraining Loss: 0.299534 \tValidation Loss: 2.491911\n",
      "Epoch: 19 \tTraining Loss: 0.266463 \tValidation Loss: 2.507896\n",
      "Epoch: 20 \tTraining Loss: 0.233355 \tValidation Loss: 2.527836\n",
      "Epoch: 1 \tTraining Loss: 6.183710 \tValidation Loss: 4.870571\n",
      "Validation loss decreased (inf --> 4.87057).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.447690 \tValidation Loss: 4.602747\n",
      "Validation loss decreased (4.87057 --> 4.60275).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.889138 \tValidation Loss: 4.220519\n",
      "Validation loss decreased (4.60275 --> 4.22052).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.134382 \tValidation Loss: 3.816980\n",
      "Validation loss decreased (4.22052 --> 3.81698).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.375122 \tValidation Loss: 3.484790\n",
      "Validation loss decreased (3.81698 --> 3.48479).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.728709 \tValidation Loss: 3.226433\n",
      "Validation loss decreased (3.48479 --> 3.22643).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.203285 \tValidation Loss: 3.027168\n",
      "Validation loss decreased (3.22643 --> 3.02717).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.784232 \tValidation Loss: 2.874479\n",
      "Validation loss decreased (3.02717 --> 2.87448).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.447591 \tValidation Loss: 2.758889\n",
      "Validation loss decreased (2.87448 --> 2.75889).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.184949 \tValidation Loss: 2.670522\n",
      "Validation loss decreased (2.75889 --> 2.67052).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.973831 \tValidation Loss: 2.605928\n",
      "Validation loss decreased (2.67052 --> 2.60593).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.802688 \tValidation Loss: 2.560753\n",
      "Validation loss decreased (2.60593 --> 2.56075).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.662167 \tValidation Loss: 2.531925\n",
      "Validation loss decreased (2.56075 --> 2.53193).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.553765 \tValidation Loss: 2.513547\n",
      "Validation loss decreased (2.53193 --> 2.51355).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.465800 \tValidation Loss: 2.505310\n",
      "Validation loss decreased (2.51355 --> 2.50531).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.396430 \tValidation Loss: 2.507513\n",
      "Epoch: 17 \tTraining Loss: 0.342070 \tValidation Loss: 2.515340\n",
      "Epoch: 18 \tTraining Loss: 0.296427 \tValidation Loss: 2.530068\n",
      "Epoch: 19 \tTraining Loss: 0.260360 \tValidation Loss: 2.545679\n",
      "Epoch: 20 \tTraining Loss: 0.231516 \tValidation Loss: 2.562986\n",
      "Epoch: 1 \tTraining Loss: 6.181319 \tValidation Loss: 4.897510\n",
      "Validation loss decreased (inf --> 4.89751).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.446005 \tValidation Loss: 4.622895\n",
      "Validation loss decreased (4.89751 --> 4.62289).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.885339 \tValidation Loss: 4.237395\n",
      "Validation loss decreased (4.62289 --> 4.23739).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.133864 \tValidation Loss: 3.831292\n",
      "Validation loss decreased (4.23739 --> 3.83129).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.377587 \tValidation Loss: 3.490352\n",
      "Validation loss decreased (3.83129 --> 3.49035).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.726548 \tValidation Loss: 3.222122\n",
      "Validation loss decreased (3.49035 --> 3.22212).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.199507 \tValidation Loss: 3.018845\n",
      "Validation loss decreased (3.22212 --> 3.01885).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.785827 \tValidation Loss: 2.862610\n",
      "Validation loss decreased (3.01885 --> 2.86261).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.451209 \tValidation Loss: 2.743024\n",
      "Validation loss decreased (2.86261 --> 2.74302).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.184424 \tValidation Loss: 2.652586\n",
      "Validation loss decreased (2.74302 --> 2.65259).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.971788 \tValidation Loss: 2.587159\n",
      "Validation loss decreased (2.65259 --> 2.58716).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.805718 \tValidation Loss: 2.541126\n",
      "Validation loss decreased (2.58716 --> 2.54113).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.663576 \tValidation Loss: 2.512233\n",
      "Validation loss decreased (2.54113 --> 2.51223).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.553943 \tValidation Loss: 2.493624\n",
      "Validation loss decreased (2.51223 --> 2.49362).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.466720 \tValidation Loss: 2.489303\n",
      "Validation loss decreased (2.49362 --> 2.48930).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.399538 \tValidation Loss: 2.492477\n",
      "Epoch: 17 \tTraining Loss: 0.341670 \tValidation Loss: 2.502477\n",
      "Epoch: 18 \tTraining Loss: 0.298831 \tValidation Loss: 2.511817\n",
      "Epoch: 19 \tTraining Loss: 0.262582 \tValidation Loss: 2.527768\n",
      "Epoch: 20 \tTraining Loss: 0.236113 \tValidation Loss: 2.546085\n",
      "\n",
      " Starting:...-> Lemmatize = True , window = 10 \n",
      "\n",
      "Epoch: 1 \tTraining Loss: 6.232822 \tValidation Loss: 4.732295\n",
      "Validation loss decreased (inf --> 4.73229).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.457425 \tValidation Loss: 4.502142\n",
      "Validation loss decreased (4.73229 --> 4.50214).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \tTraining Loss: 4.962950 \tValidation Loss: 4.178586\n",
      "Validation loss decreased (4.50214 --> 4.17859).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.281577 \tValidation Loss: 3.815284\n",
      "Validation loss decreased (4.17859 --> 3.81528).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.548902 \tValidation Loss: 3.497262\n",
      "Validation loss decreased (3.81528 --> 3.49726).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.897877 \tValidation Loss: 3.246430\n",
      "Validation loss decreased (3.49726 --> 3.24643).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.352849 \tValidation Loss: 3.054950\n",
      "Validation loss decreased (3.24643 --> 3.05495).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.914883 \tValidation Loss: 2.911262\n",
      "Validation loss decreased (3.05495 --> 2.91126).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.561622 \tValidation Loss: 2.801664\n",
      "Validation loss decreased (2.91126 --> 2.80166).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.272099 \tValidation Loss: 2.718194\n",
      "Validation loss decreased (2.80166 --> 2.71819).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.038316 \tValidation Loss: 2.658206\n",
      "Validation loss decreased (2.71819 --> 2.65821).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.846433 \tValidation Loss: 2.615361\n",
      "Validation loss decreased (2.65821 --> 2.61536).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.693945 \tValidation Loss: 2.585885\n",
      "Validation loss decreased (2.61536 --> 2.58589).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.570959 \tValidation Loss: 2.569817\n",
      "Validation loss decreased (2.58589 --> 2.56982).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.475334 \tValidation Loss: 2.564960\n",
      "Validation loss decreased (2.56982 --> 2.56496).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.397197 \tValidation Loss: 2.565870\n",
      "Epoch: 17 \tTraining Loss: 0.337094 \tValidation Loss: 2.575276\n",
      "Epoch: 18 \tTraining Loss: 0.288373 \tValidation Loss: 2.589076\n",
      "Epoch: 19 \tTraining Loss: 0.252244 \tValidation Loss: 2.608595\n",
      "Epoch: 20 \tTraining Loss: 0.221387 \tValidation Loss: 2.622134\n",
      "Epoch: 1 \tTraining Loss: 6.230023 \tValidation Loss: 4.801328\n",
      "Validation loss decreased (inf --> 4.80133).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.446004 \tValidation Loss: 4.566090\n",
      "Validation loss decreased (4.80133 --> 4.56609).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.943981 \tValidation Loss: 4.239582\n",
      "Validation loss decreased (4.56609 --> 4.23958).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.259483 \tValidation Loss: 3.875578\n",
      "Validation loss decreased (4.23958 --> 3.87558).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.531045 \tValidation Loss: 3.560562\n",
      "Validation loss decreased (3.87558 --> 3.56056).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.880383 \tValidation Loss: 3.318946\n",
      "Validation loss decreased (3.56056 --> 3.31895).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.338159 \tValidation Loss: 3.132658\n",
      "Validation loss decreased (3.31895 --> 3.13266).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.896842 \tValidation Loss: 2.988254\n",
      "Validation loss decreased (3.13266 --> 2.98825).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.544788 \tValidation Loss: 2.874327\n",
      "Validation loss decreased (2.98825 --> 2.87433).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.260597 \tValidation Loss: 2.787489\n",
      "Validation loss decreased (2.87433 --> 2.78749).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.027968 \tValidation Loss: 2.722000\n",
      "Validation loss decreased (2.78749 --> 2.72200).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.839246 \tValidation Loss: 2.674425\n",
      "Validation loss decreased (2.72200 --> 2.67443).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.688611 \tValidation Loss: 2.645411\n",
      "Validation loss decreased (2.67443 --> 2.64541).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.566943 \tValidation Loss: 2.630634\n",
      "Validation loss decreased (2.64541 --> 2.63063).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.470808 \tValidation Loss: 2.625053\n",
      "Validation loss decreased (2.63063 --> 2.62505).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.394501 \tValidation Loss: 2.625952\n",
      "Epoch: 17 \tTraining Loss: 0.336601 \tValidation Loss: 2.635422\n",
      "Epoch: 18 \tTraining Loss: 0.290510 \tValidation Loss: 2.651654\n",
      "Epoch: 19 \tTraining Loss: 0.252511 \tValidation Loss: 2.666872\n",
      "Epoch: 20 \tTraining Loss: 0.224191 \tValidation Loss: 2.684004\n",
      "Epoch: 1 \tTraining Loss: 6.244276 \tValidation Loss: 4.750981\n",
      "Validation loss decreased (inf --> 4.75098).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.463092 \tValidation Loss: 4.520528\n",
      "Validation loss decreased (4.75098 --> 4.52053).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.963834 \tValidation Loss: 4.195526\n",
      "Validation loss decreased (4.52053 --> 4.19553).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.277556 \tValidation Loss: 3.824916\n",
      "Validation loss decreased (4.19553 --> 3.82492).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.548538 \tValidation Loss: 3.500203\n",
      "Validation loss decreased (3.82492 --> 3.50020).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.892790 \tValidation Loss: 3.243069\n",
      "Validation loss decreased (3.50020 --> 3.24307).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.350907 \tValidation Loss: 3.045013\n",
      "Validation loss decreased (3.24307 --> 3.04501).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.907181 \tValidation Loss: 2.893871\n",
      "Validation loss decreased (3.04501 --> 2.89387).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.554137 \tValidation Loss: 2.775872\n",
      "Validation loss decreased (2.89387 --> 2.77587).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.262637 \tValidation Loss: 2.683468\n",
      "Validation loss decreased (2.77587 --> 2.68347).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.027091 \tValidation Loss: 2.614927\n",
      "Validation loss decreased (2.68347 --> 2.61493).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.838308 \tValidation Loss: 2.569685\n",
      "Validation loss decreased (2.61493 --> 2.56968).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.686075 \tValidation Loss: 2.541234\n",
      "Validation loss decreased (2.56968 --> 2.54123).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.569728 \tValidation Loss: 2.524164\n",
      "Validation loss decreased (2.54123 --> 2.52416).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.468372 \tValidation Loss: 2.519876\n",
      "Validation loss decreased (2.52416 --> 2.51988).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.395661 \tValidation Loss: 2.518936\n",
      "Validation loss decreased (2.51988 --> 2.51894).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.334708 \tValidation Loss: 2.526379\n",
      "Epoch: 18 \tTraining Loss: 0.288667 \tValidation Loss: 2.538857\n",
      "Epoch: 19 \tTraining Loss: 0.251191 \tValidation Loss: 2.554217\n",
      "Epoch: 20 \tTraining Loss: 0.221783 \tValidation Loss: 2.567908\n",
      "Epoch: 1 \tTraining Loss: 6.238195 \tValidation Loss: 4.774553\n",
      "Validation loss decreased (inf --> 4.77455).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.457557 \tValidation Loss: 4.540404\n",
      "Validation loss decreased (4.77455 --> 4.54040).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.960200 \tValidation Loss: 4.211423\n",
      "Validation loss decreased (4.54040 --> 4.21142).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.276794 \tValidation Loss: 3.845757\n",
      "Validation loss decreased (4.21142 --> 3.84576).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.544485 \tValidation Loss: 3.532269\n",
      "Validation loss decreased (3.84576 --> 3.53227).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.894299 \tValidation Loss: 3.281717\n",
      "Validation loss decreased (3.53227 --> 3.28172).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.352256 \tValidation Loss: 3.083094\n",
      "Validation loss decreased (3.28172 --> 3.08309).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.913790 \tValidation Loss: 2.928249\n",
      "Validation loss decreased (3.08309 --> 2.92825).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.559580 \tValidation Loss: 2.802389\n",
      "Validation loss decreased (2.92825 --> 2.80239).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.271202 \tValidation Loss: 2.706266\n",
      "Validation loss decreased (2.80239 --> 2.70627).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.033728 \tValidation Loss: 2.635090\n",
      "Validation loss decreased (2.70627 --> 2.63509).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.844121 \tValidation Loss: 2.585572\n",
      "Validation loss decreased (2.63509 --> 2.58557).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.692823 \tValidation Loss: 2.552244\n",
      "Validation loss decreased (2.58557 --> 2.55224).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.570904 \tValidation Loss: 2.534450\n",
      "Validation loss decreased (2.55224 --> 2.53445).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 \tTraining Loss: 0.472001 \tValidation Loss: 2.528311\n",
      "Validation loss decreased (2.53445 --> 2.52831).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.393432 \tValidation Loss: 2.530267\n",
      "Epoch: 17 \tTraining Loss: 0.336739 \tValidation Loss: 2.535662\n",
      "Epoch: 18 \tTraining Loss: 0.289403 \tValidation Loss: 2.546236\n",
      "Epoch: 19 \tTraining Loss: 0.249141 \tValidation Loss: 2.562193\n",
      "Epoch: 20 \tTraining Loss: 0.220288 \tValidation Loss: 2.578575\n",
      "Epoch: 1 \tTraining Loss: 6.235315 \tValidation Loss: 4.774587\n",
      "Validation loss decreased (inf --> 4.77459).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.465336 \tValidation Loss: 4.543275\n",
      "Validation loss decreased (4.77459 --> 4.54328).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.971808 \tValidation Loss: 4.207039\n",
      "Validation loss decreased (4.54328 --> 4.20704).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.286212 \tValidation Loss: 3.835123\n",
      "Validation loss decreased (4.20704 --> 3.83512).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.548774 \tValidation Loss: 3.514679\n",
      "Validation loss decreased (3.83512 --> 3.51468).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.892862 \tValidation Loss: 3.259430\n",
      "Validation loss decreased (3.51468 --> 3.25943).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.352616 \tValidation Loss: 3.061124\n",
      "Validation loss decreased (3.25943 --> 3.06112).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.911923 \tValidation Loss: 2.901372\n",
      "Validation loss decreased (3.06112 --> 2.90137).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.552380 \tValidation Loss: 2.777522\n",
      "Validation loss decreased (2.90137 --> 2.77752).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.265722 \tValidation Loss: 2.681985\n",
      "Validation loss decreased (2.77752 --> 2.68198).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.027426 \tValidation Loss: 2.612302\n",
      "Validation loss decreased (2.68198 --> 2.61230).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.840456 \tValidation Loss: 2.562962\n",
      "Validation loss decreased (2.61230 --> 2.56296).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.687497 \tValidation Loss: 2.533157\n",
      "Validation loss decreased (2.56296 --> 2.53316).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.566146 \tValidation Loss: 2.518182\n",
      "Validation loss decreased (2.53316 --> 2.51818).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.468646 \tValidation Loss: 2.513931\n",
      "Validation loss decreased (2.51818 --> 2.51393).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.396113 \tValidation Loss: 2.516118\n",
      "Epoch: 17 \tTraining Loss: 0.335510 \tValidation Loss: 2.524112\n",
      "Epoch: 18 \tTraining Loss: 0.288154 \tValidation Loss: 2.536725\n",
      "Epoch: 19 \tTraining Loss: 0.251706 \tValidation Loss: 2.552917\n",
      "Epoch: 20 \tTraining Loss: 0.220809 \tValidation Loss: 2.569847\n",
      "Epoch: 1 \tTraining Loss: 6.244595 \tValidation Loss: 4.731617\n",
      "Validation loss decreased (inf --> 4.73162).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.463997 \tValidation Loss: 4.500720\n",
      "Validation loss decreased (4.73162 --> 4.50072).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.966443 \tValidation Loss: 4.175717\n",
      "Validation loss decreased (4.50072 --> 4.17572).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.282073 \tValidation Loss: 3.808868\n",
      "Validation loss decreased (4.17572 --> 3.80887).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.546718 \tValidation Loss: 3.500187\n",
      "Validation loss decreased (3.80887 --> 3.50019).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.887159 \tValidation Loss: 3.255353\n",
      "Validation loss decreased (3.50019 --> 3.25535).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.340280 \tValidation Loss: 3.061683\n",
      "Validation loss decreased (3.25535 --> 3.06168).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.901746 \tValidation Loss: 2.914943\n",
      "Validation loss decreased (3.06168 --> 2.91494).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.547321 \tValidation Loss: 2.806815\n",
      "Validation loss decreased (2.91494 --> 2.80682).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.257459 \tValidation Loss: 2.723928\n",
      "Validation loss decreased (2.80682 --> 2.72393).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.026886 \tValidation Loss: 2.664401\n",
      "Validation loss decreased (2.72393 --> 2.66440).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.838990 \tValidation Loss: 2.621502\n",
      "Validation loss decreased (2.66440 --> 2.62150).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.685883 \tValidation Loss: 2.594670\n",
      "Validation loss decreased (2.62150 --> 2.59467).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.570924 \tValidation Loss: 2.582251\n",
      "Validation loss decreased (2.59467 --> 2.58225).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.473662 \tValidation Loss: 2.575792\n",
      "Validation loss decreased (2.58225 --> 2.57579).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.397700 \tValidation Loss: 2.581546\n",
      "Epoch: 17 \tTraining Loss: 0.337490 \tValidation Loss: 2.590896\n",
      "Epoch: 18 \tTraining Loss: 0.289570 \tValidation Loss: 2.603132\n",
      "Epoch: 19 \tTraining Loss: 0.251917 \tValidation Loss: 2.617646\n",
      "Epoch: 20 \tTraining Loss: 0.219859 \tValidation Loss: 2.635853\n",
      "Epoch: 1 \tTraining Loss: 6.239065 \tValidation Loss: 4.752243\n",
      "Validation loss decreased (inf --> 4.75224).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.454173 \tValidation Loss: 4.509636\n",
      "Validation loss decreased (4.75224 --> 4.50964).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.945913 \tValidation Loss: 4.168579\n",
      "Validation loss decreased (4.50964 --> 4.16858).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.255745 \tValidation Loss: 3.797512\n",
      "Validation loss decreased (4.16858 --> 3.79751).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.528102 \tValidation Loss: 3.480313\n",
      "Validation loss decreased (3.79751 --> 3.48031).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.882298 \tValidation Loss: 3.230807\n",
      "Validation loss decreased (3.48031 --> 3.23081).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.339671 \tValidation Loss: 3.040334\n",
      "Validation loss decreased (3.23081 --> 3.04033).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.900103 \tValidation Loss: 2.894960\n",
      "Validation loss decreased (3.04033 --> 2.89496).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.541868 \tValidation Loss: 2.785722\n",
      "Validation loss decreased (2.89496 --> 2.78572).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.254071 \tValidation Loss: 2.702679\n",
      "Validation loss decreased (2.78572 --> 2.70268).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.019763 \tValidation Loss: 2.638660\n",
      "Validation loss decreased (2.70268 --> 2.63866).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.833721 \tValidation Loss: 2.595836\n",
      "Validation loss decreased (2.63866 --> 2.59584).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.684859 \tValidation Loss: 2.567190\n",
      "Validation loss decreased (2.59584 --> 2.56719).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.560275 \tValidation Loss: 2.548937\n",
      "Validation loss decreased (2.56719 --> 2.54894).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.466855 \tValidation Loss: 2.543708\n",
      "Validation loss decreased (2.54894 --> 2.54371).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.391681 \tValidation Loss: 2.544618\n",
      "Epoch: 17 \tTraining Loss: 0.331782 \tValidation Loss: 2.548341\n",
      "Epoch: 18 \tTraining Loss: 0.284760 \tValidation Loss: 2.559786\n",
      "Epoch: 19 \tTraining Loss: 0.247778 \tValidation Loss: 2.572727\n",
      "Epoch: 20 \tTraining Loss: 0.218063 \tValidation Loss: 2.586970\n",
      "Epoch: 1 \tTraining Loss: 6.233404 \tValidation Loss: 4.776795\n",
      "Validation loss decreased (inf --> 4.77679).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.457705 \tValidation Loss: 4.540098\n",
      "Validation loss decreased (4.77679 --> 4.54010).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.959288 \tValidation Loss: 4.203139\n",
      "Validation loss decreased (4.54010 --> 4.20314).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.270594 \tValidation Loss: 3.823042\n",
      "Validation loss decreased (4.20314 --> 3.82304).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.534218 \tValidation Loss: 3.492005\n",
      "Validation loss decreased (3.82304 --> 3.49200).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.875687 \tValidation Loss: 3.234502\n",
      "Validation loss decreased (3.49200 --> 3.23450).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.329368 \tValidation Loss: 3.042377\n",
      "Validation loss decreased (3.23450 --> 3.04238).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.890358 \tValidation Loss: 2.896835\n",
      "Validation loss decreased (3.04238 --> 2.89683).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.533150 \tValidation Loss: 2.785874\n",
      "Validation loss decreased (2.89683 --> 2.78587).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 \tTraining Loss: 1.251527 \tValidation Loss: 2.702392\n",
      "Validation loss decreased (2.78587 --> 2.70239).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.018720 \tValidation Loss: 2.639157\n",
      "Validation loss decreased (2.70239 --> 2.63916).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.833237 \tValidation Loss: 2.595704\n",
      "Validation loss decreased (2.63916 --> 2.59570).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.681925 \tValidation Loss: 2.566721\n",
      "Validation loss decreased (2.59570 --> 2.56672).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.559491 \tValidation Loss: 2.551192\n",
      "Validation loss decreased (2.56672 --> 2.55119).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.465969 \tValidation Loss: 2.542743\n",
      "Validation loss decreased (2.55119 --> 2.54274).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.389907 \tValidation Loss: 2.545693\n",
      "Epoch: 17 \tTraining Loss: 0.329732 \tValidation Loss: 2.550445\n",
      "Epoch: 18 \tTraining Loss: 0.284350 \tValidation Loss: 2.560881\n",
      "Epoch: 19 \tTraining Loss: 0.247415 \tValidation Loss: 2.573608\n",
      "Epoch: 20 \tTraining Loss: 0.217872 \tValidation Loss: 2.590142\n",
      "Epoch: 1 \tTraining Loss: 6.239352 \tValidation Loss: 4.750036\n",
      "Validation loss decreased (inf --> 4.75004).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.453492 \tValidation Loss: 4.521444\n",
      "Validation loss decreased (4.75004 --> 4.52144).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.944716 \tValidation Loss: 4.195695\n",
      "Validation loss decreased (4.52144 --> 4.19570).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.252326 \tValidation Loss: 3.831030\n",
      "Validation loss decreased (4.19570 --> 3.83103).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.519870 \tValidation Loss: 3.525626\n",
      "Validation loss decreased (3.83103 --> 3.52563).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.863465 \tValidation Loss: 3.288683\n",
      "Validation loss decreased (3.52563 --> 3.28868).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.321336 \tValidation Loss: 3.107845\n",
      "Validation loss decreased (3.28868 --> 3.10785).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.884339 \tValidation Loss: 2.967742\n",
      "Validation loss decreased (3.10785 --> 2.96774).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.533672 \tValidation Loss: 2.856868\n",
      "Validation loss decreased (2.96774 --> 2.85687).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.247315 \tValidation Loss: 2.768854\n",
      "Validation loss decreased (2.85687 --> 2.76885).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.018970 \tValidation Loss: 2.700194\n",
      "Validation loss decreased (2.76885 --> 2.70019).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.830104 \tValidation Loss: 2.651467\n",
      "Validation loss decreased (2.70019 --> 2.65147).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.679792 \tValidation Loss: 2.617752\n",
      "Validation loss decreased (2.65147 --> 2.61775).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.558056 \tValidation Loss: 2.597835\n",
      "Validation loss decreased (2.61775 --> 2.59784).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.465228 \tValidation Loss: 2.589865\n",
      "Validation loss decreased (2.59784 --> 2.58986).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.387391 \tValidation Loss: 2.587847\n",
      "Validation loss decreased (2.58986 --> 2.58785).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.329843 \tValidation Loss: 2.591927\n",
      "Epoch: 18 \tTraining Loss: 0.281948 \tValidation Loss: 2.603757\n",
      "Epoch: 19 \tTraining Loss: 0.247039 \tValidation Loss: 2.618613\n",
      "Epoch: 20 \tTraining Loss: 0.216406 \tValidation Loss: 2.631333\n",
      "Epoch: 1 \tTraining Loss: 6.227568 \tValidation Loss: 4.759654\n",
      "Validation loss decreased (inf --> 4.75965).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.456517 \tValidation Loss: 4.525343\n",
      "Validation loss decreased (4.75965 --> 4.52534).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 4.956629 \tValidation Loss: 4.203429\n",
      "Validation loss decreased (4.52534 --> 4.20343).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.270420 \tValidation Loss: 3.841951\n",
      "Validation loss decreased (4.20343 --> 3.84195).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.541377 \tValidation Loss: 3.526479\n",
      "Validation loss decreased (3.84195 --> 3.52648).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.884717 \tValidation Loss: 3.279569\n",
      "Validation loss decreased (3.52648 --> 3.27957).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.339015 \tValidation Loss: 3.093297\n",
      "Validation loss decreased (3.27957 --> 3.09330).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.901840 \tValidation Loss: 2.946838\n",
      "Validation loss decreased (3.09330 --> 2.94684).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 1.547806 \tValidation Loss: 2.832648\n",
      "Validation loss decreased (2.94684 --> 2.83265).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 1.259215 \tValidation Loss: 2.747116\n",
      "Validation loss decreased (2.83265 --> 2.74712).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 1.028895 \tValidation Loss: 2.681453\n",
      "Validation loss decreased (2.74712 --> 2.68145).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.838409 \tValidation Loss: 2.634310\n",
      "Validation loss decreased (2.68145 --> 2.63431).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.683414 \tValidation Loss: 2.603860\n",
      "Validation loss decreased (2.63431 --> 2.60386).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.568657 \tValidation Loss: 2.585973\n",
      "Validation loss decreased (2.60386 --> 2.58597).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.470219 \tValidation Loss: 2.580400\n",
      "Validation loss decreased (2.58597 --> 2.58040).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.395312 \tValidation Loss: 2.580584\n",
      "Epoch: 17 \tTraining Loss: 0.335655 \tValidation Loss: 2.587386\n",
      "Epoch: 18 \tTraining Loss: 0.289308 \tValidation Loss: 2.596431\n",
      "Epoch: 19 \tTraining Loss: 0.251116 \tValidation Loss: 2.612483\n",
      "Epoch: 20 \tTraining Loss: 0.222423 \tValidation Loss: 2.631307\n"
     ]
    }
   ],
   "source": [
    "# Preparing the results dataframes:\n",
    "windows = list(range(3,11))\n",
    "columns = ['Predicted_top5_mean', 'Predicted_top5_std', 'Predicted_top10_mean', 'Predicted_top10_std']\n",
    "Results_Nolemmatize = pd.DataFrame(index=index, columns=columns)\n",
    "Results_lemmatize = pd.DataFrame(index=index, columns=columns)\n",
    "\n",
    "# Getting some results:\n",
    "for lemmatize in [False , True]:\n",
    "    \n",
    "    # Building the corpus\n",
    "    corpus = Corpus(meta = 'Corpus BBC '+category+' News, only verbs as target, no stopwords.')\n",
    "    import_bbc_folder(category,corpus , lemmatize = lemmatize)\n",
    "    \n",
    "    for window in windows:\n",
    "                \n",
    "        # Building the dataset:\n",
    "        sentences , verbs = Build_Dataset([category], corpus, window, one_hot=True , lemmatize=lemmatize)\n",
    "        \n",
    "        print('\\n Starting:...-> Lemmatize =',lemmatize,', window =', window , '\\n')\n",
    "        \n",
    "        lr=0.001\n",
    "        batch_size = 512\n",
    "        n_epochs = 20\n",
    "        file_name = 'CBOW_BBC_'+category+'_lemmatize='+str(lemmatize)+'_window='+str(window)+'_crossval.pt'\n",
    "        random_state = 123\n",
    "        K = 10\n",
    "        \n",
    "        # Cross validating the model:\n",
    "        training_losses, validation_losses, predicted_intop5, predicted_intop10 = K_fold_Cross_validate(K , sentences , verbs,\n",
    "                                                                                                corpus, lr,batch_size ,n_epochs,\n",
    "                                                                                                file_name, random_state)\n",
    "        \n",
    "        # Getting the prediction measures mean and standard deviation:\n",
    "        predicted_intop5_mean , predicted_intop5_std  = np.mean(predicted_intop5) , np.std(predicted_intop5)\n",
    "        predicted_intop10_mean , predicted_intop10_std  = np.mean(predicted_intop10) , np.std(predicted_intop10)\n",
    "        \n",
    "        # Adding the measures to the corresponding dataframe:\n",
    "        if lemmatize:\n",
    "            Results_lemmatize.loc[window , 'Predicted_top5_mean'] = predicted_intop5_mean\n",
    "            Results_lemmatize.loc[window , 'Predicted_top5_std'] = predicted_intop5_std\n",
    "            Results_lemmatize.loc[window , 'Predicted_top10_mean'] = predicted_intop10_mean\n",
    "            Results_lemmatize.loc[window , 'Predicted_top10_std'] = predicted_intop10_std\n",
    "        else:\n",
    "            Results_Nolemmatize.loc[window , 'Predicted_top5_mean'] = predicted_intop5_mean\n",
    "            Results_Nolemmatize.loc[window , 'Predicted_top5_std'] = predicted_intop5_std\n",
    "            Results_Nolemmatize.loc[window , 'Predicted_top10_mean'] = predicted_intop10_mean\n",
    "            Results_Nolemmatize.loc[window , 'Predicted_top10_std'] = predicted_intop10_std\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(category+'results.pkl', 'wb') as f:\n",
    "    pickle.dump((Results_lemmatize , Results_Nolemmatize),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(category+'results.pkl', 'rb') as f:\n",
    "    Results_lemmatize , Results_Nolemmatize = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_top5_mean</th>\n",
       "      <th>Predicted_top5_std</th>\n",
       "      <th>Predicted_top10_mean</th>\n",
       "      <th>Predicted_top10_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.417984</td>\n",
       "      <td>0.00915615</td>\n",
       "      <td>0.516421</td>\n",
       "      <td>0.00881875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.551839</td>\n",
       "      <td>0.00438321</td>\n",
       "      <td>0.641162</td>\n",
       "      <td>0.00580352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.629769</td>\n",
       "      <td>0.00609909</td>\n",
       "      <td>0.707308</td>\n",
       "      <td>0.00734627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.679629</td>\n",
       "      <td>0.0086755</td>\n",
       "      <td>0.742891</td>\n",
       "      <td>0.00782869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.697439</td>\n",
       "      <td>0.00781298</td>\n",
       "      <td>0.753733</td>\n",
       "      <td>0.00677959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.701172</td>\n",
       "      <td>0.00732814</td>\n",
       "      <td>0.748717</td>\n",
       "      <td>0.00737072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.697298</td>\n",
       "      <td>0.0073274</td>\n",
       "      <td>0.740104</td>\n",
       "      <td>0.00648302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.682539</td>\n",
       "      <td>0.0109571</td>\n",
       "      <td>0.72332</td>\n",
       "      <td>0.00936205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted_top5_mean Predicted_top5_std Predicted_top10_mean  \\\n",
       "3             0.417984         0.00915615             0.516421   \n",
       "4             0.551839         0.00438321             0.641162   \n",
       "5             0.629769         0.00609909             0.707308   \n",
       "6             0.679629          0.0086755             0.742891   \n",
       "7             0.697439         0.00781298             0.753733   \n",
       "8             0.701172         0.00732814             0.748717   \n",
       "9             0.697298          0.0073274             0.740104   \n",
       "10            0.682539          0.0109571              0.72332   \n",
       "\n",
       "   Predicted_top10_std  \n",
       "3           0.00881875  \n",
       "4           0.00580352  \n",
       "5           0.00734627  \n",
       "6           0.00782869  \n",
       "7           0.00677959  \n",
       "8           0.00737072  \n",
       "9           0.00648302  \n",
       "10          0.00936205  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Results_lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_top5_mean</th>\n",
       "      <th>Predicted_top5_std</th>\n",
       "      <th>Predicted_top10_mean</th>\n",
       "      <th>Predicted_top10_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.459162</td>\n",
       "      <td>0.00669556</td>\n",
       "      <td>0.54288</td>\n",
       "      <td>0.00791682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.626687</td>\n",
       "      <td>0.00801537</td>\n",
       "      <td>0.701296</td>\n",
       "      <td>0.00619978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.714684</td>\n",
       "      <td>0.00549707</td>\n",
       "      <td>0.770756</td>\n",
       "      <td>0.00541502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.758848</td>\n",
       "      <td>0.00601109</td>\n",
       "      <td>0.80168</td>\n",
       "      <td>0.00500488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.772412</td>\n",
       "      <td>0.00605626</td>\n",
       "      <td>0.806616</td>\n",
       "      <td>0.00602434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.773465</td>\n",
       "      <td>0.00628435</td>\n",
       "      <td>0.80279</td>\n",
       "      <td>0.00630827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.75472</td>\n",
       "      <td>0.00671749</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>0.00601994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.737227</td>\n",
       "      <td>0.00771828</td>\n",
       "      <td>0.762891</td>\n",
       "      <td>0.00744651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted_top5_mean Predicted_top5_std Predicted_top10_mean  \\\n",
       "3             0.459162         0.00669556              0.54288   \n",
       "4             0.626687         0.00801537             0.701296   \n",
       "5             0.714684         0.00549707             0.770756   \n",
       "6             0.758848         0.00601109              0.80168   \n",
       "7             0.772412         0.00605626             0.806616   \n",
       "8             0.773465         0.00628435              0.80279   \n",
       "9              0.75472         0.00671749              0.78125   \n",
       "10            0.737227         0.00771828             0.762891   \n",
       "\n",
       "   Predicted_top10_std  \n",
       "3           0.00791682  \n",
       "4           0.00619978  \n",
       "5           0.00541502  \n",
       "6           0.00500488  \n",
       "7           0.00602434  \n",
       "8           0.00630827  \n",
       "9           0.00601994  \n",
       "10          0.00744651  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Results_Nolemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.bar(Results_lemmatize.index.values, Results_lemmatize['Predicted_top10_mean'].values, yerr=Results_lemmatize['Predicted_top10_std'].values, width=-0.4, align='edge', alpha=0.8, ecolor='black', capsize=4,  label='Top 10 +L')\n",
    "ax.bar(Results_lemmatize.index.values, Results_lemmatize['Predicted_top5_mean'].values, yerr=Results_lemmatize['Predicted_top5_std'].values, color='green', width=-0.4, align='edge', alpha=0.7, ecolor='black', capsize=4, label='Top 5 +L')\n",
    "ax.bar(Results_Nolemmatize.index.values, Results_Nolemmatize['Predicted_top10_mean'].values, yerr=Results_Nolemmatize['Predicted_top10_std'].values, width=0.4, align='edge', alpha=0.8, ecolor='black', capsize=4,  label='Top 10')\n",
    "ax.bar(Results_Nolemmatize.index.values, Results_Nolemmatize['Predicted_top5_mean'].values, yerr=Results_Nolemmatize['Predicted_top5_std'].values, color='purple', width=0.4, align='edge', alpha=0.7, ecolor='black', capsize=4, label='Top 5')\n",
    "ax.set_ylabel('Accuracy of Prediction')\n",
    "ax.set_xlabel('Window Size')\n",
    "ax.set_xticks(Results_lemmatize.index.values)\n",
    "ax.set_yticks(np.arange(0,1.1,0.1))\n",
    "ax.yaxis.grid(True)\n",
    "ax.legend()\n",
    "plt.savefig(category+'-bars.pdf', dpi=500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking a look at the predicted probabilities of the best setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 6.609850 \tValidation Loss: 5.467921\n",
      "Validation loss decreased (inf --> 5.46792).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 5.853655 \tValidation Loss: 5.089944\n",
      "Validation loss decreased (5.46792 --> 5.08994).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 5.085706 \tValidation Loss: 4.496530\n",
      "Validation loss decreased (5.08994 --> 4.49653).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 4.030479 \tValidation Loss: 3.860336\n",
      "Validation loss decreased (4.49653 --> 3.86034).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 3.035423 \tValidation Loss: 3.354807\n",
      "Validation loss decreased (3.86034 --> 3.35481).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.261018 \tValidation Loss: 2.981675\n",
      "Validation loss decreased (3.35481 --> 2.98168).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.690953 \tValidation Loss: 2.719664\n",
      "Validation loss decreased (2.98168 --> 2.71966).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.287551 \tValidation Loss: 2.534494\n",
      "Validation loss decreased (2.71966 --> 2.53449).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 0.994523 \tValidation Loss: 2.402049\n",
      "Validation loss decreased (2.53449 --> 2.40205).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.776709 \tValidation Loss: 2.308216\n",
      "Validation loss decreased (2.40205 --> 2.30822).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.614937 \tValidation Loss: 2.244871\n",
      "Validation loss decreased (2.30822 --> 2.24487).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.494022 \tValidation Loss: 2.201673\n",
      "Validation loss decreased (2.24487 --> 2.20167).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.403974 \tValidation Loss: 2.174405\n",
      "Validation loss decreased (2.20167 --> 2.17440).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.333394 \tValidation Loss: 2.162893\n",
      "Validation loss decreased (2.17440 --> 2.16289).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.281748 \tValidation Loss: 2.161633\n",
      "Validation loss decreased (2.16289 --> 2.16163).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.243914 \tValidation Loss: 2.165485\n",
      "Epoch: 17 \tTraining Loss: 0.215505 \tValidation Loss: 2.173019\n",
      "Epoch: 18 \tTraining Loss: 0.190763 \tValidation Loss: 2.184424\n",
      "Epoch: 19 \tTraining Loss: 0.173096 \tValidation Loss: 2.195496\n",
      "Epoch: 20 \tTraining Loss: 0.158428 \tValidation Loss: 2.206876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize = False\n",
    "window = 7\n",
    "\n",
    "# Building the corpus\n",
    "corpus = Corpus(meta = 'Corpus BBC '+category+' News, only verbs as target, no stopwords.')\n",
    "import_bbc_folder(category,corpus , lemmatize = lemmatize)\n",
    "\n",
    "# Building the dataset\n",
    "sentences , verbs = Build_Dataset([category], corpus, window, one_hot=True , lemmatize=lemmatize)\n",
    "\n",
    "# Getting the train_valid_test data:\n",
    "x_train, x_test, y_train, y_test = train_test_split(sentences, verbs, test_size=0.1, random_state=123)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.1, random_state=123)\n",
    "\n",
    "# Building the model\n",
    "vocab_size = len(corpus.get_vocabs_to_learn())\n",
    "verbs_size = len(corpus.get_verbs_to_learn())\n",
    "hidden_dim = 500\n",
    "\n",
    "model = CBOW(vocab_size, hidden_dim, verbs_size)\n",
    "model.cuda()\n",
    "\n",
    "# Training the model\n",
    "lr=0.001\n",
    "batch_size = 512\n",
    "n_epochs = 20\n",
    "file_name = 'CBOW_BBC'+category+'_window='+str(window)+'_forevaluation.pt'\n",
    "\n",
    "train_losses, valid_losses = Train_model(model, lr, batch_size, n_epochs, file_name, x_train, y_train, x_valid, y_valid)\n",
    "\n",
    "# Loading the best model parameters\n",
    "model.load_state_dict(torch.load(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1dc29772d48>"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label = 'Training loss')\n",
    "plt.plot(valid_losses, label = 'Validation loss')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking into a sample of predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "getbatch = iter(get_batch(x_test, y_test , 16))\n",
    "sentences, verbs = next(getbatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "output = model(sentences.cuda().float())\n",
    "ps = torch.exp(output)\n",
    "top_p, top_class = ps.topk(10, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "told\n",
      "\ttold\tsaid\tcontacted\treported\twarning\twrote\tmade\tconsider\tinvestigating\treceived\t\n",
      "handheld\n",
      "\thandheld\tlooks\tuse\tdiverting\tappeal\tship\toffered\tlook\tcarry\tfeatures\t\n",
      "sort\n",
      "\tsort\twork\tneeds\tmake\tpublished\treport\tbrings\tdone\tconsidered\tdiscover\t\n",
      "ensure\n",
      "\turged\tupdate\tdespatch\tcaught\tinfected\twanted\tcombat\tmentioned\tsent\tfiltering\t\n",
      "said\n",
      "\ttalking\tthink\tbecome\tsaid\tthinking\trealise\tlive\tpoint\tplay\ttaking\t\n",
      "helps\n",
      "\thelps\tequipped\tkeep\tmobile\tlike\teven\tmultimedia\tused\tseemed\ttransferred\t\n",
      "came\n",
      "\tcame\tsaid\tvideo\tbroadband\tgoing\tput\tget\taccording\tthought\tbuying\t\n",
      "phones\n",
      "\tgo\ttake\trun\tmobile\tback\tgiven\tcarry\twant\tsay\tset\t\n",
      "reading\n",
      "\treading\tlearning\tbroadcast\tmade\tbelieves\twebsite\tback\tonline\trun\ttext\t\n",
      "end\n",
      "\tend\tshipped\tsaid\tlike\tmeant\ttrying\thold\ttravel\tlimited\tcompared\t\n",
      "mobile\n",
      "\tmobile\trevolutionised\tsaid\tmessaging\tbecome\tevolved\tcreated\tchoosing\tpoint\tbelieves\t\n",
      "based\n",
      "\tbased\tuses\tcreated\twork\taddress\tassociated\tremains\tlaunch\tinstalled\tsaid\t\n",
      "gives\n",
      "\tgives\tshut\ttend\tweb\ttalk\tstarted\tlets\twebsite\tmaintaining\tuse\t\n",
      "released\n",
      "\tcarry\treleased\tused\tmeans\trival\tworking\tgot\tclaim\trelease\taffected\t\n",
      "picked\n",
      "\tpicked\tmade\tsaid\trival\ttest\trun\twork\tdecided\teven\tsays\t\n",
      "add\n",
      "\tset\tvideo\tdownload\tsaid\twatch\tdevelops\tmeans\tlike\tplay\tinclude\t\n"
     ]
    }
   ],
   "source": [
    "for clas, t in zip(top_class, verbs):\n",
    "    print(corpus.get_verb_from_index(t.item()) , ': ')\n",
    "    print('\\t' ,  end='' )\n",
    "    for val in clas:\n",
    "        print(corpus.get_verb_from_index(val.item()), end='\\t' )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['news', 'told', 'bbc', 'head', 'paul', 'goosens']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "sent = np.where(np.array(sentences[i]) != 0)[0]\n",
    "corpus.get_vocab_from_index(sent.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = top_p[i].tolist()\n",
    "vrbs = corpus.get_verb_from_index(top_class[i].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa0AAAEGCAYAAADWjcoaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXhU9dn/8fdH1rCL9XHFpiCiggiy+italgRBUEFpFa0FN8SWKlrU6mOtS0UtVarVahEtltaVp1ZBFEE2AVkCCsEFrApFRAUpewIE7t8f52QcQpbJMlu4X9eVK+ecOcvnzMDcOdv3KzPDOeecSweHJTuAc845FysvWs4559KGFy3nnHNpw4uWc865tOFFyznnXNqomewA6axJkyZ24oknJjsGO3fupH79+od8hlTJkQoZUiVHKmRIlRypkCFVcixdunSTmR1ZoYXNzH8q+HPSSSdZKpg1a1ayI6REBrPUyJEKGcxSI0cqZDBLjRypkMEsNXIAOVbB710/Peiccy5teNFyzjmXNrxoOeecSxtetJxzzqUNL1rOOefSht/yniRmRn5+Pnv37q30unbu3Mm2bduqIFV6Z0iVHKmQIVVypEKGVMlRUoaaNWtSt25dDjvMjyFi4UUrCQoKCvjggw/YuXMnNWrUqPT6vvzySz766KMqSJbeGVIlRypkSJUcqZAhVXKUlGHfvn3Url2bNm3aULdu3SQkSy9etBJs//79fPDBB+zfv5/MzMwqWec333xDs2bNqmRd6ZwhVXKkQoZUyZEKGVIlR2kZNm/eTG5uLu3ataNWrVoJTpZe/Hi0EvL27iv/Mnl57Ny5k6OOOioOiZxz6ahp06aYGTt27Eh2lJTnRSvB9u7dWyWnBJ1z1UuNGjXYs2dPsmOkPC9aSSDpgPGWLVtW+TbWrVvHK6+8EtO8zZo1Izs7m6+++gqALl26VHme0qxbt45BgwaVOV9hrlj3bcGCBfzsZz8rcV2bN28+YL2xbrtnz55lrjMWVbXdyqroe1GVoj+rF198kYceeqjM+UeOHFnlOeLp6quvBmDNmjVkZ2fH5f/9ocCLVjVVnqJVt25dpk+fztFHHx3nVFWjPPvmXKrJzMxk+vTpyY6RtrxopZAFCxYwaNAgrrnmGs4++2xGjBhB0LZk8NftfffdR79+/ejXrx+ff/45ACNHjmT+/PmRdRT+9TZ69GgWL15MdnY248aNK1eOI444AgiKw49+9CNuvvlmevToweDBg8nLywOCvxYvu+wy+vTpw8CBA/niiy/Yt28fZ555JmbG1q1bOf7441m4cCEAAwcO5PPPP+fdd98lOzub7OxsevfuzY4dOzjssMNo0qRJzLmK7lt+fj433ngjvXr14oYbbjjg/Si0efNmBg8eTO/evbnlllsi72v0emPZNgR3f95www1kZWVxzTXXRN4TgCeeeIJf/epXB3xGGzdu5KqrriIrK4usrCyWLFlSoe3u27cvps/i3//+NwCLFy+mf//+9O7dm4svvpiNGzdW6Xuxbt06zj777GLfi7Fjx3LuuecyYsSIA7YxaNAgli9fHslR3FFb3bp1y2yFvFatWjRq1AiAb7/9lksuuYRzzjmHW265hc6dO0eOHP/yl7/Qs2dPRowYwVNPPRVZvnB6z549I9N37drF5ZdfTlZWFj179uTVV18FYMWKFVx00UX06dOHSy+9lK+//jqyL4X/J7t168aiRYsAWLVqFf369SM7O5usrCw+++wzgEheVznVtmhJmiBpUDg8XtKpyc4Ui5UrV3L33Xcze/Zs1q5dG/mCA2jQoAGvv/46Q4cO5be//W2p67n99tvp3Lkz06dPZ9iwYXz11VdcfvnlMWWYOnVqZPjzzz9nyJAhzJo1i0aNGkVeu+WWW7j33nt58803+c1vfsMTTzxBjRo1aN68OatXr2bx4sW0bduWRYsWsXv3bjZs2MAPfvADnnzySUaPHs306dN55ZVXqFu3Lscddxzjx4+POVfRfZswYQIAb7/9NjfffDMjR44kPz//gGXHjh1L586deeutt+jduzfr168vdn9jeU8+/fRTfvrTnzJjxgwaNmzIs88+G3mtQYMGPPTQQwd8Rr/5zW/o2rUrM2bMYNq0abRq1apC2431s7jtttsAOPXUU5k8eTJvvfUWF1xwAX/+858T9l4MHTqUqVOn8thjj5GXl1euI4sLLriA4cOHlzpPp06duOeeewB4+OGH+eEPf8i0adPo27dvZH9WrFjBSy+9xJQpUxgzZgzPPfccK1euPGD65MmTI9NnzZrF0UcfzYwZM5g5cyY9evRg79693HHHHYwbN44333yTiy++mAcffDCSo6CggNdff527776bhx9+GICJEydy1VVXMX36dKZOncoxxxwTyekq75C45d3Mrk52hli1a9eOY489FoDWrVuzbt06OnfuDMCAAQMiv++6665yrffoo49m4sSJ5c7TrFkz2rRpA0Dbtm1Zt24dO3fuZOnSpVx77bWR+QofmuzcuTMLFy5k3bp1jBgxgueee44zzzyT008/HQi+bO6++24GDhxI3759I/taGUuWLOGKK64A4Pjjj+f444+P/HVbaOHChZHCmJWVFdORXUmOPfZYOnXqBMCFF17IM888E/mSHTBgAJs2bTrgM5o/fz6PPPIIEFxsr+hf3LF+FoUX8zdt2sSll17KN998w549ezjhhBOAxLwXCxYs4IknnmDz5s3s3r2bVq1a0bt37wpvpzSLFy/m6aefBqBHjx6R/Vm8eDF9+vShXr16ZGRk0LdvXxYtWoSZRaYDkendu3fn3nvv5b777iMrK4suXbrw8ccfs2rVKi655BIgeGTlf/7nfyLbPvfcc4Hg8/jiiy8A6NChA48++igbNmygb9++NG/ePC77fahKq6Il6SbgynB0PPAv4A1gHvD/gPXABWaWV2S52cAoM8uRtAN4BOgP5IXzfy3pSOBJ4IRwsZFmdvB5pjirXbt2ZLhGjRoUFBRExqNv4CgcrlmzZuTUi5lVSQsb0erUqXNAnvz8fPbv30+jRo0O+Ot56dKlQHAac+LEiXz99deMGjWKJ554ggULFtC1a1cARowYQa9evZg5cybnnXceL774IpXtSDP69FZpit4AU1FF11Pc51KV2ysU62dRaNy4cfzqV7+id+/eLFiw4IC/9OP5XuTn53P77bczdepUvvrqK2bPns3u3bsjuffv3w9w0NFwRZX0+Zd3eosWLXjjjTeYOXMm999/Pz/60Y/o06cPJ510EpMnTy52mcL/r9H/VwcOHEj79u15++23ueyyyxgzZgzdunUr7265EqTN6UFJHYArgC5AV+Aa4HCgJfC4mbUGtgAXlbGq+sBCMzsdmBuuB4JCNtbMOoXrKPZ8laRhknIk5exIcLMwr732WuR3hw4dgODIovAaxrRp0yJFq0GDBuzcuTMuORo2bEizZs0i/5HNLHL9pn379uTk5CCJunXr0rp1a/7+979HjhbXrFnDKaecwi9+8QtOP/30SPZCGzZs4Cc/+Ump2y+6b126dIncmLF+/XrWr19PixYtDlima9eu/POf/wRg5syZbNmypdh1n3322WXu//r168nJyQHg1VdfjRxpQPGfUbdu3fjb3/4GBNeltm/fXqHtFqe4z+KDDz4AgmaDCm+uefnllyPLxPu9KCxQTZs2JS8vj9dffz0yf7NmzVixYgXAAdNL8sYbb3D//feXOk/nzp0j+z9nzpzI/nTt2pVp06aRl5dHfn4+b775Jl26dDlg+q5duyLTv/rqKzIyMrjooosYPnw4ubm5tGjRgs2bN0f2ce/evaxatarUPGvXruX73/8+V111FdnZ2UlviaO6SZuiBXQDXjGznWa2A/gncBbwuZm9H86zFMgsYz17gCnFzJ8FPCbpfeA1oJGkhkUXNrNxZtbRzDo2SPCF1T179tC/f3+efvrpyKmnyy67jJUrV9KvXz/ee++9yCmPU045hRo1apCVlcW4cePKdU0rFo899hgvvPACWVlZ9OjRI3IRuk6dOhx77LGcccYZQFBQdu7cySmnnALA+PHj6dmzJ1lZWdStW5cePXocsN5vvvmGmjVLPwFQdN+GDBnCvn376NWrF7///e8ZO3bsAUclADfeeCOLFi3inHPOYc6cORx33HEHrXfz5s0xHbW1bNmSl19+maysLLZs2cKQIUMir+3Zs4dRo0Yd8Bndc889LFiwgF69etGnT5+DvvRi3W5Jin4Wb731FgCDBw/m2muvZeDAgTRt2jQyf7zfi8aNG3PppZeSlZXF6NGjI6eGAYYPH87EiRM5//zzY3o8YO3atTRo0KDUeW666SbmzJnDOeecw8yZMznqqKOoX78+p512Gj/+8Y/p168fo0aNYvDgwbRp0+aA6f37949M//jjj+nfvz/Z2dk8+uij3HDDDdSuXZu//OUvjB49mqysLHr37h0pYCV57bXX6NmzJ9nZ2Xz66acxPc7hYqfK/GdJJEkjgaZmdmc4fi+wERhmZm3CaaOABmZ2l6QJwBQzm1T09KCZNQjnHwT0N7OhkjYBzYqeWizNCc1PtP989u+yZ4yyZcsWVq9ezfHHH1+u5bp06cIbb7xxwJdPoaVLl0b+qq+Ili1b8sknn1R4+arIUOivf/0rxx13XIWvf1Qmx/Tp0/nPf/7DVVddVaHlK5qhqrZb2RzlzbRu3TqGDBnCzJkz45IB4Je//CV33XVXqXc17t69mxo1alCzZk1ycnK47bbbDjpdWlX/PiujaIai/+82bNjA8ccfH/fWcmbPnk337t3juo2ySFpqZh0rsmw6XdOaC0yQ9AAgYCBwOTCsitb/FjACGAMgqV3UEVyVOeywwyr1V3U8NGzYkOzsbCZOnJj0Z7UKb6hIhuzs7ENqu6VJlUx/+tOfypxn/fr1DB8+nP3791O7dm3GjBmTgGQVt2bNGq655hqOPPLIA6abmbf0HoO0KVpmtiw8elocThoP/LcKN3E98LikFQTvy1yg9PtuK6Bu3brs3buX/Pz8crXoXHj6LR6WLVsWt3W76qtZs2alHmUlSvPmzSOnRNNBcQ8XFxQUsHv3bjIyMpKUKn2kTdECMLOHgaIPO7SJev0PUcNDo4a7Rw03iBqeBEwKhzcBF1d15qJq165Nq1atWL16NY0bN66SFp137dpV7MX9REqFDKmSIxUypEqOVMiQKjlKylBQUMDWrVvJzMws8/qdS7OiVV0ceeSR1KpVi40bN1ZJA5n5+fkH3BqfDKmQIVVypEKGVMmRChlSJUdJGWrVqkXLli0POl3oiudFK0maNGlSqYc6o23cuJHWrVtXybrSOUOq5EiFDKmSIxUypEqOVMhQHfhVv0rIqOVdjDjnXCJ50XLOOZc2vGg555xLG35NK0ny8/PZtm1bldyI8c0330Qa60yWRGeoXbs2jRo1KtdjA8659OdFqxLy9u6r0HI7duwgNzeXWrVqUaNGjUo3Xpqfn8+mTZsqtY7KSmQGM2Pfvn3s3buXtm3bltn3knOu+vCilWAFBQWsXLmSpk2b0rDhQU0bVsjhhx9+QHcJyZCMDNu2bSM3N5dOnTpRo4bfFOPcocCvaSVYYc+uVVWwDmWF/VJF9xzsnKvevGgl2L59+7x9sSokiX37Knaa1jmXfvzbM8k2b95MdnY22dnZtGvXjg4dOkTGq+ImjeLk5uYya9asuKy7UIcOHdi6dWtM8y5btizSNf28efMiHUo651xR1e6alqS7gB3R7RCmsqZNm0Yaz3zooYeoX79+pOv2WFTkKCM3N5ePP/74oL6skuWMM86I9L81f/58mjZtmvRuJJxzqcmPtFLYkCFD6NOnDz169OC5554Dghs5TjnlFB588MFIx4+LFi3irLPOYuDAgdxxxx1ceeWVQNBz7ciRI+nXrx+9e/fmrbfeIi8vj7Fjx/LKK6+QnZ3NlClTStz+o48+yoQJEwC44447GDx4MBD0xzNy5Egg6Pn2vPPOY+TIkQwfPpxdu3ZFln/88ccjHe2tXbsWCHq3LewEsrBzvLlz53LllVeyZs0ann/+eZ588kmys7NZsmQJGzdu5Oqrr6Zv377069fPj8KcO8RViyMtSf8L/AxYR9Ax5FJJ7YAngXrAp8CVZvbfsEPIRUAPoAlwlZm9I6kG8ADQHagDPG5mf0n0vkT74x//yOGHH05eXh59+/bl3HPPpUGDBmzbto3TTjuNW2+9lby8PK688kqmTp3Kcccdx7XXXhtZfuzYsfTo0YM//vGPbNmyhf79+zNjxgxuvPFGPv74Y+655x4gOD334osv8uCDDx6w/a5duzJhwgSGDh1Kbm4uBQUFFBQUsHjxYrp06cKmTZt4/PHHeemll/jwww+ZN28e48eP5/rrrwegcePGvP7667zwwgvcfffdPPPMMzz88MNMmjSJI4888qDTh5mZmQwePJimTZtyzTXXAEFPt9dddx0dOnSIqdNB51z1lvZFS1IH4BKgPcH+LAOWAn8DfmlmcyTdA/wWGBkuVtPMOks6N5yeBVwFbDWzTpLqAPMlvWVmnxfZ3jDCjicPPyK+rTI/9dRTkX6CNmzYwNq1a2ndujW1a9emb9++AKxevZrjjjsu0hPygAEDmDRpEgBz5sxh1qxZPPbYY0DQw+v69esP2k706blop59+OsuXL2fr1q3Ur1+fzMxMVq5cyeLFi7nooovIyclh9erVnH/++eTl5VGzZk06d+4cWX7AgAEADBw4kNGjRwPQqVMnbrjhBvr37x/Zh9K88847fPrpp5HxrVu3kpeX5/0OOXeISvuiBZwFvGJmuwAkvQbUB5qY2ZxwnmeBl6OW+Wf4eymQGQ73BtpKGhSONwZaAgcULTMbB4wDOKH5iXHrgnju3LksWrSIyZMnk5GRwYABA9i9ezcQdCRZ+EByab0gmxlPP/00mZmZB0yPtUPJOnXqcNRRRzFp0iQ6depE8+bNmTdvHuvXr6dFixasXr2a7t2786c//Snm7szHjBnDsmXLmDFjBtnZ2cyYMaPMZV5//XVq164dU2bnXPVWXa5plbd47A5/7+O7wi2CI7N24c8PzCxp3aFu376dJk2akJGRwapVq1i+fHmx87Vq1Yr169ezfv16zIzXXnst8lr37t155plnIuMrV64EoH79+uzcuTOmHF26dOHJJ5+kS5cudO7cmQkTJnDaaacB0LFjRxYuXBi5XrVr1y4+++yzyLKTJ08G4F//+hedOnUCYO3atXTo0IFbbrmFJk2a8NVXXx2wvQYNGrBjx47IeLdu3SLX1aL3wTl3aKoORWsuMFBShqSGwHnATuC/ks4K57kcmFPSCkLTgOsk1QKQdJKkpLUP1KtXL/Ly8sjKymLs2LG0b9++2PkyMjK49tprueSSSxg4cCBHHXVU5MHlm266iby8PHr16kWPHj146KGHgKAQfPjhh/Tu3ZspU6awbNkybr311mLXX3jtqn379hxzzDHUqlWLLl26AEFnlg899BDXXXcd119/Peeff/4BRSsvL49+/foxceJE7rzzTgDuuusuevXqRa9evejWrRsnn3zyAds755xzmDJlCr1792bJkiWMHj2aJUuWkJWVRffu3SM3pDjnDk0q7fRSuoi6EWMt8AXwITCD727E+Ay4IupGjFFmliPpe0COmWVKOgz4HUHRE8ENHQPMrMSHjU5ofqL957N/lyvrli1bWLVqFc2aNSvvbpZo3rx5dOvWDTPj1ltv5eSTT47cQZgosZ4erGrr1q3j5JNPpnHjxkBwZ2P37t0TniNaKmRIlRypkCFVcqRChlTJIWmpmXWsyLLV4ZoWZnYfcF8xL3UtZt7uUcObCK9pmdl+4PbwJ25q1qxZ6nWoinjjjTe4++672bNnD23btuXSSy+t0vWnMjPzdgedO4RUi6KVTgrvetu6dWvk6KCyLrzwQu67r7iaXb1t2bIFSX4noXOHEC9aCVajRg3atm1Lbm4u27dvp2bNyn8E33777UE3NCRaojMUFBRgZrRt29aPtJw7hHjRSoJ69erRrl07tm/fTkFBQaXXt2bNGo499tgqSJY+GWrWrEmjRo38VnjnDjFetCoho1bF/8KvU6cOderUqZIcTZs25eijj66SdaVzBudc9Vcdbnl3zjl3iPCi5ZxzLm140XLOOZc2vGhVQt5e7zHXOecSyYuWc865tOFFyznnXNrwouWccy5teNFyzjmXNrxoOeecSxvVqmhJqi/pdUnLJa2UdLGkOyUtCcfHKdBC0rKo5VpKWhoOPyDpQ0krJP0heXvjnHOuqOrWjFMf4Esz6wcgqTEw3czuCccnAv3NbLKkrZLamdn7wBXABElNgYHAyWZmkpokaT+cc84Vo1odaQG5QJakByWdFXbg2EPSIkm5QE+gdTjveOAKSTWAi4HngG1APjBe0oXArqIbkDRMUo6knB3btiVin5xzzoWqVdEys9VAB4Lidb+kO4E/A4PM7DTgKaBuOPv/AX2B/sBSM/vWzAqAzuFrA4A3i9nGODPraGYdGzRqFPd9cs45951qdXpQ0rHAZjP7u6QdwNDwpU2SGgCDgEkAZpYvaRrwBHBVuHwDoJ6ZTZW0EPh3ovfBOedcyapV0QJOA8ZI2g/sBa4jOGLKBdYAS4rM/w/gQuCtcLwh8KqkuoCAGxOQ2TnnXIyqVdEys2nAtCKTc4A7SlikG/CMme0Ll99AcHrQOedcCqpWRas8JL0CtCC4OcM551waOGSLlpkNTHYG55xz5VOt7h50zjlXvXnRqoSMWjWSHcE55w4pXrScc86lDS9azjnn0oYXLeecc2mjzKIl6YeS6ofDP5X0sKTvxz9a6svbuy/ZEZxz7pASy5HWE8AuSacDtwBrgb/FNZVzzjlXjFiKVoGZGXAB8IiZPULQ3JFzzjmXULE8XLxd0m3A5cBZYVceteIbyznnnDtYLEdaFwO7gSvN7CvgOGBMXFM555xzxSizaIWF6jngcEnnAXvMLCWuaUm6XtJHkv6R7CzOOefiL5a7B68GFhN04TEIWCjpyngHi9HPgXPN7LJkB3HOORd/sZwevBlob2ZDzWwIQc/At8Y3VtkkPQk0B16T9CtJ/5K0QtJCSW3DeRpI+quk3PC1i8LpO6LWM0jShHD4x5JWSlouaW4Sdss551wpYilaXwDbo8a3A+viEyd2ZjYc+BLoAWQC75lZW+B2vrsl/zfAVjM7LXxtZhmrvRM4x8xOB84vbgZJwyTlSMrZsW1bFeyJc865WJV496Ckm8LB9cAiSa8Chbe+L05AtvLoBlwEYGYzJR0hqTGQBVxSOJOZ/beM9cwHJkh6CfhncTOY2ThgHMAJzU+0KsjunHMuRqXd8l74LNan4U+hV+MXp8JUzDQLpxdXWKKn1Y1MNBsuqQvQD3hfUjsz+7ZKkzrnnKuwEouWmd0dPpP1gJndnMBMFTEXuAy4V1J3YJOZbZP0FjACGAkg6fDwaOtrSacAq4CBhKc/JbUws0UER5bnAc0AL1rOOZciSr2mZWb7gDMSlKUy7gI6SloBPAAMCaf/juBW/ZWSlhNc/wL4NTCF4BrXhqj1jAlv2lhJUAiXJyK8c8652MTSIsb7kl4DXgZ2Fk40s2Kv+SSSmWVGjV5QzOs7+K6ARU+fBEwqZvqFVZnPOedc1YqlaDUlOEXWM2qaUcKNCs4551y8lFm0zOyKRARxzjnnyhJLixgnSXo7vM6DpLaS7oh/tNSXUatGsiM459whJZaHi58CbgP2ApjZCqKefXLOOecSJZaiVc/Mij5MXBCPMM4551xpYilamyS1IHwgV9IgDrxN3DnnnEuIWO4e/AVBs0UnS1oPfE7wIO8hL2/vvmRHcM65Q0ppbQ8eZWZfm9lnQJak+sBhZra9pGWcc865eCrt9OBySdMlXSmpkZnt9ILlnHMumUorWscBfwDOAj4J+6u6WFJGYqI555xzByqxaJnZPjObFj5c3Az4KzAA+Ny7t3fOOZcMsdw9iJntAT4EPgK2AadWdRBJmYUPMCdKdA/GRaYPkFTl++icc65ySi1akk6QdLOkZQStotcALjCz9glJd3CeRDVBMYA4FGbnnHOVU2LRkrQAeAc4ChhmZq3M7Ldm9lEc89SU9KykFZImSaonaY2kOyXNA34sqZ2kheE8r0g6PMw7W1LHcPh7ktaEw/UkvRTO/6KkRYXzha/fJ2l5uM6jJP0/4HyCbkreD59Rc845lwJKO9K6Dcg0s1FmlpOgPK2AcWbWluA05M/D6flm1s3MXgD+BtwazpML/LaMdf4c+G84/71Ah6jX6gMLzex0gv6zrjGzBcBrwM1m1s7MonttRtIwSTmScnZs21a5vXXOOVcupd2IMcfMiuuqPp7Wmdn8cPjvQLdw+EUASY2BJmY2J5z+LHB2GevsBrwAYGYrgRVRr+0hOO0JsBTILCugmY0zs45m1rFBo0Zlze6cc64KxXQjRgIVLZKF4zuLzliMAr7bn7pR01XKMnujCvM+YmshxDnnXJKkWtE6QdKZ4fBgYF70i2a2FfivpLPCSZcDhUdda/ju1N+gqMXmAT8BCO8IPC2GHNuBhuUN75xzLr5Ka8bpptIWNLOHqz4OHwFDJP0F+AR4AvhlkXmGAE9Kqgd8BhR2UvkH4CVJlwMzo+b/M/CspBXAewSnB7eWkeMF4ClJ1wODil7Xcs45lxylnQ4rPNJoBXQiuDkB4DyCmxaqlJmtofjbzDOLzPc+0LWY5T8G2kZNKuyoMh/4qZnlh3cCvg2sDZdpELX8JGBSODy/hCzOOeeSqMSiZWZ3A0h6CzijsN1BSXcBLyckXdWoB8ySVIvg+tZ14cPSzjnn0kwsNx6cQHCXXaE9xHCXXaoIi23HMmd0zjmX8mIpWhOBxZJeIbibbyDBs1KHvIxaiWqgwznnHMRQtMzsPklvELT2DnCFmb0X31jOOefcwWK95b0esM3MHgG+kPSDOGZyzjnnilVm0ZL0W+BWgmadAGoRtFbhnHPOJVQsR1oDCRqQ3QlgZl/iD94CkLd3X7IjOOfcISWWorUnbOrIACTVj28k55xzrnixFK2XwhYqmki6BpgBjI9vLOecc+5gsdw9+AdJ2QRdhbQC7jSz6XFP5sQ8xEkAABSmSURBVJxzzhVRZtGS9KCZ3QpML2aac845lzCxnB7MLmZa36oOkgyS7pGUVcz07pKmFLeMc8655CmtlffrCHr9bRG2kF6oIbAg3sESwczuTHYG55xzsSvt9OBzwBvA/cCvo6ZvN7PNcU1VCeHdjS8BxwM1gHsJrsWdB2QQFNxrzcwkTQCmmNkkSX2APwKbgGXJyO6cc650JZ4eNLOtYXchjwCbzWytma0F9krqkqiAFdAH+NLMTjezNsCbwGNm1ikczwD6Ry8gqS7wFEFhOws4uqSVSxomKUdSzo5t2+K2E8455w4WyzWtJ4AdUeM7w2mpKhfIkvSgpLPC3o57SFokKRfoCbQusszJwOdm9kn4TFqJLX6Y2Tgz62hmHRs0ahS3nXDOOXewWFp5V/hFDoCZ7ZcUy3JJYWarJXUAzgXuD/sD+wXQ0czWhf2B1S1u0QTGdM45VwGxHGl9Jul6SbXCnxsIurlPSZKOBXaZ2d+BPwBnhC9tktQAGFTMYh8DPwh7NgYYHP+kzjnnyiuWI6bhwKME3dcbQXf1w+IZqpJOA8ZI2g/sBa4DBhCcNlwDLCm6gJnlSxoGvC5pEzAPaJOwxM4552ISS4sY3wCXJCBLlTCzacC0IpNzCIpu0XmHRg2/SXBtyznnXIoq7TmtW8zs95L+RDHXe8zs+rgmc84554oo7Ujro/B3TiKCOOecc2UpsWiZ2eTw97OJi5NeMmrVSHYE55w7pJR2enAypdwGbmbnxyWRc845V4LSTg/+Ifx9IUELEYUP3A4muAvPOeecS6jSTg/OAZB0r5mdHfXSZElz457MOeecKyKWh4uPlNS8cETSD4Aj4xcpfeTt3ZfsCM45d0iJ5eHiG4HZkgpbwcgEro1bIuecc64EsTxc/Kaklnz34O3HZrY7vrGcc865g5V5elBSPeBmYISZLQdOkNS/jMWcc865KhfLNa2/AnuAM8PxL4DfxS2Rc845V4JYilYLM/s9QeOzmFkeoLimSiBJsyV1THYO55xzZYulaO2RlEH4oHHYfYdf03LOOZdwsRSt3xJ0Wd9M0j8Iuia5Ja6pyiApU9LHksZLWinpH5KyJM2X9ImkzuHPAknvhb9bhctmSHpB0gpJLwIZUevtLeldScskvRz2v+Wccy5FlFq0JImgg8QLgaHA8wQ9AM+Oe7KynQg8ArQluLPxUqAbMAq4nSD32WbWHrgTGB0udx1BJ5FtgfuADgCSvkfQfUmWmZ1B0FDwTUU3KmmYpBxJOTu2bYvj7jnnnCuq1Fvezcwk/cvMOgCvJyhTrD43s1wASR8Ab4d5cwmeJWsMPBverm9ArXC5swk6tcTMVkhaEU7vCpwKzA9qNbWBd4tu1MzGAeMATmh+YoltMzrnnKt6sTxcvFBSJzM7qMffJIu+rrY/anw/wX7dC8wys4GSMoHZUfMXV2wETDezwVWe1DnnXJWI5ZpWD4LC9Wl4HSg36ugklTUG1ofDQ6OmzwUuA5DUhuD0IsBC4IeSTgxfqyfppMREdc45F4tYjrT6xj1FfPye4PTgTcDMqOlPAH8NC+/7wGIAM9soaSjwvKQ64bx3AKsTF9k551xpSutPqy4wnOCGh1zgaTMrSFSw0pjZGqBN1PjQEl6LPlL6Tfh6HnBJCeudCXSq0rDOOeeqTGmnB58FOhIUrL7AQwlJ5JxzzpWgtNODp5rZaQCSniY8jeacc84lS2lHWnsLB1LltGCqyahVI9kRnHPukFLakdbpkgqfnhWQEY6L4BGuRnFP55xzzkUpsWiZmR9GOOecSymxPKflnHPOpQQvWpWQt3dfsiM459whxYuWc865tOFFyznnXNrwouWccy5teNFyzjmXNtKiaEnqLmlKOeZvJ+ncqPHzJf06Pumcc84lSsoXLUmxtERfVDsgUrTM7DUze6DqUjnnnEuGuBUtSZmSPpY0XtJKSf+QlCVpvqRPJHUOfxZIei/83SpcdqiklyVNBt4qst5O4fzNJdWX9IykJeG0CyTVBu4BLpb0vqSLw/U9Fi4/QdKj4fY+kzQonH6YpD9L+kDSFElTC19zzjmXGuJ9pHUi8AhBR4snA5cC3YBRwO3Ax8DZZtYeuBMYHbXsmcAQM+tZOEHS/wOeBC4ws8+A/wVmmlkngs4qxwC1wnW9aGbtzOzFYnIdE+boDxQegV0IZAKnAVeH23fOOZdCKnLqrTw+N7NcAEkfAG+bmUnKJSgQjQk6amwJGEHBKTTdzDZHjZ8CjAN6m9mX4bTewPmSRoXjdYETYsj1LzPbD3wo6ahwWjfg5XD6V5JmFbegpGHAMIDDjzgyhk0555yrKvE+0todNbw/anw/QcG8F5hlZm2A8wiKTqGdRda1AcgH2kdNE3BReETVzsxOMLOPyplLRX6XyszGmVlHM+vYoJG3Geycc4mU7BsxGgPrw+GhZcy7BegHjJbUPZw2DfilJAFIKixo24GG5cwyD7govLZ1FNC9jPmdc84lWLKL1u+B+yXNB8psVd7MviY4IntcUheCI7VawApJK8NxgFnAqYU3YsSY5f+AL4CVwF+ARcDW8uyMc865+IrbNS0zWwO0iRofWsJrJ0Ut9pvw9QnAhKj5ZwOzw+H/AK2jlrm2mG1vBjoVmTyhaI5wvEH4e7+kUWa2Q9IRBD0155ayi8455xIs3jdipJspkpoAtYF7zeyrZAdyzjn3HS9aUcyse7IzOOecK1myr2k555xzMfOiVQkZtcq8d8Q551wV8qLlnHMubXjRcs45lza8aDnnnEsbfvdgJeTt3Ufmr1+v0LJrHuhXxWmcc6768yMt55xzacOLlnPOubThRcs551za8KLlnHMubaR90ZK0RtL3Ypy3o6RHw+HuYU/Izjnn0sQhdfegmeUAOeFod2AHsCBpgZxzzpVLyhxpSbpF0vXh8FhJM8PhXpL+Lqm3pHclLZP0sqQGUYvfLGlx+HNiuNyPJa2UtFzS3HBad0lTJGUCw4Ebwz63zpJ0pKT/k7Qk/PlhQt8A55xzZUqZogXMBc4KhzsCDSTVAroR9Gt1B5BlZmcQHC3dFLXsNjPrDDwG/DGcdidwjpmdDpwfvaGwP68ngbFm1s7M3gEeCcc7ARcB44sLKWmYpBxJOTu2bavsPjvnnCuHVDo9uBToIKkhsBtYRlC8zgJeA04F5kuCoL+rd6OWfT7q99hweD4wQdJLwD9j2H4WQW/HheONJDU0s+3RM5nZOGAcwAnNT7Ty7KBzzrnKSZmiZWZ7Ja0BriC4zrQC6AG0AD4HppvZ4JIWLzpsZsMldQH6Ae9LaldGhMOAM80sr+J74ZxzLp5S6fQgBKcIR4W/3yG47vQ+sBD4YdT1qnqSTopa7uKo3++G87Qws0VmdiewCWhWZFvbgYZR428BIwpHYihyzjnnEizVitY7wDHAu2b2NZAPvGNmG4GhwPOSVhAUsZOjlqsjaRFwA3BjOG2MpFxJKwmK4PIi25oMDCy8EQO4HugoaYWkDwkKpnPOuRSSMqcHAczsbaBW1PhJUcMzgU7FLJMZDt5dZPqFxWxidviDma0G2hZ5/WKcc86lrFQ70nLOOedK5EXLOedc2kip04PpJqNWDVZ5v1jOOZcwfqTlnHMubXjRcs45lza8aDnnnEsbMvOWiCrqhOYn2mE/eSTZMfjVaQU8lJvcy5OpkCFVcqRChlTJkQoZUiVHKmSoqhxrKnktX9JSM+tYkWX9SMs551za8KLlnHMubXjRcs45lza8aDnnnEsb1bZoSWoi6edlzJMZNqhb3GuzJVXoQqFzzrn4qLZFC2gClFq0nHPOpZfk338ZPw8ALSS9D0wPp/Ul6CTyd2b2YvTMkjKAvxL0kPwRkJHArM4552JQnYvWr4E2ZtZO0kUE/WOdDnwPWCJpbpH5rwN2mVlbSW2BZcWtVNIwYBjA4UccSaO4xXfOOVdUdT49GK0b8LyZ7Qs7l5zDwX1znQ38HcDMVgAriluRmY0zs45m1rFBIy9ZzjmXSIdK0VKM83nzIM45l8Kqc9HaDjQMh+cCF0uqIelIgqOqxUXmnwtcBiCpDQf3auyccy7Jqm3RMrNvgfnhLe1nEpzuWw7MBG4xs6+KLPIE0EDSCuAWDi5qzjnnkqw634iBmV1aZNLNRV5fA7QJh/OASxKTzDnnXEVU2yMt55xz1Y8XLeecc+nDzPyngj8nnXSSpYJZs2YlO0JKZDBLjRypkMEsNXKkQgaz1MiRChnMUiMHkGMV/N71Iy3nnHNpw4uWc865tOFFyznnXNrwouWccy5teNFyzjmXNrxoOeecSxtetJxzzqUNL1rOOefShhct55xzaUPBw8muIiRtB1YlOwdBb8ybPAOQGjlSIQOkRo5UyACpkSMVMkBq5GhlZg3Lnu1g1bqV9wRYZWYdkx1CUk6yc6RChlTJkQoZUiVHKmRIlRypkCFVckjKqeiyfnrQOedc2vCi5ZxzLm140aqccckOEEqFHKmQAVIjRypkgNTIkQoZIDVypEIGSI0cFc7gN2I455xLG36k5ZxzLm140XLOOZc2vGjFQFIfSask/VvSr4t5vY6kF8PXF0nKTFKOsyUtk1QgaVCSMtwk6UNJKyS9Len7ScoxXFKupPclzZN0aqIzRM03SJJJisttxjG8F0MlbQzfi/clXZ3oDOE8Pwn/bXwg6blEZ5A0Nuo9WC1pS1VniDHHCZJmSXov/H9ybhIyfD/8/7lC0mxJx8chwzOSvpG0soTXJenRMOMKSWfEtOKKdnl8qPwANYBPgeZAbWA5cGqReX4OPBkOXwK8mKQcmUBb4G/AoCRl6AHUC4evS+J70Shq+HzgzURnCOdrCMwFFgIdk/ReDAUeq+ptlzNDS+A94PBw/H+S8XlEzf9L4JkkvRfjgOvC4VOBNUnI8DIwJBzuCUyMw3txNnAGsLKE188F3gAEdAUWxbJeP9IqW2fg32b2mZntAV4ALigyzwXAs+HwJKCXJCU6h5mtMbMVwP4q3nZ5Mswys13h6EKgyv+CizHHtqjR+kBV33EUy78LgHuB3wP5Vbz98uaIp1gyXAM8bmb/BTCzb5KQIdpg4PkqzhBrDgMahcONgS+TkOFU4O1weFYxr1eamc0FNpcyywXA3yywEGgi6Ziy1utFq2zHAeuixr8IpxU7j5kVAFuBI5KQI97Km+Eqgr+kkpJD0i8kfUpQNK5PdAZJ7YFmZjalirddrhyhi8JTMJMkNUtChpOAkyTNl7RQUp8kZACCU2PAD4CZVZwh1hx3AT+V9AUwleCoL9EZlgMXhcMDgYaSqvo7qywV+k7zolW24o6Yiv7VHss8icgRbzFnkPRToCMwJlk5zOxxM2sB3ArckcgMkg4DxgK/quLtlitHaDKQaWZtgRl8d1YgkRlqEpwi7E5wlDNeUpMEZyh0CTDJzPZV4fbLk2MwMMHMjic4RTYx/PeSyAyjgB9Jeg/4EbAeKKjCDLGo0HeaF62yfQFE/2V6PAcfzkfmkVST4JC/tMPieOWIt5gySMoC/hc438x2JytHlBeAAQnO0BBoA8yWtIbgnP1rcbgZo8z3wsy+jfocngI6JDpDOM+rZrbXzD4naGi6ZYIzFLqE+JwajDXHVcBLAGb2LlCXoBHbhGUwsy/N7EIza0/wfxUz21qFGWJRse+0qr74Vt1+CP5C/IzgdELhRc3WReb5BQfeiPFSMnJEzTuB+NyIEct70Z7gInDLJH8mLaOGzwNykvV5hPPPJj43YsTyXhwTNTwQWJiEDH2AZ8Ph7xGcFjoi0Z8H0ApYQ9iwQpI+jzeAoeHwKQRf1FWWJ8YM3wMOC4fvA+6J0/uRSck3YvTjwBsxFse0zngErW4/BIfwq8Mv4/8Np91DcCQBwV9KLwP/BhYDzZOUoxPBXy87gW+BD5KQYQbwNfB++PNakt6LR4APwgyzivsCi3eGIvPOJg5FK8b34v7wvVgevhcnJyGDgIeBD4Fc4JJkfB4E15MeiMfnUI734lRgfvh5vA/0TkKGQcAn4TzjgTpxyPA8sAHYG34vXQUMB4ZH/Zt4PMyYG+v/D2/GyTnnXNrwa1rOOefShhct55xzacOLlnPOubThRcs551za8KLlnHMubXjRci7OJO0LWxZfKellSfXKufyOcs4/obhW/iV1lPRoODxU0mPh8HBJP4uafmzUMuPj0UK+cxVVM9kBnDsE5JlZOwBJ/yB4VuXhwhfDxpVlZvFq6BgAM8sBcoqZ/mTU6FBgJWHLBGZW5d2YOFcZfqTlXGK9A5woKVPSR5L+DCwDmkkaHPYBtlLSg9ELSXpIQV9pb0s6Mpx2jaQlkpZL+r8iR3BZkt4J+43qH87fXdJBjfdKukvSqPDorCPwj/DIMCPsa6ljOF9vSe+GOV6W1CCc/oC+60PtD/F405wr5EXLuQQJ26XsS/D0PwRNCv3Ngvbf9gIPEvRt1A7oJKmwvcT6wDIzOwOYA/w2nP5PM+tkZqcDHxG0OFAok6Ah1H7Ak5LqlpXPzCYRHIldZmbtzCwvKvv3CBodzgpz5AA3SWpK0DRUawsa5P1ded4T58rLi5Zz8Zch6X2CL/r/AE+H09da0I8QBE1wzTazjRZ0b/MPgk70IOgf7cVw+O9At3C4TXg0lQtcBrSO2uZLZrbfzD4haIfu5EruQ1fC5ofCfRkCfB/YRtBX2HhJFwK7Sl6Fc5Xn17Sci7/INa1CYR+hO6MnlWN9hW2vTQAGmNlySUMJuv0oOk9J4+UlYLqZDT7oBakz0IugsegRBEeLzsWFH2k5lxoWEfRv9D1JNQj6XJoTvnYYQQOnAJcC88LhhsAGSbUIjrSi/VjSYZJaEHS7virGHNvD9Ra1EPihpBMBJNWTdFJ4XauxmU0FRhKc2nQubvxIy7kUYGYbJN1G0Aq7gKlm9mr48k6gtaSlBL1iXxxO/w1BsVtLcJ0sutisIih6RxG0qp0fHt2VZQLBNbA84MyofBvDo7nnJdUJJ99BUOReDa+ZCbixPPvtXHl5K+/OOefShp8edM45lza8aDnnnEsbXrScc86lDS9azjnn0oYXLeecc2nDi5Zzzrm04UXLOedc2vj//JKDPEbTvMUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "props = dict(boxstyle='round', facecolor='grey', alpha=0.2)\n",
    "ax.text(0.05, 0.95, 'Input: '+str(corpus.get_vocab_from_index(sent.tolist())), transform=ax.transAxes, fontsize=10, verticalalignment='top', bbox=props)\n",
    "ax.text(0.05, 0.85, 'Target: '+corpus.get_verb_from_index(verbs[i].item()), transform=ax.transAxes, fontsize=10, verticalalignment='top', bbox=props)\n",
    "ax.barh(vrbs, probs, align='center')\n",
    "plt.xlabel('Probabilities')\n",
    "plt.ylabel('Predicted Verbs')\n",
    "ax.set_xticks(np.arange(0,1.1,0.1))\n",
    "ax.xaxis.grid(True)\n",
    "plt.savefig(category+'-probs.pdf', dpi=500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
